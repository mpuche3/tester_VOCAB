[
    {
        "Question": "Imagine you're teaching your smartphone to recognize photos of cats. You show it lots of labeled cat and non-cat pictures so it learns what makes a cat a cat. What machine learning approach are you using?",
        "RightAnswer": "Supervised Learning",
        "WrongAnswers": [
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Deep Learning",
            "Semi-supervised Learning",
            "Transfer Learning"
        ],
        "Explanation": "Supervised learning is like teaching by example. You give your model plenty of examples that have already been labeled or identified, and the model learns to recognize patterns based on these examples. Think of it as providing answers along with the questions, allowing your model to gradually understand the difference between, say, cats and dogs, or spam emails versus legitimate ones. It's called 'supervised' because you're essentially supervising the learning process by clearly defining right and wrong answers from the start.",
        "trans_Question": "ɪmǽdʒɪn júwr tíjtʃɪŋ jɔr smɑ́rtfòwn tə rɛ́kəɡnàjz fówtòwz əv kǽts. juw ʃów ɪt lɒ́ts əv léjbəld kǽt ənd nɒn-kǽt pɪ́ktʃərz sow ɪt lɜ́rnz wɒt méjks ə kǽt ə kǽt. wɒt məʃíjn lɜ́rnɪŋ əprówtʃ ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "súwpərvàjzd lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ"
        ],
        "trans_Explanation": "súwpərvàjzd lɜ́rnɪŋ ɪz lájk tíjtʃɪŋ baj əɡzǽmpəl. juw ɡɪ́v jɔr mɒ́dəl plɛ́ntij əv əɡzǽmpəlz ðət həv ɔ̀lrɛ́dij bɪn léjbəld ɔr ajdɛ́ntɪfàjd, ənd ðə mɒ́dəl lɜ́rnz tə rɛ́kəɡnàjz pǽtərnz béjst ɒn ðijz əɡzǽmpəlz. θɪ́ŋk əv ɪt æz prəvájdɪŋ ǽnsərz əlɔ́ŋ wɪð ðə kwɛ́stʃənz, əláwɪŋ jɔr mɒ́dəl tə ɡrǽdʒuwəlij ʌ̀ndərstǽnd ðə dɪ́fərəns bijtwíjn, séj, kǽts ənd dɒ́ɡz, ɔr spǽm íjmejlz vɜ́rsəs lədʒɪ́tɪmət wʌ́nz. ɪt's kɔ́ld 'súwpərvàjzd' bəkɒ́z júwr əsɛ́nʃəlij súwpərvàjzɪŋ ðə lɜ́rnɪŋ prɒ́sɛs baj klɪ́ərlij dəfájnɪŋ rájt ənd rɔ́ŋ ǽnsərz frəm ðə stɑ́rt."
    },
    {
        "Question": "Imagine you have data about various customers, but there's no label telling you who might purchase your products. You ask your algorithm to explore the data on its own and spot natural patterns or groups. What machine learning approach fits this description?",
        "RightAnswer": "Unsupervised Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Reinforcement Learning",
            "Transfer Learning",
            "Semi-supervised Learning",
            "Deep Learning"
        ],
        "Explanation": "Unsupervised Learning is a type of machine learning where the algorithm explores and identifies hidden patterns or groups within data without any labels or explicit instructions. Think of it like giving someone a basket of mixed fruits without labels, and they naturally start grouping bananas, apples, and oranges based solely on similarities. Similarly, unsupervised learning helps us discover hidden patterns, categories, or structures in data without extra guidance.",
        "trans_Question": "ɪmǽdʒɪn juw həv déjtə əbawt vɛ́ərijəs kʌ́stəmərz, bʌt ðɛər'z now léjbəl tɛ́lɪŋ juw huw majt pɜ́rtʃəs jɔr prɒ́dəkts. juw ǽsk jɔr ǽlɡərɪ̀ðəm tə əksplɔ́r ðə déjtə ɒn ɪts ówn ənd spɒ́t nǽtʃərəl pǽtərnz ɔr ɡrúwps. wɒt məʃíjn lɜ́rnɪŋ əprówtʃ fɪ́ts ðɪs dəskrɪ́pʃən?",
        "trans_RightAnswer": "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ ɪz ə tájp əv məʃíjn lɜ́rnɪŋ wɛ́ər ðə ǽlɡərɪ̀ðəm əksplɔ́rz ənd ajdɛ́ntɪfàjz hɪ́dən pǽtərnz ɔr ɡrúwps wɪðɪ́n déjtə wɪðáwt ɛ́nij léjbəlz ɔr əksplɪ́sɪt ɪnstrʌ́kʃənz. θɪ́ŋk əv ɪt lájk ɡɪ́vɪŋ sʌ́mwʌ̀n ə bǽskət əv mɪ́kst frúwts wɪðáwt léjbəlz, ənd ðej nǽtʃərəlij stɑ́rt ɡrúwpɪŋ bənǽnəz, ǽpəlz, ənd ɔ́rəndʒɪz béjst sówlij ɒn sɪ̀mɪlɛ́ərɪtijz. sɪ́mɪlərlij, ʌ̀nsúwpərvàjzd lɜ́rnɪŋ hɛ́lps ʌs dɪskʌ́vər hɪ́dən pǽtərnz, kǽtəɡɔ̀rijz, ɔr strʌ́ktʃərz ɪn déjtə wɪðáwt ɛ́kstrə ɡájdəns."
    },
    {
        "Question": "Imagine a machine learning approach where an AI system learns by interacting with its environment, receiving rewards for good behaviors and penalties for bad ones, gradually figuring out the best decisions through trial-and-error experiences—what is this approach called?",
        "RightAnswer": "Reinforcement Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Unsupervised Learning",
            "Transfer Learning",
            "Ensemble Learning",
            "Semi-supervised Learning"
        ],
        "Explanation": "Reinforcement learning is like training a pet with rewards and gently guiding corrections whenever it makes mistakes. An AI agent interacts with its environment, tries different actions (trial-and-error), and learns from the feedback (rewards or penalties) it receives. Over time, it learns what choices lead to the best outcomes without needing constant instructions.",
        "trans_Question": "ɪmǽdʒɪn ə məʃíjn lɜ́rnɪŋ əprówtʃ wɛ́ər ən AI sɪ́stəm lɜ́rnz baj ɪ̀ntərǽktɪŋ wɪð ɪts ənvájərənmənt, rəsíjvɪŋ rəwɔ́rdz fɔr ɡʊ́d bəhéjvjərz ənd pɛ́nəltijz fɔr bǽd wʌ́nz, ɡrǽdʒuwəlij fɪ́ɡjərɪŋ awt ðə bɛ́st dəsɪ́ʒənz θrúw trájəl-ənd-ɛ́ərər əkspɪ́ərijənsijz—wɒt ɪz ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ"
        ],
        "trans_Explanation": "rìjɪnfɔ́rsmənt lɜ́rnɪŋ ɪz lájk tréjnɪŋ ə pɛ́t wɪð rəwɔ́rdz ənd dʒɛ́ntlij ɡájdɪŋ kərɛ́kʃənz wɛnɛ́vər ɪt méjks mɪstéjks. ən AI éjdʒənt ɪ̀ntərǽkts wɪð ɪts ənvájərənmənt, trájz dɪ́fərənt ǽkʃənz (trájəl-ənd-ɛ́ərər), ənd lɜ́rnz frəm ðə fíjdbæ̀k (rəwɔ́rdz ɔr pɛ́nəltijz) ɪt rəsíjvz. ówvər tájm, ɪt lɜ́rnz wɒt tʃɔ́jsɪz líjd tə ðə bɛ́st áwtkʌ̀mz wɪðáwt níjdɪŋ kɒ́nstənt ɪnstrʌ́kʃənz."
    },
    {
        "Question": "Imagine you have lots of data, but only a small portion of it comes with clear, helpful labels. You're hoping to use the labeled data to help your computer learn something useful from the unlabeled information as well. What approach would best describe your machine learning strategy?",
        "RightAnswer": "Semi-Supervised Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Transfer Learning",
            "Deep Learning"
        ],
        "Explanation": "Semi-Supervised Learning is a type of machine learning approach where the model learns from a mixture of labeled and unlabeled data. Imagine you're trying to teach someone to recognize dogs—but instead of having pictures of each dog clearly labeled, you have just a few labeled photos and many unlabeled ones. Your goal is to make use of both kinds of data so the model learns effectively, even when labels aren't always available.",
        "trans_Question": "ɪmǽdʒɪn juw həv lɒ́ts əv déjtə, bʌt ównlij ə smɔ́l pɔ́rʃən əv ɪt kʌ́mz wɪð klɪ́ər, hɛ́lpfəl léjbəlz. júwr hówpɪŋ tə juwz ðə léjbəld déjtə tə hɛ́lp jɔr kəmpjúwtər lɜ́rn sʌ́mθɪŋ júwsfəl frəm ðə ʌ̀nléjbəld ɪnfərméjʃən æz wɛ́l. wɒt əprówtʃ wʊd bɛ́st dəskrájb jɔr məʃíjn lɜ́rnɪŋ strǽtədʒij?",
        "trans_RightAnswer": "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ"
        ],
        "trans_Explanation": "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ ɪz ə tájp əv məʃíjn lɜ́rnɪŋ əprówtʃ wɛ́ər ðə mɒ́dəl lɜ́rnz frəm ə mɪ́kstʃər əv léjbəld ənd ʌ̀nléjbəld déjtə. ɪmǽdʒɪn júwr trájɪŋ tə tíjtʃ sʌ́mwʌ̀n tə rɛ́kəɡnàjz dɒ́ɡz—bʌt ɪnstɛ́d əv hǽvɪŋ pɪ́ktʃərz əv ijtʃ dɔ́ɡ klɪ́ərlij léjbəld, juw həv dʒəst ə fjúw léjbəld fówtòwz ənd mɛ́nij ʌ̀nléjbəld wʌ́nz. jɔr ɡówl ɪz tə méjk juwz əv bówθ kájndz əv déjtə sow ðə mɒ́dəl lɜ́rnz əfɛ́ktɪvlij, íjvən wɛ́n léjbəlz ɑrənt ɔ́lwejz əvéjləbəl."
    },
    {
        "Question": "What is the name for machine learning models inspired by the workings of the human brain, consisting of interconnected layers that can recognize patterns and make decisions?",
        "RightAnswer": "Neural Networks",
        "WrongAnswers": [
            "Decision Trees",
            "Linear Regression",
            "Support Vector Machines",
            "Clustering Algorithms",
            "Bayesian Networks"
        ],
        "Explanation": "Neural Networks are machine learning models designed to mimic how our brains function, using interconnected layers of 'neurons' to identify patterns, learn from data, and make decisions. They're at the core of many exciting innovations we use daily—like recognizing faces in photos, recommending movies, or powering voice assistants—all because they're great at finding complex patterns that simpler methods might miss.",
        "trans_Question": "wɒt ɪz ðə néjm fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz ɪnspájərd baj ðə wɜ́rkɪŋz əv ðə hjúwmən bréjn, kənsɪ́stɪŋ əv ɪ̀ntərkənɛ́ktɪd léjərz ðət kən rɛ́kəɡnàjz pǽtərnz ənd méjk dəsɪ́ʒənz?",
        "trans_RightAnswer": "nʊ́rəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríjz",
            "lɪ́nijər rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz",
            "béjʒən nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "nʊ́rəl nɛ́twɜ̀rks ɑr məʃíjn lɜ́rnɪŋ mɒ́dəlz dəzájnd tə mɪ́mɪk háw awər bréjnz fʌ́ŋkʃən, júwzɪŋ ɪ̀ntərkənɛ́ktɪd léjərz əv 'nʊ́rɒnz' tə ajdɛ́ntɪfàj pǽtərnz, lɜ́rn frəm déjtə, ənd méjk dəsɪ́ʒənz. ðɛ́ər æt ðə kɔ́r əv mɛ́nij əksájtɪŋ ɪnəvéjʃənz wij juwz déjlij—lájk rɛ́kəɡnàjzɪŋ féjsɪz ɪn fówtòwz, rɛ̀kəmɛ́ndɪŋ múwvijz, ɔr páwərɪŋ vɔ́js əsɪ́stənts—ɔl bəkɒ́z ðɛ́ər ɡréjt æt fájndɪŋ kɒ́mplɛks pǽtərnz ðət sɪ́mplər mɛ́θədz majt mɪ́s."
    },
    {
        "Question": "Which term describes a type of machine learning approach inspired by the networks of neurons in the human brain, often used in tasks like image recognition, speech recognition, and translation?",
        "RightAnswer": "Deep Learning",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Supervised Learning",
            "Regression Analysis",
            "Decision Tree",
            "Support Vector Machine"
        ],
        "Explanation": "Deep Learning is a specialized type of machine learning built around neural networks—structures inspired by the human brain. Just like our brains learn through experience, deep learning systems process vast amounts of data to learn, make decisions, and identify complex patterns. They're key players behind advancements such as self-driving cars, facial and voice recognition software, and even language translation apps.",
        "trans_Question": "wɪ́tʃ tɜ́rm dəskrájbz ə tájp əv məʃíjn lɜ́rnɪŋ əprówtʃ ɪnspájərd baj ðə nɛ́twɜ̀rks əv nʊ́rɒnz ɪn ðə hjúwmən bréjn, ɔ́fən júwzd ɪn tǽsks lájk ɪ́mɪdʒ rɛ̀kəɡnɪ́ʃən, spíjtʃ rɛ̀kəɡnɪ́ʃən, ənd trænsléjʃən?",
        "trans_RightAnswer": "díjp lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "dəsɪ́ʒən tríj",
            "səpɔ́rt vɛ́ktər məʃíjn"
        ],
        "trans_Explanation": "díjp lɜ́rnɪŋ ɪz ə spɛ́ʃəlàjzd tájp əv məʃíjn lɜ́rnɪŋ bɪ́lt əráwnd nʊ́rəl nɛ́twɜ̀rks—strʌ́ktʃərz ɪnspájərd baj ðə hjúwmən bréjn. dʒəst lájk awər bréjnz lɜ́rn θrúw əkspɪ́ərijəns, díjp lɜ́rnɪŋ sɪ́stəmz prɒ́sɛs vǽst əmáwnts əv déjtə tə lɜ́rn, méjk dəsɪ́ʒənz, ənd ajdɛ́ntɪfàj kɒ́mplɛks pǽtərnz. ðɛ́ər kíj pléjərz bəhájnd ədvǽnsmənts sʌtʃ æz sɛ́lf-drájvɪŋ kɑ́rz, féjʃəl ənd vɔ́js rɛ̀kəɡnɪ́ʃən sɔ́ftwɛ̀ər, ənd íjvən lǽŋɡwədʒ trænsléjʃən ǽps."
    },
    {
        "Question": "What do we call the process where computers improve how well they perform tasks by finding patterns in data, without being explicitly programmed for each task?",
        "RightAnswer": "Machine Learning",
        "WrongAnswers": [
            "Cloud Computing",
            "Data Encryption",
            "Blockchain Technology",
            "Robotics Engineering",
            "Software Debugging"
        ],
        "Explanation": "Machine learning is a fascinating branch of artificial intelligence where computers learn by themselves from data and experience. Instead of humans having to program precise instructions for every task, the computer figures out patterns and rules on its own, improving its accuracy over time. From predicting what movies you might like to recognizing your voice commands, machine learning lets computers grow smarter and more helpful through continuous learning.",
        "trans_Question": "wɒt dúw wij kɔ́l ðə prɒ́sɛs wɛ́ər kəmpjúwtərz ɪmprúwv háw wɛ́l ðej pərfɔ́rm tǽsks baj fájndɪŋ pǽtərnz ɪn déjtə, wɪðáwt bíjɪŋ əksplɪ́sɪtlij prówɡræ̀md fɔr ijtʃ tǽsk?",
        "trans_RightAnswer": "məʃíjn lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "kláwd kəmpjúwtɪŋ",
            "déjtə ɛnkrɪ́pʃən",
            "blɒ́ktʃéjn tɛknɒ́lədʒij",
            "ròwbɒ́tɪks ɛ̀ndʒɪnɪ́ərɪŋ",
            "sɔ́ftwɛ̀ər dijbʌ́ɡɪŋ"
        ],
        "trans_Explanation": "məʃíjn lɜ́rnɪŋ ɪz ə fǽsɪnèjtɪŋ brǽntʃ əv ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns wɛ́ər kəmpjúwtərz lɜ́rn baj ðəmsɛ́lvz frəm déjtə ənd əkspɪ́ərijəns. ɪnstɛ́d əv hjúwmənz hǽvɪŋ tə prówɡræ̀m prəsájs ɪnstrʌ́kʃənz fɔr ɛvərij tǽsk, ðə kəmpjúwtər fɪ́ɡjərz awt pǽtərnz ənd rúwlz ɒn ɪts ówn, ɪmprúwvɪŋ ɪts ǽkjərəsij ówvər tájm. frəm prədɪ́ktɪŋ wɒt múwvijz juw majt lájk tə rɛ́kəɡnàjzɪŋ jɔr vɔ́js kəmǽndz, məʃíjn lɜ́rnɪŋ lɛts kəmpjúwtərz ɡrów smɑ́rtər ənd mɔr hɛ́lpfəl θrúw kəntɪ́njuwəs lɜ́rnɪŋ."
    },
    {
        "Question": "When you're building a machine learning model, what's the important step called where you creatively select, combine, or transform certain data characteristics to make your model smarter and more efficient?",
        "RightAnswer": "Feature Engineering",
        "WrongAnswers": [
            "Model Optimization",
            "Overfitting Control",
            "Hyperparameter Tuning",
            "Gradient Descent",
            "Validation Set Selection"
        ],
        "Explanation": "Feature engineering is the creative process of choosing, modifying, and combining different aspects of your data that clearly highlight patterns or trends. It's similar to selecting the perfect ingredients to make your recipe (the model) taste just right. Effective feature engineering can greatly impact your model's performance by helping the algorithm capture meaningful insights more easily, rather than overwhelming it with irrelevant or noisy data.",
        "trans_Question": "wɛ́n júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, wɒt's ðə ɪmpɔ́rtənt stɛ́p kɔ́ld wɛ́ər juw krijéjtɪvlij səlɛ́kt, kɒ́mbajn, ɔr trǽnsfɔrm sɜ́rtən déjtə kæ̀rəktərɪ́stɪks tə méjk jɔr mɒ́dəl smɑ́rtər ənd mɔr əfɪ́ʃənt?",
        "trans_RightAnswer": "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
        "trans_WrongAnswers": [
            "mɒ́dəl ɒptɪmɪzéjʃən",
            "òwvərfɪ́tɪŋ kəntrówl",
            "hàjpərpǽrəmətər túwnɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "væ̀lɪdéjʃən sɛ́t səlɛ́kʃən"
        ],
        "trans_Explanation": "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ ɪz ðə krijéjtɪv prɒ́sɛs əv tʃúwzɪŋ, mɒ́dɪfàjɪŋ, ənd kəmbájnɪŋ dɪ́fərənt ǽspɛkts əv jɔr déjtə ðət klɪ́ərlij hájlàjt pǽtərnz ɔr trɛ́ndz. ɪt's sɪ́mɪlər tə səlɛ́ktɪŋ ðə pɜ́rfəkt ɪnɡríjdijənts tə méjk jɔr rɛ́sɪpij (ðə mɒ́dəl) téjst dʒəst rájt. əféktɪv fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ kən ɡréjtlij ɪ́mpækt jɔr mɒ́dəl'z pərfɔ́rməns baj hɛ́lpɪŋ ðə ǽlɡərɪ̀ðəm kǽptʃər míjnɪŋfəl ɪ́nsàjts mɔr íjzəlij, rǽðər ðʌn òwvərwɛ́lmɪŋ ɪt wɪð ɪ̀ərɛ́ləvənt ɔr nɔ́jzij déjtə."
    },
    {
        "Question": "You're building a machine learning application and have trained different algorithms to predict house prices. To achieve the best possible performance, you must carefully choose the algorithm that generalizes best to unseen data without overfitting or underfitting. What is the term for this crucial step in machine learning?",
        "RightAnswer": "Model Selection",
        "WrongAnswers": [
            "Feature Scaling",
            "Cross Validation",
            "Data Augmentation",
            "Gradient Descent",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Model selection refers to the important step of choosing the most appropriate machine learning algorithm (or model) from a group of options based on how well they perform on unseen data. The goal is to pick a model that finds the right balance—not too simple (underfitting), and not overly complicated (overfitting)—to ensure reliable and accurate predictions when applied to real-world data.",
        "trans_Question": "júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ æ̀plɪkéjʃən ənd həv tréjnd dɪ́fərənt ǽlɡərɪ̀ðəmz tə prədɪ́kt haws prájsɪz. tə ətʃíjv ðə bɛ́st pɒ́sɪbəl pərfɔ́rməns, juw mʌst kɛ́ərfəlij tʃúwz ðə ǽlɡərɪ̀ðəm ðət dʒɛ́nərəlajz bɛ́st tə ʌ̀nsíjn déjtə wɪðáwt òwvərfɪ́tɪŋ ɔr ʌ̀ndərfɪ́tɪŋ. wɒt ɪz ðə tɜ́rm fɔr ðɪs krúwʃəl stɛ́p ɪn məʃíjn lɜ́rnɪŋ?",
        "trans_RightAnswer": "mɒ́dəl səlɛ́kʃən",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "krɔ́s væ̀lɪdéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "mɒ́dəl səlɛ́kʃən rəfɜ́rz tə ðə ɪmpɔ́rtənt stɛ́p əv tʃúwzɪŋ ðə mówst əprówprijèjt məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm (ɔr mɒ́dəl) frəm ə ɡrúwp əv ɒ́pʃənz béjst ɒn háw wɛ́l ðej pərfɔ́rm ɒn ʌ̀nsíjn déjtə. ðə ɡówl ɪz tə pɪ́k ə mɒ́dəl ðət fájndz ðə rájt bǽləns—nɒt túw sɪ́mpəl (ʌ̀ndərfɪ́tɪŋ), ənd nɒt ówvərlij kɒ́mplɪkèjtɪd (òwvərfɪ́tɪŋ)—tə ənʃʊ́r rəlájəbəl ənd ǽkjərət prədɪ́kʃənz wɛ́n əplájd tə ríjəl-wɜ́rld déjtə."
    },
    {
        "Question": "In machine learning, what do we call the process of testing a model's performance by splitting the data into several sections and taking turns using each section as a test set while training the model on the rest?",
        "RightAnswer": "Cross-Validation",
        "WrongAnswers": [
            "Feature Scaling",
            "Data Normalization",
            "Gradient Descent",
            "Hyperparameter Tuning",
            "Random Forest"
        ],
        "Explanation": "Cross-Validation is a method in machine learning used to check how well a model is likely to perform on unseen data. Instead of testing once on a single dataset, we divide the data into several segments, using one segment as the testing set and others for training, and repeat this process multiple times. This helps ensure that the model's results are reliable and not just good 'by chance'.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt dúw wij kɔ́l ðə prɒ́sɛs əv tɛ́stɪŋ ə mɒ́dəl'z pərfɔ́rməns baj splɪ́tɪŋ ðə déjtə ɪntə sɛ́vərəl sɛ́kʃənz ənd téjkɪŋ tɜ́rnz júwzɪŋ ijtʃ sɛ́kʃən æz ə tɛ́st sɛ́t wájl tréjnɪŋ ðə mɒ́dəl ɒn ðə rɛ́st?",
        "trans_RightAnswer": "krɔ́s-væ̀lɪdéjʃən",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "déjtə nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "hàjpərpǽrəmətər túwnɪŋ",
            "rǽndəm fɔ́rəst"
        ],
        "trans_Explanation": "krɔ́s-væ̀lɪdéjʃən ɪz ə mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ júwzd tə tʃɛ́k háw wɛ́l ə mɒ́dəl ɪz lájklij tə pərfɔ́rm ɒn ʌ̀nsíjn déjtə. ɪnstɛ́d əv tɛ́stɪŋ wʌ́ns ɒn ə sɪ́ŋɡəl déjtəsɛ̀t, wij dɪvájd ðə déjtə ɪntə sɛ́vərəl sɛ́ɡmənts, júwzɪŋ wʌ́n sɛ́gmənt æz ðə tɛ́stɪŋ sɛ́t ənd ʌ́ðərz fɔr tréjnɪŋ, ənd rəpíjt ðɪs prɒ́sɛs mʌ́ltɪpəl tájmz. ðɪs hɛ́lps ənʃʊ́r ðət ðə mɒ́dəl'z rəzʌ́lts ɑr rəlájəbəl ənd nɒt dʒəst ɡʊ́d 'baj tʃǽns'."
    },
    {
        "Question": "What machine learning approach would you use to predict housing prices based on features like size, location, and number of bedrooms?",
        "RightAnswer": "Regression",
        "WrongAnswers": [
            "Classification",
            "Clustering",
            "Reinforcement Learning",
            "Dimensionality Reduction",
            "Anomaly Detection"
        ],
        "Explanation": "Regression is a type of supervised machine learning technique that predicts continuous numerical outcomes, such as housing prices, temperature forecasts, or sales revenue. Instead of categorizing objects into groups or labels, regression helps us understand relationships between features (like home size or location) and numerical results (like price).",
        "trans_Question": "wɒt məʃíjn lɜ́rnɪŋ əprówtʃ wʊd juw juwz tə prədɪ́kt háwzɪŋ prájsɪz béjst ɒn fíjtʃərz lájk sájz, lowkéjʃən, ənd nʌ́mbər əv bɛ́drùwmz?",
        "trans_RightAnswer": "rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "klæ̀sɪfɪkéjʃən",
            "klʌ́stərɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "ənɒ́məlij dətɛ́kʃən"
        ],
        "trans_Explanation": "rəɡrɛ́ʃən ɪz ə tájp əv súwpərvàjzd məʃíjn lɜ́rnɪŋ tɛkníjk ðət prədɪ́kts kəntɪ́njuwəs njuwmɛ́ərɪkəl áwtkʌ̀mz, sʌtʃ æz háwzɪŋ prájsɪz, tɛ́mpərətʃər fɔ́rkæ̀s, ɔr séjlz rɛ́vənùw. ɪnstɛ́d əv kǽtəɡəràjzɪŋ ɒ́bdʒɛkts ɪntə ɡrúwps ɔr léjbəlz, rəɡrɛ́ʃən hɛ́lps ʌs ʌ̀ndərstǽnd rəléjʃənʃɪ̀ps bijtwíjn fíjtʃərz (lájk hówm sájz ɔr lowkéjʃən) ənd njuwmɛ́ərɪkəl rəzʌ́lts (lájk prájs)."
    },
    {
        "Question": "Imagine you're building a machine learning model to sort emails into categories like 'spam' or 'important'. What is the process called when the model assigns each email to a specific category by identifying patterns?",
        "RightAnswer": "Classification",
        "WrongAnswers": [
            "Regression",
            "Clustering",
            "Dimensionality Reduction",
            "Reinforcement Learning",
            "Feature Extraction"
        ],
        "Explanation": "In machine learning, classification is like grouping things into clear categories based on patterns you've learned. For example, deciding if an email is 'spam' or 'important' is classification. The model learns from previous examples and makes predictions by spotting characteristic patterns.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə sɔ́rt íjmejlz ɪntə kǽtəɡɔ̀rijz lájk 'spǽm' ɔr 'ɪmpɔ́rtənt'. wɒt ɪz ðə prɒ́sɛs kɔ́ld wɛ́n ðə mɒ́dəl əsájnz ijtʃ íjmejl tə ə spəsɪ́fɪk kǽtəɡɔ̀rij baj ajdɛ́ntɪfàjɪŋ pǽtərnz?",
        "trans_RightAnswer": "klæ̀sɪfɪkéjʃən",
        "trans_WrongAnswers": [
            "rəɡrɛ́ʃən",
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "fíjtʃər əkstrǽkʃən"
        ],
        "trans_Explanation": "ɪn məʃíjn lɜ́rnɪŋ, klæ̀sɪfɪkéjʃən ɪz lájk ɡrúwpɪŋ θɪ́ŋz ɪntə klɪ́ər kǽtəɡɔ̀rijz béjst ɒn pǽtərnz júwv lɜ́rnd. fɔr əɡzǽmpəl, dəsájdɪŋ ɪf ən íjmejl ɪz 'spǽm' ɔr 'ɪmpɔ́rtənt' ɪz klæ̀sɪfɪkéjʃən. ðə mɒ́dəl lɜ́rnz frəm príjvijəs əɡzǽmpəlz ənd méjks prədɪ́kʃənz baj spɒ́tɪŋ kæ̀rəktərɪ́stɪk pǽtərnz."
    },
    {
        "Question": "Imagine you have tons of unlabeled customer data, and you want to understand patterns, like grouping similar shopping habits or interests together naturally. Which machine learning technique helps you group these similar items without labels or predefined categories?",
        "RightAnswer": "Clustering",
        "WrongAnswers": [
            "Supervised Learning",
            "Regression",
            "Classification",
            "Deep Learning",
            "Feature Scaling"
        ],
        "Explanation": "Clustering is a technique in machine learning where the goal is to naturally group data points into clusters. Think of it as letting data organize itself by similarity, without being told upfront what the groups should be. It's especially useful when you have large amounts of unlabelled data and want to discover natural patterns, such as spotting groups of customers with similar buying habits or interests.",
        "trans_Question": "ɪmǽdʒɪn juw həv tʌ́nz əv ʌ̀nléjbəld kʌ́stəmər déjtə, ənd juw wɒ́nt tə ʌ̀ndərstǽnd pǽtərnz, lájk ɡrúwpɪŋ sɪ́mɪlər ʃɒ́pɪŋ hǽbɪts ɔr ɪ́ntərəsts təɡɛ́ðər nǽtʃərəlij. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk hɛ́lps juw ɡrúwp ðijz sɪ́mɪlər ájtəmz wɪðáwt léjbəlz ɔr prìjdəfájnd kǽtəɡɔ̀rijz?",
        "trans_RightAnswer": "klʌ́stərɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "rəɡrɛ́ʃən",
            "klæ̀sɪfɪkéjʃən",
            "díjp lɜ́rnɪŋ",
            "fíjtʃər skéjlɪŋ"
        ],
        "trans_Explanation": "klʌ́stərɪŋ ɪz ə tɛkníjk ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ðə ɡówl ɪz tə nǽtʃərəlij ɡrúwp déjtə pɔ́jnts ɪntə klʌ́stərz. θɪ́ŋk əv ɪt æz lɛ́tɪŋ déjtə ɔ́rɡənàjz ɪtsɛ́lf baj sɪ̀mɪlɛ́ərɪtij, wɪðáwt bíjɪŋ tówld ʌ́pfrʌ̀nt wɒt ðə ɡrúwps ʃʊd bij. ɪt's əspɛ́ʃəlij júwsfəl wɛ́n juw həv lɑ́rdʒ əmáwnts əv ʌnléjbəld déjtə ənd wɒ́nt tə dɪskʌ́vər nǽtʃərəl pǽtərnz, sʌtʃ æz spɒ́tɪŋ ɡrúwps əv kʌ́stəmərz wɪð sɪ́mɪlər bájɪŋ hǽbɪts ɔr ɪ́ntərəsts."
    },
    {
        "Question": "When you're training a machine learning model, sometimes having tons of features is like having too many cooks in the kitchen—it just makes things complicated. What's the term for the process of cleverly simplifying your data by reducing the number of features, but keeping most of the useful information intact?",
        "RightAnswer": "Dimensionality Reduction",
        "WrongAnswers": [
            "Overfitting Avoidance",
            "Model Validation",
            "Feature Engineering",
            "Hyperparameter Tuning",
            "Gradient Descent"
        ],
        "Explanation": "Dimensionality reduction is like packing for a trip: you try to keep what's essential and get rid of extra baggage. In machine learning, it means simplifying your data by reducing the number of features (or dimensions). This helps your models learn faster, perform better, and avoid getting confused by unnecessary details. It's all about finding a simpler yet still effective representation of your data.",
        "trans_Question": "wɛ́n júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, sʌ́mtàjmz hǽvɪŋ tʌ́nz əv fíjtʃərz ɪz lájk hǽvɪŋ túw mɛ́nij kʊ́ks ɪn ðə kɪ́tʃən—ɪt dʒəst méjks θɪ́ŋz kɒ́mplɪkèjtɪd. wɒt's ðə tɜ́rm fɔr ðə prɒ́sɛs əv klɛ́vərlij sɪ́mpləfajɪŋ jɔr déjtə baj rədjúwsɪŋ ðə nʌ́mbər əv fíjtʃərz, bʌt kíjpɪŋ mówst əv ðə júwsfəl ɪnfərméjʃən ɪntǽkt?",
        "trans_RightAnswer": "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ əvɔ́jdəns",
            "mɒ́dəl væ̀lɪdéjʃən",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən ɪz lájk pǽkɪŋ fɔr ə trɪ́p: juw tráj tə kíjp wɒt's əsɛ́nʃəl ənd ɡɛt rɪ́d əv ɛ́kstrə bǽɡɪdʒ. ɪn məʃíjn lɜ́rnɪŋ, ɪt míjnz sɪ́mpləfajɪŋ jɔr déjtə baj rədjúwsɪŋ ðə nʌ́mbər əv fíjtʃərz (ɔr dajmɛ́nʃənz). ðɪs hɛ́lps jɔr mɒ́dəlz lɜ́rn fǽstər, pərfɔ́rm bɛ́tər, ənd əvɔ́jd ɡɛ́tɪŋ kənfjúwzd baj ʌ̀nnɛ́səsɛ̀ərij díjtejlz. ɪt's ɔl əbawt fájndɪŋ ə sɪ́mplər jɛt stɪ́l əféktɪv rɛ̀prəzɛntéjʃən əv jɔr déjtə."
    },
    {
        "Question": "Which machine learning technique helps simplify complex datasets by identifying the most important features and reducing dimensionality, allowing easier visualization and faster computation?",
        "RightAnswer": "Principal Component Analysis",
        "WrongAnswers": [
            "Decision Tree Classification",
            "Support Vector Machines",
            "Gradient Descent Optimization",
            "Naive Bayes Classification",
            "K-Means Clustering"
        ],
        "Explanation": "Principal Component Analysis, often called PCA, is a popular machine learning method used to simplify large, complex datasets. Think of it as decluttering your workspace—PCA identifies and keeps the most significant parts of information, combining or discarding less important aspects. This makes data easier to visualize, faster to process, and helps algorithms perform better.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk hɛ́lps sɪ́mpləfaj kɒ́mplɛks déjtəsɛ̀ts baj ajdɛ́ntɪfàjɪŋ ðə mówst ɪmpɔ́rtənt fíjtʃərz ənd rədjúwsɪŋ dajmɛ̀nʃənǽlɪtij, əláwɪŋ íjzijər vɪ̀ʒwəlɪzéjʃən ənd fǽstər kɒ̀mpjətéjʃən?",
        "trans_RightAnswer": "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríj klæ̀sɪfɪkéjʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "ɡréjdijənt dəsɛ́nt ɒptɪmɪzéjʃən",
            "nàjíjv béjz klæ̀sɪfɪkéjʃən",
            "k-míjnz klʌ́stərɪŋ"
        ],
        "trans_Explanation": "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs, ɔ́fən kɔ́ld PCA, ɪz ə pɒ́pjələr məʃíjn lɜ́rnɪŋ mɛ́θəd júwzd tə sɪ́mpləfaj lɑ́rdʒ, kɒ́mplɛks déjtəsɛ̀ts. θɪ́ŋk əv ɪt æz dìjklʌ́tərɪŋ jɔr wɜ́rkspèjs—pij ajdɛ́ntɪfàjz ənd kíjps ðə mówst sɪɡnɪ́fɪkənt pɑ́rts əv ɪnfərméjʃən, kəmbájnɪŋ ɔr dɪskɑ́rdɪŋ lɛ́s ɪmpɔ́rtənt ǽspɛkts. ðɪs méjks déjtə íjzijər tə vɪ́ʒwəlàjz, fǽstər tə prɒ́sɛs, ənd hɛ́lps ǽlɡərɪ̀ðəmz pərfɔ́rm bɛ́tər."
    },
    {
        "Question": "Which machine learning approach involves drawing a boundary that best separates different categories of data, aiming for the widest possible margin between groups?",
        "RightAnswer": "Support Vector Machines",
        "WrongAnswers": [
            "Random Forests",
            "Neural Networks",
            "K-Nearest Neighbors",
            "Decision Trees",
            "Gradient Boosting"
        ],
        "Explanation": "Support Vector Machines, or SVMs, are machine learning algorithms that classify data by finding the best separation point between groups. Imagine drawing a smart, safe boundary between two different teams, ensuring there's as much open space between them as possible. This boundary helps the algorithm clearly understand and predict new data points. SVMs are known for their accuracy and effectiveness, especially with clear-cut distinctions between data groups.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ ɪnvɒ́lvz drɔ́jŋ ə báwndərij ðət bɛ́st sɛ́pərèjts dɪ́fərənt kǽtəɡɔ̀rijz əv déjtə, éjmɪŋ fɔr ðə wájdəst pɒ́sɪbəl mɑ́rdʒɪn bijtwíjn ɡrúwps?",
        "trans_RightAnswer": "səpɔ́rt vɛ́ktər məʃíjnz",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəsts",
            "nʊ́rəl nɛ́twɜ̀rks",
            "k-nɪ́ərəst néjbərz",
            "dəsɪ́ʒən tríjz",
            "ɡréjdijənt búwstɪŋ"
        ],
        "trans_Explanation": "səpɔ́rt vɛ́ktər məʃíjnz, ɔr SVMs, ɑr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz ðət klǽsɪfàj déjtə baj fájndɪŋ ðə bɛ́st sɛ̀pərèjʃən pɔ́jnt bijtwíjn ɡrúwps. ɪmǽdʒɪn drɔ́jŋ ə smɑ́rt, séjf báwndərij bijtwíjn túw dɪ́fərənt tíjmz, ɛnʃʊ́rɪŋ ðɛər'z æz mʌtʃ ówpən spéjs bijtwíjn ðɛm æz pɒ́sɪbəl. ðɪs báwndərij hɛ́lps ðə ǽlɡərɪ̀ðəm klɪ́ərlij ʌ̀ndərstǽnd ənd prədɪ́kt núw déjtə pɔ́jnts. SVMs ɑr nówn fɔr ðɛər ǽkjərəsij ənd əfɛ́ktɪvnəs, əspɛ́ʃəlij wɪð klɪ́ər-kʌ́t dɪstɪ́ŋkʃənz bijtwíjn déjtə ɡrúwps."
    },
    {
        "Question": "Which machine learning technique involves breaking down data into simple, easy-to-understand branching structures that help computers make choices step-by-step?",
        "RightAnswer": "Decision Trees",
        "WrongAnswers": [
            "Neural Networks",
            "K-Means Clustering",
            "Linear Regression",
            "Support Vector Machines",
            "Principal Component Analysis"
        ],
        "Explanation": "Think of decision trees like flowcharts or choose-your-own-adventure stories, where data is sorted step-by-step by answering simple yes/no questions or testing thresholds. Each branch leads you closer to an outcome, making them a simple, intuitive way for a computer to make predictions based on past experiences.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪnvɒ́lvz bréjkɪŋ dawn déjtə ɪntə sɪ́mpəl, íjzij-tə-ʌ̀ndərstǽnd brǽntʃɪŋ strʌ́ktʃərz ðət hɛ́lp kəmpjúwtərz méjk tʃɔ́jsɪz stɛ́p-baj-stɛ́p?",
        "trans_RightAnswer": "dəsɪ́ʒən tríjz",
        "trans_WrongAnswers": [
            "nʊ́rəl nɛ́twɜ̀rks",
            "k-míjnz klʌ́stərɪŋ",
            "lɪ́nijər rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "θɪ́ŋk əv dəsɪ́ʒən tríjz lájk flówtʃɑ̀rts ɔr tʃúwz-jɔr-ówn-ædvɛ́ntʃər stɔ́rijz, wɛ́ər déjtə ɪz sɔ́rtɪd stɛ́p-baj-stɛ́p baj ǽnsərɪŋ sɪ́mpəl jɛs/now kwɛ́stʃənz ɔr tɛ́stɪŋ θrɛ́ʃòwldz. ijtʃ brǽntʃ líjdz juw klówsər tə ən áwtkʌ̀m, méjkɪŋ ðɛm ə sɪ́mpəl, ɪntúwɪtɪv wej fɔr ə kəmpjúwtər tə méjk prədɪ́kʃənz béjst ɒn pǽst əkspɪ́ərijənsijz."
    },
    {
        "Question": "Which machine learning approach combines multiple decision trees, each trained slightly differently, then averages their outcomes to make accurate predictions?",
        "RightAnswer": "Random Forests",
        "WrongAnswers": [
            "Gradient Descent",
            "Support Vector Machines",
            "Neural Networks",
            "Clustering Algorithms",
            "Ensemble Clustering"
        ],
        "Explanation": "Random Forests are like a group of friends who each analyze the data slightly differently and have a discussion to reach the best decision together. In technical terms, it involves creating multiple decision trees, each trained on slightly different subsets of data. Then, all their predictions are combined (usually averaged or through voting) to produce a more robust and accurate prediction than using a single decision tree alone. This collaborative approach helps random forests handle complex data and reduce common pitfalls like overfitting.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ kəmbájnz mʌ́ltɪpəl dəsɪ́ʒən tríjz, ijtʃ tréjnd slájtlij dɪ́fərɛ́ntlij, ðɛn ǽvrɪdʒɪz ðɛər áwtkʌ̀mz tə méjk ǽkjərət prədɪ́kʃənz?",
        "trans_RightAnswer": "rǽndəm fɔ́rəsts",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "nʊ́rəl nɛ́twɜ̀rks",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz",
            "ɒnsɒ́mbəl klʌ́stərɪŋ"
        ],
        "trans_Explanation": "rǽndəm fɔ́rəsts ɑr lájk ə ɡrúwp əv frɛ́ndz huw ijtʃ ǽnəlàjz ðə déjtə slájtlij dɪ́fərɛ́ntlij ənd həv ə dɪskʌ́ʃən tə ríjtʃ ðə bɛ́st dəsɪ́ʒən təɡɛ́ðər. ɪn tɛ́knɪkəl tɜ́rmz, ɪt ɪnvɒ́lvz krijéjtɪŋ mʌ́ltɪpəl dəsɪ́ʒən tríjz, ijtʃ tréjnd ɒn slájtlij dɪ́fərənt sʌ́bsɛ̀ts əv déjtə. ðɛn, ɔl ðɛər prədɪ́kʃənz ɑr kəmbájnd (júwʒəlij ǽvrədʒd ɔr θrúw vówtɪŋ) tə prədúws ə mɔr rowbʌ́st ənd ǽkjərət prədɪ́kʃən ðʌn júwzɪŋ ə sɪ́ŋɡəl dəsɪ́ʒən tríj əlówn. ðɪs kəlǽbərèjtɪv əprówtʃ hɛ́lps rǽndəm fɔ́rəsts hǽndəl kɒ́mplɛks déjtə ənd rədjúws kɒ́mən pɪ́tfɔ̀lz lájk òwvərfɪ́tɪŋ."
    },
    {
        "Question": "Which machine learning method creates a strong predictive model by combining a series of weaker decision trees, each built by focusing on correcting the mistakes made by previous trees?",
        "RightAnswer": "Gradient Boosting",
        "WrongAnswers": [
            "Support Vector Machines",
            "K-Means Clustering",
            "Neural Network",
            "Random Forest",
            "Principal Component Analysis"
        ],
        "Explanation": "Gradient Boosting is an exciting and powerful machine learning strategy that builds a strong overall model out of many simpler, smaller decision trees. It works step by step—each new tree crafted carefully to correct errors made by the trees before it. Imagine each tree learning from the previous one's mistakes, gradually improving until you have a highly accurate predictive model. This method is especially popular for its accuracy and effectiveness in various predictive modeling tasks.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ mɛ́θəd krijéjts ə strɔ́ŋ prədɪ́ktɪv mɒ́dəl baj kəmbájnɪŋ ə sɪ́ərijz əv wíjkər dəsɪ́ʒən tríjz, ijtʃ bɪ́lt baj fówkəsɪŋ ɒn kərɛ́ktɪŋ ðə mɪstéjks méjd baj príjvijəs tríjz?",
        "trans_RightAnswer": "ɡréjdijənt búwstɪŋ",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "k-míjnz klʌ́stərɪŋ",
            "nʊ́rəl nɛ́twɜ̀rk",
            "rǽndəm fɔ́rəst",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "ɡréjdijənt búwstɪŋ ɪz ən əksájtɪŋ ənd páwərfəl məʃíjn lɜ́rnɪŋ strǽtədʒij ðət bɪ́ldz ə strɔ́ŋ ówvərɔ̀l mɒ́dəl awt əv mɛ́nij sɪ́mplər, smɔ́lər dəsɪ́ʒən tríjz. ɪt wɜ́rks stɛ́p baj stɛ́p—ijtʃ núw tríj krǽftɪd kɛ́ərfəlij tə kərɛ́kt ɛ́ərərz méjd baj ðə tríjz bəfɔ́r ɪt. ɪmǽdʒɪn ijtʃ tríj lɜ́rnɪŋ frəm ðə príjvijəs wʌ́n'z mɪstéjks, ɡrǽdʒuwəlij ɪmprúwvɪŋ əntɪ́l juw həv ə hájlij ǽkjərət prədɪ́ktɪv mɒ́dəl. ðɪs mɛ́θəd ɪz əspɛ́ʃəlij pɒ́pjələr fɔr ɪts ǽkjərəsij ənd əfɛ́ktɪvnəs ɪn vɛ́ərijəs prədɪ́ktɪv mɒ́dəlɪ̀ŋ tǽsks."
    },
    {
        "Question": "Imagine you're training a machine learning model, and you notice it consistently makes mistakes on certain tricky data points. Now, you're looking for a technique that specifically helps your model focus more on these tough instances by repeatedly tweaking the training process to correct earlier errors. Which boosting algorithm best fits this description?",
        "RightAnswer": "AdaBoost",
        "WrongAnswers": [
            "Gradient Descent",
            "Random Forest",
            "K-means",
            "Principal Component Analysis",
            "Support Vector Machines"
        ],
        "Explanation": "AdaBoost, short for 'Adaptive Boosting,' is an engaging concept in machine learning where multiple simple models work together as a team. Each model in the sequence attempts to fix the previous model's mistakes by giving more attention (increasing the weight) to the tricky data points that were previously misclassified. Over several rounds, this collaborative process builds a stronger and more accurate predictor. It's like hiring specialists one after another to solve challenges—the next specialist always steps in to address what the previous one missed!",
        "trans_Question": "ɪmǽdʒɪn júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, ənd juw nówtɪs ɪt kənsɪ́stəntlij méjks mɪstéjks ɒn sɜ́rtən trɪ́kij déjtə pɔ́jnts. náw, júwr lʊ́kɪŋ fɔr ə tɛkníjk ðət spəsɪ́fɪklij hɛ́lps jɔr mɒ́dəl fówkəs mɔr ɒn ðijz tʌ́f ɪ́nstənsɪz baj rəpíjtɪdlij twíjkɪŋ ðə tréjnɪŋ prɒ́sɛs tə kərɛ́kt ɜ́rlijər ɛ́ərərz. wɪ́tʃ búwstɪŋ ǽlɡərɪ̀ðəm bɛ́st fɪ́ts ðɪs dəskrɪ́pʃən?",
        "trans_RightAnswer": "ADABOOST",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "rǽndəm fɔ́rəst",
            "k-míjnz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "səpɔ́rt vɛ́ktər məʃíjnz"
        ],
        "trans_Explanation": "ADABOOST, ʃɔ́rt fɔr 'ədǽptɪv búwstɪŋ,' ɪz ən ənɡéjdʒɪŋ kɒ́nsɛpt ɪn məʃíjn lɜ́rnɪŋ wɛ́ər mʌ́ltɪpəl sɪ́mpəl mɒ́dəlz wɜ́rk təɡɛ́ðər æz ə tíjm. ijtʃ mɒ́dəl ɪn ðə síjkwəns ətɛ́mpts tə fɪ́ks ðə príjvijəs mɒ́dəl'z mɪstéjks baj ɡɪ́vɪŋ mɔr ətɛ́nʃən (ɪnkríjsɪŋ ðə wéjt) tə ðə trɪ́kij déjtə pɔ́jnts ðət wɜ́r príjvijəslij mɪsklǽsɪfajd. ówvər sɛ́vərəl ráwndz, ðɪs kəlǽbərèjtɪv prɒ́sɛs bɪ́ldz ə strɔ́ŋər ənd mɔr ǽkjərət prədɪ́ktər. ɪt's lájk hájərɪŋ spɛ́ʃəlɪsts wʌ́n ǽftər ənʌ́ðər tə sɒ́lv tʃǽləndʒɪz—ðə nɛ́kst spɛ́ʃəlɪst ɔ́lwejz stɛ́ps ɪn tə æ̀drɛ́s wɒt ðə príjvijəs wʌ́n mɪ́st!"
    },
    {
        "Question": "In machine learning, what is the technique called when we combine several independent models, each trained on random subsets of data, and then average their predictions to make more stable and accurate results?",
        "RightAnswer": "Bagging",
        "WrongAnswers": [
            "Boosting",
            "Regularization",
            "Dropout",
            "Cross-validation",
            "Gradient Descent"
        ],
        "Explanation": "Imagine asking several friends their opinions on something and then averaging their answers to get a better, more reliable idea of what's correct—this is essentially what Bagging does. Bagging (short for Bootstrap Aggregating) trains multiple models on different random subsets of the data, then averages their predictions. This clever strategy helps reduce errors and improve a model's stability, making it much better at generalizing to new data.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt ɪz ðə tɛkníjk kɔ́ld wɛ́n wij kɒ́mbajn sɛ́vərəl ɪndəpɛ́ndənt mɒ́dəlz, ijtʃ tréjnd ɒn rǽndəm sʌ́bsɛ̀ts əv déjtə, ənd ðɛn ǽvərɪdʒ ðɛər prədɪ́kʃənz tə méjk mɔr stéjbəl ənd ǽkjərət rəzʌ́lts?",
        "trans_RightAnswer": "bǽɡɪŋ",
        "trans_WrongAnswers": [
            "búwstɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "drɒ́pàwt",
            "krɔ́s-væ̀lɪdéjʃən",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "ɪmǽdʒɪn ǽskɪŋ sɛ́vərəl frɛ́ndz ðɛər əpɪ́njənz ɒn sʌ́mθɪŋ ənd ðɛn ǽvrɪdʒɪŋ ðɛər ǽnsərz tə ɡɛt ə bɛ́tər, mɔr rəlájəbəl ajdíjə əv wɒt's kərɛ́kt—ðɪs ɪz əsɛ́nʃəlij wɒt bǽɡɪŋ dʌz. bǽɡɪŋ (ʃɔ́rt fɔr búwtstræ̀p ǽɡrəɡejtɪŋ) tréjnz mʌ́ltɪpəl mɒ́dəlz ɒn dɪ́fərənt rǽndəm sʌ́bsɛ̀ts əv ðə déjtə, ðɛn ǽvrɪdʒɪz ðɛər prədɪ́kʃənz. ðɪs klɛ́vər strǽtədʒij hɛ́lps rədjúws ɛ́ərərz ənd ɪmprúwv ə mɒ́dəl'z stəbɪ́lɪtij, méjkɪŋ ɪt mʌtʃ bɛ́tər æt dʒɛ́nərəlàjzɪŋ tə núw déjtə."
    },
    {
        "Question": "Which machine learning approach combines predictions from multiple models to achieve better accuracy and reduce errors than any single model alone?",
        "RightAnswer": "Ensemble Learning",
        "WrongAnswers": [
            "Back Propagation",
            "Feature Engineering",
            "Gradient Descent",
            "Dimensionality Reduction",
            "Cross-validation"
        ],
        "Explanation": "Ensemble Learning is a powerful machine learning technique where several individual models are trained separately, and then their predictions are combined into a single result. Think of it like assembling a team of experts—each bringing unique strengths—to tackle a tough problem together, resulting in more accurate and reliable predictions than any single expert alone could offer.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ kəmbájnz prədɪ́kʃənz frəm mʌ́ltɪpəl mɒ́dəlz tə ətʃíjv bɛ́tər ǽkjərəsij ənd rədjúws ɛ́ərərz ðʌn ɛ́nij sɪ́ŋɡəl mɒ́dəl əlówn?",
        "trans_RightAnswer": "ɒnsɒ́mbəl lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "bǽk prɒ̀pəɡéjʃən",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "krɔ́s-væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "ɒnsɒ́mbəl lɜ́rnɪŋ ɪz ə páwərfəl məʃíjn lɜ́rnɪŋ tɛkníjk wɛ́ər sɛ́vərəl ɪndɪvɪ́dʒəwəl mɒ́dəlz ɑr tréjnd sɛ́pərətlij, ənd ðɛn ðɛər prədɪ́kʃənz ɑr kəmbájnd ɪntə ə sɪ́ŋɡəl rəzʌ́lt. θɪ́ŋk əv ɪt lájk əsɛ́mbəlɪŋ ə tíjm əv ɛ́kspərts—ijtʃ brɪ́ŋɪŋ juwnɪ́k strɛ́ŋθs—tə tǽkəl ə tʌ́f prɒ́bləm təɡɛ́ðər, rəzʌ́ltɪŋ ɪn mɔr ǽkjərət ənd rəlájəbəl prədɪ́kʃənz ðʌn ɛ́nij sɪ́ŋɡəl ɛ́kspərt əlówn kʊ́d ɔ́fər."
    },
    {
        "Question": "Imagine you're trying to predict if a new movie will appeal to a specific viewer based on movies that viewer already likes. Which simple and intuitive machine learning method predicts results by looking at the most similar previous examples and taking a majority vote or average of them?",
        "RightAnswer": "K-Nearest Neighbors",
        "WrongAnswers": [
            "Random Forest",
            "Linear Regression",
            "Neural Network",
            "Clustering",
            "Gradient Boosting"
        ],
        "Explanation": "K-Nearest Neighbors is a simple, intuitive machine learning algorithm that works by finding the most similar past examples (the 'neighbors') based on a measure of distance or similarity. Once it finds these neighbors, it makes a prediction for a new data point by either taking a vote (if it's classification) or averaging their outcomes (if it's regression). Think of it like asking your friends who share your taste in movies for a new recommendation—it's practical, effective, and easy to understand.",
        "trans_Question": "ɪmǽdʒɪn júwr trájɪŋ tə prədɪ́kt ɪf ə núw múwvij wɪl əpíjl tə ə spəsɪ́fɪk vjúwər béjst ɒn múwvijz ðət vjúwər ɔ̀lrɛ́dij lájks. wɪ́tʃ sɪ́mpəl ənd ɪntúwɪtɪv məʃíjn lɜ́rnɪŋ mɛ́θəd prədɪ́kts rəzʌ́lts baj lʊ́kɪŋ æt ðə mówst sɪ́mɪlər príjvijəs əɡzǽmpəlz ənd téjkɪŋ ə mədʒɔ́rɪtij vówt ɔr ǽvərɪdʒ əv ðɛm?",
        "trans_RightAnswer": "k-nɪ́ərəst néjbərz",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəst",
            "lɪ́nijər rəɡrɛ́ʃən",
            "nʊ́rəl nɛ́twɜ̀rk",
            "klʌ́stərɪŋ",
            "ɡréjdijənt búwstɪŋ"
        ],
        "trans_Explanation": "k-nɪ́ərəst néjbərz ɪz ə sɪ́mpəl, ɪntúwɪtɪv məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm ðət wɜ́rks baj fájndɪŋ ðə mówst sɪ́mɪlər pǽst əɡzǽmpəlz (ðə 'néjbərz') béjst ɒn ə mɛ́ʒər əv dɪ́stəns ɔr sɪ̀mɪlɛ́ərɪtij. wʌ́ns ɪt fájndz ðijz néjbərz, ɪt méjks ə prədɪ́kʃən fɔr ə núw déjtə pɔ́jnt baj ájðər téjkɪŋ ə vówt (ɪf ɪt's klæ̀sɪfɪkéjʃən) ɔr ǽvrɪdʒɪŋ ðɛər áwtkʌ̀mz (ɪf ɪt's rəɡrɛ́ʃən). θɪ́ŋk əv ɪt lájk ǽskɪŋ jɔr frɛ́ndz huw ʃɛ́ər jɔr téjst ɪn múwvijz fɔr ə núw rɛ̀kəməndéjʃən—ɪt's prǽktɪkəl, əféktɪv, ənd íjzij tə ʌ̀ndərstǽnd."
    },
    {
        "Question": "Imagine you want to quickly classify an email as 'spam' or 'not spam' by looking at words contained in the email. Which machine learning algorithm, known for being fast, simple, and built upon probabilities of words appearing independently, would you most likely use?",
        "RightAnswer": "Naive Bayes",
        "WrongAnswers": [
            "Linear Regression",
            "K-Means Clustering",
            "Decision Trees",
            "Random Forest",
            "Convolutional Neural Network"
        ],
        "Explanation": "Naive Bayes is a simple yet powerful machine learning algorithm that applies Bayes' theorem. It's called 'naive' because it assumes each feature (like a word in an email) independently contributes to predicting the classification—ignoring any correlation between features. It's widely popular for tasks such as spam filtering or sentiment analysis because it's fast, effective with small datasets, and easy to implement.",
        "trans_Question": "ɪmǽdʒɪn juw wɒ́nt tə kwɪ́klij klǽsɪfàj ən íjmejl æz 'spǽm' ɔr 'nɒt spǽm' baj lʊ́kɪŋ æt wɜ́rdz kəntéjnd ɪn ðə íjmejl. wɪ́tʃ məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm, nówn fɔr bíjɪŋ fǽst, sɪ́mpəl, ənd bɪ́lt əpɒ́n prɒ̀bəbɪ́lɪtìjz əv wɜ́rdz əpɪ́ərɪŋ ɪndəpɛ́ndəntlij, wʊd juw mówst lájklij juwz?",
        "trans_RightAnswer": "nàjíjv béjz",
        "trans_WrongAnswers": [
            "lɪ́nijər rəɡrɛ́ʃən",
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríjz",
            "rǽndəm fɔ́rəst",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rk"
        ],
        "trans_Explanation": "nàjíjv béjz ɪz ə sɪ́mpəl jɛt páwərfəl məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm ðət əplájz béjz' θɪ́ərəm. ɪt's kɔ́ld 'nàjíjv' bəkɒ́z ɪt əsúwmz ijtʃ fíjtʃər (lájk ə wɜ́rd ɪn ən íjmejl) ɪndəpɛ́ndəntlij kəntrɪ́bjuwts tə prədɪ́ktɪŋ ðə klæ̀sɪfɪkéjʃən—ɪ̀ɡnɔ́rɪŋ ɛ́nij kɔ̀rəléjʃən bijtwíjn fíjtʃərz. ɪt's wájdlij pɒ́pjələr fɔr tǽsks sʌtʃ æz spǽm fɪ́ltərɪŋ ɔr sɛ́ntɪmənt ənǽlɪsɪs bəkɒ́z ɪt's fǽst, əféktɪv wɪð smɔ́l déjtəsɛ̀ts, ənd íjzij tə ɪ́mpləmənt."
    },
    {
        "Question": "Imagine you're building an app to predict whether an email is spam or not spam based on features like certain keywords, length, and sender details. Which machine learning algorithm would you commonly choose for classifying emails into these two distinct groups?",
        "RightAnswer": "Logistic Regression",
        "WrongAnswers": [
            "Linear Regression",
            "K-Means Clustering",
            "Principal Component Analysis",
            "Decision Tree Regression",
            "Gradient Descent Optimization"
        ],
        "Explanation": "Logistic Regression is a machine learning method commonly used when you're tackling classification problems—situations in which you want your system to distinguish between two distinct categories (like whether an email is spam or not spam). Unlike standard linear regression that predicts a numeric value, logistic regression predicts the likelihood of an event (like spam vs. not spam) by providing results as probabilities between 0 and 1, making it ideal for clear yes-no or either-or decisions within applications.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ən ǽp tə prədɪ́kt wɛ́ðər ən íjmejl ɪz spǽm ɔr nɒt spǽm béjst ɒn fíjtʃərz lájk sɜ́rtən kíjwɜ̀rdz, lɛ́ŋθ, ənd sɛ́ndər díjtejlz. wɪ́tʃ məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm wʊd juw kɒ́mənlij tʃúwz fɔr klǽsɪfàjɪŋ íjmejlz ɪntə ðijz túw dɪstɪ́ŋkt ɡrúwps?",
        "trans_RightAnswer": "lədʒɪ́stɪk rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "lɪ́nijər rəɡrɛ́ʃən",
            "k-míjnz klʌ́stərɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "dəsɪ́ʒən tríj rəɡrɛ́ʃən",
            "ɡréjdijənt dəsɛ́nt ɒptɪmɪzéjʃən"
        ],
        "trans_Explanation": "lədʒɪ́stɪk rəɡrɛ́ʃən ɪz ə məʃíjn lɜ́rnɪŋ mɛ́θəd kɒ́mənlij júwzd wɛ́n júwr tǽkəlɪŋ klæ̀sɪfɪkéjʃən prɒ́bləmz—sɪ̀tʃuwéjʃənz ɪn wɪ́tʃ juw wɒ́nt jɔr sɪ́stəm tə dɪstɪ́ŋɡwɪʃ bijtwíjn túw dɪstɪ́ŋkt kǽtəɡɔ̀rijz (lájk wɛ́ðər ən íjmejl ɪz spǽm ɔr nɒt spǽm). ʌ̀nlájk stǽndərd lɪ́nijər rəɡrɛ́ʃən ðət prədɪ́kts ə njuwmɛ́ərɪk vǽljuw, lədʒɪ́stɪk rəɡrɛ́ʃən prədɪ́kts ðə lájklijhʊ̀d əv ən əvɛ́nt (lájk spǽm vɜ́rsəs. nɒt spǽm) baj prəvájdɪŋ rəzʌ́lts æz prɒ̀bəbɪ́lɪtìjz bijtwíjn 0 ənd 1, méjkɪŋ ɪt ajdíjəl fɔr klɪ́ər jɛs-now ɔr ájðər-ɔr dəsɪ́ʒənz wɪðɪ́n æ̀plɪkéjʃənz."
    },
    {
        "Question": "Imagine you're trying to predict the price of a house based on its size. Which simple yet powerful method would you use to draw a straight line that best fits your data, helping you make clear predictions?",
        "RightAnswer": "Linear Regression",
        "WrongAnswers": [
            "Decision Tree Regression",
            "Logistic Regression",
            "Neural Network",
            "Random Forest",
            "Support Vector Machine"
        ],
        "Explanation": "Linear regression is one of the simplest and most intuitive machine learning techniques used to predict continuous values—like house prices, salaries, or temperatures—by finding the best-fitting straight line through your data points. It's like drawing the straightest possible line that best captures the trend and helps you see clearly how one thing affects another.",
        "trans_Question": "ɪmǽdʒɪn júwr trájɪŋ tə prədɪ́kt ðə prájs əv ə haws béjst ɒn ɪts sájz. wɪ́tʃ sɪ́mpəl jɛt páwərfəl mɛ́θəd wʊd juw juwz tə drɔ́ ə stréjt lájn ðət bɛ́st fɪ́ts jɔr déjtə, hɛ́lpɪŋ juw méjk klɪ́ər prədɪ́kʃənz?",
        "trans_RightAnswer": "lɪ́nijər rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríj rəɡrɛ́ʃən",
            "lədʒɪ́stɪk rəɡrɛ́ʃən",
            "nʊ́rəl nɛ́twɜ̀rk",
            "rǽndəm fɔ́rəst",
            "səpɔ́rt vɛ́ktər məʃíjn"
        ],
        "trans_Explanation": "lɪ́nijər rəɡrɛ́ʃən ɪz wʌ́n əv ðə sɪ́mpləst ənd mówst ɪntúwɪtɪv məʃíjn lɜ́rnɪŋ tɛkníjks júwzd tə prədɪ́kt kəntɪ́njuwəs vǽljuwz—lájk haws prájsɪz, sǽlərijz, ɔr tɛ́mpərətʃərz—baj fájndɪŋ ðə bɛ́st-fɪ́tɪŋ stréjt lájn θrúw jɔr déjtə pɔ́jnts. ɪt's lájk drɔ́jŋ ðə stréjtɪst pɒ́sɪbəl lájn ðət bɛ́st kǽptʃərz ðə trɛ́nd ənd hɛ́lps juw síj klɪ́ərlij háw wʌ́n θɪ́ŋ əfɛ́kts ənʌ́ðər."
    },
    {
        "Question": "Suppose you have data showing a relationship that's clearly curved or nonlinear—like the way house size relates to price (beyond simple straight-line relationships). Which machine learning approach would you use to fit a curve effectively to this type of data?",
        "RightAnswer": "Polynomial Regression",
        "WrongAnswers": [
            "Logistic Regression",
            "Decision Tree Classification",
            "Linear Regression",
            "K-Means Clustering",
            "Support Vector Classification"
        ],
        "Explanation": "Polynomial Regression is a technique used in machine learning to handle data that doesn't fit a straight line. Instead of sticking strictly to linear (straight-line) predictions, it uses curves to better capture complex relationships between variables. Think of it as adapting your prediction to the shape of the data, making predictions more accurate when there's clear curvature or patterns that simply can't be described adequately by a straight line.",
        "trans_Question": "səpówz juw həv déjtə ʃówɪŋ ə rəléjʃənʃɪ̀p ðət's klɪ́ərlij kɜ́rvd ɔr nɒnlɪ́nìjər—lájk ðə wej haws sájz rəléjts tə prájs (bìjɔ́nd sɪ́mpəl stréjt-lájn rəléjʃənʃɪ̀ps). wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ wʊd juw juwz tə fɪ́t ə kɜ́rv əfɛ́ktɪvlij tə ðɪs tájp əv déjtə?",
        "trans_RightAnswer": "pɒ̀lijnówmijəl rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "lədʒɪ́stɪk rəɡrɛ́ʃən",
            "dəsɪ́ʒən tríj klæ̀sɪfɪkéjʃən",
            "lɪ́nijər rəɡrɛ́ʃən",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər klæ̀sɪfɪkéjʃən"
        ],
        "trans_Explanation": "pɒ̀lijnówmijəl rəɡrɛ́ʃən ɪz ə tɛkníjk júwzd ɪn məʃíjn lɜ́rnɪŋ tə hǽndəl déjtə ðət dʌ́zənt fɪ́t ə stréjt lájn. ɪnstɛ́d əv stɪ́kɪŋ strɪ́ktlij tə lɪ́nijər (stréjt-lájn) prədɪ́kʃənz, ɪt júwsɪz kɜ́rvz tə bɛ́tər kǽptʃər kɒ́mplɛks rəléjʃənʃɪ̀ps bijtwíjn vɛ́ərijəbəlz. θɪ́ŋk əv ɪt æz ədǽptɪŋ jɔr prədɪ́kʃən tə ðə ʃéjp əv ðə déjtə, méjkɪŋ prədɪ́kʃənz mɔr ǽkjərət wɛ́n ðɛər'z klɪ́ər kɜ́rvətʃər ɔr pǽtərnz ðət sɪ́mplij kǽnt bij dəskrájbd ǽdəkwətlij baj ə stréjt lájn."
    },
    {
        "Question": "You're building a machine learning model to predict house prices, but your model seems to be overfitting due to overly complex relationships. Which technique could you apply that penalizes large coefficients and helps simplify the model, making it more stable and less prone to overfitting?",
        "RightAnswer": "Ridge Regression",
        "WrongAnswers": [
            "K-Means Clustering",
            "Decision Tree Classification",
            "Support Vector Machines",
            "Gradient Boosting",
            "Principal Component Analysis"
        ],
        "Explanation": "Ridge Regression is a popular regularization technique in machine learning, used specifically in linear regression problems. It introduces a penalty term on the coefficients, which actively discourages overly complex models—by shrinking large coefficient values closer to zero. This helps your model to avoid overfitting, improving its ability to generalize well to new data.",
        "trans_Question": "júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə prədɪ́kt haws prájsɪz, bʌt jɔr mɒ́dəl síjmz tə bij òwvərfɪ́tɪŋ djúw tə ówvərlij kɒ́mplɛks rəléjʃənʃɪ̀ps. wɪ́tʃ tɛkníjk kʊ́d juw əpláj ðət pɛ́nəlàjzɪz lɑ́rdʒ kòwəfɪ́ʃənts ənd hɛ́lps sɪ́mpləfaj ðə mɒ́dəl, méjkɪŋ ɪt mɔr stéjbəl ənd lɛ́s prówn tə òwvərfɪ́tɪŋ?",
        "trans_RightAnswer": "rɪ́dʒ rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríj klæ̀sɪfɪkéjʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "ɡréjdijənt búwstɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "rɪ́dʒ rəɡrɛ́ʃən ɪz ə pɒ́pjələr rèɡjəlɛ̀ərɪzéjʃən tɛkníjk ɪn məʃíjn lɜ́rnɪŋ, júwzd spəsɪ́fɪklij ɪn lɪ́nijər rəɡrɛ́ʃən prɒ́bləmz. ɪt ɪntrədúwsɪz ə pɛ́nəltij tɜ́rm ɒn ðə kòwəfɪ́ʃənts, wɪ́tʃ ǽktɪvlij dɪskɜ́rɪdʒɪz ówvərlij kɒ́mplɛks mɒ́dəlz—baj ʃrɪ́ŋkɪŋ lɑ́rdʒ kòwəfɪ́ʃənt vǽljuwz klówsər tə zíjərow. ðɪs hɛ́lps jɔr mɒ́dəl tə əvɔ́jd òwvərfɪ́tɪŋ, ɪmprúwvɪŋ ɪts əbɪ́lɪtij tə dʒɛ́nərəlàjz wɛ́l tə núw déjtə."
    },
    {
        "Question": "Which regression method in machine learning helps make our model simpler and clearer by shrinking some feature weights down to zero, effectively getting rid of less important variables?",
        "RightAnswer": "Lasso Regression",
        "WrongAnswers": [
            "Ridge Regression",
            "Polynomial Regression",
            "Linear Regression",
            "Logistic Regression",
            "Support Vector Regression"
        ],
        "Explanation": "Lasso Regression is like a strict professor who carefully picks only the most important features for your model while completely throwing out less relevant ones. It does this by pushing the weights (coefficients) of less useful variables down to exactly zero. This makes your model easier to interpret, reduces chance of overfitting, and keeps your predictions clear and understandable.",
        "trans_Question": "wɪ́tʃ rəɡrɛ́ʃən mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ hɛ́lps méjk awər mɒ́dəl sɪ́mplər ənd klɪ́ərər baj ʃrɪ́ŋkɪŋ sʌm fíjtʃər wéjts dawn tə zíjərow, əfɛ́ktɪvlij ɡɛ́tɪŋ rɪ́d əv lɛ́s ɪmpɔ́rtənt vɛ́ərijəbəlz?",
        "trans_RightAnswer": "lǽsow rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "rɪ́dʒ rəɡrɛ́ʃən",
            "pɒ̀lijnówmijəl rəɡrɛ́ʃən",
            "lɪ́nijər rəɡrɛ́ʃən",
            "lədʒɪ́stɪk rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər rəɡrɛ́ʃən"
        ],
        "trans_Explanation": "lǽsow rəɡrɛ́ʃən ɪz lájk ə strɪ́kt prəfɛ́sər huw kɛ́ərfəlij pɪ́ks ównlij ðə mówst ɪmpɔ́rtənt fíjtʃərz fɔr jɔr mɒ́dəl wájl kəmplíjtlij θrówɪŋ awt lɛ́s rɛ́ləvənt wʌ́nz. ɪt dʌz ðɪs baj pʊ́ʃɪŋ ðə wéjts (kòwəfɪ́ʃənts) əv lɛ́s júwsfəl vɛ́ərijəbəlz dawn tə əɡzǽktlij zíjərow. ðɪs méjks jɔr mɒ́dəl íjzijər tə ɪntɜ́rprət, rədjúwsɪz tʃǽns əv òwvərfɪ́tɪŋ, ənd kíjps jɔr prədɪ́kʃənz klɪ́ər ənd ʌ̀ndərstǽndəbəl."
    },
    {
        "Question": "Imagine you're building a machine learning model and struggling because your data has many features—some that strongly influence your predictions, others much less so. You're worried about overfitting and want an approach that smoothly balances between keeping the most useful features and reducing less significant ones. Which technique could you choose to accomplish both feature selection and shrinkage?",
        "RightAnswer": "Elastic Net",
        "WrongAnswers": [
            "Decision Tree",
            "Cross-Validation",
            "Gradient Boosting",
            "Random Forest",
            "Kernel Trick"
        ],
        "Explanation": "Elastic Net is a smart regression technique used in machine learning that combines two different methods—Ridge and Lasso regression. Ridge regression reduces the impact of less important features by shrinking their coefficients toward zero, while Lasso regression also shrinks coefficients and has the additional advantage of completely eliminating some features by setting their coefficients exactly to zero. Elastic Net smoothly balances both approaches, making it especially useful when you have many correlated features and want a practical, 'best-of-both-worlds' solution.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ənd strʌ́ɡəlɪŋ bəkɒ́z jɔr déjtə həz mɛ́nij fíjtʃərz—sʌm ðət strɔ́ŋlij ɪ́nfluwəns jɔr prədɪ́kʃənz, ʌ́ðərz mʌtʃ lɛ́s sow. júwr wɜ́rijd əbawt òwvərfɪ́tɪŋ ənd wɒ́nt ən əprówtʃ ðət smúwðlij bǽlənsɪz bijtwíjn kíjpɪŋ ðə mówst júwsfəl fíjtʃərz ənd rədjúwsɪŋ lɛ́s sɪɡnɪ́fɪkənt wʌ́nz. wɪ́tʃ tɛkníjk kʊ́d juw tʃúwz tə əkɒ́mplɪʃ bówθ fíjtʃər səlɛ́kʃən ənd ʃrɪ́ŋkɪdʒ?",
        "trans_RightAnswer": "əlǽstɪk nɛ́t",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríj",
            "krɔ́s-væ̀lɪdéjʃən",
            "ɡréjdijənt búwstɪŋ",
            "rǽndəm fɔ́rəst",
            "kɜ́rnəl trɪ́k"
        ],
        "trans_Explanation": "əlǽstɪk nɛ́t ɪz ə smɑ́rt rəɡrɛ́ʃən tɛkníjk júwzd ɪn məʃíjn lɜ́rnɪŋ ðət kəmbájnz túw dɪ́fərənt mɛ́θədz—rɪ́dʒ ənd lǽsow rəɡrɛ́ʃən. rɪ́dʒ rəɡrɛ́ʃən rədjúwsɪz ðə ɪ́mpækt əv lɛ́s ɪmpɔ́rtənt fíjtʃərz baj ʃrɪ́ŋkɪŋ ðɛər kòwəfɪ́ʃənts təwɔ́rd zíjərow, wájl lǽsow rəɡrɛ́ʃən ɔ́lsow ʃrɪ́ŋks kòwəfɪ́ʃənts ənd həz ðə ədɪ́ʃənəl ədvǽntɪdʒ əv kəmplíjtlij əlɪ́mɪnèjtɪŋ sʌm fíjtʃərz baj sɛ́tɪŋ ðɛər kòwəfɪ́ʃənts əɡzǽktlij tə zíjərow. əlǽstɪk nɛ́t smúwðlij bǽlənsɪz bówθ əprówtʃɪz, méjkɪŋ ɪt əspɛ́ʃəlij júwsfəl wɛ́n juw həv mɛ́nij kɔ́rəlèjtɪd fíjtʃərz ənd wɒ́nt ə prǽktɪkəl, 'bɛ́st-əv-bówθ-wɜ́rldz' səlúwʃən."
    },
    {
        "Question": "In machine learning, what approach involves updating our beliefs and predictions as we gather more evidence or data, gradually refining our understanding of the situation?",
        "RightAnswer": "Bayesian Inference",
        "WrongAnswers": [
            "Gradient Descent",
            "Decision Tree Analysis",
            "Support Vector Machines",
            "K-Means Clustering",
            "Reinforcement Learning"
        ],
        "Explanation": "Bayesian Inference is a way of thinking about machine learning and probability in which we start with an initial belief (called a prior), then gradually adjust that belief as new data or evidence comes in. Think of it as updating your understanding step by step as you learn more, allowing you to make increasingly accurate predictions and decisions. It contrasts with approaches that treat data in isolation without explicitly updating prior beliefs.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt əprówtʃ ɪnvɒ́lvz ʌ́pdèjtɪŋ awər bəlíjfs ənd prədɪ́kʃənz æz wij ɡǽðər mɔr ɛ́vɪdəns ɔr déjtə, ɡrǽdʒuwəlij rəfájnɪŋ awər ʌ̀ndərstǽndɪŋ əv ðə sɪ̀tʃuwéjʃən?",
        "trans_RightAnswer": "béjʒən ɪ́nfərəns",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "dəsɪ́ʒən tríj ənǽlɪsɪs",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "k-míjnz klʌ́stərɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "béjʒən ɪ́nfərəns ɪz ə wej əv θɪ́ŋkɪŋ əbawt məʃíjn lɜ́rnɪŋ ənd prɒ̀bəbɪ́lɪtij ɪn wɪ́tʃ wij stɑ́rt wɪð ən ɪnɪ́ʃəl bəlíjf (kɔ́ld ə prájər), ðɛn ɡrǽdʒuwəlij ədʒʌ́st ðət bəlíjf æz núw déjtə ɔr ɛ́vɪdəns kʌ́mz ɪn. θɪ́ŋk əv ɪt æz ʌ́pdèjtɪŋ jɔr ʌ̀ndərstǽndɪŋ stɛ́p baj stɛ́p æz juw lɜ́rn mɔr, əláwɪŋ juw tə méjk ɪnkríjsɪŋɡlij ǽkjərət prədɪ́kʃənz ənd dəsɪ́ʒənz. ɪt kɒ́ntræs wɪð əprówtʃɪz ðət tríjt déjtə ɪn àjsəléjʃən wɪðáwt əksplɪ́sɪtlij ʌ́pdèjtɪŋ prájər bəlíjfs."
    },
    {
        "Question": "In machine learning, what technique helps an agent make smart decisions by choosing actions based purely on its current state, without worrying about past states, to maximize rewards in uncertain environments?",
        "RightAnswer": "Markov Decision Processes",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Gradient Descent",
            "Support Vector Machines",
            "Principal Component Analysis",
            "Recurrent Neural Networks"
        ],
        "Explanation": "Markov Decision Processes (MDPs) are a framework used in machine learning, especially in reinforcement learning, where an agent makes choices based only on its current situation—without being influenced directly by past events—and receives rewards or penalties for its decisions. Over time, the agent learns the best strategy to maximize its total rewards in uncertain scenarios, becoming smarter and more effective in decision-making.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tɛkníjk hɛ́lps ən éjdʒənt méjk smɑ́rt dəsɪ́ʒənz baj tʃúwzɪŋ ǽkʃənz béjst pjʊ́rlij ɒn ɪts kɑ́rənt stéjt, wɪðáwt wɜ́rijɪŋ əbawt pǽst stéjts, tə mǽksɪmàjz rəwɔ́rdz ɪn ʌ̀nsɜ́rtən ənvájərənmənts?",
        "trans_RightAnswer": "mɑ́rkowv dəsɪ́ʒən prɒ́sɛsɪz",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "ɡréjdijənt dəsɛ́nt",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "mɑ́rkowv dəsɪ́ʒən prɒ́sɛsɪz (ɛm) ɑr ə fréjmwɜ̀rk júwzd ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɛ́ər ən éjdʒənt méjks tʃɔ́jsɪz béjst ównlij ɒn ɪts kɑ́rənt sɪ̀tʃuwéjʃən—wɪðáwt bíjɪŋ ɪ́nfluwənst dɪərɛ́klij baj pǽst əvɛ́nts—ənd rəsíjvz rəwɔ́rdz ɔr pɛ́nəltijz fɔr ɪts dəsɪ́ʒənz. ówvər tájm, ðə éjdʒənt lɜ́rnz ðə bɛ́st strǽtədʒij tə mǽksɪmàjz ɪts tówtəl rəwɔ́rdz ɪn ʌ̀nsɜ́rtən sənɛ́ərijowz, bəkʌ́mɪŋ smɑ́rtər ənd mɔr əféktɪv ɪn dəsɪ́ʒən-méjkɪŋ."
    },
    {
        "Question": "In machine learning, suppose you have a complex problem that's hard to solve exactly, and you decide to tackle it by running lots of random simulations, averaging their outcomes to approximate a good solution. What is this approach called?",
        "RightAnswer": "Monte Carlo Methods",
        "WrongAnswers": [
            "Gradient Descent",
            "Random Forests",
            "K-Means Clustering",
            "Decision Tree Learning",
            "Neural Network Optimization"
        ],
        "Explanation": "Monte Carlo methods are clever techniques where you repeatedly run random experiments or simulations to estimate solutions for problems too complex for precise, deterministic methods. Think of it as repeatedly rolling dice to figure out odds, but applied to more complex scenarios in AI and machine learning. By averaging the results of many random simulations, Monte Carlo methods can find surprisingly accurate approximations to super tough problems.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, səpówz juw həv ə kɒ́mplɛks prɒ́bləm ðət's hɑ́rd tə sɒ́lv əɡzǽktlij, ənd juw dəsájd tə tǽkəl ɪt baj rʌ́nɪŋ lɒ́ts əv rǽndəm sɪ̀mjəléjʃənz, ǽvrɪdʒɪŋ ðɛər áwtkʌ̀mz tə əprɒ́ksəmèjt ə ɡʊ́d səlúwʃən. wɒt ɪz ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "mɒ́ntij kɑ́rlow mɛ́θədz",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "rǽndəm fɔ́rəsts",
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríj lɜ́rnɪŋ",
            "nʊ́rəl nɛ́twɜ̀rk ɒptɪmɪzéjʃən"
        ],
        "trans_Explanation": "mɒ́ntij kɑ́rlow mɛ́θədz ɑr klɛ́vər tɛkníjks wɛ́ər juw rəpíjtɪdlij rʌ́n rǽndəm əkspɛ́ərɪmənts ɔr sɪ̀mjəléjʃənz tə ɛ́stɪmèjt səlúwʃənz fɔr prɒ́bləmz túw kɒ́mplɛks fɔr prəsájs, dətɜ̀rmɪnɪ́stɪk mɛ́θədz. θɪ́ŋk əv ɪt æz rəpíjtɪdlij rówlɪŋ dájs tə fɪ́ɡjər awt ɒ́dz, bʌt əplájd tə mɔr kɒ́mplɛks sənɛ́ərijowz ɪn AI ənd məʃíjn lɜ́rnɪŋ. baj ǽvrɪdʒɪŋ ðə rəzʌ́lts əv mɛ́nij rǽndəm sɪ̀mjəléjʃənz, mɒ́ntij kɑ́rlow mɛ́θədz kən fájnd sərprájzɪŋlij ǽkjərət əprɒ̀ksəméjʃənz tə súwpər tʌ́f prɒ́bləmz."
    },
    {
        "Question": "Which machine learning approach imitates natural selection and evolution by repeatedly combining and modifying potential solutions to solve complex problems?",
        "RightAnswer": "Genetic Algorithms",
        "WrongAnswers": [
            "Gradient Descent",
            "K-Means Clustering",
            "Decision Trees",
            "Support Vector Machines",
            "Random Forests"
        ],
        "Explanation": "Genetic Algorithms are inspired by the biological process of evolution and natural selection. Just like nature combines and tweaks genetic material to evolve species, genetic algorithms imitate this process by repeatedly mixing, mutating, and selecting the best-performing 'solutions'. They help computers efficiently find answers to tricky problems by evolving towards better solutions over time.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ ɪ́mɪtèjts nǽtʃərəl səlɛ́kʃən ənd ɛ̀vəlúwʃən baj rəpíjtɪdlij kəmbájnɪŋ ənd mɒ́dɪfàjɪŋ pətɛ́nʃəl səlúwʃənz tə sɒ́lv kɒ́mplɛks prɒ́bləmz?",
        "trans_RightAnswer": "dʒənɛ́tɪk ǽlɡərɪ̀ðəmz",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "rǽndəm fɔ́rəsts"
        ],
        "trans_Explanation": "dʒənɛ́tɪk ǽlɡərɪ̀ðəmz ɑr ɪnspájərd baj ðə bàjəlɒ́dʒɪkəl prɒ́sɛs əv ɛ̀vəlúwʃən ənd nǽtʃərəl səlɛ́kʃən. dʒəst lájk néjtʃər kəmbájnz ənd twíjks dʒənɛ́tɪk mətɪ́ərijəl tə əvɒ́lv spíjʃijz, dʒənɛ́tɪk ǽlɡərɪ̀ðəmz ɪ́mɪtèjt ðɪs prɒ́sɛs baj rəpíjtɪdlij mɪ́ksɪŋ, mjúwtejtɪŋ, ənd səlɛ́ktɪŋ ðə bɛ́st-pərfɔ́rmɪŋ 'səlúwʃənz'. ðej hɛ́lp kəmpjúwtərz əfɪ́ʃəntlij fájnd ǽnsərz tə trɪ́kij prɒ́bləmz baj əvɒ́lvɪŋ təwɔ́rdz bɛ́tər səlúwʃənz ówvər tájm."
    },
    {
        "Question": "Which machine learning technique takes inspiration from biological concepts like mutation, selection, and survival of the fittest, gradually finding solutions to complex problems by evolving over several generations?",
        "RightAnswer": "Evolutionary Algorithms",
        "WrongAnswers": [
            "Gradient Descent Algorithms",
            "Rule-Based Systems",
            "Bayesian Networks",
            "Clustering Algorithms",
            "Markov Decision Processes"
        ],
        "Explanation": "Evolutionary algorithms are a fascinating family of algorithms in machine learning inspired by biological evolution. They simulate concepts like mutation, selection, and crossover—essentially survival of the fittest—to iteratively improve solutions to difficult problems. Think of it like 'breeding' solutions generation after generation, where each round only the best-suited candidates survive and create new, potentially stronger offspring solutions.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk téjks ɪnspəréjʃən frəm bàjəlɒ́dʒɪkəl kɒ́nsɛpts lájk mjuwtéjʃən, səlɛ́kʃən, ənd sərvájvəl əv ðə fɪ́təst, ɡrǽdʒuwəlij fájndɪŋ səlúwʃənz tə kɒ́mplɛks prɒ́bləmz baj əvɒ́lvɪŋ ówvər sɛ́vərəl dʒɛ̀nəréjʃənz?",
        "trans_RightAnswer": "ɛ̀vəlúwʃənɛ̀ərij ǽlɡərɪ̀ðəmz",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt ǽlɡərɪ̀ðəmz",
            "rúwl-béjst sɪ́stəmz",
            "béjʒən nɛ́twɜ̀rks",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz",
            "mɑ́rkowv dəsɪ́ʒən prɒ́sɛsɪz"
        ],
        "trans_Explanation": "ɛ̀vəlúwʃənɛ̀ərij ǽlɡərɪ̀ðəmz ɑr ə fǽsɪnèjtɪŋ fǽmɪlij əv ǽlɡərɪ̀ðəmz ɪn məʃíjn lɜ́rnɪŋ ɪnspájərd baj bàjəlɒ́dʒɪkəl ɛ̀vəlúwʃən. ðej sɪ́mjəlèjt kɒ́nsɛpts lájk mjuwtéjʃən, səlɛ́kʃən, ənd krɔ́sòwvər—əsɛ́nʃəlij sərvájvəl əv ðə fɪ́təst—tə ɪ́tərətɪvlij ɪmprúwv səlúwʃənz tə dɪ́fɪkəlt prɒ́bləmz. θɪ́ŋk əv ɪt lájk 'bríjdɪŋ' səlúwʃənz dʒɛ̀nəréjʃən ǽftər dʒɛ̀nəréjʃən, wɛ́ər ijtʃ ráwnd ównlij ðə bɛ́st-súwtɪd kǽndɪdejts sərvájv ənd krijéjt núw, pətɛ́nʃəlij strɔ́ŋər ɔ́fsprɪ̀ŋ səlúwʃənz."
    },
    {
        "Question": "When developing a machine learning model, you notice it's performing decently but you sense it could do better with some adjustments. To boost performance and find the ideal settings, you systematically experiment by adjusting variables like learning rate, batch size, or number of layers. What is this process called?",
        "RightAnswer": "Hyperparameter Tuning",
        "WrongAnswers": [
            "Feature Extraction",
            "Gradient Descent",
            "Data Preprocessing",
            "Model Validation",
            "Regularization"
        ],
        "Explanation": "Hyperparameter tuning is the process of carefully experimenting with various 'settings' (also called hyperparameters) of a machine learning algorithm—such as the learning rate, the size of hidden layers, or the training batch size—to find the combination that generates the best results for your model. Think of it like adjusting knobs on a radio—you're trying to find the settings that give you the clearest signal, or in this case, the most accurate predictions. It's a key step for obtaining peak performance from machine learning models.",
        "trans_Question": "wɛ́n dəvɛ́ləpɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, juw nówtɪs ɪt's pərfɔ́rmɪŋ díjsəntlij bʌt juw sɛ́ns ɪt kʊ́d dúw bɛ́tər wɪð sʌm ədʒʌ́stmənts. tə búwst pərfɔ́rməns ənd fájnd ðə ajdíjəl sɛ́tɪŋz, juw sɪ̀stəmǽtɪklij əkspɛ́ərɪmənt baj ədʒʌ́stɪŋ vɛ́ərijəbəlz lájk lɜ́rnɪŋ réjt, bǽtʃ sájz, ɔr nʌ́mbər əv léjərz. wɒt ɪz ðɪs prɒ́sɛs kɔ́ld?",
        "trans_RightAnswer": "hàjpərpǽrəmətər túwnɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "déjtə prìjprʌ́ʊsɛsɪŋ",
            "mɒ́dəl væ̀lɪdéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "hàjpərpǽrəmətər túwnɪŋ ɪz ðə prɒ́sɛs əv kɛ́ərfəlij əkspɛ́ərɪmɛ̀ntɪŋ wɪð vɛ́ərijəs 'sɛ́tɪŋz' (ɔ́lsow kɔ́ld hàjpərpǽrəmətərz) əv ə məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm—sʌtʃ æz ðə lɜ́rnɪŋ réjt, ðə sájz əv hɪ́dən léjərz, ɔr ðə tréjnɪŋ bǽtʃ sájz—tə fájnd ðə kɒ̀mbɪnéjʃən ðət dʒɛ́nərèjts ðə bɛ́st rəzʌ́lts fɔr jɔr mɒ́dəl. θɪ́ŋk əv ɪt lájk ədʒʌ́stɪŋ nɒ́bz ɒn ə réjdijòw—júwr trájɪŋ tə fájnd ðə sɛ́tɪŋz ðət ɡɪ́v juw ðə klɪ́ərəst sɪ́ɡnəl, ɔr ɪn ðɪs kéjs, ðə mówst ǽkjərət prədɪ́kʃənz. ɪt's ə kíj stɛ́p fɔr əbtéjnɪŋ píjk pərfɔ́rməns frəm məʃíjn lɜ́rnɪŋ mɒ́dəlz."
    },
    {
        "Question": "When you're training a machine learning model and want to figure out the best combination of hyperparameters (like learning rate, depth, etc.) by systematically evaluating every possible combination, what is this method called?",
        "RightAnswer": "Grid Search",
        "WrongAnswers": [
            "Random Sampling",
            "Gradient Descent",
            "Feature Engineering",
            "Cross Validation",
            "Regularization"
        ],
        "Explanation": "Grid Search is like running a thorough, organized sweep through every combination of settings (hyperparameters) to find the 'sweet spot' that makes your machine learning model perform best. Imagine having a grid with different hyperparameter values, and carefully testing each and every combination. It's straightforward and comprehensive, helping you pinpoint exactly which configuration works best.",
        "trans_Question": "wɛ́n júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ənd wɒ́nt tə fɪ́ɡjər awt ðə bɛ́st kɒ̀mbɪnéjʃən əv hàjpərpǽrəmətərz (lájk lɜ́rnɪŋ réjt, dɛ́pθ, ɛ̀tsɛ́tərə.) baj sɪ̀stəmǽtɪklij əvǽljuwèjtɪŋ ɛvərij pɒ́sɪbəl kɒ̀mbɪnéjʃən, wɒt ɪz ðɪs mɛ́θəd kɔ́ld?",
        "trans_RightAnswer": "ɡrɪ́d sɜ́rtʃ",
        "trans_WrongAnswers": [
            "rǽndəm sǽmplɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "krɔ́s væ̀lɪdéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "ɡrɪ́d sɜ́rtʃ ɪz lájk rʌ́nɪŋ ə θɜ́row, ɔ́rɡənàjzd swíjp θrúw ɛvərij kɒ̀mbɪnéjʃən əv sɛ́tɪŋz (hàjpərpǽrəmətərz) tə fájnd ðə 'swíjt spɒ́t' ðət méjks jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl pərfɔ́rm bɛ́st. ɪmǽdʒɪn hǽvɪŋ ə ɡrɪ́d wɪð dɪ́fərənt hàjpərpǽrəmətər vǽljuwz, ənd kɛ́ərfəlij tɛ́stɪŋ ijtʃ ənd ɛvərij kɒ̀mbɪnéjʃən. ɪt's stréjtfɔ́rwərd ənd kɒ̀mprəhɛ́nsɪv, hɛ́lpɪŋ juw pɪ́npɔ̀jnt əɡzǽktlij wɪ́tʃ kənfɪ̀ɡjəréjʃən wɜ́rks bɛ́st."
    },
    {
        "Question": "Imagine you're searching for the best settings for a complex machine learning model, and since there are a ton of possible options, you decide to try various options completely at random to find the optimal combination. What approach are you using?",
        "RightAnswer": "Random Search",
        "WrongAnswers": [
            "Grid Search",
            "Gradient Descent",
            "Bayesian Optimization",
            "Cross-validation",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Random Search is like trying different spices randomly while cooking, hoping to discover the perfect flavor combination. In machine learning, it's an approach where you randomly sample combinations of settings (hyperparameters) to find the set that best improves model performance. While it sounds basic compared to meticulous methods like Grid Search, Random Search can often discover effective setups faster, especially when dealing with many hyperparameters.",
        "trans_Question": "ɪmǽdʒɪn júwr sɜ́rtʃɪŋ fɔr ðə bɛ́st sɛ́tɪŋz fɔr ə kɒ́mplɛks məʃíjn lɜ́rnɪŋ mɒ́dəl, ənd sɪns ðɛər ɑr ə tʌ́n əv pɒ́sɪbəl ɒ́pʃənz, juw dəsájd tə tráj vɛ́ərijəs ɒ́pʃənz kəmplíjtlij æt rǽndəm tə fájnd ðə ɒ́ptɪməl kɒ̀mbɪnéjʃən. wɒt əprówtʃ ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "rǽndəm sɜ́rtʃ",
        "trans_WrongAnswers": [
            "ɡrɪ́d sɜ́rtʃ",
            "ɡréjdijənt dəsɛ́nt",
            "béjʒən ɒptɪmɪzéjʃən",
            "krɔ́s-væ̀lɪdéjʃən",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "rǽndəm sɜ́rtʃ ɪz lájk trájɪŋ dɪ́fərənt spájsɪz rǽndəmlij wájl kʊ́kɪŋ, hówpɪŋ tə dɪskʌ́vər ðə pɜ́rfəkt fléjvər kɒ̀mbɪnéjʃən. ɪn məʃíjn lɜ́rnɪŋ, ɪt's ən əprówtʃ wɛ́ər juw rǽndəmlij sǽmpəl kɒ̀mbɪnéjʃənz əv sɛ́tɪŋz (hàjpərpǽrəmətərz) tə fájnd ðə sɛ́t ðət bɛ́st ɪmprúwvz mɒ́dəl pərfɔ́rməns. wájl ɪt sáwndz béjsɪk kəmpɛ́ərd tə mətɪ́kjələs mɛ́θədz lájk ɡrɪ́d sɜ́rtʃ, rǽndəm sɜ́rtʃ kən ɔ́fən dɪskʌ́vər əféktɪv sɛ́tʌ̀ps fǽstər, əspɛ́ʃəlij wɛ́n díjlɪŋ wɪð mɛ́nij hàjpərpǽrəmətərz."
    },
    {
        "Question": "You're developing a new machine learning model, but training it is slow because there are many hyperparameters to tune. You decide to use a clever strategy that constructs a probabilistic model of your experiment results and helps intelligently guess the best combinations to test next. Which method are you using?",
        "RightAnswer": "Bayesian Optimization",
        "WrongAnswers": [
            "Grid Search",
            "Gradient Descent",
            "Randomized Search",
            "K-means Clustering",
            "Early Stopping"
        ],
        "Explanation": "Bayesian Optimization is like having a smart assistant who keeps track of how different hyperparameter choices performed in past experiments, building a probabilistic model to intelligently pick the most promising sets of parameters to test next. This method efficiently narrows down hyperparameter tuning, leading you more quickly to the best settings for your machine learning model.",
        "trans_Question": "júwr dəvɛ́ləpɪŋ ə núw məʃíjn lɜ́rnɪŋ mɒ́dəl, bʌt tréjnɪŋ ɪt ɪz slów bəkɒ́z ðɛər ɑr mɛ́nij hàjpərpǽrəmətərz tə túwn. juw dəsájd tə juwz ə klɛ́vər strǽtədʒij ðət kɒ́nstrəkts ə prɒ̀bəbɪlɪ́stɪk mɒ́dəl əv jɔr əkspɛ́ərɪmənt rəzʌ́lts ənd hɛ́lps ɪntɛ́lɪdʒəntlij ɡɛ́s ðə bɛ́st kɒ̀mbɪnéjʃənz tə tɛ́st nɛ́kst. wɪ́tʃ mɛ́θəd ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "béjʒən ɒptɪmɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡrɪ́d sɜ́rtʃ",
            "ɡréjdijənt dəsɛ́nt",
            "rǽndəmàjzd sɜ́rtʃ",
            "k-míjnz klʌ́stərɪŋ",
            "ɜ́rlij stɒ́pɪŋ"
        ],
        "trans_Explanation": "béjʒən ɒptɪmɪzéjʃən ɪz lájk hǽvɪŋ ə smɑ́rt əsɪ́stənt huw kíjps trǽk əv háw dɪ́fərənt hàjpərpǽrəmətər tʃɔ́jsɪz pərfɔ́rmd ɪn pǽst əkspɛ́ərɪmənts, bɪ́ldɪŋ ə prɒ̀bəbɪlɪ́stɪk mɒ́dəl tə ɪntɛ́lɪdʒəntlij pɪ́k ðə mówst prɒ́mɪsɪŋ sɛ́ts əv pərǽmətərz tə tɛ́st nɛ́kst. ðɪs mɛ́θəd əfɪ́ʃəntlij nǽrowz dawn hàjpərpǽrəmətər túwnɪŋ, líjdɪŋ juw mɔr kwɪ́klij tə ðə bɛ́st sɛ́tɪŋz fɔr jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl."
    },
    {
        "Question": "In machine learning, when you're training your model, how do you measure how far off your predictions are from reality, helping you decide how to improve the model?",
        "RightAnswer": "Cost Function",
        "WrongAnswers": [
            "Activation Function",
            "Gradient Descent",
            "Feature Scaling",
            "Overfitting",
            "Bias Term"
        ],
        "Explanation": "Think of the 'Cost Function' as a helpful judge that measures how accurate your model's predictions are. It calculates the difference between what your model predicts and the actual outcomes. If this function gives you a low result, your model is doing great! If it's high, that means your model needs more fine-tuning. It acts like a friendly guide that points your training process in the right direction.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n júwr tréjnɪŋ jɔr mɒ́dəl, háw dúw juw mɛ́ʒər háw fɑ́r ɔ́f jɔr prədɪ́kʃənz ɑr frəm rìjǽlɪtij, hɛ́lpɪŋ juw dəsájd háw tə ɪmprúwv ðə mɒ́dəl?",
        "trans_RightAnswer": "kɒ́st fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "fíjtʃər skéjlɪŋ",
            "òwvərfɪ́tɪŋ",
            "bájəs tɜ́rm"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə 'kɒ́st fʌ́ŋkʃən' æz ə hɛ́lpfəl dʒʌ́dʒ ðət mɛ́ʒərz háw ǽkjərət jɔr mɒ́dəl'z prədɪ́kʃənz ɑr. ɪt kǽlkjəlèjts ðə dɪ́fərəns bijtwíjn wɒt jɔr mɒ́dəl prədɪ́kts ənd ðə ǽktʃəl áwtkʌ̀mz. ɪf ðɪs fʌ́ŋkʃən ɡɪ́vz juw ə lów rəzʌ́lt, jɔr mɒ́dəl ɪz dúwɪŋ ɡréjt! ɪf ɪt's háj, ðət míjnz jɔr mɒ́dəl níjdz mɔr fájn-túwnɪŋ. ɪt ǽkts lájk ə frɛ́ndlij ɡájd ðət pɔ́jnts jɔr tréjnɪŋ prɒ́sɛs ɪn ðə rájt dɪərɛ́kʃən."
    },
    {
        "Question": "In machine learning, when training a model, we need a way to measure how incorrect or off-target the model’s predictions are. What do we call the function specifically designed to quantify these prediction errors and guide the training?",
        "RightAnswer": "Loss Function",
        "WrongAnswers": [
            "Activation Function",
            "Gradient Descent",
            "Overfitting Measure",
            "Feature Scaling",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Think of a loss function as a ‘scorecard’ that assesses how well a machine learning model is doing at making accurate predictions. It calculates the level of error or difference between predicted values and actual results. By adjusting the model to minimize this loss, we gently nudge the model towards making more accurate predictions in the future.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n tréjnɪŋ ə mɒ́dəl, wij níjd ə wej tə mɛ́ʒər háw ɪ̀nkərɛ́kt ɔr ɔ́f-tɑ́rɡət ðə mɒ́dəl'z prədɪ́kʃənz ɑr. wɒt dúw wij kɔ́l ðə fʌ́ŋkʃən spəsɪ́fɪklij dəzájnd tə kwɑ́ntᵻfàj ðijz prədɪ́kʃən ɛ́ərərz ənd ɡájd ðə tréjnɪŋ?",
        "trans_RightAnswer": "lɔ́s fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ mɛ́ʒər",
            "fíjtʃər skéjlɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "θɪ́ŋk əv ə lɔ́s fʌ́ŋkʃən æz ə ‘skɔ́rkɑ̀rd’ ðət əsɛ́sɪz háw wɛ́l ə məʃíjn lɜ́rnɪŋ mɒ́dəl ɪz dúwɪŋ æt méjkɪŋ ǽkjərət prədɪ́kʃənz. ɪt kǽlkjəlèjts ðə lɛ́vəl əv ɛ́ərər ɔr dɪ́fərəns bijtwíjn prədɪ́ktɪd vǽljuwz ənd ǽktʃəl rəzʌ́lts. baj ədʒʌ́stɪŋ ðə mɒ́dəl tə mɪ́nɪmàjz ðɪs lɔ́s, wij dʒɛ́ntlij nʌ́dʒ ðə mɒ́dəl təwɔ́rdz méjkɪŋ mɔr ǽkjərət prədɪ́kʃənz ɪn ðə fjúwtʃər."
    },
    {
        "Question": "When training a machine learning model, sometimes it becomes overly sensitive and tries too hard to fit every tiny detail of the training data, missing the bigger patterns. Which one of the following techniques helps to gently guide the model away from this overly-specific behavior, keeping it simple and generalizable?",
        "RightAnswer": "Regularization",
        "WrongAnswers": [
            "Gradient Descent",
            "Feature Scaling",
            "Cross-validation",
            "Clustering",
            "Dimensionality Reduction"
        ],
        "Explanation": "Regularization is like giving your model a friendly nudge that discourages it from becoming overly complicated. It adds a bit of extra structure or constraints to the training process, gently encouraging simpler patterns and preventing the model from fitting every little bit of noise. This helps the model perform better when facing new, unseen data.",
        "trans_Question": "wɛ́n tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, sʌ́mtàjmz ɪt bəkʌ́mz ówvərlij sɛ́nsɪtɪv ənd trájz túw hɑ́rd tə fɪ́t ɛvərij tájnij díjtejl əv ðə tréjnɪŋ déjtə, mɪ́sɪŋ ðə bɪ́ɡər pǽtərnz. wɪ́tʃ wʌ́n əv ðə fɒ́lowɪŋ tɛkníjks hɛ́lps tə dʒɛ́ntlij ɡájd ðə mɒ́dəl əwéj frəm ðɪs ówvərlij-spəsɪ́fɪk bəhéjvjər, kíjpɪŋ ɪt sɪ́mpəl ənd dʒɛ́nrəlàjzəbəl?",
        "trans_RightAnswer": "rèɡjəlɛ̀ərɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "fíjtʃər skéjlɪŋ",
            "krɔ́s-væ̀lɪdéjʃən",
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "rèɡjəlɛ̀ərɪzéjʃən ɪz lájk ɡɪ́vɪŋ jɔr mɒ́dəl ə frɛ́ndlij nʌ́dʒ ðət dɪskɜ́rɪdʒɪz ɪt frəm bəkʌ́mɪŋ ówvərlij kɒ́mplɪkèjtɪd. ɪt ǽdz ə bɪ́t əv ɛ́kstrə strʌ́ktʃər ɔr kənstréjnts tə ðə tréjnɪŋ prɒ́sɛs, dʒɛ́ntlij ənkɜ́rɪdʒɪŋ sɪ́mplər pǽtərnz ənd prəvɛ́ntɪŋ ðə mɒ́dəl frəm fɪ́tɪŋ ɛvərij lɪ́təl bɪ́t əv nɔ́jz. ðɪs hɛ́lps ðə mɒ́dəl pərfɔ́rm bɛ́tər wɛ́n féjsɪŋ núw, ʌ̀nsíjn déjtə."
    },
    {
        "Question": "In machine learning, often models might become too complex, capturing noise rather than meaningful patterns. To simplify the model by encouraging it to focus only on the most important features—effectively making less important ones drop out—which regularization technique can we use?",
        "RightAnswer": "L1 Regularization",
        "WrongAnswers": [
            "L2 Regularization",
            "Dropout",
            "Early Stopping",
            "Batch Normalization",
            "Data Augmentation"
        ],
        "Explanation": "L1 Regularization is like a strict coach for your machine learning model—it penalizes complexity by directly pushing less important features towards zero, effectively 'dropping' irrelevant or redundant features entirely. It helps create simpler, clearer models by keeping only the most significant factors that actually matter for predictions.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ɔ́fən mɒ́dəlz majt bəkʌ́m túw kɒ́mplɛks, kǽptʃərɪŋ nɔ́jz rǽðər ðʌn míjnɪŋfəl pǽtərnz. tə sɪ́mpləfaj ðə mɒ́dəl baj ənkɜ́rɪdʒɪŋ ɪt tə fówkəs ównlij ɒn ðə mówst ɪmpɔ́rtənt fíjtʃərz—əfɛ́ktɪvlij méjkɪŋ lɛ́s ɪmpɔ́rtənt wʌ́nz drɒ́p awt—wɪ́tʃ rèɡjəlɛ̀ərɪzéjʃən tɛkníjk kən wij juwz?",
        "trans_RightAnswer": "L1 rèɡjəlɛ̀ərɪzéjʃən",
        "trans_WrongAnswers": [
            "L2 rèɡjəlɛ̀ərɪzéjʃən",
            "drɒ́pàwt",
            "ɜ́rlij stɒ́pɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "L1 rèɡjəlɛ̀ərɪzéjʃən ɪz lájk ə strɪ́kt kówtʃ fɔr jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl—ɪt pɛ́nəlàjzɪz kəmplɛ́ksɪtij baj dɪərɛ́klij pʊ́ʃɪŋ lɛ́s ɪmpɔ́rtənt fíjtʃərz təwɔ́rdz zíjərow, əfɛ́ktɪvlij 'drɒ́pɪŋ' ɪ̀ərɛ́ləvənt ɔr rədʌ́ndənt fíjtʃərz əntájərlij. ɪt hɛ́lps krijéjt sɪ́mplər, klɪ́ərər mɒ́dəlz baj kíjpɪŋ ównlij ðə mówst sɪɡnɪ́fɪkənt fǽktərz ðət ǽktʃùwəlij mǽtər fɔr prədɪ́kʃənz."
    },
    {
        "Question": "When training machine learning models, sometimes your model can fit training data a little too well, causing poor results on new data. To address this, which method smoothly penalizes larger weights by adding the squared magnitude of parameters to the loss function, encouraging simpler models?",
        "RightAnswer": "L2 Regularization",
        "WrongAnswers": [
            "L1 Regularization",
            "Dropout",
            "Early Stopping",
            "Batch Normalization",
            "Gradient Clipping"
        ],
        "Explanation": "L2 Regularization is like gently nudging your machine learning model to avoid overly complex solutions. It does this by adding a penalty term based on the squared size (or 'magnitude') of your model's parameters. This encourages smoother, simpler models that are less likely to memorize noise in the training data, resulting in better generalization to unseen data.",
        "trans_Question": "wɛ́n tréjnɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz, sʌ́mtàjmz jɔr mɒ́dəl kən fɪ́t tréjnɪŋ déjtə ə lɪ́təl túw wɛ́l, kɒ́zɪŋ pɔ́r rəzʌ́lts ɒn núw déjtə. tə æ̀drɛ́s ðɪs, wɪ́tʃ mɛ́θəd smúwðlij pɛ́nəlàjzɪz lɑ́rdʒər wéjts baj ǽdɪŋ ðə skwɛ́ərd mǽɡnɪtùwd əv pərǽmətərz tə ðə lɔ́s fʌ́ŋkʃən, ənkɜ́rɪdʒɪŋ sɪ́mplər mɒ́dəlz?",
        "trans_RightAnswer": "L2 rèɡjəlɛ̀ərɪzéjʃən",
        "trans_WrongAnswers": [
            "L1 rèɡjəlɛ̀ərɪzéjʃən",
            "drɒ́pàwt",
            "ɜ́rlij stɒ́pɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt klɪ́pɪŋ"
        ],
        "trans_Explanation": "L2 rèɡjəlɛ̀ərɪzéjʃən ɪz lájk dʒɛ́ntlij nʌ́dʒɪŋ jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl tə əvɔ́jd ówvərlij kɒ́mplɛks səlúwʃənz. ɪt dʌz ðɪs baj ǽdɪŋ ə pɛ́nəltij tɜ́rm béjst ɒn ðə skwɛ́ərd sájz (ɔr 'mǽɡnɪtùwd') əv jɔr mɒ́dəl'z pərǽmətərz. ðɪs ənkɜ́rɪdʒɪz smúwðər, sɪ́mplər mɒ́dəlz ðət ɑr lɛ́s lájklij tə mɛ́məràjz nɔ́jz ɪn ðə tréjnɪŋ déjtə, rəzʌ́ltɪŋ ɪn bɛ́tər dʒɛ̀nərəlɪzéjʃən tə ʌ̀nsíjn déjtə."
    },
    {
        "Question": "During training your neural network, you notice it quickly memorizes the training data perfectly but struggles with new, unseen data. You decide to randomly remove some neurons temporarily during training to prevent your network from relying too much on particular connections. What is this machine learning method called?",
        "RightAnswer": "Dropout",
        "WrongAnswers": [
            "Early stopping",
            "Batch normalization",
            "Gradient descent",
            "Data augmentation",
            "Regularization"
        ],
        "Explanation": "Dropout is a technique commonly used in training neural networks where individual neurons are randomly turned off or 'dropped out' temporarily. By forcing the network to operate without relying too heavily on particular neurons, dropout helps your model become more robust, preventing it from memorizing training examples and improving its ability to generalize to new, unseen data.",
        "trans_Question": "dʊ́rɪŋ tréjnɪŋ jɔr nʊ́rəl nɛ́twɜ̀rk, juw nówtɪs ɪt kwɪ́klij mɛ́məràjzɪz ðə tréjnɪŋ déjtə pɜ́rfəktlij bʌt strʌ́ɡəlz wɪð núw, ʌ̀nsíjn déjtə. juw dəsájd tə rǽndəmlij rijmúwv sʌm nʊ́rɒnz tɛ̀mpərɛ́ərɪlij dʊ́rɪŋ tréjnɪŋ tə prəvɛ́nt jɔr nɛ́twɜ̀rk frəm rəlájɪŋ túw mʌtʃ ɒn pərtɪ́kjələr kənɛ́kʃənz. wɒt ɪz ðɪs məʃíjn lɜ́rnɪŋ mɛ́θəd kɔ́ld?",
        "trans_RightAnswer": "drɒ́pàwt",
        "trans_WrongAnswers": [
            "ɜ́rlij stɒ́pɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "drɒ́pàwt ɪz ə tɛkníjk kɒ́mənlij júwzd ɪn tréjnɪŋ nʊ́rəl nɛ́twɜ̀rks wɛ́ər ɪndɪvɪ́dʒəwəl nʊ́rɒnz ɑr rǽndəmlij tɜ́rnd ɔ́f ɔr 'drɒ́pt awt' tɛ̀mpərɛ́ərɪlij. baj fɔ́rsɪŋ ðə nɛ́twɜ̀rk tə ɒ́pərèjt wɪðáwt rəlájɪŋ túw hɛ́vɪlij ɒn pərtɪ́kjələr nʊ́rɒnz, drɒ́pàwt hɛ́lps jɔr mɒ́dəl bəkʌ́m mɔr rowbʌ́st, prəvɛ́ntɪŋ ɪt frəm mɛ́məràjzɪŋ tréjnɪŋ əɡzǽmpəlz ənd ɪmprúwvɪŋ ɪts əbɪ́lɪtij tə dʒɛ́nərəlàjz tə núw, ʌ̀nsíjn déjtə."
    },
    {
        "Question": "In a neural network, what's the special mechanism that decides whether or not to 'light up' neurons, adding complexity and non-linearity to the network?",
        "RightAnswer": "Activation Function",
        "WrongAnswers": [
            "Gradient Descent",
            "Loss Function",
            "Backpropagation",
            "Feature Scaling",
            "Overfitting"
        ],
        "Explanation": "An activation function is like the 'on-off' or dimming switch for neurons in a neural network—it decides how much each neuron 'lights up' based on the input it receives. Without it, neural networks would behave like simple linear models and wouldn't be able to solve complex problems. Activation functions let the network learn complicated patterns, helping it approach complex problems like recognizing images or making predictions.",
        "trans_Question": "ɪn ə nʊ́rəl nɛ́twɜ̀rk, wɒt's ðə spɛ́ʃəl mɛ́kənɪzəm ðət dəsájdz wɛ́ðər ɔr nɒt tə 'lájt ʌp' nʊ́rɒnz, ǽdɪŋ kəmplɛ́ksɪtij ənd nɒn-lɪ̀nijǽrɪtij tə ðə nɛ́twɜ̀rk?",
        "trans_RightAnswer": "æ̀ktɪvéjʃən fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "lɔ́s fʌ́ŋkʃən",
            "bǽkprəpəgéjʃən",
            "fíjtʃər skéjlɪŋ",
            "òwvərfɪ́tɪŋ"
        ],
        "trans_Explanation": "ən æ̀ktɪvéjʃən fʌ́ŋkʃən ɪz lájk ðə 'ɒn-ɔ́f' ɔr dɪ́mɪŋ swɪ́tʃ fɔr nʊ́rɒnz ɪn ə nʊ́rəl nɛ́twɜ̀rk—ɪt dəsájdz háw mʌtʃ ijtʃ nʊ́rɒn 'lájts ʌp' béjst ɒn ðə ɪ́npʊ̀t ɪt rəsíjvz. wɪðáwt ɪt, nʊ́rəl nɛ́twɜ̀rks wʊd bəhéjv lájk sɪ́mpəl lɪ́nijər mɒ́dəlz ənd wʊ́dənt bij éjbəl tə sɒ́lv kɒ́mplɛks prɒ́bləmz. æ̀ktɪvéjʃən fʌ́ŋkʃənz lɛt ðə nɛ́twɜ̀rk lɜ́rn kɒ́mplɪkèjtɪd pǽtərnz, hɛ́lpɪŋ ɪt əprówtʃ kɒ́mplɛks prɒ́bləmz lájk rɛ́kəɡnàjzɪŋ ɪ́mɪdʒɪz ɔr méjkɪŋ prədɪ́kʃənz."
    },
    {
        "Question": "Which term describes a mathematical function often used in machine learning, especially neural networks, that smoothly converts input values into a range between 0 and 1, helping the model predict probabilities?",
        "RightAnswer": "Sigmoid Function",
        "WrongAnswers": [
            "Gradient Descent",
            "Hyperparameter Tuning",
            "Decision Tree",
            "Linear Regression",
            "Confusion Matrix"
        ],
        "Explanation": "A sigmoid function is like squeezing all your numbers into a range between 0 and 1, turning complicated values into clear probabilities. In machine learning, especially neural networks, sigmoid functions help models decide whether something belongs to one category or another by smoothly rounding off predictions.",
        "trans_Question": "wɪ́tʃ tɜ́rm dəskrájbz ə mæ̀θəmǽtɪkəl fʌ́ŋkʃən ɔ́fən júwzd ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij nʊ́rəl nɛ́twɜ̀rks, ðət smúwðlij kɒ́nvərts ɪ́npʊ̀t vǽljuwz ɪntə ə réjndʒ bijtwíjn 0 ənd 1, hɛ́lpɪŋ ðə mɒ́dəl prədɪ́kt prɒ̀bəbɪ́lɪtìjz?",
        "trans_RightAnswer": "sɪ́ɡmɔ̀jd fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "hàjpərpǽrəmətər túwnɪŋ",
            "dəsɪ́ʒən tríj",
            "lɪ́nijər rəɡrɛ́ʃən",
            "kənfjúwʒən méjtrɪks"
        ],
        "trans_Explanation": "ə sɪ́ɡmɔ̀jd fʌ́ŋkʃən ɪz lájk skwíjzɪŋ ɔl jɔr nʌ́mbərz ɪntə ə réjndʒ bijtwíjn 0 ənd 1, tɜ́rnɪŋ kɒ́mplɪkèjtɪd vǽljuwz ɪntə klɪ́ər prɒ̀bəbɪ́lɪtìjz. ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij nʊ́rəl nɛ́twɜ̀rks, sɪ́ɡmɔ̀jd fʌ́ŋkʃənz hɛ́lp mɒ́dəlz dəsájd wɛ́ðər sʌ́mθɪŋ bəlɔ́ŋz tə wʌ́n kǽtəɡɔ̀rij ɔr ənʌ́ðər baj smúwðlij ráwndɪŋ ɔ́f prədɪ́kʃənz."
    },
    {
        "Question": "In machine learning, which activation function is known for swiftly turning negative inputs into zeros while allowing positive inputs through unchanged, effectively making neurons make quick 'yes-or-no' decisions?",
        "RightAnswer": "ReLU",
        "WrongAnswers": [
            "Sigmoid",
            "Tanh",
            "Softmax",
            "Leaky ReLU",
            "ELU"
        ],
        "Explanation": "ReLU stands for Rectified Linear Unit. It is an activation function that's simple and efficient, helping neurons in artificial neural networks decide whether to pass along a signal (if positive) or silence it entirely (if negative). Think of ReLU like a gatekeeper—allowing positive signals through unchanged, but completely blocking out negative signals, setting them to zero. This simplicity makes neural networks faster to train and often leads to better performance.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ æ̀ktɪvéjʃən fʌ́ŋkʃən ɪz nówn fɔr swɪ́ftlij tɜ́rnɪŋ nɛ́ɡətɪv ɪ́npʊ̀ts ɪntə zɪ́ərowz wájl əláwɪŋ pɒ́zɪtɪv ɪ́npʊ̀ts θrúw ʌ̀ntʃéjndʒd, əfɛ́ktɪvlij méjkɪŋ nʊ́rɒnz méjk kwɪ́k 'jɛs-ɔr-now' dəsɪ́ʒənz?",
        "trans_RightAnswer": "RELU",
        "trans_WrongAnswers": [
            "sɪ́ɡmɔ̀jd",
            "TANH",
            "sɔ̀ftmǽks",
            "líjkij RELU",
            "ELU"
        ],
        "trans_Explanation": "RELU stǽndz fɔr rɛ́ktɪfàjd lɪ́nijər júwnɪt. ɪt ɪz ən æ̀ktɪvéjʃən fʌ́ŋkʃən ðət's sɪ́mpəl ənd əfɪ́ʃənt, hɛ́lpɪŋ nʊ́rɒnz ɪn ɑ̀rtɪfɪ́ʃəl nʊ́rəl nɛ́twɜ̀rks dəsájd wɛ́ðər tə pǽs əlɔ́ŋ ə sɪ́ɡnəl (ɪf pɒ́zɪtɪv) ɔr sájləns ɪt əntájərlij (ɪf nɛ́ɡətɪv). θɪ́ŋk əv RELU lájk ə ɡéjtkìjpər—əláwɪŋ pɒ́zɪtɪv sɪ́ɡnəlz θrúw ʌ̀ntʃéjndʒd, bʌt kəmplíjtlij blɒ́kɪŋ awt nɛ́ɡətɪv sɪ́ɡnəlz, sɛ́tɪŋ ðɛm tə zíjərow. ðɪs sɪmplɪ́sɪtij méjks nʊ́rəl nɛ́twɜ̀rks fǽstər tə tréjn ənd ɔ́fən líjdz tə bɛ́tər pərfɔ́rməns."
    },
    {
        "Question": "In neural networks, choosing the right activation function is key to effective learning. Which activation function improves the traditional Rectified Linear Unit (ReLU) by allowing small negative outputs, helping neurons stay active and avoid the issue of dying neurons?",
        "RightAnswer": "Leaky ReLU",
        "WrongAnswers": [
            "Softmax",
            "Hyperbolic Tangent (tanh)",
            "Sigmoid Function",
            "Swish Activation",
            "Softplus Activation"
        ],
        "Explanation": "Leaky ReLU is an activation function similar to the standard ReLU, but with one key difference: instead of giving zero output for negative inputs, it allows a small, proportional negative signal to pass through. This simple tweak helps neurons continue learning effectively during training, reducing the chances of them becoming inactive or 'dead.' It's like leaving the faucet dripping slightly instead of fully switching it off, ensuring a steady flow of information.",
        "trans_Question": "ɪn nʊ́rəl nɛ́twɜ̀rks, tʃúwzɪŋ ðə rájt æ̀ktɪvéjʃən fʌ́ŋkʃən ɪz kíj tə əféktɪv lɜ́rnɪŋ. wɪ́tʃ æ̀ktɪvéjʃən fʌ́ŋkʃən ɪmprúwvz ðə trədɪ́ʃənəl rɛ́ktɪfàjd lɪ́nijər júwnɪt (RELU) baj əláwɪŋ smɔ́l nɛ́ɡətɪv áwtpʊ̀ts, hɛ́lpɪŋ nʊ́rɒnz stéj ǽktɪv ənd əvɔ́jd ðə ɪ́ʃuw əv dájɪŋ nʊ́rɒnz?",
        "trans_RightAnswer": "líjkij RELU",
        "trans_WrongAnswers": [
            "sɔ̀ftmǽks",
            "hàjpərbɒ́lɪk tǽndʒənt (TANH)",
            "sɪ́ɡmɔ̀jd fʌ́ŋkʃən",
            "swɪ́ʃ æ̀ktɪvéjʃən",
            "sɔ́ftplʌ̀s æ̀ktɪvéjʃən"
        ],
        "trans_Explanation": "líjkij RELU ɪz ən æ̀ktɪvéjʃən fʌ́ŋkʃən sɪ́mɪlər tə ðə stǽndərd RELU, bʌt wɪð wʌ́n kíj dɪ́fərəns: ɪnstɛ́d əv ɡɪ́vɪŋ zíjərow áwtpʊ̀t fɔr nɛ́ɡətɪv ɪ́npʊ̀ts, ɪt əláwz ə smɔ́l, prəpɔ́rʃənəl nɛ́ɡətɪv sɪ́ɡnəl tə pǽs θrúw. ðɪs sɪ́mpəl twíjk hɛ́lps nʊ́rɒnz kəntɪ́njuw lɜ́rnɪŋ əfɛ́ktɪvlij dʊ́rɪŋ tréjnɪŋ, rədjúwsɪŋ ðə tʃǽnsɪz əv ðɛm bəkʌ́mɪŋ ɪ̀nǽktɪv ɔr 'dɛ́d.' ɪt's lájk líjvɪŋ ðə fɔ́sət drɪ́pɪŋ slájtlij ɪnstɛ́d əv fʊ́lij swɪ́tʃɪŋ ɪt ɔ́f, ɛnʃʊ́rɪŋ ə stɛ́dij flów əv ɪnfərméjʃən."
    },
    {
        "Question": "In machine learning, neural networks often need a clever way to introduce non-linearity into their layers, helping them solve complex tasks better. Which of the following terms refers to a smooth, S-shaped activation function that scales outputs between -1 and 1, allowing a neuron to send strongly negative, neutral, and strongly positive signals?",
        "RightAnswer": "Tanh Function",
        "WrongAnswers": [
            "Sigmoid Function",
            "ReLU Function",
            "Softmax Function",
            "Linear Function",
            "Leaky ReLU Function"
        ],
        "Explanation": "The Tanh (short for hyperbolic tangent) function is a popular activation function in neural networks. Just like the sigmoid, it's shaped like an 'S' curve, but while sigmoid outputs values between 0 and 1, the tanh function outputs values between -1 and 1. Because it can deliver negative as well as positive signals, it helps neurons detect and transmit clear distinctions like 'strongly disagree', 'neutral', or 'strongly agree'. This symmetry often helps neural networks learn faster and make richer distinctions when solving complex problems.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, nʊ́rəl nɛ́twɜ̀rks ɔ́fən níjd ə klɛ́vər wej tə ɪntrədúws nɒn-lɪ̀nijǽrɪtij ɪntə ðɛər léjərz, hɛ́lpɪŋ ðɛm sɒ́lv kɒ́mplɛks tǽsks bɛ́tər. wɪ́tʃ əv ðə fɒ́lowɪŋ tɜ́rmz rəfɜ́rz tə ə smúwð, s-ʃéjpt æ̀ktɪvéjʃən fʌ́ŋkʃən ðət skéjlz áwtpʊ̀ts bijtwíjn -1 ənd 1, əláwɪŋ ə nʊ́rɒn tə sɛ́nd strɔ́ŋlij nɛ́ɡətɪv, núwtrəl, ənd strɔ́ŋlij pɒ́zɪtɪv sɪ́ɡnəlz?",
        "trans_RightAnswer": "TANH fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "sɪ́ɡmɔ̀jd fʌ́ŋkʃən",
            "RELU fʌ́ŋkʃən",
            "sɔ̀ftmǽks fʌ́ŋkʃən",
            "lɪ́nijər fʌ́ŋkʃən",
            "líjkij RELU fʌ́ŋkʃən"
        ],
        "trans_Explanation": "ðə TANH (ʃɔ́rt fɔr hàjpərbɒ́lɪk tǽndʒənt) fʌ́ŋkʃən ɪz ə pɒ́pjələr æ̀ktɪvéjʃən fʌ́ŋkʃən ɪn nʊ́rəl nɛ́twɜ̀rks. dʒəst lájk ðə sɪ́ɡmɔ̀jd, ɪt's ʃéjpt lájk ən 'S' kɜ́rv, bʌt wájl sɪ́ɡmɔ̀jd áwtpʊ̀ts vǽljuwz bijtwíjn 0 ənd 1, ðə TANH fʌ́ŋkʃən áwtpʊ̀ts vǽljuwz bijtwíjn -1 ənd 1. bəkɒ́z ɪt kən dəlɪ́vər nɛ́ɡətɪv æz wɛ́l æz pɒ́zɪtɪv sɪ́ɡnəlz, ɪt hɛ́lps nʊ́rɒnz dətɛ́kt ənd trænzmɪ́t klɪ́ər dɪstɪ́ŋkʃənz lájk 'strɔ́ŋlij dɪsəɡríj', 'núwtrəl', ɔr 'strɔ́ŋlij əɡríj'. ðɪs sɪ́mətrij ɔ́fən hɛ́lps nʊ́rəl nɛ́twɜ̀rks lɜ́rn fǽstər ənd méjk rɪ́tʃər dɪstɪ́ŋkʃənz wɛ́n sɒ́lvɪŋ kɒ́mplɛks prɒ́bləmz."
    },
    {
        "Question": "When a neural network is classifying an image and outputs a set of scores for each possible category, which function is usually applied to transform these scores into probabilities that add up neatly to 1, making it easy to see the most likely outcome?",
        "RightAnswer": "Softmax Function",
        "WrongAnswers": [
            "Sigmoid Activation",
            "ReLU Function",
            "Gradient Descent",
            "Batch Normalization",
            "Dropout Method"
        ],
        "Explanation": "The softmax function takes a set of raw numbers (often called logits) produced by a neural network and converts them into probabilities that sum to exactly 1. This helps clearly show which category the model thinks is most likely. It's particularly useful when you're trying to classify an input into one of several possible outcomes, as it makes the output easier to interpret.",
        "trans_Question": "wɛ́n ə nʊ́rəl nɛ́twɜ̀rk ɪz klǽsɪfàjɪŋ ən ɪ́mɪdʒ ənd áwtpʊ̀ts ə sɛ́t əv skɔ́rz fɔr ijtʃ pɒ́sɪbəl kǽtəɡɔ̀rij, wɪ́tʃ fʌ́ŋkʃən ɪz júwʒəlij əplájd tə trǽnsfɔrm ðijz skɔ́rz ɪntə prɒ̀bəbɪ́lɪtìjz ðət ǽd ʌp níjtlij tə 1, méjkɪŋ ɪt íjzij tə síj ðə mówst lájklij áwtkʌ̀m?",
        "trans_RightAnswer": "sɔ̀ftmǽks fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "sɪ́ɡmɔ̀jd æ̀ktɪvéjʃən",
            "RELU fʌ́ŋkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "drɒ́pàwt mɛ́θəd"
        ],
        "trans_Explanation": "ðə sɔ̀ftmǽks fʌ́ŋkʃən téjks ə sɛ́t əv rɔ́ nʌ́mbərz (ɔ́fən kɔ́ld lówdʒɪts) prədúwst baj ə nʊ́rəl nɛ́twɜ̀rk ənd kɒ́nvərts ðɛm ɪntə prɒ̀bəbɪ́lɪtìjz ðət sʌ́m tə əɡzǽktlij 1. ðɪs hɛ́lps klɪ́ərlij ʃów wɪ́tʃ kǽtəɡɔ̀rij ðə mɒ́dəl θɪ́ŋks ɪz mówst lájklij. ɪt's pərtɪ́kjələrlij júwsfəl wɛ́n júwr trájɪŋ tə klǽsɪfàj ən ɪ́npʊ̀t ɪntə wʌ́n əv sɛ́vərəl pɒ́sɪbəl áwtkʌ̀mz, æz ɪt méjks ðə áwtpʊ̀t íjzijər tə ɪntɜ́rprət."
    },
    {
        "Question": "In machine learning, especially deep neural networks, what is the term for a technique used to stabilize and speed up training by keeping intermediate layers' input values consistent, thus preventing exploding or vanishing gradients?",
        "RightAnswer": "Batch Normalization",
        "WrongAnswers": [
            "Gradient Clipping",
            "Early Stopping",
            "Dropout Regularization",
            "Feature Scaling",
            "Weight Initialization"
        ],
        "Explanation": "Batch Normalization is a useful technique in machine learning that helps neural networks train faster and more consistently. It does this by normalizing (adjusting and scaling) the input data to each layer of the network per batch. By maintaining consistent values inside the network, batch normalization helps prevent common training problems like exploding or vanishing gradients, making it easier to build more stable and effective models.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij díjp nʊ́rəl nɛ́twɜ̀rks, wɒt ɪz ðə tɜ́rm fɔr ə tɛkníjk júwzd tə stéjbɪlàjz ənd spíjd ʌp tréjnɪŋ baj kíjpɪŋ ɪ̀ntərmíjdijət léjərz' ɪ́npʊ̀t vǽljuwz kənsɪ́stənt, ðʌs prəvɛ́ntɪŋ əksplówdɪŋ ɔr vǽnɪʃɪŋ ɡréjdijənts?",
        "trans_RightAnswer": "bǽtʃ nɔ̀rməlɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt klɪ́pɪŋ",
            "ɜ́rlij stɒ́pɪŋ",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən",
            "fíjtʃər skéjlɪŋ",
            "wéjt ɪnɪ́ʃəlɪzéjʃən"
        ],
        "trans_Explanation": "bǽtʃ nɔ̀rməlɪzéjʃən ɪz ə júwsfəl tɛkníjk ɪn məʃíjn lɜ́rnɪŋ ðət hɛ́lps nʊ́rəl nɛ́twɜ̀rks tréjn fǽstər ənd mɔr kənsɪ́stəntlij. ɪt dʌz ðɪs baj nɔ́rməlàjzɪŋ (ədʒʌ́stɪŋ ənd skéjlɪŋ) ðə ɪ́npʊ̀t déjtə tə ijtʃ léjər əv ðə nɛ́twɜ̀rk pɜ́r bǽtʃ. baj mejntéjnɪŋ kənsɪ́stənt vǽljuwz ɪnsájd ðə nɛ́twɜ̀rk, bǽtʃ nɔ̀rməlɪzéjʃən hɛ́lps prəvɛ́nt kɒ́mən tréjnɪŋ prɒ́bləmz lájk əksplówdɪŋ ɔr vǽnɪʃɪŋ ɡréjdijənts, méjkɪŋ ɪt íjzijər tə bɪ́ld mɔr stéjbəl ənd əféktɪv mɒ́dəlz."
    },
    {
        "Question": "What is the term for the important step in machine learning where raw data is cleaned, transformed, and prepared to ensure that learning algorithms can perform better?",
        "RightAnswer": "Data Preprocessing",
        "WrongAnswers": [
            "Parameter Tuning",
            "Feature Scaling",
            "Regularization",
            "Model Selection",
            "Cross Validation"
        ],
        "Explanation": "Data preprocessing is like tidying up and organizing your ingredients before you start cooking. It involves cleaning messy or incomplete data, removing irrelevant information, and converting data into a format your machine learning algorithms can easily digest. Well-preprocessed data helps models learn faster, perform better, and avoid misunderstandings!",
        "trans_Question": "wɒt ɪz ðə tɜ́rm fɔr ðə ɪmpɔ́rtənt stɛ́p ɪn məʃíjn lɜ́rnɪŋ wɛ́ər rɔ́ déjtə ɪz klíjnd, trænsfɔ́rmd, ənd prəpɛ́ərd tə ənʃʊ́r ðət lɜ́rnɪŋ ǽlɡərɪ̀ðəmz kən pərfɔ́rm bɛ́tər?",
        "trans_RightAnswer": "déjtə prìjprʌ́ʊsɛsɪŋ",
        "trans_WrongAnswers": [
            "pərǽmətər túwnɪŋ",
            "fíjtʃər skéjlɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "mɒ́dəl səlɛ́kʃən",
            "krɔ́s væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "déjtə prìjprʌ́ʊsɛsɪŋ ɪz lájk tájdijɪŋ ʌp ənd ɔ́rɡənàjzɪŋ jɔr ɪnɡríjdijənts bəfɔ́r juw stɑ́rt kʊ́kɪŋ. ɪt ɪnvɒ́lvz klíjnɪŋ mɛ́sij ɔr ɪ̀nkəmplíjt déjtə, rijmúwvɪŋ ɪ̀ərɛ́ləvənt ɪnfərméjʃən, ənd kənvɜ́rtɪŋ déjtə ɪntə ə fɔ́rmæ̀t jɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz kən íjzəlij dájdʒɛst. wɛ́l-prijprəsɛ́st déjtə hɛ́lps mɒ́dəlz lɜ́rn fǽstər, pərfɔ́rm bɛ́tər, ənd əvɔ́jd mɪ̀səndərstǽndɪŋz!"
    },
    {
        "Question": "Your image classification model isn't performing well due to limited training images. You decide to artificially create more variety by rotating, flipping, and slightly altering the images you already have. Which machine learning concept describes this approach?",
        "RightAnswer": "Data Augmentation",
        "WrongAnswers": [
            "Feature Scaling",
            "Hyperparameter Tuning",
            "Dimensionality Reduction",
            "Regularization",
            "Ensemble Learning"
        ],
        "Explanation": "Data augmentation is a handy machine learning technique where you artificially expand your training dataset by applying simple transformations—like rotating, flipping, zooming, or shifting—to your existing data. By creating slightly altered copies, your model gains exposure to more diverse situations, which can significantly boost its performance and generalization, especially when real data is limited.",
        "trans_Question": "jɔr ɪ́mɪdʒ klæ̀sɪfɪkéjʃən mɒ́dəl ɪzənt pərfɔ́rmɪŋ wɛ́l djúw tə lɪ́mɪtɪd tréjnɪŋ ɪ́mɪdʒɪz. juw dəsájd tə ɑ̀rtɪfɪ́ʃəlij krijéjt mɔr vərájətij baj rówtèjtɪŋ, flɪ́pɪŋ, ənd slájtlij ɔ́ltərɪŋ ðə ɪ́mɪdʒɪz juw ɔ̀lrɛ́dij həv. wɪ́tʃ məʃíjn lɜ́rnɪŋ kɒ́nsɛpt dəskrájbz ðɪs əprówtʃ?",
        "trans_RightAnswer": "déjtə ɒ̀ɡmɛntéjʃən",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "ɒnsɒ́mbəl lɜ́rnɪŋ"
        ],
        "trans_Explanation": "déjtə ɒ̀ɡmɛntéjʃən ɪz ə hǽndij məʃíjn lɜ́rnɪŋ tɛkníjk wɛ́ər juw ɑ̀rtɪfɪ́ʃəlij əkspǽnd jɔr tréjnɪŋ déjtəsɛ̀t baj əplájɪŋ sɪ́mpəl træ̀nsfərméjʃənz—lájk rówtèjtɪŋ, flɪ́pɪŋ, zúwmɪŋ, ɔr ʃɪ́ftɪŋ—tə jɔr əɡzɪ́stɪŋ déjtə. baj krijéjtɪŋ slájtlij ɔ́ltərd kɒ́pijz, jɔr mɒ́dəl ɡéjnz əkspówʒər tə mɔr dajvɜ́rs sɪ̀tʃuwéjʃənz, wɪ́tʃ kən sɪɡnɪ́fɪkəntlij búwst ɪts pərfɔ́rməns ənd dʒɛ̀nərəlɪzéjʃən, əspɛ́ʃəlij wɛ́n ríjəl déjtə ɪz lɪ́mɪtɪd."
    },
    {
        "Question": "Which term refers to the process in machine learning of identifying unusual or unexpected data points that differ significantly from typical patterns?",
        "RightAnswer": "Outlier Detection",
        "WrongAnswers": [
            "Data Augmentation",
            "Feature Extraction",
            "Cluster Analysis",
            "Dimensionality Reduction",
            "Supervised Learning"
        ],
        "Explanation": "Outlier detection is like playing detective with your data. It involves finding those odd or unusual points that don't quite fit the normal patterns and stand out from the crowd. Spotting these outliers can be really valuable because it helps prevent misleading results, improves model accuracy, and might even help you identify interesting events or errors within your data.",
        "trans_Question": "wɪ́tʃ tɜ́rm rəfɜ́rz tə ðə prɒ́sɛs ɪn məʃíjn lɜ́rnɪŋ əv ajdɛ́ntɪfàjɪŋ ʌ̀njúwʒùwəl ɔr ʌ̀nəkspɛ́ktɪd déjtə pɔ́jnts ðət dɪ́fər sɪɡnɪ́fɪkəntlij frəm tɪ́pɪkəl pǽtərnz?",
        "trans_RightAnswer": "áwtlajər dətɛ́kʃən",
        "trans_WrongAnswers": [
            "déjtə ɒ̀ɡmɛntéjʃən",
            "fíjtʃər əkstrǽkʃən",
            "klʌ́stər ənǽlɪsɪs",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "súwpərvàjzd lɜ́rnɪŋ"
        ],
        "trans_Explanation": "áwtlajər dətɛ́kʃən ɪz lájk pléjɪŋ dətɛ́ktɪv wɪð jɔr déjtə. ɪt ɪnvɒ́lvz fájndɪŋ ðowz ɒ́d ɔr ʌ̀njúwʒùwəl pɔ́jnts ðət dównt kwájt fɪ́t ðə nɔ́rməl pǽtərnz ənd stǽnd awt frəm ðə kráwd. spɒ́tɪŋ ðijz áwtlajərz kən bij ríjlij vǽljəbəl bəkɒ́z ɪt hɛ́lps prəvɛ́nt mɪ̀slíjdɪŋ rəzʌ́lts, ɪmprúwvz mɒ́dəl ǽkjərəsij, ənd majt íjvən hɛ́lp juw ajdɛ́ntɪfàj ɪ́ntərəstɪŋ əvɛ́nts ɔr ɛ́ərərz wɪðɪ́n jɔr déjtə."
    },
    {
        "Question": "Imagine you've trained a model to check financial transactions and alert you whenever there's suspicious activity that's drastically different from usual patterns. What type of machine learning approach are you most likely using?",
        "RightAnswer": "Anomaly Detection",
        "WrongAnswers": [
            "Supervised Classification",
            "Reinforcement Learning",
            "Regression Analysis",
            "Natural Language Processing",
            "Clustering"
        ],
        "Explanation": "Anomaly detection is a technique where machine learning models spot unusual, unexpected, or out-of-the-ordinary occurrences within the data. It's like the detective of machine learning—continually watching for activities that don't fit typical behaviors, such as fraudulent transactions, network intrusions, or sensor failures.",
        "trans_Question": "ɪmǽdʒɪn júwv tréjnd ə mɒ́dəl tə tʃɛ́k fàjnǽnʃəl trænzǽkʃənz ənd əlɜ́rt juw wɛnɛ́vər ðɛər'z səspɪ́ʃəs æktɪ́vɪtij ðət's drǽstɪklij dɪ́fərənt frəm júwʒəwəl pǽtərnz. wɒt tájp əv məʃíjn lɜ́rnɪŋ əprówtʃ ɑr juw mówst lájklij júwzɪŋ?",
        "trans_RightAnswer": "ənɒ́məlij dətɛ́kʃən",
        "trans_WrongAnswers": [
            "súwpərvàjzd klæ̀sɪfɪkéjʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ",
            "klʌ́stərɪŋ"
        ],
        "trans_Explanation": "ənɒ́məlij dətɛ́kʃən ɪz ə tɛkníjk wɛ́ər məʃíjn lɜ́rnɪŋ mɒ́dəlz spɒ́t ʌ̀njúwʒùwəl, ʌ̀nəkspɛ́ktɪd, ɔr awt-əv-ðə-ɔ́rdɪnɛ̀ərij əkɜ́rənsɪz wɪðɪ́n ðə déjtə. ɪt's lájk ðə dətɛ́ktɪv əv məʃíjn lɜ́rnɪŋ—kəntɪ́njuwəlij wɒ́tʃɪŋ fɔr æktɪ́vɪtijz ðət dównt fɪ́t tɪ́pɪkəl bəhéjvjərz, sʌtʃ æz frɔ́dʒələnt trænzǽkʃənz, nɛ́twɜ̀rk ɪntrúwʒənz, ɔr sɛ́nsər féjljərz."
    },
    {
        "Question": "You're working at an online clothing store, and you want to organize your customers into different groups based on shopping habits, taste, and preferences. You don't have pre-defined categories, but you're looking for a method that automatically discovers meaningful clusters of customers based on their purchase behavior data alone. Which approach would best help you achieve this?",
        "RightAnswer": "K-Means Clustering",
        "WrongAnswers": [
            "Decision Tree Classification",
            "Linear Regression",
            "Gradient Descent Optimization",
            "Support Vector Machines",
            "Neural Networks"
        ],
        "Explanation": "K-Means Clustering is an unsupervised machine learning technique that splits data into distinct groups (called clusters) based purely on similarities within the data. Each data point ends up in a cluster with others like it, without the need for labels or prior categories. Think of it as bringing order to chaos by automatically grouping similar things together—like customers with similar tastes or behaviors, making it easier for businesses to understand their audience and target their efforts effectively.",
        "trans_Question": "júwr wɜ́rkɪŋ æt ən ɔ́nlàjn klówðɪŋ stɔ́r, ənd juw wɒ́nt tə ɔ́rɡənàjz jɔr kʌ́stəmərz ɪntə dɪ́fərənt ɡrúwps béjst ɒn ʃɒ́pɪŋ hǽbɪts, téjst, ənd prɛ́fərənsɪz. juw dównt həv príj-dəfájnd kǽtəɡɔ̀rijz, bʌt júwr lʊ́kɪŋ fɔr ə mɛ́θəd ðət ɔ̀təmǽtɪklij dɪskʌ́vərz míjnɪŋfəl klʌ́stərz əv kʌ́stəmərz béjst ɒn ðɛər pɜ́rtʃəs bəhéjvjər déjtə əlówn. wɪ́tʃ əprówtʃ wʊd bɛ́st hɛ́lp juw ətʃíjv ðɪs?",
        "trans_RightAnswer": "k-míjnz klʌ́stərɪŋ",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríj klæ̀sɪfɪkéjʃən",
            "lɪ́nijər rəɡrɛ́ʃən",
            "ɡréjdijənt dəsɛ́nt ɒptɪmɪzéjʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "k-míjnz klʌ́stərɪŋ ɪz ən ʌ̀nsúwpərvàjzd məʃíjn lɜ́rnɪŋ tɛkníjk ðət splɪ́ts déjtə ɪntə dɪstɪ́ŋkt ɡrúwps (kɔ́ld klʌ́stərz) béjst pjʊ́rlij ɒn sɪ̀mɪlɛ́ərɪtijz wɪðɪ́n ðə déjtə. ijtʃ déjtə pɔ́jnt ɛ́ndz ʌp ɪn ə klʌ́stər wɪð ʌ́ðərz lájk ɪt, wɪðáwt ðə níjd fɔr léjbəlz ɔr prájər kǽtəɡɔ̀rijz. θɪ́ŋk əv ɪt æz brɪ́ŋɪŋ ɔ́rdər tə kéjɒs baj ɔ̀təmǽtɪklij ɡrúwpɪŋ sɪ́mɪlər θɪ́ŋz təɡɛ́ðər—lájk kʌ́stəmərz wɪð sɪ́mɪlər téjsts ɔr bəhéjvjərz, méjkɪŋ ɪt íjzijər fɔr bɪ́znəsɪz tə ʌ̀ndərstǽnd ðɛər ɒ́dijəns ənd tɑ́rɡət ðɛər ɛ́fərts əfɛ́ktɪvlij."
    },
    {
        "Question": "Imagine you're exploring customer preferences for your online store and want to group them step-by-step, forming clusters repeatedly until all customers form a single group. Which machine learning method allows you to build this kind of grouping by creating clusters progressively, visualized usually as a 'tree'-like structure?",
        "RightAnswer": "Hierarchical Clustering",
        "WrongAnswers": [
            "K-Means Clustering",
            "Logistic Regression",
            "Principal Component Analysis",
            "Decision Trees",
            "Neural Networks"
        ],
        "Explanation": "Hierarchical clustering is a method for grouping data points by successively merging or splitting them. It works like building a family tree—starting by pairing similar data points, then grouping those pairs into larger clusters, repeatedly forming groups until you have just one big cluster. This approach is commonly visualized using a dendrogram, a tree-like representation that helps you easily understand the relationships between data points at different stages of clustering.",
        "trans_Question": "ɪmǽdʒɪn júwr əksplɔ́rɪŋ kʌ́stəmər prɛ́fərənsɪz fɔr jɔr ɔ́nlàjn stɔ́r ənd wɒ́nt tə ɡrúwp ðɛm stɛ́p-baj-stɛ́p, fɔ́rmɪŋ klʌ́stərz rəpíjtɪdlij əntɪ́l ɔl kʌ́stəmərz fɔ́rm ə sɪ́ŋɡəl ɡrúwp. wɪ́tʃ məʃíjn lɜ́rnɪŋ mɛ́θəd əláwz juw tə bɪ́ld ðɪs kájnd əv ɡrúwpɪŋ baj krijéjtɪŋ klʌ́stərz prɒɡrɛ́sɪvlij, vɪ́ʒwəlàjzd júwʒəlij æz ə 'tríj'-lájk strʌ́ktʃər?",
        "trans_RightAnswer": "hàjərɑ́rkɪkəl klʌ́stərɪŋ",
        "trans_WrongAnswers": [
            "k-míjnz klʌ́stərɪŋ",
            "lədʒɪ́stɪk rəɡrɛ́ʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "dəsɪ́ʒən tríjz",
            "nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "hàjərɑ́rkɪkəl klʌ́stərɪŋ ɪz ə mɛ́θəd fɔr ɡrúwpɪŋ déjtə pɔ́jnts baj səksɛ́sɪvlij mɜ́rdʒɪŋ ɔr splɪ́tɪŋ ðɛm. ɪt wɜ́rks lájk bɪ́ldɪŋ ə fǽmɪlij tríj—stɑ́rtɪŋ baj pɛ́ərɪŋ sɪ́mɪlər déjtə pɔ́jnts, ðɛn ɡrúwpɪŋ ðowz pɛ́ərz ɪntə lɑ́rdʒər klʌ́stərz, rəpíjtɪdlij fɔ́rmɪŋ ɡrúwps əntɪ́l juw həv dʒəst wʌ́n bɪ́ɡ klʌ́stər. ðɪs əprówtʃ ɪz kɒ́mənlij vɪ́ʒwəlàjzd júwzɪŋ ə dɛ́ndrəɡræm, ə tríj-lájk rɛ̀prəzɛntéjʃən ðət hɛ́lps juw íjzəlij ʌ̀ndərstǽnd ðə rəléjʃənʃɪ̀ps bijtwíjn déjtə pɔ́jnts æt dɪ́fərənt stéjdʒɪz əv klʌ́stərɪŋ."
    },
    {
        "Question": "Which machine learning algorithm groups data points based on density, effectively spotting clusters of varying shapes and identifying noise without needing the number of groups beforehand?",
        "RightAnswer": "DBSCAN",
        "WrongAnswers": [
            "K-means",
            "Decision Tree",
            "Linear Regression",
            "Random Forest",
            "Support Vector Machine (SVM)"
        ],
        "Explanation": "DBSCAN, or Density-Based Spatial Clustering of Applications with Noise, is a smart clustering algorithm that sorts data points by looking at how closely packed together they are. Unlike traditional clustering methods such as K-means, DBSCAN can detect groups of different shapes and doesn't need you to specify upfront how many groups there are. It's also great at identifying outliers—those lone points that don't fit neatly into any cluster—which is incredibly helpful for real-world data exploration.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm ɡrúwps déjtə pɔ́jnts béjst ɒn dɛ́nsɪtij, əfɛ́ktɪvlij spɒ́tɪŋ klʌ́stərz əv vɛ́ərijɪŋ ʃéjps ənd ajdɛ́ntɪfàjɪŋ nɔ́jz wɪðáwt níjdɪŋ ðə nʌ́mbər əv ɡrúwps bəfɔ́rhæ̀nd?",
        "trans_RightAnswer": "DBSCAN",
        "trans_WrongAnswers": [
            "k-míjnz",
            "dəsɪ́ʒən tríj",
            "lɪ́nijər rəɡrɛ́ʃən",
            "rǽndəm fɔ́rəst",
            "səpɔ́rt vɛ́ktər məʃíjn (SVM)"
        ],
        "trans_Explanation": "DBSCAN, ɔr dɛ́nsɪtij-béjst spéjʃəl klʌ́stərɪŋ əv æ̀plɪkéjʃənz wɪð nɔ́jz, ɪz ə smɑ́rt klʌ́stərɪŋ ǽlɡərɪ̀ðəm ðət sɔ́rts déjtə pɔ́jnts baj lʊ́kɪŋ æt háw klówslij pǽkt təɡɛ́ðər ðej ɑr. ʌ̀nlájk trədɪ́ʃənəl klʌ́stərɪŋ mɛ́θədz sʌtʃ æz k-míjnz, DBSCAN kən dətɛ́kt ɡrúwps əv dɪ́fərənt ʃéjps ənd dʌ́zənt níjd juw tə spɛ́sɪfàj ʌ́pfrʌ̀nt háw mɛ́nij ɡrúwps ðɛər ɑr. ɪt's ɔ́lsow ɡréjt æt ajdɛ́ntɪfàjɪŋ áwtlajərz—ðowz lówn pɔ́jnts ðət dównt fɪ́t níjtlij ɪntə ɛ́nij klʌ́stər—wɪ́tʃ ɪz ɪnkrɛ́dɪblij hɛ́lpfəl fɔr ríjəl-wɜ́rld déjtə ɛ̀kspləréjʃən."
    },
    {
        "Question": "Which clustering algorithm works by repeatedly shifting data points toward the areas of higher density until clusters naturally form?",
        "RightAnswer": "Mean Shift",
        "WrongAnswers": [
            "K-Means",
            "Hierarchical Clustering",
            "Gaussian Mixture Model",
            "DBSCAN",
            "Spectral Clustering"
        ],
        "Explanation": "Mean Shift is an intuitive clustering method that treats data points as gradually moving towards regions with more points—much like people gathering in popular spots at a festival. Each data point 'shifts' its position toward denser groups until clear, natural clusters emerge. This makes it effective for discovering unique clusters without needing an initial guess of how many groups there are.",
        "trans_Question": "wɪ́tʃ klʌ́stərɪŋ ǽlɡərɪ̀ðəm wɜ́rks baj rəpíjtɪdlij ʃɪ́ftɪŋ déjtə pɔ́jnts təwɔ́rd ðə ɛ́ərijəz əv hájər dɛ́nsɪtij əntɪ́l klʌ́stərz nǽtʃərəlij fɔ́rm?",
        "trans_RightAnswer": "míjn ʃɪ́ft",
        "trans_WrongAnswers": [
            "k-míjnz",
            "hàjərɑ́rkɪkəl klʌ́stərɪŋ",
            "ɡáwsijən mɪ́kstʃər mɒ́dəl",
            "DBSCAN",
            "spɛ́ktrəl klʌ́stərɪŋ"
        ],
        "trans_Explanation": "míjn ʃɪ́ft ɪz ən ɪntúwɪtɪv klʌ́stərɪŋ mɛ́θəd ðət tríjts déjtə pɔ́jnts æz ɡrǽdʒuwəlij múwvɪŋ təwɔ́rdz ríjdʒənz wɪð mɔr pɔ́jnts—mʌtʃ lájk píjpəl ɡǽðərɪŋ ɪn pɒ́pjələr spɒ́ts æt ə fɛ́stɪvəl. ijtʃ déjtə pɔ́jnt 'ʃɪ́fts' ɪts pəzɪ́ʃən təwɔ́rd dɛ́nsər ɡrúwps əntɪ́l klɪ́ər, nǽtʃərəl klʌ́stərz əmɜ́rdʒ. ðɪs méjks ɪt əféktɪv fɔr dɪskʌ́vərɪŋ juwnɪ́k klʌ́stərz wɪðáwt níjdɪŋ ən ɪnɪ́ʃəl ɡɛ́s əv háw mɛ́nij ɡrúwps ðɛər ɑr."
    },
    {
        "Question": "You're working with a dataset of customer data, and you notice there are distinct groups within your audience, but they're overlapping and not clearly separable. You're aiming for a method that assumes each cluster is shaped like a familiar bell-shaped curve, allowing clusters to overlap naturally. Which machine learning technique would best suit this scenario?",
        "RightAnswer": "Gaussian Mixture Models",
        "WrongAnswers": [
            "Decision Trees",
            "Linear Regression",
            "Logistic Regression",
            "K-Means Clustering",
            "Support Vector Machines"
        ],
        "Explanation": "Gaussian Mixture Models (GMM) are machine learning algorithms used for clustering data by assuming that the data consists of a mixture of several Gaussian distributions, or bell-shaped curves. Unlike methods like K-Means that assume clusters are neatly separated, GMM can comfortably handle overlapping clusters because it captures both the center and the shape (spread) of each cluster. Think of it as identifying several soft 'bubbles' of grouped data rather than precise hard-edged clusters.",
        "trans_Question": "júwr wɜ́rkɪŋ wɪð ə déjtəsɛ̀t əv kʌ́stəmər déjtə, ənd juw nówtɪs ðɛər ɑr dɪstɪ́ŋkt ɡrúwps wɪðɪ́n jɔr ɒ́dijəns, bʌt ðɛ́ər ówvərlæ̀pɪŋ ənd nɒt klɪ́ərlij sɛ́pərəbəl. júwr éjmɪŋ fɔr ə mɛ́θəd ðət əsúwmz ijtʃ klʌ́stər ɪz ʃéjpt lájk ə fəmɪ́ljər bɛ́l-ʃéjpt kɜ́rv, əláwɪŋ klʌ́stərz tə ówvərlæ̀p nǽtʃərəlij. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk wʊd bɛ́st súwt ðɪs sənɛ́ərijow?",
        "trans_RightAnswer": "ɡáwsijən mɪ́kstʃər mɒ́dəlz",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríjz",
            "lɪ́nijər rəɡrɛ́ʃən",
            "lədʒɪ́stɪk rəɡrɛ́ʃən",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjnz"
        ],
        "trans_Explanation": "ɡáwsijən mɪ́kstʃər mɒ́dəlz (GMM) ɑr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz júwzd fɔr klʌ́stərɪŋ déjtə baj əsúwmɪŋ ðət ðə déjtə kənsɪ́sts əv ə mɪ́kstʃər əv sɛ́vərəl ɡáwsijən dɪ̀strəbjúwʃənz, ɔr bɛ́l-ʃéjpt kɜ́rvz. ʌ̀nlájk mɛ́θədz lájk k-míjnz ðət əsúwm klʌ́stərz ɑr níjtlij sɛ́pərèjtɪd, GMM kən kʌ́mfərtəblij hǽndəl ówvərlæ̀pɪŋ klʌ́stərz bəkɒ́z ɪt kǽptʃərz bówθ ðə sɛ́ntər ənd ðə ʃéjp (sprɛ́d) əv ijtʃ klʌ́stər. θɪ́ŋk əv ɪt æz ajdɛ́ntɪfàjɪŋ sɛ́vərəl sɒ́ft 'bʌ́bəlz' əv ɡrúwpt déjtə rǽðər ðʌn prəsájs hɑ́rd-ɛ́dʒd klʌ́stərz."
    },
    {
        "Question": "Which algorithm would you use in machine learning when dealing with data that has missing or hidden values, aiming to intelligently estimate these unknowns through iterative guessing and adjusting?",
        "RightAnswer": "Expectation-Maximization",
        "WrongAnswers": [
            "Gradient Boosting",
            "Support Vector Machine",
            "K-Means Clustering",
            "Random Forest",
            "Principal Component Analysis"
        ],
        "Explanation": "Expectation-Maximization, often called EM, is an iterative algorithm used in machine learning when you have incomplete or partially hidden data. Think of it as a clever detective working in rounds: first guessing the missing values (Expectation step) based on what it currently knows, and then refining how it guesses by improving parameters (Maximization step). It continues cycling through these two stages until its guesses stabilize, providing a helpful way to make sense of tricky, incomplete data sets.",
        "trans_Question": "wɪ́tʃ ǽlɡərɪ̀ðəm wʊd juw juwz ɪn məʃíjn lɜ́rnɪŋ wɛ́n díjlɪŋ wɪð déjtə ðət həz mɪ́sɪŋ ɔr hɪ́dən vǽljuwz, éjmɪŋ tə ɪntɛ́lɪdʒəntlij ɛ́stɪmèjt ðijz ənównz θrúw ɪ́tərətɪv ɡɛ́sɪŋ ənd ədʒʌ́stɪŋ?",
        "trans_RightAnswer": "ɛ̀kspɛktéjʃən-mæ̀ksɪmɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "k-míjnz klʌ́stərɪŋ",
            "rǽndəm fɔ́rəst",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "ɛ̀kspɛktéjʃən-mæ̀ksɪmɪzéjʃən, ɔ́fən kɔ́ld EM, ɪz ən ɪ́tərətɪv ǽlɡərɪ̀ðəm júwzd ɪn məʃíjn lɜ́rnɪŋ wɛ́n juw həv ɪ̀nkəmplíjt ɔr pɑ́rʃəlij hɪ́dən déjtə. θɪ́ŋk əv ɪt æz ə klɛ́vər dətɛ́ktɪv wɜ́rkɪŋ ɪn ráwndz: fɜ́rst ɡɛ́sɪŋ ðə mɪ́sɪŋ vǽljuwz (ɛ̀kspɛktéjʃən stɛ́p) béjst ɒn wɒt ɪt kɜ́rəntlij nówz, ənd ðɛn rəfájnɪŋ háw ɪt ɡɛ́sɪz baj ɪmprúwvɪŋ pərǽmətərz (mæ̀ksɪmɪzéjʃən stɛ́p). ɪt kəntɪ́njuwz sájklɪŋ θrúw ðijz túw stéjdʒɪz əntɪ́l ɪts ɡɛ́sɪz stéjbɪlàjz, prəvájdɪŋ ə hɛ́lpfəl wej tə méjk sɛ́ns əv trɪ́kij, ɪ̀nkəmplíjt déjtə sɛ́ts."
    },
    {
        "Question": "You're working for an online retail store, and your team wants to understand sales trends to predict future demand. Your dataset records sales figures at consistent intervals, like daily or weekly. Which machine learning approach would best help you analyze trends, patterns, and future predictions based on this ordered data over periods of time?",
        "RightAnswer": "Time Series Analysis",
        "WrongAnswers": [
            "Clustering",
            "Image Recognition",
            "Sentiment Analysis",
            "Dimensionality Reduction",
            "Classification"
        ],
        "Explanation": "Time Series Analysis involves examining data points collected or recorded at specific, equally spaced intervals (like hourly, daily, monthly). It's particularly useful for spotting patterns, seasonal variations, and trends, helping businesses and analysts forecast future values based on past information. For instance, retailers often use it to predict future sales and inventory needs.",
        "trans_Question": "júwr wɜ́rkɪŋ fɔr ən ɔ́nlàjn ríjtèjl stɔ́r, ənd jɔr tíjm wɒ́nts tə ʌ̀ndərstǽnd séjlz trɛ́ndz tə prədɪ́kt fjúwtʃər dəmǽnd. jɔr déjtəsɛ̀t rɛ́kərdz séjlz fɪ́ɡjərz æt kənsɪ́stənt ɪ́ntərvəlz, lájk déjlij ɔr wíjklij. wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ wʊd bɛ́st hɛ́lp juw ǽnəlàjz trɛ́ndz, pǽtərnz, ənd fjúwtʃər prədɪ́kʃənz béjst ɒn ðɪs ɔ́rdərd déjtə ówvər pɪ́ərijədz əv tájm?",
        "trans_RightAnswer": "tájm sɪ́ərijz ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "klʌ́stərɪŋ",
            "ɪ́mɪdʒ rɛ̀kəɡnɪ́ʃən",
            "sɛ́ntɪmənt ənǽlɪsɪs",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "klæ̀sɪfɪkéjʃən"
        ],
        "trans_Explanation": "tájm sɪ́ərijz ənǽlɪsɪs ɪnvɒ́lvz əɡzǽmɪnɪŋ déjtə pɔ́jnts kəlɛ́ktɪd ɔr rəkɔ́rdɪd æt spəsɪ́fɪk, íjkwəlij spéjst ɪ́ntərvəlz (lájk áwrlij, déjlij, mʌ́nθlij). ɪt's pərtɪ́kjələrlij júwsfəl fɔr spɒ́tɪŋ pǽtərnz, síjzənəl vɛ̀ərijéjʃənz, ənd trɛ́ndz, hɛ́lpɪŋ bɪ́znəsɪz ənd ǽnəlɪsts fɔ́rkæ̀st fjúwtʃər vǽljuwz béjst ɒn pǽst ɪnfərméjʃən. fɔr ɪ́nstəns, ríjtèjlərz ɔ́fən juwz ɪt tə prədɪ́kt fjúwtʃər séjlz ənd ɪnvəntɔ́rij níjdz."
    },
    {
        "Question": "You're building a smart app that needs to predict the next word in a sentence or the next song in a playlist. What machine learning technique would best allow the app to understand and predict patterns over time or sequential order?",
        "RightAnswer": "Sequence Modeling",
        "WrongAnswers": [
            "Classification",
            "Clustering",
            "Dimensionality Reduction",
            "Regression Analysis",
            "Anomaly Detection"
        ],
        "Explanation": "Sequence Modeling is a machine learning technique specifically designed to analyze data that occurs in a specific order, like words in sentences, frames in a video, or events happening over time. It helps algorithms spot patterns from sequential or time-dependent data, allowing applications (like smart keyboards or recommendation systems) to make accurate predictions about what's likely to come next.",
        "trans_Question": "júwr bɪ́ldɪŋ ə smɑ́rt ǽp ðət níjdz tə prədɪ́kt ðə nɛ́kst wɜ́rd ɪn ə sɛ́ntəns ɔr ðə nɛ́kst sɔ́ŋ ɪn ə pléjlɪst. wɒt məʃíjn lɜ́rnɪŋ tɛkníjk wʊd bɛ́st əláw ðə ǽp tə ʌ̀ndərstǽnd ənd prədɪ́kt pǽtərnz ówvər tájm ɔr səkwɛ́nʃəl ɔ́rdər?",
        "trans_RightAnswer": "síjkwəns mɒ́dəlɪ̀ŋ",
        "trans_WrongAnswers": [
            "klæ̀sɪfɪkéjʃən",
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "ənɒ́məlij dətɛ́kʃən"
        ],
        "trans_Explanation": "síjkwəns mɒ́dəlɪ̀ŋ ɪz ə məʃíjn lɜ́rnɪŋ tɛkníjk spəsɪ́fɪklij dəzájnd tə ǽnəlàjz déjtə ðət əkɜ́rz ɪn ə spəsɪ́fɪk ɔ́rdər, lájk wɜ́rdz ɪn sɛ́ntənsɪz, fréjmz ɪn ə vɪ́dijow, ɔr əvɛ́nts hǽpənɪŋ ówvər tájm. ɪt hɛ́lps ǽlɡərɪ̀ðəmz spɒ́t pǽtərnz frəm səkwɛ́nʃəl ɔr tájm-dəpɛ́ndənt déjtə, əláwɪŋ æ̀plɪkéjʃənz (lájk smɑ́rt kíjbɔ̀rdz ɔr rɛ̀kəməndéjʃən sɪ́stəmz) tə méjk ǽkjərət prədɪ́kʃənz əbawt wɒt's lájklij tə kʌ́m nɛ́kst."
    },
    {
        "Question": "What area of machine learning enables computers to understand, interpret, and respond to human languages like English or Spanish, helping apps perform tasks like answering questions or analyzing customer sentiment?",
        "RightAnswer": "Natural Language Processing",
        "WrongAnswers": [
            "Computer Vision",
            "Predictive Analytics",
            "Deep Reinforcement Learning",
            "Data Wrangling",
            "Feature Engineering"
        ],
        "Explanation": "Natural Language Processing (or NLP for short) is the field in machine learning where computers are taught how to understand, interpret, and interact with human languages. It's like teaching a machine how to 'speak human', so it can read text, understand the meaning behind words, respond conversationally, and even gauge the emotions or intentions behind what someone says.",
        "trans_Question": "wɒt ɛ́ərijə əv məʃíjn lɜ́rnɪŋ ɛnéjbəlz kəmpjúwtərz tə ʌ̀ndərstǽnd, ɪntɜ́rprət, ənd rəspɒ́nd tə hjúwmən lǽŋɡwədʒɪz lájk ɪ́ŋɡlɪʃ ɔr spǽnɪʃ, hɛ́lpɪŋ ǽps pərfɔ́rm tǽsks lájk ǽnsərɪŋ kwɛ́stʃənz ɔr ǽnəlàjzɪŋ kʌ́stəmər sɛ́ntɪmənt?",
        "trans_RightAnswer": "nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ",
        "trans_WrongAnswers": [
            "kəmpjúwtər vɪ́ʒən",
            "prədɪ́ktɪv æ̀nəlɪ́tɪks",
            "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "déjtə rǽŋɡəlɪŋ",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ"
        ],
        "trans_Explanation": "nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ (ɔr NLP fɔr ʃɔ́rt) ɪz ðə fíjld ɪn məʃíjn lɜ́rnɪŋ wɛ́ər kəmpjúwtərz ɑr tɔ́t háw tə ʌ̀ndərstǽnd, ɪntɜ́rprət, ənd ɪ̀ntərǽkt wɪð hjúwmən lǽŋɡwədʒɪz. ɪt's lájk tíjtʃɪŋ ə məʃíjn háw tə 'spíjk hjúwmən', sow ɪt kən rɛ́d tɛ́kst, ʌ̀ndərstǽnd ðə míjnɪŋ bəhájnd wɜ́rdz, rəspɒ́nd kɒ̀nvərséjʃənəlij, ənd íjvən ɡéjdʒ ðə əmówʃənz ɔr ɪntɛ́ntʃənz bəhájnd wɒt sʌ́mwʌ̀n sɛ́z."
    },
    {
        "Question": "What do we call the area of machine learning where computers are trained to interpret and understand visual images, enabling them to do things like identify faces in photos or guide self-driving cars?",
        "RightAnswer": "Computer Vision",
        "WrongAnswers": [
            "Natural Language Processing",
            "Deep Reinforcement Learning",
            "Clustering",
            "Dimensionality Reduction",
            "Time Series Analysis"
        ],
        "Explanation": "Computer Vision is the part of AI and machine learning that gives computers the ability to \"see\" and understand the visual world much like humans do. This means recognizing faces, spotting objects, understanding surroundings, or interpreting video imagery. It's used widely in technologies like face recognition, autonomous driving, and even Snapchat filters. Think of it as giving computers eyes and a sense of understanding what they see!",
        "trans_Question": "wɒt dúw wij kɔ́l ðə ɛ́ərijə əv məʃíjn lɜ́rnɪŋ wɛ́ər kəmpjúwtərz ɑr tréjnd tə ɪntɜ́rprət ənd ʌ̀ndərstǽnd vɪ́ʒəwəl ɪ́mɪdʒɪz, ɛnéjbəlɪŋ ðɛm tə dúw θɪ́ŋz lájk ajdɛ́ntɪfàj féjsɪz ɪn fówtòwz ɔr ɡájd sɛ́lf-drájvɪŋ kɑ́rz?",
        "trans_RightAnswer": "kəmpjúwtər vɪ́ʒən",
        "trans_WrongAnswers": [
            "nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ",
            "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "tájm sɪ́ərijz ənǽlɪsɪs"
        ],
        "trans_Explanation": "kəmpjúwtər vɪ́ʒən ɪz ðə pɑ́rt əv AI ənd məʃíjn lɜ́rnɪŋ ðət ɡɪ́vz kəmpjúwtərz ðə əbɪ́lɪtij tə \"síj\" ənd ʌ̀ndərstǽnd ðə vɪ́ʒəwəl wɜ́rld mʌtʃ lájk hjúwmənz dúw. ðɪs míjnz rɛ́kəɡnàjzɪŋ féjsɪz, spɒ́tɪŋ ɒ́bdʒɛkts, ʌ̀ndərstǽndɪŋ səráwndɪŋz, ɔr ɪntərprɛ́tɪŋ vɪ́dijow ɪ́mɪdʒrij. ɪt's júwzd wájdlij ɪn tɛknɒ́lədʒijz lájk féjs rɛ̀kəɡnɪ́ʃən, ɔtɒ́nəməs drájvɪŋ, ənd íjvən snǽptʃæ̀t fɪ́ltərz. θɪ́ŋk əv ɪt æz ɡɪ́vɪŋ kəmpjúwtərz ájz ənd ə sɛ́ns əv ʌ̀ndərstǽndɪŋ wɒt ðej síj!"
    },
    {
        "Question": "In machine learning, there's a clever strategy that lets us leverage knowledge from previous models trained on large datasets, saving time and resources when tackling new but similar problems. What is this smart approach called?",
        "RightAnswer": "Transfer Learning",
        "WrongAnswers": [
            "Gradient Boosting",
            "Hyperparameter Tuning",
            "Backpropagation",
            "Reinforcement Learning",
            "Overfitting"
        ],
        "Explanation": "Transfer Learning is like using the experience you've gained learning one skill to quickly become proficient in another related skill. Instead of training a model completely from scratch, we utilize a pre-trained model (trained on lots of data) and just fine-tune it for our specific task. This technique saves time, resources, and often improves performance, especially when we don't have tons of new data available.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə klɛ́vər strǽtədʒij ðət lɛts ʌs lɛ́vərɪdʒ nɒ́lɪdʒ frəm príjvijəs mɒ́dəlz tréjnd ɒn lɑ́rdʒ déjtəsɛ̀ts, séjvɪŋ tájm ənd ríjsɔrsɪz wɛ́n tǽkəlɪŋ núw bʌt sɪ́mɪlər prɒ́bləmz. wɒt ɪz ðɪs smɑ́rt əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "trǽnsfər lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "bǽkprəpəgéjʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "òwvərfɪ́tɪŋ"
        ],
        "trans_Explanation": "trǽnsfər lɜ́rnɪŋ ɪz lájk júwzɪŋ ðə əkspɪ́ərijəns júwv ɡéjnd lɜ́rnɪŋ wʌ́n skɪ́l tə kwɪ́klij bəkʌ́m prɒfɪ́ʃənt ɪn ənʌ́ðər rəléjtɪd skɪ́l. ɪnstɛ́d əv tréjnɪŋ ə mɒ́dəl kəmplíjtlij frəm skrǽtʃ, wij júwtɪlàjz ə príj-tréjnd mɒ́dəl (tréjnd ɒn lɒ́ts əv déjtə) ənd dʒəst fájn-túwn ɪt fɔr awər spəsɪ́fɪk tǽsk. ðɪs tɛkníjk séjvz tájm, ríjsɔrsɪz, ənd ɔ́fən ɪmprúwvz pərfɔ́rməns, əspɛ́ʃəlij wɛ́n wij dównt həv tʌ́nz əv núw déjtə əvéjləbəl."
    },
    {
        "Question": "In machine learning, what's it called when a model is trained to perform several related tasks simultaneously, allowing it to leverage shared patterns across them?",
        "RightAnswer": "Multi-task Learning",
        "WrongAnswers": [
            "Transfer Learning",
            "Reinforcement Learning",
            "Federated Learning",
            "Ensemble Learning",
            "Self-supervised Learning"
        ],
        "Explanation": "Multi-task learning is like teaching someone multiple related skills at once—by understanding the common patterns shared among similar tasks, the learning becomes more efficient. For example, training one ML model to both detect and classify objects helps it leverage shared knowledge, improving the overall performance. In other words, it's an approach where a model learns multiple tasks simultaneously so each task can benefit from the insights gained by the others.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt's ɪt kɔ́ld wɛ́n ə mɒ́dəl ɪz tréjnd tə pərfɔ́rm sɛ́vərəl rəléjtɪd tǽsks sàjməltéjnijəslij, əláwɪŋ ɪt tə lɛ́vərɪdʒ ʃɛ́ərd pǽtərnz əkrɔ́s ðɛm?",
        "trans_RightAnswer": "mʌ́ltij-tǽsk lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "trǽnsfər lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "fɛ́dərèjtɪd lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "sɛ́lf-súwpərvàjzd lɜ́rnɪŋ"
        ],
        "trans_Explanation": "mʌ́ltij-tǽsk lɜ́rnɪŋ ɪz lájk tíjtʃɪŋ sʌ́mwʌ̀n mʌ́ltɪpəl rəléjtɪd skɪ́lz æt wʌ́ns—baj ʌ̀ndərstǽndɪŋ ðə kɒ́mən pǽtərnz ʃɛ́ərd əmʌ́ŋ sɪ́mɪlər tǽsks, ðə lɜ́rnɪŋ bəkʌ́mz mɔr əfɪ́ʃənt. fɔr əɡzǽmpəl, tréjnɪŋ wʌ́n ML mɒ́dəl tə bówθ dətɛ́kt ənd klǽsɪfàj ɒ́bdʒɛkts hɛ́lps ɪt lɛ́vərɪdʒ ʃɛ́ərd nɒ́lɪdʒ, ɪmprúwvɪŋ ðə ówvərɔ̀l pərfɔ́rməns. ɪn ʌ́ðər wɜ́rdz, ɪt's ən əprówtʃ wɛ́ər ə mɒ́dəl lɜ́rnz mʌ́ltɪpəl tǽsks sàjməltéjnijəslij sow ijtʃ tǽsk kən bɛ́nəfɪt frəm ðə ɪ́nsàjts ɡéjnd baj ðə ʌ́ðərz."
    },
    {
        "Question": "In machine learning, what term refers to training AI algorithms not just to solve one particular task, but learning HOW to learn, allowing them to rapidly master new tasks with minimal new training data?",
        "RightAnswer": "Meta-Learning",
        "WrongAnswers": [
            "Transfer Learning",
            "Supervised Learning",
            "Reinforcement Learning",
            "Active Learning",
            "Deep Learning"
        ],
        "Explanation": "Meta-learning, often called 'learning to learn', involves teaching AI models foundational strategies for quickly adapting to new tasks or situations. Instead of starting from scratch each time, these models use insights from past learning experiences to quickly grasp new tasks, much like a skilled learner who understands HOW to approach unfamiliar subjects effectively.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tɜ́rm rəfɜ́rz tə tréjnɪŋ AI ǽlɡərɪ̀ðəmz nɒt dʒəst tə sɒ́lv wʌ́n pərtɪ́kjələr tǽsk, bʌt lɜ́rnɪŋ HOW tə lɜ́rn, əláwɪŋ ðɛm tə rǽpɪdlij mǽstər núw tǽsks wɪð mɪ́nɪməl núw tréjnɪŋ déjtə?",
        "trans_RightAnswer": "mɛ́tə-lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "trǽnsfər lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "ǽktɪv lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ"
        ],
        "trans_Explanation": "mɛ́tə-lɜ́rnɪŋ, ɔ́fən kɔ́ld 'lɜ́rnɪŋ tə lɜ́rn', ɪnvɒ́lvz tíjtʃɪŋ AI mɒ́dəlz fawndéjʃənəl strǽtədʒijz fɔr kwɪ́klij ədǽptɪŋ tə núw tǽsks ɔr sɪ̀tʃuwéjʃənz. ɪnstɛ́d əv stɑ́rtɪŋ frəm skrǽtʃ ijtʃ tájm, ðijz mɒ́dəlz juwz ɪ́nsàjts frəm pǽst lɜ́rnɪŋ əkspɪ́ərijənsijz tə kwɪ́klij ɡrǽsp núw tǽsks, mʌtʃ lájk ə skɪ́ld lɜ́rnər huw ʌ̀ndərstǽndz HOW tə əprówtʃ ʌ̀nfəmɪ́ljər sʌ́bdʒəkts əfɛ́ktɪvlij."
    },
    {
        "Question": "Imagine you want your machine learning model to quickly recognize new objects by seeing only a handful of examples for each one, rather than thousands of images. Which method allows models to efficiently learn new categories using a very limited amount of data?",
        "RightAnswer": "Few-shot Learning",
        "WrongAnswers": [
            "Transfer Learning",
            "Supervised Learning",
            "Batch Normalization",
            "Ensemble Learning",
            "Backpropagation"
        ],
        "Explanation": "Few-shot learning is like a super-fast learner that can understand and identify new concepts reliably after seeing just a few examples. Unlike traditional machine learning methods, which often need large amounts of data, few-shot learning can pick up new ideas extremely quickly. This makes it especially useful for scenarios where gathering extensive examples is time-consuming, expensive, or impractical.",
        "trans_Question": "ɪmǽdʒɪn juw wɒ́nt jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl tə kwɪ́klij rɛ́kəɡnàjz núw ɒ́bdʒɛkts baj síjɪŋ ównlij ə hǽndfʊ̀l əv əɡzǽmpəlz fɔr ijtʃ wʌ́n, rǽðər ðʌn θáwzəndz əv ɪ́mɪdʒɪz. wɪ́tʃ mɛ́θəd əláwz mɒ́dəlz tə əfɪ́ʃəntlij lɜ́rn núw kǽtəɡɔ̀rijz júwzɪŋ ə vɛ́ərij lɪ́mɪtɪd əmáwnt əv déjtə?",
        "trans_RightAnswer": "fjúw-ʃɒ́t lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "trǽnsfər lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "bǽkprəpəgéjʃən"
        ],
        "trans_Explanation": "fjúw-ʃɒ́t lɜ́rnɪŋ ɪz lájk ə súwpər-fǽst lɜ́rnər ðət kən ʌ̀ndərstǽnd ənd ajdɛ́ntɪfàj núw kɒ́nsɛpts rəlájəblij ǽftər síjɪŋ dʒəst ə fjúw əɡzǽmpəlz. ʌ̀nlájk trədɪ́ʃənəl məʃíjn lɜ́rnɪŋ mɛ́θədz, wɪ́tʃ ɔ́fən níjd lɑ́rdʒ əmáwnts əv déjtə, fjúw-ʃɒ́t lɜ́rnɪŋ kən pɪ́k ʌp núw ajdíjəz əkstríjmlij kwɪ́klij. ðɪs méjks ɪt əspɛ́ʃəlij júwsfəl fɔr sənɛ́ərijowz wɛ́ər ɡǽðərɪŋ əkstɛ́nsɪv əɡzǽmpəlz ɪz tájm-kənsúwmɪŋ, əkspɛ́nsɪv, ɔr ɪ̀mprǽktɪkəl."
    },
    {
        "Question": "Imagine you're training an AI to recognize animals. You've given it pictures of cats, dogs, and birds, but suddenly ask it to recognize zebras—animals it has never encountered before. Surprisingly, the AI can correctly identify a zebra without having trained directly on images of them. What kind of machine learning approach allows this remarkable ability?",
        "RightAnswer": "Zero-shot Learning",
        "WrongAnswers": [
            "Few-shot Learning",
            "Supervised Learning",
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Transfer Learning"
        ],
        "Explanation": "Zero-shot learning refers to the fascinating ability of a machine learning model to recognize and classify new objects or concepts it hasn't directly encountered during training. Instead, it uses generalized knowledge or descriptive information it has learned from related examples. Think of it like recognizing a zebra for the first time just by knowing it's 'striped, horse-like, and two-toned' without having been explicitly trained on zebra images.",
        "trans_Question": "ɪmǽdʒɪn júwr tréjnɪŋ ən AI tə rɛ́kəɡnàjz ǽnɪməlz. júwv ɡɪ́vən ɪt pɪ́ktʃərz əv kǽts, dɒ́ɡz, ənd bɜ́rdz, bʌt sʌ́dənlij ǽsk ɪt tə rɛ́kəɡnàjz zíjbrəz—ǽnɪməlz ɪt həz nɛ́vər ənkáwntərd bəfɔ́r. sərprájzɪŋlij, ðə AI kən kərɛ́ktlij ajdɛ́ntɪfàj ə zíjbrə wɪðáwt hǽvɪŋ tréjnd dɪərɛ́klij ɒn ɪ́mɪdʒɪz əv ðɛm. wɒt kájnd əv məʃíjn lɜ́rnɪŋ əprówtʃ əláwz ðɪs rəmɑ́rkəbəl əbɪ́lɪtij?",
        "trans_RightAnswer": "zíjərow-ʃɒ́t lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "fjúw-ʃɒ́t lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ"
        ],
        "trans_Explanation": "zíjərow-ʃɒ́t lɜ́rnɪŋ rəfɜ́rz tə ðə fǽsɪnèjtɪŋ əbɪ́lɪtij əv ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə rɛ́kəɡnàjz ənd klǽsɪfàj núw ɒ́bdʒɛkts ɔr kɒ́nsɛpts ɪt hǽzənt dɪərɛ́klij ənkáwntərd dʊ́rɪŋ tréjnɪŋ. ɪnstɛ́d, ɪt júwsɪz dʒɛ́nərəlàjzd nɒ́lɪdʒ ɔr dəskrɪ́ptɪv ɪnfərméjʃən ɪt həz lɜ́rnd frəm rəléjtɪd əɡzǽmpəlz. θɪ́ŋk əv ɪt lájk rɛ́kəɡnàjzɪŋ ə zíjbrə fɔr ðə fɜ́rst tájm dʒəst baj nówɪŋ ɪt's 'strájpt, hɔ́rs-lájk, ənd túw-tównd' wɪðáwt hǽvɪŋ bɪn əksplɪ́sɪtlij tréjnd ɒn zíjbrə ɪ́mɪdʒɪz."
    },
    {
        "Question": "In machine learning, sometimes your model needs to recognize a new object after seeing just a single example. What is this special kind of learning called?",
        "RightAnswer": "One-shot Learning",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Batch Learning",
            "Unsupervised Learning",
            "Transfer Learning",
            "Online Learning"
        ],
        "Explanation": "One-shot learning helps machines quickly recognize new things even when shown only one example. Humans naturally excel at recognizing someone they've seen just once. Similarly, one-shot learning techniques allow algorithms to identify a new object or concept from a single exposure, without requiring lots of examples. This skill is especially useful for tasks where collecting a lot of data isn't practical.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, sʌ́mtàjmz jɔr mɒ́dəl níjdz tə rɛ́kəɡnàjz ə núw ɒ́bdʒəkt ǽftər síjɪŋ dʒəst ə sɪ́ŋɡəl əɡzǽmpəl. wɒt ɪz ðɪs spɛ́ʃəl kájnd əv lɜ́rnɪŋ kɔ́ld?",
        "trans_RightAnswer": "wʌ́n-ʃɒ́t lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "bǽtʃ lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "ɔ́nlàjn lɜ́rnɪŋ"
        ],
        "trans_Explanation": "wʌ́n-ʃɒ́t lɜ́rnɪŋ hɛ́lps məʃíjnz kwɪ́klij rɛ́kəɡnàjz núw θɪ́ŋz íjvən wɛ́n ʃówn ównlij wʌ́n əɡzǽmpəl. hjúwmənz nǽtʃərəlij əksɛ́l æt rɛ́kəɡnàjzɪŋ sʌ́mwʌ̀n ðéjv síjn dʒəst wʌ́ns. sɪ́mɪlərlij, wʌ́n-ʃɒ́t lɜ́rnɪŋ tɛkníjks əláw ǽlɡərɪ̀ðəmz tə ajdɛ́ntɪfàj ə núw ɒ́bdʒəkt ɔr kɒ́nsɛpt frəm ə sɪ́ŋɡəl əkspówʒər, wɪðáwt rijkwájərɪŋ lɒ́ts əv əɡzǽmpəlz. ðɪs skɪ́l ɪz əspɛ́ʃəlij júwsfəl fɔr tǽsks wɛ́ər kəlɛ́ktɪŋ ə lɒ́t əv déjtə ɪzənt prǽktɪkəl."
    },
    {
        "Question": "Which machine learning technique tries to understand and reproduce the input data by compressing it into a smaller form, and then reconstructing it as accurately as possible, commonly used for data denoising or detecting anomalies?",
        "RightAnswer": "Autoencoders",
        "WrongAnswers": [
            "Support Vector Machines",
            "Decision Trees",
            "Recurrent Neural Networks",
            "Random Forests",
            "Gradient Boosting Machines"
        ],
        "Explanation": "Think of autoencoders as clever data compression machines. They learn to squish complex input data into a simpler, compact representation ('encoding'), and then reconstruct ('decode') it back. They're popular for tasks like removing noise from data, catching anomalies (strange or unusual data points), or simply understanding and visualizing complex data patterns in an easier form.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk trájz tə ʌ̀ndərstǽnd ənd rìjprədúws ðə ɪ́npʊ̀t déjtə baj kəmprɛ́sɪŋ ɪt ɪntə ə smɔ́lər fɔ́rm, ənd ðɛn rìjkənstrʌ́ktɪŋ ɪt æz ǽkjərətlij æz pɒ́sɪbəl, kɒ́mənlij júwzd fɔr déjtə dìjnɔ́jzɪŋ ɔr dətɛ́ktɪŋ ənɒ́məlijz?",
        "trans_RightAnswer": "ɔ̀towənkówdərz",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "dəsɪ́ʒən tríjz",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "rǽndəm fɔ́rəsts",
            "ɡréjdijənt búwstɪŋ məʃíjnz"
        ],
        "trans_Explanation": "θɪ́ŋk əv ɔ̀towənkówdərz æz klɛ́vər déjtə kəmprɛ́ʃən məʃíjnz. ðej lɜ́rn tə skwɪʃ kɒ́mplɛks ɪ́npʊ̀t déjtə ɪntə ə sɪ́mplər, kɒ́mpækt rɛ̀prəzɛntéjʃən ('ɛnkówdɪŋ'), ənd ðɛn rìjkənstrʌ́kt ('dəkówd') ɪt bǽk. ðɛ́ər pɒ́pjələr fɔr tǽsks lájk rijmúwvɪŋ nɔ́jz frəm déjtə, kǽtʃɪŋ ənɒ́məlijz (stréjndʒ ɔr ʌ̀njúwʒùwəl déjtə pɔ́jnts), ɔr sɪ́mplij ʌ̀ndərstǽndɪŋ ənd vɪ́ʒwəlàjzɪŋ kɒ́mplɛks déjtə pǽtərnz ɪn ən íjzijər fɔ́rm."
    },
    {
        "Question": "Which type of machine learning model learns to compress and later recreate data by encoding inputs into a smooth, continuous space, allowing the generation of new and original examples similar to the ones it trained on?",
        "RightAnswer": "Variational Autoencoders",
        "WrongAnswers": [
            "Support Vector Machines",
            "Decision Trees",
            "Convolutional Neural Networks",
            "K-Means Clusters",
            "Random Forests"
        ],
        "Explanation": "Variational Autoencoders (VAEs) are fascinating neural networks used primarily for generative modeling. Think of them as creative artists—they 'encode' original data (like images or sounds) into a smooth and continuous mathematical space and then try to 'decode' that data back to its original form. What's exciting is that once VAEs have learned this encoding-decoding trick, you can create entirely new and imaginative samples that resemble your original data. This makes them incredibly useful for generating realistic images, reconstructing missing data, and transforming existing data into creative variants.",
        "trans_Question": "wɪ́tʃ tájp əv məʃíjn lɜ́rnɪŋ mɒ́dəl lɜ́rnz tə kɒ́mprɛs ənd léjtər rɛ́krijèjt déjtə baj ɛnkówdɪŋ ɪ́npʊ̀ts ɪntə ə smúwð, kəntɪ́njuwəs spéjs, əláwɪŋ ðə dʒɛ̀nəréjʃən əv núw ənd ərɪ́dʒɪnəl əɡzǽmpəlz sɪ́mɪlər tə ðə wʌ́nz ɪt tréjnd ɒn?",
        "trans_RightAnswer": "vɛ̀ərijéjʃənəl ɔ̀towənkówdərz",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "dəsɪ́ʒən tríjz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "k-míjnz klʌ́stərz",
            "rǽndəm fɔ́rəsts"
        ],
        "trans_Explanation": "vɛ̀ərijéjʃənəl ɔ̀towənkówdərz (vejs) ɑr fǽsɪnèjtɪŋ nʊ́rəl nɛ́twɜ̀rks júwzd prajmɛ́ərɪlij fɔr dʒɛ́nərətɪv mɒ́dəlɪ̀ŋ. θɪ́ŋk əv ðɛm æz krijéjtɪv ɑ́rtɪsts—ðej 'ɛnkówd' ərɪ́dʒɪnəl déjtə (lájk ɪ́mɪdʒɪz ɔr sáwndz) ɪntə ə smúwð ənd kəntɪ́njuwəs mæ̀θəmǽtɪkəl spéjs ənd ðɛn tráj tə 'dəkówd' ðət déjtə bǽk tə ɪts ərɪ́dʒɪnəl fɔ́rm. wɒt's əksájtɪŋ ɪz ðət wʌ́ns vejs həv lɜ́rnd ðɪs ɛnkówdɪŋ-dəkówdɪŋ trɪ́k, juw kən krijéjt əntájərlij núw ənd ɪmǽdʒɪnətɪv sǽmpəlz ðət rijzɛ́mbəl jɔr ərɪ́dʒɪnəl déjtə. ðɪs méjks ðɛm ɪnkrɛ́dɪblij júwsfəl fɔr dʒɛ́nərèjtɪŋ rìjəlɪ́stɪk ɪ́mɪdʒɪz, rìjkənstrʌ́ktɪŋ mɪ́sɪŋ déjtə, ənd trænsfɔ́rmɪŋ əɡzɪ́stɪŋ déjtə ɪntə krijéjtɪv vɛ́ərijənts."
    },
    {
        "Question": "Which machine learning technique involves two neural networks competing against each other, one trying to generate realistic data and the other trying to distinguish between genuine and fake samples?",
        "RightAnswer": "Generative Adversarial Networks",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Support Vector Machines",
            "Recurrent Neural Networks",
            "K-Means Clustering",
            "Decision Trees"
        ],
        "Explanation": "Generative Adversarial Networks, or GANs, are machine learning models inspired by competition. Imagine two neural network 'players' in a friendly match: one player (the generator) continually creates fake images or data, while the other (the discriminator) tries to spot if they're real or fake. Through constant competition, GANs learn to produce impressively realistic outputs, such as lifelike images, videos, or even text!",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪnvɒ́lvz túw nʊ́rəl nɛ́twɜ̀rks kəmpíjtɪŋ əɡéjnst ijtʃ ʌ́ðər, wʌ́n trájɪŋ tə dʒɛ́nərèjt rìjəlɪ́stɪk déjtə ənd ðə ʌ́ðər trájɪŋ tə dɪstɪ́ŋɡwɪʃ bijtwíjn dʒénjuwɪn ənd féjk sǽmpəlz?",
        "trans_RightAnswer": "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríjz"
        ],
        "trans_Explanation": "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks, ɔr ɡǽnz, ɑr məʃíjn lɜ́rnɪŋ mɒ́dəlz ɪnspájərd baj kɒ̀mpətɪ́ʃən. ɪmǽdʒɪn túw nʊ́rəl nɛ́twɜ̀rk 'pléjərz' ɪn ə frɛ́ndlij mǽtʃ: wʌ́n pléjər (ðə dʒɛ́nərèjtər) kəntɪ́njuwəlij krijéjts féjk ɪ́mɪdʒɪz ɔr déjtə, wájl ðə ʌ́ðər (ðə dɪ̀skrɪmɪnéjtər) trájz tə spɒ́t ɪf ðɛ́ər ríjəl ɔr féjk. θrúw kɒ́nstənt kɒ̀mpətɪ́ʃən, ɡǽnz lɜ́rn tə prədúws ɪ̀mprɛ́sɪvlij rìjəlɪ́stɪk áwtpʊ̀ts, sʌtʃ æz lájflàjk ɪ́mɪdʒɪz, vɪ́dijowz, ɔr íjvən tɛ́kst!"
    },
    {
        "Question": "What do you call a type of machine learning approach that uses multiple layers of hidden neurons, each layer learning complex patterns from data by breaking down features step by step, initially trained through an unsupervised method, then fine-tuned with supervision?",
        "RightAnswer": "Deep Belief Networks",
        "WrongAnswers": [
            "Support Vector Machines",
            "Decision Trees",
            "K-Means Clustering",
            "Genetic Algorithms",
            "Linear Regression"
        ],
        "Explanation": "Deep Belief Networks (DBNs) are a powerful type of neural network often used in machine learning. They consist of multiple hidden layers of neurons, each layer learning increasingly sophisticated representations of data. DBNs initially learn these patterns without needing labeled data (unsupervised learning), then fine-tune their parameters using labeled examples (supervised learning). Imagine them as a multi-layered puzzle solver—first figuring things out independently, then refining their understanding with guided examples.",
        "trans_Question": "wɒt dúw juw kɔ́l ə tájp əv məʃíjn lɜ́rnɪŋ əprówtʃ ðət júwsɪz mʌ́ltɪpəl léjərz əv hɪ́dən nʊ́rɒnz, ijtʃ léjər lɜ́rnɪŋ kɒ́mplɛks pǽtərnz frəm déjtə baj bréjkɪŋ dawn fíjtʃərz stɛ́p baj stɛ́p, ɪnɪ́ʃəlij tréjnd θrúw ən ʌ̀nsúwpərvàjzd mɛ́θəd, ðɛn fájn-túwnd wɪð sùwpərvɪ́ʒən?",
        "trans_RightAnswer": "díjp bəlíjf nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "dəsɪ́ʒən tríjz",
            "k-míjnz klʌ́stərɪŋ",
            "dʒənɛ́tɪk ǽlɡərɪ̀ðəmz",
            "lɪ́nijər rəɡrɛ́ʃən"
        ],
        "trans_Explanation": "díjp bəlíjf nɛ́twɜ̀rks (DBNz) ɑr ə páwərfəl tájp əv nʊ́rəl nɛ́twɜ̀rk ɔ́fən júwzd ɪn məʃíjn lɜ́rnɪŋ. ðej kənsɪ́st əv mʌ́ltɪpəl hɪ́dən léjərz əv nʊ́rɒnz, ijtʃ léjər lɜ́rnɪŋ ɪnkríjsɪŋɡlij səfɪ́stɪkèjtɪd rɛ̀prəzəntéjʃənz əv déjtə. DBNz ɪnɪ́ʃəlij lɜ́rn ðijz pǽtərnz wɪðáwt níjdɪŋ léjbəld déjtə (ʌ̀nsúwpərvàjzd lɜ́rnɪŋ), ðɛn fájn-túwn ðɛər pərǽmətərz júwzɪŋ léjbəld əɡzǽmpəlz (súwpərvàjzd lɜ́rnɪŋ). ɪmǽdʒɪn ðɛm æz ə mʌ́ltij-léjərd pʌ́zəl sɒ́lvər—fɜ́rst fɪ́ɡjərɪŋ θɪ́ŋz awt ɪndəpɛ́ndəntlij, ðɛn rəfájnɪŋ ðɛər ʌ̀ndərstǽndɪŋ wɪð ɡájdɪd əɡzǽmpəlz."
    },
    {
        "Question": "Imagine you're exploring different types of neural network models. You encounter a special type that learns probability distributions, using ideas from physics (like energy states) to find patterns and relationships. This model can even model uncertainty and incomplete data effectively. What do we call such networks?",
        "RightAnswer": "Boltzmann Machines",
        "WrongAnswers": [
            "Decision Trees",
            "Support Vector Machines",
            "Backpropagation Networks",
            "Convolutional Neural Networks",
            "K-Means Clusters"
        ],
        "Explanation": "Boltzmann Machines are a type of neural network inspired by concepts from physics, specifically thermodynamics. Imagine them as neural networks that use 'energy levels' and probability to model complex relationships and situations with uncertainty or incomplete information. Essentially, they learn by adjusting their connections based on probabilities, helping them discover patterns in a way similar to how physical systems settle into equilibrium states. They're quite helpful for understanding and predicting complicated data sets where some information might be missing or uncertain.",
        "trans_Question": "ɪmǽdʒɪn júwr əksplɔ́rɪŋ dɪ́fərənt tájps əv nʊ́rəl nɛ́twɜ̀rk mɒ́dəlz. juw ənkáwntər ə spɛ́ʃəl tájp ðət lɜ́rnz prɒ̀bəbɪ́lɪtij dɪ̀strəbjúwʃənz, júwzɪŋ ajdíjəz frəm fɪ́zɪks (lájk ɛ́nərdʒij stéjts) tə fájnd pǽtərnz ənd rəléjʃənʃɪ̀ps. ðɪs mɒ́dəl kən íjvən mɒ́dəl ʌ̀nsɜ́rtəntij ənd ɪ̀nkəmplíjt déjtə əfɛ́ktɪvlij. wɒt dúw wij kɔ́l sʌtʃ nɛ́twɜ̀rks?",
        "trans_RightAnswer": "bɔ́ltzmæn məʃíjnz",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "bǽkprəpəgéjʃən nɛ́twɜ̀rks",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "k-míjnz klʌ́stərz"
        ],
        "trans_Explanation": "bɔ́ltzmæn məʃíjnz ɑr ə tájp əv nʊ́rəl nɛ́twɜ̀rk ɪnspájərd baj kɒ́nsɛpts frəm fɪ́zɪks, spəsɪ́fɪklij θɜ̀rmowdàjnǽmɪks. ɪmǽdʒɪn ðɛm æz nʊ́rəl nɛ́twɜ̀rks ðət juwz 'ɛ́nərdʒij lɛ́vəlz' ənd prɒ̀bəbɪ́lɪtij tə mɒ́dəl kɒ́mplɛks rəléjʃənʃɪ̀ps ənd sɪ̀tʃuwéjʃənz wɪð ʌ̀nsɜ́rtəntij ɔr ɪ̀nkəmplíjt ɪnfərméjʃən. əsɛ́nʃəlij, ðej lɜ́rn baj ədʒʌ́stɪŋ ðɛər kənɛ́kʃənz béjst ɒn prɒ̀bəbɪ́lɪtìjz, hɛ́lpɪŋ ðɛm dɪskʌ́vər pǽtərnz ɪn ə wej sɪ́mɪlər tə háw fɪ́zɪkəl sɪ́stəmz sɛ́təl ɪntə ìjkwɪlɪ́brijəm stéjts. ðɛ́ər kwájt hɛ́lpfəl fɔr ʌ̀ndərstǽndɪŋ ənd prədɪ́ktɪŋ kɒ́mplɪkèjtɪd déjtə sɛ́ts wɛ́ər sʌm ɪnfərméjʃən majt bij mɪ́sɪŋ ɔr ʌ̀nsɜ́rtən."
    },
    {
        "Question": "In machine learning, which algorithm is often used to learn hidden patterns from unlabeled data by modeling the probability distribution through interconnected units organized into visible and hidden layers, where each neuron is symmetrically connected without connections within the same layer?",
        "RightAnswer": "Restricted Boltzmann Machines",
        "WrongAnswers": [
            "Support Vector Machines",
            "Convolutional Neural Networks",
            "K-Means Clustering",
            "Decision Trees",
            "Long Short-Term Memory Networks"
        ],
        "Explanation": "Restricted Boltzmann Machines, or RBMs, are a type of neural network algorithm commonly used in unsupervised learning. They have a unique structure composed of visible and hidden layers, and importantly, neurons are symmetrically connected across layers but have no connections between neurons within the same layer. RBMs help discover patterns and features in data by learning probability distributions, making them valuable in fields like feature extraction, collaborative filtering, and dimensionality reduction.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ ǽlɡərɪ̀ðəm ɪz ɔ́fən júwzd tə lɜ́rn hɪ́dən pǽtərnz frəm ʌ̀nléjbəld déjtə baj mɒ́dəlɪ̀ŋ ðə prɒ̀bəbɪ́lɪtij dɪ̀strəbjúwʃən θrúw ɪ̀ntərkənɛ́ktɪd júwnɪts ɔ́rɡənàjzd ɪntə vɪ́zɪbəl ənd hɪ́dən léjərz, wɛ́ər ijtʃ nʊ́rɒn ɪz sɪmɛ́trɪklij kənɛ́ktɪd wɪðáwt kənɛ́kʃənz wɪðɪ́n ðə séjm léjər?",
        "trans_RightAnswer": "rəstrɪ́ktɪd bɔ́ltzmæn məʃíjnz",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríjz",
            "lɔ́ŋ ʃɔ́rt-tɜ́rm mɛ́mərij nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "rəstrɪ́ktɪd bɔ́ltzmæn məʃíjnz, ɔr RBMz, ɑr ə tájp əv nʊ́rəl nɛ́twɜ̀rk ǽlɡərɪ̀ðəm kɒ́mənlij júwzd ɪn ʌ̀nsúwpərvàjzd lɜ́rnɪŋ. ðej həv ə juwnɪ́k strʌ́ktʃər kəmpówzd əv vɪ́zɪbəl ənd hɪ́dən léjərz, ənd ɪmpɔ́rtəntlij, nʊ́rɒnz ɑr sɪmɛ́trɪklij kənɛ́ktɪd əkrɔ́s léjərz bʌt həv now kənɛ́kʃənz bijtwíjn nʊ́rɒnz wɪðɪ́n ðə séjm léjər. RBMz hɛ́lp dɪskʌ́vər pǽtərnz ənd fíjtʃərz ɪn déjtə baj lɜ́rnɪŋ prɒ̀bəbɪ́lɪtij dɪ̀strəbjúwʃənz, méjkɪŋ ðɛm vǽljəbəl ɪn fíjldz lájk fíjtʃər əkstrǽkʃən, kəlǽbərèjtɪv fɪ́ltərɪŋ, ənd dajmɛ̀nʃənǽlɪtij rədʌ́kʃən."
    },
    {
        "Question": "What machine learning approach allows an agent, like a video game character or robot, to learn complex behaviors by repeatedly interacting with its environment, making decisions, and receiving rewards or penalties based on its actions?",
        "RightAnswer": "Deep Reinforcement Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Transfer Learning",
            "Clustering Algorithms",
            "Decision Tree Learning",
            "Natural Language Processing"
        ],
        "Explanation": "Deep Reinforcement Learning combines reinforcement learning (where an agent learns by trial and error, receiving rewards or penalties for its decisions) with deep neural networks. It's like teaching a video game character to play a game by letting it learn from its own actions, discovering strategies on its own, and gradually improving with practice. This approach has become famous for helping AI master games like chess, Go, and even complex video games—allowing agents to learn sophisticated behaviors without explicitly being told what to do.",
        "trans_Question": "wɒt məʃíjn lɜ́rnɪŋ əprówtʃ əláwz ən éjdʒənt, lájk ə vɪ́dijow ɡéjm kǽrəktər ɔr rówbɒ̀t, tə lɜ́rn kɒ́mplɛks bəhéjvjərz baj rəpíjtɪdlij ɪ̀ntərǽktɪŋ wɪð ɪts ənvájərənmənt, méjkɪŋ dəsɪ́ʒənz, ənd rəsíjvɪŋ rəwɔ́rdz ɔr pɛ́nəltijz béjst ɒn ɪts ǽkʃənz?",
        "trans_RightAnswer": "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz",
            "dəsɪ́ʒən tríj lɜ́rnɪŋ",
            "nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ"
        ],
        "trans_Explanation": "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ kəmbájnz rìjɪnfɔ́rsmənt lɜ́rnɪŋ (wɛ́ər ən éjdʒənt lɜ́rnz baj trájəl ənd ɛ́ərər, rəsíjvɪŋ rəwɔ́rdz ɔr pɛ́nəltijz fɔr ɪts dəsɪ́ʒənz) wɪð díjp nʊ́rəl nɛ́twɜ̀rks. ɪt's lájk tíjtʃɪŋ ə vɪ́dijow ɡéjm kǽrəktər tə pléj ə ɡéjm baj lɛ́tɪŋ ɪt lɜ́rn frəm ɪts ówn ǽkʃənz, dɪskʌ́vərɪŋ strǽtədʒijz ɒn ɪts ówn, ənd ɡrǽdʒuwəlij ɪmprúwvɪŋ wɪð prǽktɪs. ðɪs əprówtʃ həz bəkʌ́m féjməs fɔr hɛ́lpɪŋ AI mǽstər ɡéjmz lájk tʃɛ́s, ɡow, ənd íjvən kɒ́mplɛks vɪ́dijow ɡéjmz—əláwɪŋ éjdʒənts tə lɜ́rn səfɪ́stɪkèjtɪd bəhéjvjərz wɪðáwt əksplɪ́sɪtlij bíjɪŋ tówld wɒt tə dúw."
    },
    {
        "Question": "What type of machine learning involves an agent learning the best actions to take in a specific environment by experimenting and receiving rewards, gradually optimizing decisions over time through trial-and-error?",
        "RightAnswer": "Q-Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Clustering",
            "Linear Regression",
            "Support Vector Machines",
            "Gradient Descent"
        ],
        "Explanation": "Q-Learning is an exciting form of reinforcement learning, where an agent learns how to act best in a given environment through rewarding 'good' and discouraging 'bad' actions. The agent experiments, makes mistakes, learns from experience, and gradually improves decision-making at each step. It's similar to how you might train a puppy by rewarding good behavior and gently correcting bad choices—over time, the puppy (or agent) learns the right actions.",
        "trans_Question": "wɒt tájp əv məʃíjn lɜ́rnɪŋ ɪnvɒ́lvz ən éjdʒənt lɜ́rnɪŋ ðə bɛ́st ǽkʃənz tə téjk ɪn ə spəsɪ́fɪk ənvájərənmənt baj əkspɛ́ərɪmɛ̀ntɪŋ ənd rəsíjvɪŋ rəwɔ́rdz, ɡrǽdʒuwəlij ɒ́ptɪmàjzɪŋ dəsɪ́ʒənz ówvər tájm θrúw trájəl-ənd-ɛ́ərər?",
        "trans_RightAnswer": "q-lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "klʌ́stərɪŋ",
            "lɪ́nijər rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "q-lɜ́rnɪŋ ɪz ən əksájtɪŋ fɔ́rm əv rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɛ́ər ən éjdʒənt lɜ́rnz háw tə ǽkt bɛ́st ɪn ə ɡɪ́vən ənvájərənmənt θrúw rəwɔ́rdɪŋ 'ɡʊ́d' ənd dɪskɜ́rɪdʒɪŋ 'bǽd' ǽkʃənz. ðə éjdʒənt əkspɛ́ərɪmənts, méjks mɪstéjks, lɜ́rnz frəm əkspɪ́ərijəns, ənd ɡrǽdʒuwəlij ɪmprúwvz dəsɪ́ʒən-méjkɪŋ æt ijtʃ stɛ́p. ɪt's sɪ́mɪlər tə háw juw majt tréjn ə pʌ́pij baj rəwɔ́rdɪŋ ɡʊ́d bəhéjvjər ənd dʒɛ́ntlij kərɛ́ktɪŋ bǽd tʃɔ́jsɪz—ówvər tájm, ðə pʌ́pij (ɔr éjdʒənt) lɜ́rnz ðə rájt ǽkʃənz."
    },
    {
        "Question": "In machine learning, there's a reinforcement learning approach where a learning agent adjusts its policy based on the experience it actually had, reflecting the sequence: State-Action-Reward-State-Action. What is this method commonly called?",
        "RightAnswer": "SARSA",
        "WrongAnswers": [
            "Q-learning",
            "Monte Carlo Learning",
            "Deep Reinforcement Learning",
            "Actor-Critic Method",
            "Temporal-Difference Learning"
        ],
        "Explanation": "SARSA is a reinforcement learning algorithm where the agent learns from the specific actions it actually took, rather than just the best possible actions it could have taken. Named after the sequence of events it uses — State, Action, Reward, next State, next Action — SARSA helps an agent to learn safely by directly experiencing and improving behavior based on real interactions with its environment, rather than assuming ideal behavior.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə rìjɪnfɔ́rsmənt lɜ́rnɪŋ əprówtʃ wɛ́ər ə lɜ́rnɪŋ éjdʒənt ədʒʌ́sts ɪts pɒ́lɪsij béjst ɒn ðə əkspɪ́ərijəns ɪt ǽktʃùwəlij hǽd, rəflɛ́ktɪŋ ðə síjkwəns: stéjt-ǽkʃən-rəwɔ́rd-stéjt-ǽkʃən. wɒt ɪz ðɪs mɛ́θəd kɒ́mənlij kɔ́ld?",
        "trans_RightAnswer": "SARSA",
        "trans_WrongAnswers": [
            "q-lɜ́rnɪŋ",
            "mɒ́ntij kɑ́rlow lɜ́rnɪŋ",
            "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "ǽktər-krɪ́tɪk mɛ́θəd",
            "tɛ́mpərəl-dɪ́fərəns lɜ́rnɪŋ"
        ],
        "trans_Explanation": "SARSA ɪz ə rìjɪnfɔ́rsmənt lɜ́rnɪŋ ǽlɡərɪ̀ðəm wɛ́ər ðə éjdʒənt lɜ́rnz frəm ðə spəsɪ́fɪk ǽkʃənz ɪt ǽktʃùwəlij tʊ́k, rǽðər ðʌn dʒəst ðə bɛ́st pɒ́sɪbəl ǽkʃənz ɪt kʊ́d həv téjkən. néjmd ǽftər ðə síjkwəns əv əvɛ́nts ɪt júwsɪz — stéjt, ǽkʃən, rəwɔ́rd, nɛ́kst stéjt, nɛ́kst ǽkʃən — SARSA hɛ́lps ən éjdʒənt tə lɜ́rn séjflij baj dɪərɛ́klij əkspɪ́ərijənsɪŋ ənd ɪmprúwvɪŋ bəhéjvjər béjst ɒn ríjəl ɪ̀ntərǽkʃənz wɪð ɪts ənvájərənmənt, rǽðər ðʌn əsúwmɪŋ ajdíjəl bəhéjvjər."
    },
    {
        "Question": "In reinforcement learning, what term describes a method where an agent learns by directly adjusting its decision-making strategies based on how actions impact future rewards?",
        "RightAnswer": "Policy Gradient",
        "WrongAnswers": [
            "Gradient Boosting",
            "Linear Regression",
            "Supervised Learning",
            "Monte Carlo Simulation",
            "Batch Normalization"
        ],
        "Explanation": "Policy Gradient refers to methods in reinforcement learning where the agent improves its actions by directly tweaking the strategy (policy). Imagine it like training a soccer player who fine-tunes their playing style based on previous match experiences. The agent adjusts its decision-making approach by estimating how certain actions affect future outcomes, gradually getting better at making decisions that maximize rewards.",
        "trans_Question": "ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɒt tɜ́rm dəskrájbz ə mɛ́θəd wɛ́ər ən éjdʒənt lɜ́rnz baj dɪərɛ́klij ədʒʌ́stɪŋ ɪts dəsɪ́ʒən-méjkɪŋ strǽtədʒijz béjst ɒn háw ǽkʃənz ɪ́mpækt fjúwtʃər rəwɔ́rdz?",
        "trans_RightAnswer": "pɒ́lɪsij ɡréjdijənt",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "lɪ́nijər rəɡrɛ́ʃən",
            "súwpərvàjzd lɜ́rnɪŋ",
            "mɒ́ntij kɑ́rlow sɪ̀mjəléjʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən"
        ],
        "trans_Explanation": "pɒ́lɪsij ɡréjdijənt rəfɜ́rz tə mɛ́θədz ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ wɛ́ər ðə éjdʒənt ɪmprúwvz ɪts ǽkʃənz baj dɪərɛ́klij twíjkɪŋ ðə strǽtədʒij (pɒ́lɪsij). ɪmǽdʒɪn ɪt lájk tréjnɪŋ ə sɒ́kər pléjər huw fájn-túwnz ðɛər pléjɪŋ stájl béjst ɒn príjvijəs mǽtʃ əkspɪ́ərijənsijz. ðə éjdʒənt ədʒʌ́sts ɪts dəsɪ́ʒən-méjkɪŋ əprówtʃ baj ɛ́stɪmèjtɪŋ háw sɜ́rtən ǽkʃənz əfɛ́kt fjúwtʃər áwtkʌ̀mz, ɡrǽdʒuwəlij ɡɛ́tɪŋ bɛ́tər æt méjkɪŋ dəsɪ́ʒənz ðət mǽksɪmàjz rəwɔ́rdz."
    },
    {
        "Question": "In reinforcement learning, there's an approach where the system learns by having two distinct parts—a decision-making 'actor' who picks actions, and a value-estimating 'critic' who evaluates how good those actions are. What is this clever technique called?",
        "RightAnswer": "Actor-Critic",
        "WrongAnswers": [
            "Decision-Reward Modeling",
            "Policy Gradient Descent",
            "Value-State Pairing",
            "Feedback Reinforcement",
            "Action-Evaluation Loop"
        ],
        "Explanation": "The Actor-Critic method is a smart approach in reinforcement learning where two cooperating parts work together: the 'actor' picks actions based on learned strategies (policies), while the 'critic' evaluates those actions by estimating how good they are. Think of it like having a performer (the actor) refining their performance based on feedback from a knowledgeable critic who constantly assesses the show. This teamwork helps the system learn more efficiently and effectively.",
        "trans_Question": "ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, ðɛər'z ən əprówtʃ wɛ́ər ðə sɪ́stəm lɜ́rnz baj hǽvɪŋ túw dɪstɪ́ŋkt pɑ́rts—ə dəsɪ́ʒən-méjkɪŋ 'ǽktər' huw pɪ́ks ǽkʃənz, ənd ə vǽljuw-ɛ́stɪmèjtɪŋ 'krɪ́tɪk' huw əvǽljuwèjts háw ɡʊ́d ðowz ǽkʃənz ɑr. wɒt ɪz ðɪs klɛ́vər tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "ǽktər-krɪ́tɪk",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən-rəwɔ́rd mɒ́dəlɪ̀ŋ",
            "pɒ́lɪsij ɡréjdijənt dəsɛ́nt",
            "vǽljuw-stéjt pɛ́ərɪŋ",
            "fíjdbæ̀k rìjɪnfɔ́rsmənt",
            "ǽkʃən-əvæ̀ljuwéjʃən lúwp"
        ],
        "trans_Explanation": "ðə ǽktər-krɪ́tɪk mɛ́θəd ɪz ə smɑ́rt əprówtʃ ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ wɛ́ər túw kowɒ́pərèjtɪŋ pɑ́rts wɜ́rk təɡɛ́ðər: ðə 'ǽktər' pɪ́ks ǽkʃənz béjst ɒn lɜ́rnd strǽtədʒijz (pɒ́lɪsijz), wájl ðə 'krɪ́tɪk' əvǽljuwèjts ðowz ǽkʃənz baj ɛ́stɪmèjtɪŋ háw ɡʊ́d ðej ɑr. θɪ́ŋk əv ɪt lájk hǽvɪŋ ə pərfɔ́rmər (ðə ǽktər) rəfájnɪŋ ðɛər pərfɔ́rməns béjst ɒn fíjdbæ̀k frəm ə nɒ́lɪdʒəbəl krɪ́tɪk huw kɒ́nstəntlij əsɛ́sɪz ðə ʃów. ðɪs tíjmwɜ̀rk hɛ́lps ðə sɪ́stəm lɜ́rn mɔr əfɪ́ʃəntlij ənd əfɛ́ktɪvlij."
    },
    {
        "Question": "When building an AI agent for a game, you notice the agent sometimes tries random new moves to see if they're better, and other times sticks with moves it already knows will succeed. What concept describes the balance your agent must achieve to learn effectively?",
        "RightAnswer": "Exploration vs Exploitation",
        "WrongAnswers": [
            "Gradient Descent",
            "Feature Extraction",
            "Training vs Testing",
            "Bias vs Variance",
            "Supervised Learning"
        ],
        "Explanation": "Imagine you're at your favorite restaurant. Do you order your usual dish (something you already know you love) or take the risk and try something new? 'Exploration vs Exploitation' captures this dilemma. In machine learning, exploration means trying new options in hopes of finding better ones, while exploitation means focusing and acting on what's already known to work well. Balancing these two approaches is key to creating agents or systems that can learn efficiently and successfully navigate unknown environments.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ ən AI éjdʒənt fɔr ə ɡéjm, juw nówtɪs ðə éjdʒənt sʌ́mtàjmz trájz rǽndəm núw múwvz tə síj ɪf ðɛ́ər bɛ́tər, ənd ʌ́ðər tájmz stɪ́ks wɪð múwvz ɪt ɔ̀lrɛ́dij nówz wɪl səksíjd. wɒt kɒ́nsɛpt dəskrájbz ðə bǽləns jɔr éjdʒənt mʌst ətʃíjv tə lɜ́rn əfɛ́ktɪvlij?",
        "trans_RightAnswer": "ɛ̀kspləréjʃən vɜ́rsəs ɛ̀ksplɔ̀jtéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "fíjtʃər əkstrǽkʃən",
            "tréjnɪŋ vɜ́rsəs tɛ́stɪŋ",
            "bájəs vɜ́rsəs vɛ́ərijəns",
            "súwpərvàjzd lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ɪmǽdʒɪn júwr æt jɔr féjvərɪt rɛ́strɑ́nt. dúw juw ɔ́rdər jɔr júwʒəwəl dɪ́ʃ (sʌ́mθɪŋ juw ɔ̀lrɛ́dij nów juw lʌ́v) ɔr téjk ðə rɪ́sk ənd tráj sʌ́mθɪŋ núw? 'ɛ̀kspləréjʃən vɜ́rsəs ɛ̀ksplɔ̀jtéjʃən' kǽptʃərz ðɪs dajlɛ́mə. ɪn məʃíjn lɜ́rnɪŋ, ɛ̀kspləréjʃən míjnz trájɪŋ núw ɒ́pʃənz ɪn hówps əv fájndɪŋ bɛ́tər wʌ́nz, wájl ɛ̀ksplɔ̀jtéjʃən míjnz fówkəsɪŋ ənd ǽktɪŋ ɒn wɒt's ɔ̀lrɛ́dij nówn tə wɜ́rk wɛ́l. bǽlənsɪŋ ðijz túw əprówtʃɪz ɪz kíj tə krijéjtɪŋ éjdʒənts ɔr sɪ́stəmz ðət kən lɜ́rn əfɪ́ʃəntlij ənd səksɛ́sfəlij nǽvɪɡejt ʌ̀nnówn ənvájərənmənts."
    },
    {
        "Question": "In reinforcement learning, what term describes how an AI knows it's on the right track by getting feedback or points for its actions?",
        "RightAnswer": "Reward Function",
        "WrongAnswers": [
            "Activation Function",
            "Loss Matrix",
            "Gradient Scheduler",
            "Feature Extractor",
            "Validation Metric"
        ],
        "Explanation": "Think of the reward function as a game's scoring system. Each time your AI makes a move, it gets feedback or scores that tell it whether it's doing well or needs to adjust. In reinforcement learning, the reward function is vital because it's how the AI learns which actions lead to success and which actions should be avoided. Just like earning points or coins in a video game, the reward function motivates the AI to find the best possible strategies.",
        "trans_Question": "ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɒt tɜ́rm dəskrájbz háw ən AI nówz ɪt's ɒn ðə rájt trǽk baj ɡɛ́tɪŋ fíjdbæ̀k ɔr pɔ́jnts fɔr ɪts ǽkʃənz?",
        "trans_RightAnswer": "rəwɔ́rd fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "lɔ́s méjtrɪks",
            "ɡréjdijənt skɛ́dʒuwlər",
            "fíjtʃər ɛkstrǽktər",
            "væ̀lɪdéjʃən mɛ́trɪk"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə rəwɔ́rd fʌ́ŋkʃən æz ə ɡéjm'z skɔ́rɪŋ sɪ́stəm. ijtʃ tájm jɔr AI méjks ə múwv, ɪt ɡɛ́ts fíjdbæ̀k ɔr skɔ́rz ðət tɛ́l ɪt wɛ́ðər ɪt's dúwɪŋ wɛ́l ɔr níjdz tə ədʒʌ́st. ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, ðə rəwɔ́rd fʌ́ŋkʃən ɪz vájtəl bəkɒ́z ɪt's háw ðə AI lɜ́rnz wɪ́tʃ ǽkʃənz líjd tə səksɛ́s ənd wɪ́tʃ ǽkʃənz ʃʊd bij əvɔ́jdɪd. dʒəst lájk ɜ́rnɪŋ pɔ́jnts ɔr kɔ́jnz ɪn ə vɪ́dijow ɡéjm, ðə rəwɔ́rd fʌ́ŋkʃən mówtɪvèjts ðə AI tə fájnd ðə bɛ́st pɒ́sɪbəl strǽtədʒijz."
    },
    {
        "Question": "In reinforcement learning, how do we refer to the mathematical tool that estimates how good a certain state (or state-action pair) is by measuring expected future rewards?",
        "RightAnswer": "Value Function",
        "WrongAnswers": [
            "Activation Function",
            "Gradient Descent",
            "Loss Function",
            "Backpropagation",
            "Regularization"
        ],
        "Explanation": "Think of the Value Function as a guide or crystal ball in reinforcement learning—it predicts the quality of a particular situation or action by estimating how many rewards it can bring in the future. Instead of only looking at immediate benefits, it helps an agent to 'think ahead' and likely make smarter decisions.",
        "trans_Question": "ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, háw dúw wij rəfɜ́r tə ðə mæ̀θəmǽtɪkəl túwl ðət ɛ́stɪmèjts háw ɡʊ́d ə sɜ́rtən stéjt (ɔr stéjt-ǽkʃən pɛ́ər) ɪz baj mɛ́ʒərɪŋ əkspɛ́ktɪd fjúwtʃər rəwɔ́rdz?",
        "trans_RightAnswer": "vǽljuw fʌ́ŋkʃən",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "lɔ́s fʌ́ŋkʃən",
            "bǽkprəpəgéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə vǽljuw fʌ́ŋkʃən æz ə ɡájd ɔr krɪ́stəl bɔ́l ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ—ɪt prədɪ́kts ðə kwɑ́lᵻtij əv ə pərtɪ́kjələr sɪ̀tʃuwéjʃən ɔr ǽkʃən baj ɛ́stɪmèjtɪŋ háw mɛ́nij rəwɔ́rdz ɪt kən brɪ́ŋ ɪn ðə fjúwtʃər. ɪnstɛ́d əv ównlij lʊ́kɪŋ æt ɪmíjdijət bɛ́nəfɪts, ɪt hɛ́lps ən éjdʒənt tə 'θɪ́ŋk əhɛ́d' ənd lájklij méjk smɑ́rtər dəsɪ́ʒənz."
    },
    {
        "Question": "In reinforcement learning, when an agent tries to predict how rewarding it will be to perform a specific action in a particular situation, what term describes this predicted reward?",
        "RightAnswer": "State-Action Value",
        "WrongAnswers": [
            "Activation Function",
            "Loss Gradient",
            "Reward Decay",
            "Policy Gradient",
            "Feature Extraction"
        ],
        "Explanation": "The 'State-Action Value' represents the expected total reward an agent believes it will receive by taking a certain action from a particular situation (state). Think of it like a guess about how good or worthwhile a move will turn out when playing a game. The agent continually updates these values as it learns more through trial and error, guiding it to make better decisions over time.",
        "trans_Question": "ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɛ́n ən éjdʒənt trájz tə prədɪ́kt háw rəwɔ́rdɪŋ ɪt wɪl bij tə pərfɔ́rm ə spəsɪ́fɪk ǽkʃən ɪn ə pərtɪ́kjələr sɪ̀tʃuwéjʃən, wɒt tɜ́rm dəskrájbz ðɪs prədɪ́ktɪd rəwɔ́rd?",
        "trans_RightAnswer": "stéjt-ǽkʃən vǽljuw",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "lɔ́s ɡréjdijənt",
            "rəwɔ́rd dəkéj",
            "pɒ́lɪsij ɡréjdijənt",
            "fíjtʃər əkstrǽkʃən"
        ],
        "trans_Explanation": "ðə 'stéjt-ǽkʃən vǽljuw' rɛ̀prəzɛ́nts ðə əkspɛ́ktɪd tówtəl rəwɔ́rd ən éjdʒənt bəlíjvz ɪt wɪl rəsíjv baj téjkɪŋ ə sɜ́rtən ǽkʃən frəm ə pərtɪ́kjələr sɪ̀tʃuwéjʃən (stéjt). θɪ́ŋk əv ɪt lájk ə ɡɛ́s əbawt háw ɡʊ́d ɔr wɜ́rθwàjl ə múwv wɪl tɜ́rn awt wɛ́n pléjɪŋ ə ɡéjm. ðə éjdʒənt kəntɪ́njuwəlij ʌ́pdèjts ðijz vǽljuwz æz ɪt lɜ́rnz mɔr θrúw trájəl ənd ɛ́ərər, ɡájdɪŋ ɪt tə méjk bɛ́tər dəsɪ́ʒənz ówvər tájm."
    },
    {
        "Question": "In reinforcement learning, when you want a way to measure how good a particular decision or action will be in the long run, which concept helps you break down this future reward into a simpler, immediate reward plus discounted future rewards?",
        "RightAnswer": "Bellman Equation",
        "WrongAnswers": [
            "Gradient Descent",
            "Kernel Trick",
            "Confusion Matrix",
            "Softmax Function",
            "Dropout Regularization"
        ],
        "Explanation": "Think of the Bellman Equation as a way of simplifying complex future decisions by breaking them down into smaller, bite-sized steps. In reinforcement learning, whenever an agent (like a robot or a game-playing AI) needs to decide what action will give it the best long-term benefit, it uses the Bellman Equation. It neatly splits a decision into an immediate reward, plus a fraction (discounted amount) of all the good outcomes likely to follow later, making evaluation and decision-making manageable and practical.",
        "trans_Question": "ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɛ́n juw wɒ́nt ə wej tə mɛ́ʒər háw ɡʊ́d ə pərtɪ́kjələr dəsɪ́ʒən ɔr ǽkʃən wɪl bij ɪn ðə lɔ́ŋ rʌ́n, wɪ́tʃ kɒ́nsɛpt hɛ́lps juw bréjk dawn ðɪs fjúwtʃər rəwɔ́rd ɪntə ə sɪ́mplər, ɪmíjdijət rəwɔ́rd plʌ́s dɪ́skàwntɪd fjúwtʃər rəwɔ́rdz?",
        "trans_RightAnswer": "bɛ́lmən əkwéjʒən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "kɜ́rnəl trɪ́k",
            "kənfjúwʒən méjtrɪks",
            "sɔ̀ftmǽks fʌ́ŋkʃən",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə bɛ́lmən əkwéjʒən æz ə wej əv sɪ́mpləfajɪŋ kɒ́mplɛks fjúwtʃər dəsɪ́ʒənz baj bréjkɪŋ ðɛm dawn ɪntə smɔ́lər, bájt-sájzd stɛ́ps. ɪn rìjɪnfɔ́rsmənt lɜ́rnɪŋ, wɛnɛ́vər ən éjdʒənt (lájk ə rówbɒ̀t ɔr ə ɡéjm-pléjɪŋ AI) níjdz tə dəsájd wɒt ǽkʃən wɪl ɡɪ́v ɪt ðə bɛ́st lɔ́ŋ-tɜ́rm bɛ́nəfɪt, ɪt júwsɪz ðə bɛ́lmən əkwéjʒən. ɪt níjtlij splɪ́ts ə dəsɪ́ʒən ɪntə ən ɪmíjdijət rəwɔ́rd, plʌ́s ə frǽkʃən (dɪ́skàwntɪd əmáwnt) əv ɔl ðə ɡʊ́d áwtkʌ̀mz lájklij tə fɒ́low léjtər, méjkɪŋ əvæ̀ljuwéjʃən ənd dəsɪ́ʒən-méjkɪŋ mǽnədʒəbəl ənd prǽktɪkəl."
    },
    {
        "Question": "In machine learning, which algorithm is commonly used to guide decision-making in game AI, such as choosing optimal moves in board games by simulating numerous possible future outcomes?",
        "RightAnswer": "Monte Carlo Tree Search",
        "WrongAnswers": [
            "Gradient Descent",
            "A* Search",
            "K-means Clustering",
            "Support Vector Machine",
            "Linear Regression"
        ],
        "Explanation": "Monte Carlo Tree Search (MCTS) is a clever algorithm often used by artificial intelligence to make decisions in games. Imagine playing chess or Go, where a computer has to pick the best move among countless possibilities. MCTS explores different potential moves by simulating random games from each possibility, slowly building up a tree of options. Over time, it identifies the moves that usually lead to better outcomes, guiding the AI efficiently toward smarter gameplay choices.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ ǽlɡərɪ̀ðəm ɪz kɒ́mənlij júwzd tə ɡájd dəsɪ́ʒən-méjkɪŋ ɪn ɡéjm AI, sʌtʃ æz tʃúwzɪŋ ɒ́ptɪməl múwvz ɪn bɔ́rd ɡéjmz baj sɪ́mjəlèjtɪŋ njúwmərəs pɒ́sɪbəl fjúwtʃər áwtkʌ̀mz?",
        "trans_RightAnswer": "mɒ́ntij kɑ́rlow tríj sɜ́rtʃ",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "A* sɜ́rtʃ",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "lɪ́nijər rəɡrɛ́ʃən"
        ],
        "trans_Explanation": "mɒ́ntij kɑ́rlow tríj sɜ́rtʃ (MCTS) ɪz ə klɛ́vər ǽlɡərɪ̀ðəm ɔ́fən júwzd baj ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns tə méjk dəsɪ́ʒənz ɪn ɡéjmz. ɪmǽdʒɪn pléjɪŋ tʃɛ́s ɔr ɡow, wɛ́ər ə kəmpjúwtər həz tə pɪ́k ðə bɛ́st múwv əmʌ́ŋ káwntləs pɒ̀sɪbɪ́lɪtijz. MCTS əksplɔ́rz dɪ́fərənt pətɛ́nʃəl múwvz baj sɪ́mjəlèjtɪŋ rǽndəm ɡéjmz frəm ijtʃ pɒ̀sɪbɪ́lɪtij, slówlij bɪ́ldɪŋ ʌp ə tríj əv ɒ́pʃənz. ówvər tájm, ɪt ajdɛ́ntɪfàjz ðə múwvz ðət júwʒəlij líjd tə bɛ́tər áwtkʌ̀mz, ɡájdɪŋ ðə AI əfɪ́ʃəntlij təwɔ́rd smɑ́rtər ɡéjmplèj tʃɔ́jsɪz."
    },
    {
        "Question": "Imagine you're training a complex model, but it's stuck in a decent yet not optimal state. You decide to occasionally accept worse solutions temporarily, hoping they'll eventually lead you to a much better solution overall. Which algorithmic strategy within machine learning best describes this approach?",
        "RightAnswer": "Simulated Annealing",
        "WrongAnswers": [
            "Gradient Descent",
            "Genetic Algorithm",
            "Nearest Neighbor Search",
            "Backpropagation",
            "K-Means Clustering"
        ],
        "Explanation": "Simulated Annealing is inspired by how metals cool and crystallize. In machine learning, it's a thoughtful way of occasionally selecting a worse solution instead of always picking the immediate best. This flexibility can help you 'escape' okay-but-not-great solutions, guiding your search toward finding even better solutions. Imagine stepping uphill occasionally when hiking downhill so you can eventually reach the lowest valley. That's what simulated annealing does—it periodically accepts slightly worse solutions in the short term to reach an even better long-term solution.",
        "trans_Question": "ɪmǽdʒɪn júwr tréjnɪŋ ə kɒ́mplɛks mɒ́dəl, bʌt ɪt's stʌ́k ɪn ə díjsənt jɛt nɒt ɒ́ptɪməl stéjt. juw dəsájd tə əkéjʒənəlij æksɛ́pt wɜ́rs səlúwʃənz tɛ̀mpərɛ́ərɪlij, hówpɪŋ ðéjl əvɛ́ntʃuwəlij líjd juw tə ə mʌtʃ bɛ́tər səlúwʃən ówvərɔ̀l. wɪ́tʃ ǽlɡərɪ̀ðəmɪk strǽtədʒij wɪðɪ́n məʃíjn lɜ́rnɪŋ bɛ́st dəskrájbz ðɪs əprówtʃ?",
        "trans_RightAnswer": "sɪ́mjəlèjtɪd əníjlɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "dʒənɛ́tɪk ǽlɡərɪ̀ðəm",
            "nɪ́ərəst néjbər sɜ́rtʃ",
            "bǽkprəpəgéjʃən",
            "k-míjnz klʌ́stərɪŋ"
        ],
        "trans_Explanation": "sɪ́mjəlèjtɪd əníjlɪŋ ɪz ɪnspájərd baj háw mɛ́təlz kúwl ənd krɪ́stəlàjz. ɪn məʃíjn lɜ́rnɪŋ, ɪt's ə θɔ́tfəl wej əv əkéjʒənəlij səlɛ́ktɪŋ ə wɜ́rs səlúwʃən ɪnstɛ́d əv ɔ́lwejz pɪ́kɪŋ ðə ɪmíjdijət bɛ́st. ðɪs flɛ̀ksɪbɪ́lɪtij kən hɛ́lp juw 'əskéjp' òwkéj-bʌt-nɒt-ɡréjt səlúwʃənz, ɡájdɪŋ jɔr sɜ́rtʃ təwɔ́rd fájndɪŋ íjvən bɛ́tər səlúwʃənz. ɪmǽdʒɪn stɛ́pɪŋ ʌ́phɪ́l əkéjʒənəlij wɛ́n hájkɪŋ dáwnhɪ́l sow juw kən əvɛ́ntʃuwəlij ríjtʃ ðə lówəst vǽlij. ðət's wɒt sɪ́mjəlèjtɪd əníjlɪŋ dʌz—ɪt pìjərijɒ́dɪkəlij æksɛ́pts slájtlij wɜ́rs səlúwʃənz ɪn ðə ʃɔ́rt tɜ́rm tə ríjtʃ ən íjvən bɛ́tər lɔ́ŋ-tɜ́rm səlúwʃən."
    },
    {
        "Question": "You're training a machine learning model and notice that updating it using the full dataset each time is slow and inefficient. Instead, you decide to randomly select data points one at a time or in small batches to rapidly adjust the model. What's the name of this method?",
        "RightAnswer": "Stochastic Gradient Descent",
        "WrongAnswers": [
            "Batch Normalization",
            "Principal Component Analysis",
            "Random Forest",
            "K-Nearest Neighbors",
            "Gradient Boosting"
        ],
        "Explanation": "Stochastic Gradient Descent (SGD) is a popular method for training machine learning models quickly and efficiently. Rather than calculating errors using the entire dataset every time—which can be slow—you take random single samples or small groups of samples (called mini-batches) to update and improve the model. This random sampling makes training faster and often helps the model find good solutions in less time, especially with large datasets.",
        "trans_Question": "júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ənd nówtɪs ðət ʌ́pdèjtɪŋ ɪt júwzɪŋ ðə fʊ́l déjtəsɛ̀t ijtʃ tájm ɪz slów ənd ɪ̀nəfɪ́ʃənt. ɪnstɛ́d, juw dəsájd tə rǽndəmlij səlɛ́kt déjtə pɔ́jnts wʌ́n æt ə tájm ɔr ɪn smɔ́l bǽtʃɪz tə rǽpɪdlij ədʒʌ́st ðə mɒ́dəl. wɒt's ðə néjm əv ðɪs mɛ́θəd?",
        "trans_RightAnswer": "stowkǽstɪk ɡréjdijənt dəsɛ́nt",
        "trans_WrongAnswers": [
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "rǽndəm fɔ́rəst",
            "k-nɪ́ərəst néjbərz",
            "ɡréjdijənt búwstɪŋ"
        ],
        "trans_Explanation": "stowkǽstɪk ɡréjdijənt dəsɛ́nt (SGD) ɪz ə pɒ́pjələr mɛ́θəd fɔr tréjnɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz kwɪ́klij ənd əfɪ́ʃəntlij. rǽðər ðʌn kǽlkjəlèjtɪŋ ɛ́ərərz júwzɪŋ ðə əntájər déjtəsɛ̀t ɛvərij tájm—wɪ́tʃ kən bij slów—juw téjk rǽndəm sɪ́ŋɡəl sǽmpəlz ɔr smɔ́l ɡrúwps əv sǽmpəlz (kɔ́ld mɪ́nij-bǽtʃɪz) tə əpdéjt ənd ɪmprúwv ðə mɒ́dəl. ðɪs rǽndəm sǽmplɪŋ méjks tréjnɪŋ fǽstər ənd ɔ́fən hɛ́lps ðə mɒ́dəl fájnd ɡʊ́d səlúwʃənz ɪn lɛ́s tájm, əspɛ́ʃəlij wɪð lɑ́rdʒ déjtəsɛ̀ts."
    },
    {
        "Question": "In machine learning, we often need efficient ways to adjust the parameters of our model using training data. When we split the training data into smaller groups and use each group separately to update our model parameters—allowing faster training and smoother updates—what is this method called?",
        "RightAnswer": "Mini-Batch Gradient Descent",
        "WrongAnswers": [
            "Full Data Gradient Descent",
            "Randomized Gradient Decay",
            "Single-Point Parameter Update",
            "Adaptive Learning Rate",
            "Hyperparameter Batch Adjustment"
        ],
        "Explanation": "Mini-Batch Gradient Descent is a popular technique for training machine learning models. Instead of calculating parameter updates using all data points at once (full batch) or just one data point at a time (stochastic), it splits training data into smaller batches called 'mini-batches.' By using these smaller groups of data, we achieve a balance—faster computation compared to full batch, and less noise compared to stochastic gradient descent, leading to smoother and quicker convergence to an optimal solution.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wij ɔ́fən níjd əfɪ́ʃənt wéjz tə ədʒʌ́st ðə pərǽmətərz əv awər mɒ́dəl júwzɪŋ tréjnɪŋ déjtə. wɛ́n wij splɪ́t ðə tréjnɪŋ déjtə ɪntə smɔ́lər ɡrúwps ənd juwz ijtʃ ɡrúwp sɛ́pərətlij tə əpdéjt awər mɒ́dəl pərǽmətərz—əláwɪŋ fǽstər tréjnɪŋ ənd smúwðər ʌ́pdèjts—wɒt ɪz ðɪs mɛ́θəd kɔ́ld?",
        "trans_RightAnswer": "mɪ́nij-bǽtʃ ɡréjdijənt dəsɛ́nt",
        "trans_WrongAnswers": [
            "fʊ́l déjtə ɡréjdijənt dəsɛ́nt",
            "rǽndəmàjzd ɡréjdijənt dəkéj",
            "sɪ́ŋɡəl-pɔ́jnt pərǽmətər əpdéjt",
            "ədǽptɪv lɜ́rnɪŋ réjt",
            "hàjpərpǽrəmətər bǽtʃ ədʒʌ́stmənt"
        ],
        "trans_Explanation": "mɪ́nij-bǽtʃ ɡréjdijənt dəsɛ́nt ɪz ə pɒ́pjələr tɛkníjk fɔr tréjnɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz. ɪnstɛ́d əv kǽlkjəlèjtɪŋ pərǽmətər ʌ́pdèjts júwzɪŋ ɔl déjtə pɔ́jnts æt wʌ́ns (fʊ́l bǽtʃ) ɔr dʒəst wʌ́n déjtə pɔ́jnt æt ə tájm (stowkǽstɪk), ɪt splɪ́ts tréjnɪŋ déjtə ɪntə smɔ́lər bǽtʃɪz kɔ́ld 'mɪ́nij-bǽtʃɪz.' baj júwzɪŋ ðijz smɔ́lər ɡrúwps əv déjtə, wij ətʃíjv ə bǽləns—fǽstər kɒ̀mpjətéjʃən kəmpɛ́ərd tə fʊ́l bǽtʃ, ənd lɛ́s nɔ́jz kəmpɛ́ərd tə stowkǽstɪk ɡréjdijənt dəsɛ́nt, líjdɪŋ tə smúwðər ənd kwɪ́kər kənvɜ́rdʒəns tə ən ɒ́ptɪməl səlúwʃən."
    },
    {
        "Question": "In machine learning, sometimes training neural networks can feel slow, especially when the learning process keeps zigzagging around the best solution. What's the term used to describe the technique that helps speed up training and smooths out these zigzags by guiding the calculation towards a consistent direction?",
        "RightAnswer": "Momentum",
        "WrongAnswers": [
            "Overfitting",
            "Backpropagation",
            "Regularization",
            "Pooling",
            "Data augmentation"
        ],
        "Explanation": "In machine learning, Momentum is like giving your model a gentle push to keep going in the direction it's already headed. Just like rolling a ball down a hill gathers speed and doesn't easily change its course, momentum helps neural network models move steadily toward the optimal solution without bouncing around aimlessly. This speeds up training and creates smoother learning paths.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, sʌ́mtàjmz tréjnɪŋ nʊ́rəl nɛ́twɜ̀rks kən fíjl slów, əspɛ́ʃəlij wɛ́n ðə lɜ́rnɪŋ prɒ́sɛs kíjps zɪ́ɡzæɡɪŋ əráwnd ðə bɛ́st səlúwʃən. wɒt's ðə tɜ́rm júwzd tə dəskrájb ðə tɛkníjk ðət hɛ́lps spíjd ʌp tréjnɪŋ ənd smúwðz awt ðijz zɪ́ɡzæɡz baj ɡájdɪŋ ðə kæ̀lkjəléjʃən təwɔ́rdz ə kənsɪ́stənt dɪərɛ́kʃən?",
        "trans_RightAnswer": "mowmɛ́ntəm",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "bǽkprəpəgéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "púwlɪŋ",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "ɪn məʃíjn lɜ́rnɪŋ, mowmɛ́ntəm ɪz lájk ɡɪ́vɪŋ jɔr mɒ́dəl ə dʒɛ́ntəl pʊ́ʃ tə kíjp ɡówɪŋ ɪn ðə dɪərɛ́kʃən ɪt's ɔ̀lrɛ́dij hɛ́dɪd. dʒəst lájk rówlɪŋ ə bɔ́l dawn ə hɪ́l ɡǽðərz spíjd ənd dʌ́zənt íjzəlij tʃéjndʒ ɪts kɔ́rs, mowmɛ́ntəm hɛ́lps nʊ́rəl nɛ́twɜ̀rk mɒ́dəlz múwv stɛ́dɪlij təwɔ́rd ðə ɒ́ptɪməl səlúwʃən wɪðáwt báwnsɪŋ əráwnd éjmləslij. ðɪs spíjdz ʌp tréjnɪŋ ənd krijéjts smúwðər lɜ́rnɪŋ pǽðz."
    },
    {
        "Question": "In machine learning, when you're training a neural network, choosing the right optimizer affects how quickly and effectively your model learns. Which of the following is a popular adaptive optimization algorithm known for efficiently updating weights during training by adjusting learning rates for each parameter?",
        "RightAnswer": "Adam Optimizer",
        "WrongAnswers": [
            "Sigmoid Activation",
            "Dropout Regularization",
            "Batch Normalization",
            "Gradient Clipping",
            "Max Pooling"
        ],
        "Explanation": "The Adam Optimizer is a widely-used optimization method in machine learning model training. It stands for 'Adaptive Moment Estimation.' Think of Adam like a smart guide who helps your neural network find the best possible solution quickly by adapting the learning speed differently for each parameter. It's popular because it's efficient, typically requires less fine-tuning, and helps accelerate the process toward higher accuracy.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n júwr tréjnɪŋ ə nʊ́rəl nɛ́twɜ̀rk, tʃúwzɪŋ ðə rájt ɒ́ptəmajzər əfɛ́kts háw kwɪ́klij ənd əfɛ́ktɪvlij jɔr mɒ́dəl lɜ́rnz. wɪ́tʃ əv ðə fɒ́lowɪŋ ɪz ə pɒ́pjələr ədǽptɪv ɒptɪmɪzéjʃən ǽlɡərɪ̀ðəm nówn fɔr əfɪ́ʃəntlij ʌ́pdèjtɪŋ wéjts dʊ́rɪŋ tréjnɪŋ baj ədʒʌ́stɪŋ lɜ́rnɪŋ réjts fɔr ijtʃ pərǽmətər?",
        "trans_RightAnswer": "ǽdəm ɒ́ptəmajzər",
        "trans_WrongAnswers": [
            "sɪ́ɡmɔ̀jd æ̀ktɪvéjʃən",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt klɪ́pɪŋ",
            "mæks púwlɪŋ"
        ],
        "trans_Explanation": "ðə ǽdəm ɒ́ptəmajzər ɪz ə wájdlij-júwzd ɒptɪmɪzéjʃən mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ mɒ́dəl tréjnɪŋ. ɪt stǽndz fɔr 'ədǽptɪv mówmənt ɛ̀stɪméjʃən.' θɪ́ŋk əv ǽdəm lájk ə smɑ́rt ɡájd huw hɛ́lps jɔr nʊ́rəl nɛ́twɜ̀rk fájnd ðə bɛ́st pɒ́sɪbəl səlúwʃən kwɪ́klij baj ədǽptɪŋ ðə lɜ́rnɪŋ spíjd dɪ́fərɛ́ntlij fɔr ijtʃ pərǽmətər. ɪt's pɒ́pjələr bəkɒ́z ɪt's əfɪ́ʃənt, tɪ́pɪkəlij rəkwájərz lɛ́s fájn-túwnɪŋ, ənd hɛ́lps æksɛ́lərèjt ðə prɒ́sɛs təwɔ́rd hájər ǽkjərəsij."
    },
    {
        "Question": "You're training a neural network, and you notice your learning rate isn't performing as you'd hoped. You decide to use an optimization algorithm that adjusts its steps by maintaining a moving average of squared gradients, allowing it to adapt the step size individually for each parameter. Which optimizer are you using?",
        "RightAnswer": "RMSprop",
        "WrongAnswers": [
            "Gradient Descent",
            "Dropout",
            "Batch Normalization",
            "ReLU activation",
            "K-means clustering"
        ],
        "Explanation": "RMSprop is an optimization technique in machine learning that helps neural networks train faster and more efficiently. It adapts the learning rate for each parameter individually by maintaining a moving average of squared gradients. By doing this, RMSprop helps avoid overly aggressive or too timid step sizes, improving stability and performance during training. Think of RMSprop as a smart cruise control for your neural network—smoothly adjusting speed based on past road conditions (gradient magnitudes) for a smoother training journey.",
        "trans_Question": "júwr tréjnɪŋ ə nʊ́rəl nɛ́twɜ̀rk, ənd juw nówtɪs jɔr lɜ́rnɪŋ réjt ɪzənt pərfɔ́rmɪŋ æz júwd hówpt. juw dəsájd tə juwz ən ɒptɪmɪzéjʃən ǽlɡərɪ̀ðəm ðət ədʒʌ́sts ɪts stɛ́ps baj mejntéjnɪŋ ə múwvɪŋ ǽvərɪdʒ əv skwɛ́ərd ɡréjdijənts, əláwɪŋ ɪt tə ədǽpt ðə stɛ́p sájz ɪndɪvɪ́dʒəlij fɔr ijtʃ pərǽmətər. wɪ́tʃ ɒ́ptəmajzər ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "RMSPROP",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "drɒ́pàwt",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "RELU æ̀ktɪvéjʃən",
            "k-míjnz klʌ́stərɪŋ"
        ],
        "trans_Explanation": "RMSPROP ɪz ən ɒptɪmɪzéjʃən tɛkníjk ɪn məʃíjn lɜ́rnɪŋ ðət hɛ́lps nʊ́rəl nɛ́twɜ̀rks tréjn fǽstər ənd mɔr əfɪ́ʃəntlij. ɪt ədǽpts ðə lɜ́rnɪŋ réjt fɔr ijtʃ pərǽmətər ɪndɪvɪ́dʒəlij baj mejntéjnɪŋ ə múwvɪŋ ǽvərɪdʒ əv skwɛ́ərd ɡréjdijənts. baj dúwɪŋ ðɪs, RMSPROP hɛ́lps əvɔ́jd ówvərlij əɡrɛ́sɪv ɔr túw tɪ́mɪd stɛ́p sájzɪz, ɪmprúwvɪŋ stəbɪ́lɪtij ənd pərfɔ́rməns dʊ́rɪŋ tréjnɪŋ. θɪ́ŋk əv RMSPROP æz ə smɑ́rt krúwz kəntrówl fɔr jɔr nʊ́rəl nɛ́twɜ̀rk—smúwðlij ədʒʌ́stɪŋ spíjd béjst ɒn pǽst rówd kəndɪ́ʃənz (ɡréjdijənt mǽɡnɪtùwdz) fɔr ə smúwðər tréjnɪŋ dʒɜ́rnij."
    },
    {
        "Question": "In machine learning, what technique do we use to gradually adjust how quickly a model learns during training to help it settle into better solutions over time?",
        "RightAnswer": "Learning Rate Scheduling",
        "WrongAnswers": [
            "Gradient Regularization",
            "Activation Optimization",
            "Feature Normalization",
            "Hyperparameter Pruning",
            "Batch Size Annealing"
        ],
        "Explanation": "Think of the learning rate as your model's speed of learning: too high and your model might overshoot good solutions, too low and your training could take forever. Learning Rate Scheduling gradually changes this speed during training—often reducing it—to help your model carefully approach the best possible solutions without missing key details. It's like slowly decreasing your car's speed as you approach your parking spot to avoid overshooting.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tɛkníjk dúw wij juwz tə ɡrǽdʒuwəlij ədʒʌ́st háw kwɪ́klij ə mɒ́dəl lɜ́rnz dʊ́rɪŋ tréjnɪŋ tə hɛ́lp ɪt sɛ́təl ɪntə bɛ́tər səlúwʃənz ówvər tájm?",
        "trans_RightAnswer": "lɜ́rnɪŋ réjt skɛ́dʒuwlɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt rèɡjəlɛ̀ərɪzéjʃən",
            "æ̀ktɪvéjʃən ɒptɪmɪzéjʃən",
            "fíjtʃər nɔ̀rməlɪzéjʃən",
            "hàjpərpǽrəmətər prúwnɪŋ",
            "bǽtʃ sájz əníjlɪŋ"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə lɜ́rnɪŋ réjt æz jɔr mɒ́dəl'z spíjd əv lɜ́rnɪŋ: túw háj ənd jɔr mɒ́dəl majt ówvərʃùwt ɡʊ́d səlúwʃənz, túw lów ənd jɔr tréjnɪŋ kʊ́d téjk fərɛ́vər. lɜ́rnɪŋ réjt skɛ́dʒuwlɪŋ ɡrǽdʒuwəlij tʃéjndʒɪz ðɪs spíjd dʊ́rɪŋ tréjnɪŋ—ɔ́fən rədjúwsɪŋ ɪt—tə hɛ́lp jɔr mɒ́dəl kɛ́ərfəlij əprówtʃ ðə bɛ́st pɒ́sɪbəl səlúwʃənz wɪðáwt mɪ́sɪŋ kíj díjtejlz. ɪt's lájk slówlij díjkrìjsɪŋ jɔr kɑ́r'z spíjd æz juw əprówtʃ jɔr pɑ́rkɪŋ spɒ́t tə əvɔ́jd ówvərʃùwtɪŋ."
    },
    {
        "Question": "When building a neural network, each neuron starts off with random numbers to help it learn better. What do we call setting these initial random values before training begins?",
        "RightAnswer": "Weight Initialization",
        "WrongAnswers": [
            "Gradient Checking",
            "Batch Normalization",
            "Overfitting",
            "Backpropagation",
            "Feature Scaling"
        ],
        "Explanation": "Weight initialization refers to assigning appropriate initial random values to the neural network's parameters (weights) before training starts. Choosing good initial values helps the network learn efficiently and perform better, rather than getting stuck or taking forever to train. Think of it as giving neurons a balanced and helpful starting point, instead of leaving them confused or biased from the beginning.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ ə nʊ́rəl nɛ́twɜ̀rk, ijtʃ nʊ́rɒn stɑ́rts ɔ́f wɪð rǽndəm nʌ́mbərz tə hɛ́lp ɪt lɜ́rn bɛ́tər. wɒt dúw wij kɔ́l sɛ́tɪŋ ðijz ɪnɪ́ʃəl rǽndəm vǽljuwz bəfɔ́r tréjnɪŋ bəɡɪ́nz?",
        "trans_RightAnswer": "wéjt ɪnɪ́ʃəlɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt tʃɛ́kɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "òwvərfɪ́tɪŋ",
            "bǽkprəpəgéjʃən",
            "fíjtʃər skéjlɪŋ"
        ],
        "trans_Explanation": "wéjt ɪnɪ́ʃəlɪzéjʃən rəfɜ́rz tə əsájnɪŋ əprówprijèjt ɪnɪ́ʃəl rǽndəm vǽljuwz tə ðə nʊ́rəl nɛ́twɜ̀rk'z pərǽmətərz (wéjts) bəfɔ́r tréjnɪŋ stɑ́rts. tʃúwzɪŋ ɡʊ́d ɪnɪ́ʃəl vǽljuwz hɛ́lps ðə nɛ́twɜ̀rk lɜ́rn əfɪ́ʃəntlij ənd pərfɔ́rm bɛ́tər, rǽðər ðʌn ɡɛ́tɪŋ stʌ́k ɔr téjkɪŋ fərɛ́vər tə tréjn. θɪ́ŋk əv ɪt æz ɡɪ́vɪŋ nʊ́rɒnz ə bǽlənst ənd hɛ́lpfəl stɑ́rtɪŋ pɔ́jnt, ɪnstɛ́d əv líjvɪŋ ðɛm kənfjúwzd ɔr bájəst frəm ðə bəɡɪ́nɪŋ."
    },
    {
        "Question": "Your neural network is training well, but after many epochs, you notice the accuracy on the validation data starts to drop, signaling that the model could be memorizing instead of truly learning. Which technique involves periodically checking the network's progress on a validation set and then halting the training as soon as the performance begins to worsen?",
        "RightAnswer": "Early Stopping",
        "WrongAnswers": [
            "Cross Validation",
            "Batch Normalization",
            "Gradient Clipping",
            "Learning Rate Decay",
            "Regularization"
        ],
        "Explanation": "Early Stopping is like a patient teacher who carefully watches a student learning. It involves monitoring the model's performance on separate validation data while training. When the performance stops improving, Early Stopping gently tells the model, 'That's enough training!' to prevent overfitting—where the model memorizes training data instead of truly learning patterns.",
        "trans_Question": "jɔr nʊ́rəl nɛ́twɜ̀rk ɪz tréjnɪŋ wɛ́l, bʌt ǽftər mɛ́nij ɛ́pəks, juw nówtɪs ðə ǽkjərəsij ɒn ðə væ̀lɪdéjʃən déjtə stɑ́rts tə drɒ́p, sɪ́ɡnəlɪŋ ðət ðə mɒ́dəl kʊ́d bij mɛ́məràjzɪŋ ɪnstɛ́d əv trúwlij lɜ́rnɪŋ. wɪ́tʃ tɛkníjk ɪnvɒ́lvz pìjərijɒ́dɪkəlij tʃɛ́kɪŋ ðə nɛ́twɜ̀rk'z prɒ́ɡrɛ̀s ɒn ə væ̀lɪdéjʃən sɛ́t ənd ðɛn hɔ́ltɪŋ ðə tréjnɪŋ æz súwn æz ðə pərfɔ́rməns bəɡɪ́nz tə wɜ́rsən?",
        "trans_RightAnswer": "ɜ́rlij stɒ́pɪŋ",
        "trans_WrongAnswers": [
            "krɔ́s væ̀lɪdéjʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt klɪ́pɪŋ",
            "lɜ́rnɪŋ réjt dəkéj",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "ɜ́rlij stɒ́pɪŋ ɪz lájk ə péjʃənt tíjtʃər huw kɛ́ərfəlij wɒ́tʃɪz ə stúwdənt lɜ́rnɪŋ. ɪt ɪnvɒ́lvz mɒ́nɪtərɪŋ ðə mɒ́dəl'z pərfɔ́rməns ɒn sɛ́pərət væ̀lɪdéjʃən déjtə wájl tréjnɪŋ. wɛ́n ðə pərfɔ́rməns stɒ́ps ɪmprúwvɪŋ, ɜ́rlij stɒ́pɪŋ dʒɛ́ntlij tɛ́lz ðə mɒ́dəl, 'ðət's ənʌ́f tréjnɪŋ!' tə prəvɛ́nt òwvərfɪ́tɪŋ—wɛ́ər ðə mɒ́dəl mɛ́məràjzɪz tréjnɪŋ déjtə ɪnstɛ́d əv trúwlij lɜ́rnɪŋ pǽtərnz."
    },
    {
        "Question": "What term describes a situation in machine learning where your model learns the training examples too well, including unnecessary noise, causing it to struggle with new, unseen data?",
        "RightAnswer": "Model Overfitting",
        "WrongAnswers": [
            "Model Underfitting",
            "Data Normalization",
            "Gradient Descent",
            "Cross-Validation",
            "Feature Engineering"
        ],
        "Explanation": "Model overfitting happens when a machine learning model tries too hard to fit every tiny detail in its training data—including random noise or irrelevant patterns. As a result, it performs excellent on familiar data but has difficulty generalizing to new data, causing poor predictions. Think of it like memorizing answers rather than understanding concepts: great on a familiar test, but struggling if questions change slightly.",
        "trans_Question": "wɒt tɜ́rm dəskrájbz ə sɪ̀tʃuwéjʃən ɪn məʃíjn lɜ́rnɪŋ wɛ́ər jɔr mɒ́dəl lɜ́rnz ðə tréjnɪŋ əɡzǽmpəlz túw wɛ́l, ɪnklúwdɪŋ ʌ̀nnɛ́səsɛ̀ərij nɔ́jz, kɒ́zɪŋ ɪt tə strʌ́ɡəl wɪð núw, ʌ̀nsíjn déjtə?",
        "trans_RightAnswer": "mɒ́dəl òwvərfɪ́tɪŋ",
        "trans_WrongAnswers": [
            "mɒ́dəl ʌ̀ndərfɪ́tɪŋ",
            "déjtə nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "krɔ́s-væ̀lɪdéjʃən",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ"
        ],
        "trans_Explanation": "mɒ́dəl òwvərfɪ́tɪŋ hǽpənz wɛ́n ə məʃíjn lɜ́rnɪŋ mɒ́dəl trájz túw hɑ́rd tə fɪ́t ɛvərij tájnij díjtejl ɪn ɪts tréjnɪŋ déjtə—ɪnklúwdɪŋ rǽndəm nɔ́jz ɔr ɪ̀ərɛ́ləvənt pǽtərnz. æz ə rəzʌ́lt, ɪt pərfɔ́rmz ɛ́ksələnt ɒn fəmɪ́ljər déjtə bʌt həz dɪ́fɪkəltij dʒɛ́nərəlàjzɪŋ tə núw déjtə, kɒ́zɪŋ pɔ́r prədɪ́kʃənz. θɪ́ŋk əv ɪt lájk mɛ́məràjzɪŋ ǽnsərz rǽðər ðʌn ʌ̀ndərstǽndɪŋ kɒ́nsɛpts: ɡréjt ɒn ə fəmɪ́ljər tɛ́st, bʌt strʌ́ɡəlɪŋ ɪf kwɛ́stʃənz tʃéjndʒ slájtlij."
    },
    {
        "Question": "You're training a machine learning model to accurately recognize images of apples. However, after training, the model performs poorly even on the training data, capturing only very general patterns and missing crucial details. What's the best term to describe this situation?",
        "RightAnswer": "Model Underfitting",
        "WrongAnswers": [
            "Model Overfitting",
            "Gradient Descent",
            "Regularization",
            "Feature Scaling",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Model underfitting happens when your machine learning algorithm hasn't learned enough from the training data. Think of it as a student who hasn’t studied enough to truly grasp the topic—they end up oversimplifying or missing the key insights. An underfitted model fails to capture important patterns, performing poorly even on data it has already seen. To overcome this, you typically choose a more complex model, train a bit longer, or make sure the selected features better represent the underlying data.",
        "trans_Question": "júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə ǽkjərətlij rɛ́kəɡnàjz ɪ́mɪdʒɪz əv ǽpəlz. hàwɛ́vər, ǽftər tréjnɪŋ, ðə mɒ́dəl pərfɔ́rmz pɔ́rlij íjvən ɒn ðə tréjnɪŋ déjtə, kǽptʃərɪŋ ównlij vɛ́ərij dʒɛ́nərəl pǽtərnz ənd mɪ́sɪŋ krúwʃəl díjtejlz. wɒt's ðə bɛ́st tɜ́rm tə dəskrájb ðɪs sɪ̀tʃuwéjʃən?",
        "trans_RightAnswer": "mɒ́dəl ʌ̀ndərfɪ́tɪŋ",
        "trans_WrongAnswers": [
            "mɒ́dəl òwvərfɪ́tɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "fíjtʃər skéjlɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "mɒ́dəl ʌ̀ndərfɪ́tɪŋ hǽpənz wɛ́n jɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm hǽzənt lɜ́rnd ənʌ́f frəm ðə tréjnɪŋ déjtə. θɪ́ŋk əv ɪt æz ə stúwdənt huw hǽzənt stʌ́dijd ənʌ́f tə trúwlij ɡrǽsp ðə tɒ́pɪk—ðej ɛ́nd ʌp òwvərsɪ́mplɪfajɪŋ ɔr mɪ́sɪŋ ðə kíj ɪ́nsàjts. ən ʌ̀ndərfɪ́tɪd mɒ́dəl féjlz tə kǽptʃər ɪmpɔ́rtənt pǽtərnz, pərfɔ́rmɪŋ pɔ́rlij íjvən ɒn déjtə ɪt həz ɔ̀lrɛ́dij síjn. tə ówvərkʌ̀m ðɪs, juw tɪ́pɪkəlij tʃúwz ə mɔr kɒ́mplɛks mɒ́dəl, tréjn ə bɪ́t lɔ́ŋɡər, ɔr méjk ʃʊ́r ðə səlɛ́ktɪd fíjtʃərz bɛ́tər rɛ̀prəzɛ́nt ðə ʌ̀ndərlájɪŋ déjtə."
    },
    {
        "Question": "When building a machine learning model, you're faced with an important balancing act. You notice that simple models make systematic mistakes because they're too rigid, while very complex models tend to chase unnecessary details and random noise. What's the term that describes this essential balancing act?",
        "RightAnswer": "Bias-Variance Tradeoff",
        "WrongAnswers": [
            "Overfitting Paradox",
            "Gradient Descent Dilemma",
            "Feature Scaling Challenge",
            "Dimensionality Reduction Balance",
            "Regularization Conundrum"
        ],
        "Explanation": "The Bias-Variance Tradeoff is like trying to find the sweet spot between two extremes in machine learning. If your model is too simple (high bias), it consistently makes incorrect assumptions and misses complex patterns. If it's overly complex (high variance), it goes after every tiny detail and even the noise, making it unreliable with new data. Recognizing and managing this tradeoff helps you build models that balance complexity and simplicity, improving performance on unseen data.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, júwr féjst wɪð ən ɪmpɔ́rtənt bǽlənsɪŋ ǽkt. juw nówtɪs ðət sɪ́mpəl mɒ́dəlz méjk sɪ̀stəmǽtɪk mɪstéjks bəkɒ́z ðɛ́ər túw rɪ́dʒɪd, wájl vɛ́ərij kɒ́mplɛks mɒ́dəlz tɛ́nd tə tʃéjs ʌ̀nnɛ́səsɛ̀ərij díjtejlz ənd rǽndəm nɔ́jz. wɒt's ðə tɜ́rm ðət dəskrájbz ðɪs əsɛ́nʃəl bǽlənsɪŋ ǽkt?",
        "trans_RightAnswer": "bájəs-vɛ́ərijəns tréjdɔ̀f",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ pǽrədɒ̀ks",
            "ɡréjdijənt dəsɛ́nt dajlɛ́mə",
            "fíjtʃər skéjlɪŋ tʃǽləndʒ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən bǽləns",
            "rèɡjəlɛ̀ərɪzéjʃən kənʌ́ndrəm"
        ],
        "trans_Explanation": "ðə bájəs-vɛ́ərijəns tréjdɔ̀f ɪz lájk trájɪŋ tə fájnd ðə swíjt spɒ́t bijtwíjn túw əkstríjmz ɪn məʃíjn lɜ́rnɪŋ. ɪf jɔr mɒ́dəl ɪz túw sɪ́mpəl (háj bájəs), ɪt kənsɪ́stəntlij méjks ɪ̀nkərɛ́kt əsʌ́mpʃənz ənd mɪ́sɪz kɒ́mplɛks pǽtərnz. ɪf ɪt's ówvərlij kɒ́mplɛks (háj vɛ́ərijəns), ɪt ɡówz ǽftər ɛvərij tájnij díjtejl ənd íjvən ðə nɔ́jz, méjkɪŋ ɪt ʌ̀nrəlájəbəl wɪð núw déjtə. rɛ́kəɡnàjzɪŋ ənd mǽnɪdʒɪŋ ðɪs tréjdɔ̀f hɛ́lps juw bɪ́ld mɒ́dəlz ðət bǽləns kəmplɛ́ksɪtij ənd sɪmplɪ́sɪtij, ɪmprúwvɪŋ pərfɔ́rməns ɒn ʌ̀nsíjn déjtə."
    },
    {
        "Question": "You're training a machine learning model and want to clearly visualize how often your algorithm correctly and incorrectly classifies different categories. Which tool would best help you see this clearly?",
        "RightAnswer": "Confusion Matrix",
        "WrongAnswers": [
            "Gradient Descent",
            "Overfitting Detector",
            "Regression Curve",
            "Feature Importance Graph",
            "Hyperparameter Grid"
        ],
        "Explanation": "A confusion matrix is basically a helpful table that lets you see how often your machine learning model gets things right or wrong for each category it's trying to predict. By summarizing true positives, true negatives, false positives, and false negatives in one easy-to-read table, it helps you quickly identify areas where your model excels and where it might need improvement.",
        "trans_Question": "júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ənd wɒ́nt tə klɪ́ərlij vɪ́ʒwəlàjz háw ɔ́fən jɔr ǽlɡərɪ̀ðəm kərɛ́ktlij ənd ɪ̀nkərɛ́ktlij klǽsɪfàjz dɪ́fərənt kǽtəɡɔ̀rijz. wɪ́tʃ túwl wʊd bɛ́st hɛ́lp juw síj ðɪs klɪ́ərlij?",
        "trans_RightAnswer": "kənfjúwʒən méjtrɪks",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ dətɛ́ktər",
            "rəɡrɛ́ʃən kɜ́rv",
            "fíjtʃər ɪmpɔ́rtəns ɡrǽf",
            "hàjpərpǽrəmətər ɡrɪ́d"
        ],
        "trans_Explanation": "ə kənfjúwʒən méjtrɪks ɪz béjsɪklij ə hɛ́lpfəl téjbəl ðət lɛts juw síj háw ɔ́fən jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ɡɛ́ts θɪ́ŋz rájt ɔr rɔ́ŋ fɔr ijtʃ kǽtəɡɔ̀rij ɪt's trájɪŋ tə prədɪ́kt. baj sʌ́məràjzɪŋ trúw pɒ́zɪtɪvz, trúw nɛ́ɡətɪvz, fɔ́ls pɒ́zɪtɪvz, ənd fɔ́ls nɛ́ɡətɪvz ɪn wʌ́n íjzij-tə-rɛ́d téjbəl, ɪt hɛ́lps juw kwɪ́klij ajdɛ́ntɪfàj ɛ́ərijəz wɛ́ər jɔr mɒ́dəl əksɛ́lz ənd wɛ́ər ɪt majt níjd ɪmprúwvmənt."
    },
    {
        "Question": "You're training a machine learning model to detect spam emails. You notice it seems to frequently mark genuine emails as spam, leading to frustration among users. To improve your model, you decide to measure how many times it's correctly identifying spam out of all emails it labeled as spam. What machine learning metric are you evaluating?",
        "RightAnswer": "Precision",
        "WrongAnswers": [
            "Accuracy",
            "Recall",
            "Sensitivity",
            "Specificity",
            "F1-score"
        ],
        "Explanation": "Precision helps us understand how trustworthy our model’s positive predictions are. Specifically, it measures the proportion of items our model labeled as 'positive' (in this case, spam emails) that were actually positive. A high precision means when our model says something is spam, it's likely correct—helpful for avoiding mislabeling genuine emails!",
        "trans_Question": "júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə dətɛ́kt spǽm íjmejlz. juw nówtɪs ɪt síjmz tə fríjkwəntlij mɑ́rk dʒénjuwɪn íjmejlz æz spǽm, líjdɪŋ tə frəstréjʃən əmʌ́ŋ júwzərz. tə ɪmprúwv jɔr mɒ́dəl, juw dəsájd tə mɛ́ʒər háw mɛ́nij tájmz ɪt's kərɛ́ktlij ajdɛ́ntɪfàjɪŋ spǽm awt əv ɔl íjmejlz ɪt léjbəld æz spǽm. wɒt məʃíjn lɜ́rnɪŋ mɛ́trɪk ɑr juw əvǽljuwèjtɪŋ?",
        "trans_RightAnswer": "prəsɪ́ʒən",
        "trans_WrongAnswers": [
            "ǽkjərəsij",
            "rijkɔ́l",
            "sɛ̀nsɪtɪ́vɪtij",
            "spɛ̀sɪfɪ́stij",
            "f1-skɔ́r"
        ],
        "trans_Explanation": "prəsɪ́ʒən hɛ́lps ʌs ʌ̀ndərstǽnd háw trʌ́stwɜ̀rðij awər mɒ́dəl'z pɒ́zɪtɪv prədɪ́kʃənz ɑr. spəsɪ́fɪklij, ɪt mɛ́ʒərz ðə prəpɔ́rʃən əv ájtəmz awər mɒ́dəl léjbəld æz 'pɒ́zɪtɪv' (ɪn ðɪs kéjs, spǽm íjmejlz) ðət wɜ́r ǽktʃùwəlij pɒ́zɪtɪv. ə háj prəsɪ́ʒən míjnz wɛ́n awər mɒ́dəl sɛ́z sʌ́mθɪŋ ɪz spǽm, ɪt's lájklij kərɛ́kt—hɛ́lpfəl fɔr əvɔ́jdɪŋ mɪ̀sléjbəlɪŋ dʒénjuwɪn íjmejlz!"
    },
    {
        "Question": "In machine learning, you have created a new model to spot emails that are spam. However, you're particularly worried about your model missing spam emails, allowing unwanted messages to enter your inbox. What measure would you check to see how good your model is at catching as many spam emails as possible?",
        "RightAnswer": "Recall",
        "WrongAnswers": [
            "Precision",
            "Accuracy",
            "Overfitting",
            "Bias",
            "Variance"
        ],
        "Explanation": "Recall is a measure used in machine learning that tells us how well a model can detect all relevant cases. Think of it like casting a wide net—high recall means your net is good at capturing the spam emails, ensuring very few slip through undetected. A high recall is important when missing positive cases (like spam emails) can be particularly problematic.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, juw həv krijéjtɪd ə núw mɒ́dəl tə spɒ́t íjmejlz ðət ɑr spǽm. hàwɛ́vər, júwr pərtɪ́kjələrlij wɜ́rijd əbawt jɔr mɒ́dəl mɪ́sɪŋ spǽm íjmejlz, əláwɪŋ ʌ̀nwɔ́ntɪd mɛ́sɪdʒɪz tə ɛ́ntər jɔr ɪ́nbɒ̀ks. wɒt mɛ́ʒər wʊd juw tʃɛ́k tə síj háw ɡʊ́d jɔr mɒ́dəl ɪz æt kǽtʃɪŋ æz mɛ́nij spǽm íjmejlz æz pɒ́sɪbəl?",
        "trans_RightAnswer": "rijkɔ́l",
        "trans_WrongAnswers": [
            "prəsɪ́ʒən",
            "ǽkjərəsij",
            "òwvərfɪ́tɪŋ",
            "bájəs",
            "vɛ́ərijəns"
        ],
        "trans_Explanation": "rijkɔ́l ɪz ə mɛ́ʒər júwzd ɪn məʃíjn lɜ́rnɪŋ ðət tɛ́lz ʌs háw wɛ́l ə mɒ́dəl kən dətɛ́kt ɔl rɛ́ləvənt kéjsɪz. θɪ́ŋk əv ɪt lájk kǽstɪŋ ə wájd nɛ́t—háj rijkɔ́l míjnz jɔr nɛ́t ɪz ɡʊ́d æt kǽptʃərɪŋ ðə spǽm íjmejlz, ɛnʃʊ́rɪŋ vɛ́ərij fjúw slɪ́p θrúw ʌ̀ndətɛ́ktɪd. ə háj rijkɔ́l ɪz ɪmpɔ́rtənt wɛ́n mɪ́sɪŋ pɒ́zɪtɪv kéjsɪz (lájk spǽm íjmejlz) kən bij pərtɪ́kjələrlij prɒ̀bləmǽtɪk."
    },
    {
        "Question": "Imagine you're evaluating a spam detection model. You're aiming for a balanced evaluation metric that considers both false positives (marking important emails as spam) and false negatives (missing spam emails). Which evaluation metric gives you a balanced measure of your model's precision and recall?",
        "RightAnswer": "F1 Score",
        "WrongAnswers": [
            "Accuracy",
            "Mean Squared Error",
            "ROC Curve",
            "Confusion Matrix",
            "Gradient Descent"
        ],
        "Explanation": "The F1 Score is a handy evaluation metric in machine learning, especially useful when dealing with imbalanced datasets. It finds the sweet spot between Precision (how many predictions were correct among labeled positives) and Recall (how many actual positives were identified correctly). In other words, it helps you judge your model's performance by balancing the trade-off between the mistakes of missing positives and wrongly labeling negatives as positives.",
        "trans_Question": "ɪmǽdʒɪn júwr əvǽljuwèjtɪŋ ə spǽm dətɛ́kʃən mɒ́dəl. júwr éjmɪŋ fɔr ə bǽlənst əvæ̀ljuwéjʃən mɛ́trɪk ðət kənsɪ́dərz bówθ fɔ́ls pɒ́zɪtɪvz (mɑ́rkɪŋ ɪmpɔ́rtənt íjmejlz æz spǽm) ənd fɔ́ls nɛ́ɡətɪvz (mɪ́sɪŋ spǽm íjmejlz). wɪ́tʃ əvæ̀ljuwéjʃən mɛ́trɪk ɡɪ́vz juw ə bǽlənst mɛ́ʒər əv jɔr mɒ́dəl'z prəsɪ́ʒən ənd rijkɔ́l?",
        "trans_RightAnswer": "F1 skɔ́r",
        "trans_WrongAnswers": [
            "ǽkjərəsij",
            "míjn skwɛ́ərd ɛ́ərər",
            "ROC kɜ́rv",
            "kənfjúwʒən méjtrɪks",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "ðə F1 skɔ́r ɪz ə hǽndij əvæ̀ljuwéjʃən mɛ́trɪk ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij júwsfəl wɛ́n díjlɪŋ wɪð ɪmbǽlənst déjtəsɛ̀ts. ɪt fájndz ðə swíjt spɒ́t bijtwíjn prəsɪ́ʒən (háw mɛ́nij prədɪ́kʃənz wɜ́r kərɛ́kt əmʌ́ŋ léjbəld pɒ́zɪtɪvz) ənd rijkɔ́l (háw mɛ́nij ǽktʃəl pɒ́zɪtɪvz wɜ́r ajdɛ́ntɪfàjd kərɛ́ktlij). ɪn ʌ́ðər wɜ́rdz, ɪt hɛ́lps juw dʒʌ́dʒ jɔr mɒ́dəl'z pərfɔ́rməns baj bǽlənsɪŋ ðə tréjd-ɔ́f bijtwíjn ðə mɪstéjks əv mɪ́sɪŋ pɒ́zɪtɪvz ənd rɔ́ŋlij léjbəlɪŋ nɛ́ɡətɪvz æz pɒ́zɪtɪvz."
    },
    {
        "Question": "When evaluating a machine learning model that tries to identify whether images contain cats, what term describes the percentage of images the model correctly sorts into 'cat' or 'not cat'?",
        "RightAnswer": "Accuracy",
        "WrongAnswers": [
            "Precision",
            "Recall",
            "Loss",
            "Overfitting",
            "Bias"
        ],
        "Explanation": "Accuracy is a straightforward measure of how often your model makes correct predictions. If your model examines 100 images and correctly classifies 90 of them as 'cat' or 'not cat,' it has an accuracy of 90%. It's a simple and intuitive way to understand how well your model is doing overall!",
        "trans_Question": "wɛ́n əvǽljuwèjtɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ðət trájz tə ajdɛ́ntɪfàj wɛ́ðər ɪ́mɪdʒɪz kəntéjn kǽts, wɒt tɜ́rm dəskrájbz ðə pərsɛ́ntɪdʒ əv ɪ́mɪdʒɪz ðə mɒ́dəl kərɛ́ktlij sɔ́rts ɪntə 'kǽt' ɔr 'nɒt kǽt'?",
        "trans_RightAnswer": "ǽkjərəsij",
        "trans_WrongAnswers": [
            "prəsɪ́ʒən",
            "rijkɔ́l",
            "lɔ́s",
            "òwvərfɪ́tɪŋ",
            "bájəs"
        ],
        "trans_Explanation": "ǽkjərəsij ɪz ə stréjtfɔ́rwərd mɛ́ʒər əv háw ɔ́fən jɔr mɒ́dəl méjks kərɛ́kt prədɪ́kʃənz. ɪf jɔr mɒ́dəl əɡzǽmɪnz 100 ɪ́mɪdʒɪz ənd kərɛ́ktlij klǽsɪfàjz 90 əv ðɛm æz 'kǽt' ɔr 'nɒt kǽt,' ɪt həz ən ǽkjərəsij əv 90%. ɪt's ə sɪ́mpəl ənd ɪntúwɪtɪv wej tə ʌ̀ndərstǽnd háw wɛ́l jɔr mɒ́dəl ɪz dúwɪŋ ówvərɔ̀l!"
    },
    {
        "Question": "In machine learning, if you want to visually evaluate how well your classifier distinguishes between two classes by plotting the true positive rate against the false positive rate, which method would you use?",
        "RightAnswer": "ROC Curve",
        "WrongAnswers": [
            "Gradient Descent",
            "Confusion Matrix",
            "Precision-Recall Plot",
            "Decision Tree",
            "Cross-Validation"
        ],
        "Explanation": "The ROC Curve (Receiver Operating Characteristic curve) helps you visualize your classifier's performance by showing the trade-off between correctly identifying positives (true positive rate) and incorrectly marking negatives as positives (false positive rate). By checking this curve, you can understand how your model behaves as you adjust the threshold for making predictions—making it easier to compare different models and choose the best one.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ɪf juw wɒ́nt tə vɪ́ʒwəlij əvǽljuwèjt háw wɛ́l jɔr klǽsɪfajər dɪstɪ́ŋɡwɪʃɪz bijtwíjn túw klǽsɪz baj plɒ́tɪŋ ðə trúw pɒ́zɪtɪv réjt əɡéjnst ðə fɔ́ls pɒ́zɪtɪv réjt, wɪ́tʃ mɛ́θəd wʊd juw juwz?",
        "trans_RightAnswer": "ROC kɜ́rv",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "kənfjúwʒən méjtrɪks",
            "prəsɪ́ʒən-rijkɔ́l plɒ́t",
            "dəsɪ́ʒən tríj",
            "krɔ́s-væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "ðə ROC kɜ́rv (rəsíjvər ɒ́pərèjtɪŋ kæ̀rəktərɪ́stɪk kɜ́rv) hɛ́lps juw vɪ́ʒwəlàjz jɔr klǽsɪfajər'z pərfɔ́rməns baj ʃówɪŋ ðə tréjd-ɔ́f bijtwíjn kərɛ́ktlij ajdɛ́ntɪfàjɪŋ pɒ́zɪtɪvz (trúw pɒ́zɪtɪv réjt) ənd ɪ̀nkərɛ́ktlij mɑ́rkɪŋ nɛ́ɡətɪvz æz pɒ́zɪtɪvz (fɔ́ls pɒ́zɪtɪv réjt). baj tʃɛ́kɪŋ ðɪs kɜ́rv, juw kən ʌ̀ndərstǽnd háw jɔr mɒ́dəl bəhéjvz æz juw ədʒʌ́st ðə θrɛ́ʃòwld fɔr méjkɪŋ prədɪ́kʃənz—méjkɪŋ ɪt íjzijər tə kəmpɛ́ər dɪ́fərənt mɒ́dəlz ənd tʃúwz ðə bɛ́st wʌ́n."
    },
    {
        "Question": "In machine learning, when you want a way to evaluate how well your model distinguishes between two classes (like spam vs. not spam) across different thresholds, which metric is your best friend?",
        "RightAnswer": "AUC-ROC",
        "WrongAnswers": [
            "Confusion matrix",
            "Mean Absolute Error",
            "Recursive Feature Elimination",
            "Cross-validation",
            "Gradient Descent"
        ],
        "Explanation": "AUC-ROC stands for 'Area Under the Receiver Operating Characteristic Curve.' Think of it as evaluating how good your model is at correctly ranking positive and negative examples across different classification thresholds. An AUC-ROC score closer to 1 means your model is awesome at telling apart two categories, whereas closer to 0.5 means it's no better than randomly guessing.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n juw wɒ́nt ə wej tə əvǽljuwèjt háw wɛ́l jɔr mɒ́dəl dɪstɪ́ŋɡwɪʃɪz bijtwíjn túw klǽsɪz (lájk spǽm vɜ́rsəs. nɒt spǽm) əkrɔ́s dɪ́fərənt θrɛ́ʃòwldz, wɪ́tʃ mɛ́trɪk ɪz jɔr bɛ́st frɛ́nd?",
        "trans_RightAnswer": "AUC-ROC",
        "trans_WrongAnswers": [
            "kənfjúwʒən méjtrɪks",
            "míjn ǽbsəlùwt ɛ́ərər",
            "rəkɜ́rsɪv fíjtʃər əlɪ̀mɪnéjʃən",
            "krɔ́s-væ̀lɪdéjʃən",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "AUC-ROC stǽndz fɔr 'ɛ́ərijə ʌ́ndər ðə rəsíjvər ɒ́pərèjtɪŋ kæ̀rəktərɪ́stɪk kɜ́rv.' θɪ́ŋk əv ɪt æz əvǽljuwèjtɪŋ háw ɡʊ́d jɔr mɒ́dəl ɪz æt kərɛ́ktlij rǽŋkɪŋ pɒ́zɪtɪv ənd nɛ́ɡətɪv əɡzǽmpəlz əkrɔ́s dɪ́fərənt klæ̀sɪfɪkéjʃən θrɛ́ʃòwldz. ən AUC-ROC skɔ́r klówsər tə 1 míjnz jɔr mɒ́dəl ɪz ɔ́səm æt tɛ́lɪŋ əpɑ́rt túw kǽtəɡɔ̀rijz, wɛərǽz klówsər tə 0.5 míjnz ɪt's now bɛ́tər ðʌn rǽndəmlij ɡɛ́sɪŋ."
    },
    {
        "Question": "You're developing a classifier for detecting fraudulent credit card transactions and need a useful visual tool to evaluate how well your model identifies fraud (positive class) across different thresholds. Which of the following graphs shows how accurately your model spots true fraud cases without mistakenly tagging safe transactions as fraud?",
        "RightAnswer": "Precision-Recall Curve",
        "WrongAnswers": [
            "ROC Curve",
            "Learning Curve",
            "Loss Curve",
            "Validation Curve",
            "Decision Boundary Plot"
        ],
        "Explanation": "A Precision-Recall Curve in machine learning is a handy visual that helps you examine the balance between 'precision' (the fraction of cases your model flags as positive that are actually positive) and 'recall' (how many real positive cases your model correctly spots). It's especially helpful when the data is imbalanced, like in fraud detection, where correctly identifying real positives (fraud cases) is critical, and distinguishing between correct detections and false alarms is vital.",
        "trans_Question": "júwr dəvɛ́ləpɪŋ ə klǽsɪfajər fɔr dətɛ́ktɪŋ frɔ́dʒələnt krɛ́dɪt kɑ́rd trænzǽkʃənz ənd níjd ə júwsfəl vɪ́ʒəwəl túwl tə əvǽljuwèjt háw wɛ́l jɔr mɒ́dəl ajdɛ́ntɪfàjz frɔ́d (pɒ́zɪtɪv klǽs) əkrɔ́s dɪ́fərənt θrɛ́ʃòwldz. wɪ́tʃ əv ðə fɒ́lowɪŋ ɡrǽfs ʃówz háw ǽkjərətlij jɔr mɒ́dəl spɒ́ts trúw frɔ́d kéjsɪz wɪðáwt mɪstéjkənlij tǽɡɪŋ séjf trænzǽkʃənz æz frɔ́d?",
        "trans_RightAnswer": "prəsɪ́ʒən-rijkɔ́l kɜ́rv",
        "trans_WrongAnswers": [
            "ROC kɜ́rv",
            "lɜ́rnɪŋ kɜ́rv",
            "lɔ́s kɜ́rv",
            "væ̀lɪdéjʃən kɜ́rv",
            "dəsɪ́ʒən báwndərij plɒ́t"
        ],
        "trans_Explanation": "ə prəsɪ́ʒən-rijkɔ́l kɜ́rv ɪn məʃíjn lɜ́rnɪŋ ɪz ə hǽndij vɪ́ʒəwəl ðət hɛ́lps juw əɡzǽmɪn ðə bǽləns bijtwíjn 'prəsɪ́ʒən' (ðə frǽkʃən əv kéjsɪz jɔr mɒ́dəl flǽɡz æz pɒ́zɪtɪv ðət ɑr ǽktʃùwəlij pɒ́zɪtɪv) ənd 'rijkɔ́l' (háw mɛ́nij ríjəl pɒ́zɪtɪv kéjsɪz jɔr mɒ́dəl kərɛ́ktlij spɒ́ts). ɪt's əspɛ́ʃəlij hɛ́lpfəl wɛ́n ðə déjtə ɪz ɪmbǽlənst, lájk ɪn frɔ́d dətɛ́kʃən, wɛ́ər kərɛ́ktlij ajdɛ́ntɪfàjɪŋ ríjəl pɒ́zɪtɪvz (frɔ́d kéjsɪz) ɪz krɪ́tɪkəl, ənd dɪstɪ́ŋɡwɪʃɪŋ bijtwíjn kərɛ́kt dətɛ́kʃənz ənd fɔ́ls əlɑ́rmz ɪz vájtəl."
    },
    {
        "Question": "When training a machine learning model to predict continuous values, we measure how well the model is performing by looking at the average of the squared differences between the predicted values and the actual values. What is this common error metric called?",
        "RightAnswer": "Mean Squared Error",
        "WrongAnswers": [
            "Mean Absolute Deviation",
            "Confusion Matrix",
            "R-squared Score",
            "Cross-Entropy Loss",
            "Precision-Recall Ratio"
        ],
        "Explanation": "Mean Squared Error (MSE) is simply the average of the squares of the differences between predicted and actual values. Think of it as a way to measure how closely your predictions match reality—the smaller the value, the better your model's predictions. Squaring these errors helps emphasize larger errors, highlighting them clearly in the evaluation.",
        "trans_Question": "wɛ́n tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə prədɪ́kt kəntɪ́njuwəs vǽljuwz, wij mɛ́ʒər háw wɛ́l ðə mɒ́dəl ɪz pərfɔ́rmɪŋ baj lʊ́kɪŋ æt ðə ǽvərɪdʒ əv ðə skwɛ́ərd dɪ́fərənsɪz bijtwíjn ðə prədɪ́ktɪd vǽljuwz ənd ðə ǽktʃəl vǽljuwz. wɒt ɪz ðɪs kɒ́mən ɛ́ərər mɛ́trɪk kɔ́ld?",
        "trans_RightAnswer": "míjn skwɛ́ərd ɛ́ərər",
        "trans_WrongAnswers": [
            "míjn ǽbsəlùwt dìjvijéjʃən",
            "kənfjúwʒən méjtrɪks",
            "r-skwɛ́ərd skɔ́r",
            "krɔ́s-ɛ́ntrəpij lɔ́s",
            "prəsɪ́ʒən-rijkɔ́l réjʃijòw"
        ],
        "trans_Explanation": "míjn skwɛ́ərd ɛ́ərər (MSE) ɪz sɪ́mplij ðə ǽvərɪdʒ əv ðə skwɛ́ərz əv ðə dɪ́fərənsɪz bijtwíjn prədɪ́ktɪd ənd ǽktʃəl vǽljuwz. θɪ́ŋk əv ɪt æz ə wej tə mɛ́ʒər háw klówslij jɔr prədɪ́kʃənz mǽtʃ rìjǽlɪtij—ðə smɔ́lər ðə vǽljuw, ðə bɛ́tər jɔr mɒ́dəl'z prədɪ́kʃənz. skwɛ́ərɪŋ ðijz ɛ́ərərz hɛ́lps ɛ́mfəsajz lɑ́rdʒər ɛ́ərərz, hájlàjtɪŋ ðɛm klɪ́ərlij ɪn ðə əvæ̀ljuwéjʃən."
    },
    {
        "Question": "When evaluating how well a machine learning model predicts numerical values (such as house prices, heights, or temperatures), what metric measures how far off your predictions are on average, without considering direction, by simply averaging all mistakes?",
        "RightAnswer": "Mean Absolute Error",
        "WrongAnswers": [
            "Mean Squared Error",
            "Root Mean Squared Error",
            "Accuracy Score",
            "Precision Metric",
            "Sensitivity Rate"
        ],
        "Explanation": "Mean Absolute Error (MAE) measures the prediction accuracy of your model by averaging just how far off each prediction is from its actual value. 'Absolute' means that it doesn't care if your predictions were too high or too low—a mistake is a mistake. It's like asking, 'On average, how badly did I miss—ignoring if I went over or under?' This practical, straightforward measure helps you understand, in simple terms, the average prediction error of your model.",
        "trans_Question": "wɛ́n əvǽljuwèjtɪŋ háw wɛ́l ə məʃíjn lɜ́rnɪŋ mɒ́dəl prədɪ́kts njuwmɛ́ərɪkəl vǽljuwz (sʌtʃ æz haws prájsɪz, hájts, ɔr tɛ́mpərətʃərz), wɒt mɛ́trɪk mɛ́ʒərz háw fɑ́r ɔ́f jɔr prədɪ́kʃənz ɑr ɒn ǽvərɪdʒ, wɪðáwt kənsɪ́dərɪŋ dɪərɛ́kʃən, baj sɪ́mplij ǽvrɪdʒɪŋ ɔl mɪstéjks?",
        "trans_RightAnswer": "míjn ǽbsəlùwt ɛ́ərər",
        "trans_WrongAnswers": [
            "míjn skwɛ́ərd ɛ́ərər",
            "rúwt míjn skwɛ́ərd ɛ́ərər",
            "ǽkjərəsij skɔ́r",
            "prəsɪ́ʒən mɛ́trɪk",
            "sɛ̀nsɪtɪ́vɪtij réjt"
        ],
        "trans_Explanation": "míjn ǽbsəlùwt ɛ́ərər (MAE) mɛ́ʒərz ðə prədɪ́kʃən ǽkjərəsij əv jɔr mɒ́dəl baj ǽvrɪdʒɪŋ dʒəst háw fɑ́r ɔ́f ijtʃ prədɪ́kʃən ɪz frəm ɪts ǽktʃəl vǽljuw. 'ǽbsəlùwt' míjnz ðət ɪt dʌ́zənt kɛ́ər ɪf jɔr prədɪ́kʃənz wɜ́r túw háj ɔr túw lów—ə mɪstéjk ɪz ə mɪstéjk. ɪt's lájk ǽskɪŋ, 'ɒn ǽvərɪdʒ, háw bǽdlij dɪd aj mɪ́s—ɪ̀ɡnɔ́rɪŋ ɪf aj wɛ́nt ówvər ɔr ʌ́ndər?' ðɪs prǽktɪkəl, stréjtfɔ́rwərd mɛ́ʒər hɛ́lps juw ʌ̀ndərstǽnd, ɪn sɪ́mpəl tɜ́rmz, ðə ǽvərɪdʒ prədɪ́kʃən ɛ́ərər əv jɔr mɒ́dəl."
    },
    {
        "Question": "You're trying to figure out how well your regression model fits the data you're analyzing. Which metric would help you understand the proportion of variance explained by your model, giving you a clear picture of its effectiveness?",
        "RightAnswer": "R-Squared",
        "WrongAnswers": [
            "Precision",
            "Recall",
            "F1-score",
            "Cross-entropy",
            "Gradient descent"
        ],
        "Explanation": "R-Squared is a handy measure that shows you how well your regression line or model matches your actual data points. It ranges from 0 to 1, where a value closer to 1 means your model is doing a great job at explaining the variation, and closer to 0 means it's not doing so well. Think of it as how confidently your model can say 'I've got this!' when predicting outcomes.",
        "trans_Question": "júwr trájɪŋ tə fɪ́ɡjər awt háw wɛ́l jɔr rəɡrɛ́ʃən mɒ́dəl fɪ́ts ðə déjtə júwr ǽnəlàjzɪŋ. wɪ́tʃ mɛ́trɪk wʊd hɛ́lp juw ʌ̀ndərstǽnd ðə prəpɔ́rʃən əv vɛ́ərijəns əkspléjnd baj jɔr mɒ́dəl, ɡɪ́vɪŋ juw ə klɪ́ər pɪ́ktʃər əv ɪts əfɛ́ktɪvnəs?",
        "trans_RightAnswer": "r-skwɛ́ərd",
        "trans_WrongAnswers": [
            "prəsɪ́ʒən",
            "rijkɔ́l",
            "f1-skɔ́r",
            "krɔ́s-ɛ́ntrəpij",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "r-skwɛ́ərd ɪz ə hǽndij mɛ́ʒər ðət ʃówz juw háw wɛ́l jɔr rəɡrɛ́ʃən lájn ɔr mɒ́dəl mǽtʃɪz jɔr ǽktʃəl déjtə pɔ́jnts. ɪt réjndʒɪz frəm 0 tə 1, wɛ́ər ə vǽljuw klówsər tə 1 míjnz jɔr mɒ́dəl ɪz dúwɪŋ ə ɡréjt dʒɒ́b æt əkspléjnɪŋ ðə vɛ̀ərijéjʃən, ənd klówsər tə 0 míjnz ɪt's nɒt dúwɪŋ sow wɛ́l. θɪ́ŋk əv ɪt æz háw kɒ́nfɪdəntlij jɔr mɒ́dəl kən séj 'ájv ɡɒt ðɪs!' wɛ́n prədɪ́ktɪŋ áwtkʌ̀mz."
    },
    {
        "Question": "When evaluating machine learning models, we sometimes use a metric that adjusts for the number of predictors used. This ensures we're not fooled by a model that seems really accurate just because we've added more inputs. What's the term for this metric?",
        "RightAnswer": "Adjusted R-Squared",
        "WrongAnswers": [
            "Precision-Recall Score",
            "Root Mean Square Error",
            "Activation Function",
            "Cross-Validation Accuracy",
            "Baseline Accuracy"
        ],
        "Explanation": "Adjusted R-Squared is a useful metric that measures how well your model fits your data, similar to regular R-Squared. However, it goes one step further and accounts for how many predictors (features or inputs) you've used. This helps you avoid getting tricked into thinking your model is great just because you've thrown in tons of individual features. Essentially, it tells you if adding more features genuinely improves your model, or if it's just adding complexity without real value.",
        "trans_Question": "wɛ́n əvǽljuwèjtɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz, wij sʌ́mtàjmz juwz ə mɛ́trɪk ðət ədʒʌ́sts fɔr ðə nʌ́mbər əv prədɪ́ktərz júwzd. ðɪs ənʃʊ́rz wɜ́r nɒt fúwld baj ə mɒ́dəl ðət síjmz ríjlij ǽkjərət dʒəst bəkɒ́z wíjv ǽdɪd mɔr ɪ́npʊ̀ts. wɒt's ðə tɜ́rm fɔr ðɪs mɛ́trɪk?",
        "trans_RightAnswer": "ədʒʌ́stɪd r-skwɛ́ərd",
        "trans_WrongAnswers": [
            "prəsɪ́ʒən-rijkɔ́l skɔ́r",
            "rúwt míjn skwɛ́ər ɛ́ərər",
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "krɔ́s-væ̀lɪdéjʃən ǽkjərəsij",
            "béjslàjn ǽkjərəsij"
        ],
        "trans_Explanation": "ədʒʌ́stɪd r-skwɛ́ərd ɪz ə júwsfəl mɛ́trɪk ðət mɛ́ʒərz háw wɛ́l jɔr mɒ́dəl fɪ́ts jɔr déjtə, sɪ́mɪlər tə rɛ́ɡjələr r-skwɛ́ərd. hàwɛ́vər, ɪt ɡówz wʌ́n stɛ́p fɜ́rðər ənd əkáwnts fɔr háw mɛ́nij prədɪ́ktərz (fíjtʃərz ɔr ɪ́npʊ̀ts) júwv júwzd. ðɪs hɛ́lps juw əvɔ́jd ɡɛ́tɪŋ trɪ́kt ɪntə θɪ́ŋkɪŋ jɔr mɒ́dəl ɪz ɡréjt dʒəst bəkɒ́z júwv θrówn ɪn tʌ́nz əv ɪndɪvɪ́dʒəwəl fíjtʃərz. əsɛ́nʃəlij, ɪt tɛ́lz juw ɪf ǽdɪŋ mɔr fíjtʃərz dʒénjuwɪnlij ɪmprúwvz jɔr mɒ́dəl, ɔr ɪf ɪt's dʒəst ǽdɪŋ kəmplɛ́ksɪtij wɪðáwt ríjəl vǽljuw."
    },
    {
        "Question": "Which term describes the process of carefully choosing the most relevant data inputs to make a machine learning model simpler, faster, and better at predicting outcomes?",
        "RightAnswer": "Feature Selection",
        "WrongAnswers": [
            "Model Training",
            "Hyperparameter Tuning",
            "Feature Scaling",
            "Data Augmentation",
            "Ensemble Learning"
        ],
        "Explanation": "Feature Selection is like being a thoughtful editor for your data: you pick the most valuable pieces (features) that truly matter, removing redundant or irrelevant information. Doing this helps your machine learning model to focus, learn quickly, and become more accurate—even with fewer resources.",
        "trans_Question": "wɪ́tʃ tɜ́rm dəskrájbz ðə prɒ́sɛs əv kɛ́ərfəlij tʃúwzɪŋ ðə mówst rɛ́ləvənt déjtə ɪ́npʊ̀ts tə méjk ə məʃíjn lɜ́rnɪŋ mɒ́dəl sɪ́mplər, fǽstər, ənd bɛ́tər æt prədɪ́ktɪŋ áwtkʌ̀mz?",
        "trans_RightAnswer": "fíjtʃər səlɛ́kʃən",
        "trans_WrongAnswers": [
            "mɒ́dəl tréjnɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "fíjtʃər skéjlɪŋ",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "ɒnsɒ́mbəl lɜ́rnɪŋ"
        ],
        "trans_Explanation": "fíjtʃər səlɛ́kʃən ɪz lájk bíjɪŋ ə θɔ́tfəl ɛ́dɪtər fɔr jɔr déjtə: juw pɪ́k ðə mówst vǽljəbəl píjsɪz (fíjtʃərz) ðət trúwlij mǽtər, rijmúwvɪŋ rədʌ́ndənt ɔr ɪ̀ərɛ́ləvənt ɪnfərméjʃən. dúwɪŋ ðɪs hɛ́lps jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl tə fówkəs, lɜ́rn kwɪ́klij, ənd bəkʌ́m mɔr ǽkjərət—íjvən wɪð fjúwər ríjsɔrsɪz."
    },
    {
        "Question": "When preparing data to train machine learning models, we often need to simplify or highlight useful details from raw data. What's the term used to describe the process of selecting or creating useful attributes from raw data to effectively train our models?",
        "RightAnswer": "Feature Extraction",
        "WrongAnswers": [
            "Overfitting",
            "Supervised Learning",
            "Gradient Descent",
            "Hyperparameter Tuning",
            "Model Evaluation"
        ],
        "Explanation": "Feature extraction is the process of identifying and picking out key parts (‘features’) from raw data that best help a machine learning algorithm learn patterns or behaviors. Think of it like mining valuable metals from a pile of rocks—you're carefully selecting the useful bits while leaving out the irrelevant ones. Good features allow models to train quicker, perform better, and make accurate predictions.",
        "trans_Question": "wɛ́n prəpɛ́ərɪŋ déjtə tə tréjn məʃíjn lɜ́rnɪŋ mɒ́dəlz, wij ɔ́fən níjd tə sɪ́mpləfaj ɔr hájlàjt júwsfəl díjtejlz frəm rɔ́ déjtə. wɒt's ðə tɜ́rm júwzd tə dəskrájb ðə prɒ́sɛs əv səlɛ́ktɪŋ ɔr krijéjtɪŋ júwsfəl ǽtrəbjùwts frəm rɔ́ déjtə tə əfɛ́ktɪvlij tréjn awər mɒ́dəlz?",
        "trans_RightAnswer": "fíjtʃər əkstrǽkʃən",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "hàjpərpǽrəmətər túwnɪŋ",
            "mɒ́dəl əvæ̀ljuwéjʃən"
        ],
        "trans_Explanation": "fíjtʃər əkstrǽkʃən ɪz ðə prɒ́sɛs əv ajdɛ́ntɪfàjɪŋ ənd pɪ́kɪŋ awt kíj pɑ́rts (‘fíjtʃərz’) frəm rɔ́ déjtə ðət bɛ́st hɛ́lp ə məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm lɜ́rn pǽtərnz ɔr bəhéjvjərz. θɪ́ŋk əv ɪt lájk májnɪŋ vǽljəbəl mɛ́təlz frəm ə pájl əv rɒ́ks—júwr kɛ́ərfəlij səlɛ́ktɪŋ ðə júwsfəl bɪ́ts wájl líjvɪŋ awt ðə ɪ̀ərɛ́ləvənt wʌ́nz. ɡʊ́d fíjtʃərz əláw mɒ́dəlz tə tréjn kwɪ́kər, pərfɔ́rm bɛ́tər, ənd méjk ǽkjərət prədɪ́kʃənz."
    },
    {
        "Question": "In a machine learning project aimed at predicting rare diseases, most of your patients do NOT have the disease. This results in having plenty of examples of healthy patients but very few cases of the disease itself. What do we call this uneven distribution of examples in your dataset?",
        "RightAnswer": "Data Imbalance",
        "WrongAnswers": [
            "Overfitting",
            "Feature Noise",
            "Data Leakage",
            "High Dimensionality",
            "Model Drift"
        ],
        "Explanation": "Data imbalance happens when one class (or group) of data is significantly more common than another in your training dataset. Typically, the less common group is the one you're most interested in predicting (like patients with rare diseases). If ignored, data imbalance can cause your machine learning model to predict inaccurately because it tends to favor the most frequent class. Learning methods or adjustments might be needed to balance the scales and make the model fair and effective.",
        "trans_Question": "ɪn ə məʃíjn lɜ́rnɪŋ prɒ́dʒɛkt éjmd æt prədɪ́ktɪŋ rɛ́ər dɪzíjzɪz, mówst əv jɔr péjʃənts dúw NOT həv ðə dɪzíjz. ðɪs rəzʌ́lts ɪn hǽvɪŋ plɛ́ntij əv əɡzǽmpəlz əv hɛ́lθij péjʃənts bʌt vɛ́ərij fjúw kéjsɪz əv ðə dɪzíjz ɪtsɛ́lf. wɒt dúw wij kɔ́l ðɪs ʌ̀níjvən dɪ̀strəbjúwʃən əv əɡzǽmpəlz ɪn jɔr déjtəsɛ̀t?",
        "trans_RightAnswer": "déjtə ɪmbǽləns",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "fíjtʃər nɔ́jz",
            "déjtə líjkɪdʒ",
            "háj dajmɛ̀nʃənǽlɪtij",
            "mɒ́dəl drɪ́ft"
        ],
        "trans_Explanation": "déjtə ɪmbǽləns hǽpənz wɛ́n wʌ́n klǽs (ɔr ɡrúwp) əv déjtə ɪz sɪɡnɪ́fɪkəntlij mɔr kɒ́mən ðʌn ənʌ́ðər ɪn jɔr tréjnɪŋ déjtəsɛ̀t. tɪ́pɪkəlij, ðə lɛ́s kɒ́mən ɡrúwp ɪz ðə wʌ́n júwr mówst ɪ́ntərəstɪd ɪn prədɪ́ktɪŋ (lájk péjʃənts wɪð rɛ́ər dɪzíjzɪz). ɪf ɪ̀ɡnɔ́rd, déjtə ɪmbǽləns kən kɒ́z jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl tə prədɪ́kt ɪ̀nǽkjərətlij bəkɒ́z ɪt tɛ́ndz tə féjvər ðə mówst fríjkwənt klǽs. lɜ́rnɪŋ mɛ́θədz ɔr ədʒʌ́stmənts majt bij níjdɪd tə bǽləns ðə skéjlz ənd méjk ðə mɒ́dəl fɛ́ər ənd əféktɪv."
    },
    {
        "Question": "When we have an imbalanced dataset where some classes are very rare compared to others, machine learning algorithms can struggle. What machine learning technique can we use to create artificial examples of the rare class, helping balance the dataset so our model learns better?",
        "RightAnswer": "Synthetic Minority Over-sampling Technique",
        "WrongAnswers": [
            "Strategic Model Optimization Technique",
            "Structured Meta Overfitting Test",
            "Selective Minimal Outlier Transformation",
            "Standardized Machine Observation Train",
            "Systematic Model Output Tuning"
        ],
        "Explanation": "The Synthetic Minority Over-sampling Technique, or SMOTE, helps machine learning models perform better when faced with imbalanced datasets—where one class is much less frequent than another. It works by creating artificial yet realistic examples of the 'minority' class, giving the model a more balanced view. Imagine trying to identify rare cases, like detecting fraud or diagnosing rare diseases. SMOTE helps your model learn effectively by reducing the imbalance, improving accuracy and predictions for uncommon events.",
        "trans_Question": "wɛ́n wij həv ən ɪmbǽlənst déjtəsɛ̀t wɛ́ər sʌm klǽsɪz ɑr vɛ́ərij rɛ́ər kəmpɛ́ərd tə ʌ́ðərz, məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz kən strʌ́ɡəl. wɒt məʃíjn lɜ́rnɪŋ tɛkníjk kən wij juwz tə krijéjt ɑ̀rtɪfɪ́ʃəl əɡzǽmpəlz əv ðə rɛ́ər klǽs, hɛ́lpɪŋ bǽləns ðə déjtəsɛ̀t sow awər mɒ́dəl lɜ́rnz bɛ́tər?",
        "trans_RightAnswer": "sɪnθɛ́tɪk majnɔ́rɪtij ówvər-sǽmplɪŋ tɛkníjk",
        "trans_WrongAnswers": [
            "strətíjdʒɪk mɒ́dəl ɒptɪmɪzéjʃən tɛkníjk",
            "strʌ́ktʃərd mɛ́tə òwvərfɪ́tɪŋ tɛ́st",
            "səlɛ́ktɪv mɪ́nɪməl áwtlajər træ̀nsfərméjʃən",
            "stǽndərdàjzd məʃíjn ɒ̀bzərvéjʃən tréjn",
            "sɪ̀stəmǽtɪk mɒ́dəl áwtpʊ̀t túwnɪŋ"
        ],
        "trans_Explanation": "ðə sɪnθɛ́tɪk majnɔ́rɪtij ówvər-sǽmplɪŋ tɛkníjk, ɔr SMOTE, hɛ́lps məʃíjn lɜ́rnɪŋ mɒ́dəlz pərfɔ́rm bɛ́tər wɛ́n féjst wɪð ɪmbǽlənst déjtəsɛ̀ts—wɛ́ər wʌ́n klǽs ɪz mʌtʃ lɛ́s fríjkwənt ðʌn ənʌ́ðər. ɪt wɜ́rks baj krijéjtɪŋ ɑ̀rtɪfɪ́ʃəl jɛt rìjəlɪ́stɪk əɡzǽmpəlz əv ðə 'majnɔ́rɪtij' klǽs, ɡɪ́vɪŋ ðə mɒ́dəl ə mɔr bǽlənst vjúw. ɪmǽdʒɪn trájɪŋ tə ajdɛ́ntɪfàj rɛ́ər kéjsɪz, lájk dətɛ́ktɪŋ frɔ́d ɔr dàjəɡnówsɪŋ rɛ́ər dɪzíjzɪz. SMOTE hɛ́lps jɔr mɒ́dəl lɜ́rn əfɛ́ktɪvlij baj rədjúwsɪŋ ðə ɪmbǽləns, ɪmprúwvɪŋ ǽkjərəsij ənd prədɪ́kʃənz fɔr ʌ̀nkɒ́mən əvɛ́nts."
    },
    {
        "Question": "Imagine you're building a machine learning model to predict customer satisfaction based on survey responses. You have a large dataset with varying numbers of participants from different age groups. To ensure your model learns effectively, you carefully pick samples for training so each age group is fairly represented according to its size in the overall population. What kind of sampling technique are you using?",
        "RightAnswer": "Stratified Sampling",
        "WrongAnswers": [
            "Random Sampling",
            "Cluster Sampling",
            "Systematic Sampling",
            "Oversampling",
            "Convenience Sampling"
        ],
        "Explanation": "Stratified sampling is like carefully selecting a team to represent different strengths in sports—you're picking a representative sample from each subgroup (or stratum) based on their actual proportions in the overall population data. This ensures your machine learning model understands and predicts accurately across all categories by maintaining their original balance.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə prədɪ́kt kʌ́stəmər sæ̀tɪsfǽkʃən béjst ɒn sɜ́rvej rəspɒ́nsɪz. juw həv ə lɑ́rdʒ déjtəsɛ̀t wɪð vɛ́ərijɪŋ nʌ́mbərz əv pɑrtɪ́səpənts frəm dɪ́fərənt éjdʒ ɡrúwps. tə ənʃʊ́r jɔr mɒ́dəl lɜ́rnz əfɛ́ktɪvlij, juw kɛ́ərfəlij pɪ́k sǽmpəlz fɔr tréjnɪŋ sow ijtʃ éjdʒ ɡrúwp ɪz fɛ́ərlij rɛ̀prəzɛ́ntɪd əkɔ́rdɪŋ tə ɪts sájz ɪn ðə ówvərɔ̀l pɒ̀pjəléjʃən. wɒt kájnd əv sǽmplɪŋ tɛkníjk ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "strǽtɪfàjd sǽmplɪŋ",
        "trans_WrongAnswers": [
            "rǽndəm sǽmplɪŋ",
            "klʌ́stər sǽmplɪŋ",
            "sɪ̀stəmǽtɪk sǽmplɪŋ",
            "òwvərsǽmplɪŋ",
            "kənvíjnjəns sǽmplɪŋ"
        ],
        "trans_Explanation": "strǽtɪfàjd sǽmplɪŋ ɪz lájk kɛ́ərfəlij səlɛ́ktɪŋ ə tíjm tə rɛ̀prəzɛ́nt dɪ́fərənt strɛ́ŋθs ɪn spɔ́rts—júwr pɪ́kɪŋ ə rɛ̀prəzɛ́nətɪv sǽmpəl frəm ijtʃ sʌ́bɡrùwp (ɔr strǽtəm) béjst ɒn ðɛər ǽktʃəl prəpɔ́rʃənz ɪn ðə ówvərɔ̀l pɒ̀pjəléjʃən déjtə. ðɪs ənʃʊ́rz jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ʌ̀ndərstǽndz ənd prədɪ́kts ǽkjərətlij əkrɔ́s ɔl kǽtəɡɔ̀rijz baj mejntéjnɪŋ ðɛər ərɪ́dʒɪnəl bǽləns."
    },
    {
        "Question": "What machine learning technique involves repeatedly sampling your existing data with replacement to estimate performance or uncertainty, especially useful when there's not a lot of data available?",
        "RightAnswer": "Bootstrapping",
        "WrongAnswers": [
            "Gradient Boosting",
            "Cross-Validation",
            "Regularization",
            "Ensemble Learning",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Bootstrapping is like creating multiple 'alternate universes' of your original dataset—by repeatedly taking random samples (with replacement)—to help estimate how reliable your model's predictions are. Especially handy when your dataset is limited, this method lets you understand the variability and confidence of your predictions without needing new data.",
        "trans_Question": "wɒt məʃíjn lɜ́rnɪŋ tɛkníjk ɪnvɒ́lvz rəpíjtɪdlij sǽmplɪŋ jɔr əɡzɪ́stɪŋ déjtə wɪð rəpléjsmənt tə ɛ́stɪmèjt pərfɔ́rməns ɔr ʌ̀nsɜ́rtəntij, əspɛ́ʃəlij júwsfəl wɛ́n ðɛər'z nɒt ə lɒ́t əv déjtə əvéjləbəl?",
        "trans_RightAnswer": "búwtstræ̀pɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "krɔ́s-væ̀lɪdéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "búwtstræ̀pɪŋ ɪz lájk krijéjtɪŋ mʌ́ltɪpəl 'ɔ́ltərnət júwnɪvɜ̀rsɪz' əv jɔr ərɪ́dʒɪnəl déjtəsɛ̀t—baj rəpíjtɪdlij téjkɪŋ rǽndəm sǽmpəlz (wɪð rəpléjsmənt)—tə hɛ́lp ɛ́stɪmèjt háw rəlájəbəl jɔr mɒ́dəl'z prədɪ́kʃənz ɑr. əspɛ́ʃəlij hǽndij wɛ́n jɔr déjtəsɛ̀t ɪz lɪ́mɪtɪd, ðɪs mɛ́θəd lɛts juw ʌ̀ndərstǽnd ðə vɛərijəbɪ́lɪtij ənd kɒ́nfɪdəns əv jɔr prədɪ́kʃənz wɪðáwt níjdɪŋ núw déjtə."
    },
    {
        "Question": "After training your machine learning algorithm, you need to know how well it performs by testing it with different data. What is this crucial step of testing and understanding your machine learning algorithm's performance called?",
        "RightAnswer": "Model Evaluation",
        "WrongAnswers": [
            "Model Deployment",
            "Feature Extraction",
            "Data Preprocessing",
            "Hyperparameter Tuning",
            "Model Initialization"
        ],
        "Explanation": "Model evaluation is like giving your trained machine learning model a practical exam—you test it with data it hasn't seen before to see how accurately and reliably it performs. This step helps you understand if your model is ready to solve real-world problems or if it needs further improvements.",
        "trans_Question": "ǽftər tréjnɪŋ jɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm, juw níjd tə nów háw wɛ́l ɪt pərfɔ́rmz baj tɛ́stɪŋ ɪt wɪð dɪ́fərənt déjtə. wɒt ɪz ðɪs krúwʃəl stɛ́p əv tɛ́stɪŋ ənd ʌ̀ndərstǽndɪŋ jɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm'z pərfɔ́rməns kɔ́ld?",
        "trans_RightAnswer": "mɒ́dəl əvæ̀ljuwéjʃən",
        "trans_WrongAnswers": [
            "mɒ́dəl dəplɔ́jmənt",
            "fíjtʃər əkstrǽkʃən",
            "déjtə prìjprʌ́ʊsɛsɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "mɒ́dəl ɪnɪ́ʃəlɪzéjʃən"
        ],
        "trans_Explanation": "mɒ́dəl əvæ̀ljuwéjʃən ɪz lájk ɡɪ́vɪŋ jɔr tréjnd məʃíjn lɜ́rnɪŋ mɒ́dəl ə prǽktɪkəl əɡzǽm—juw tɛ́st ɪt wɪð déjtə ɪt hǽzənt síjn bəfɔ́r tə síj háw ǽkjərətlij ənd rəlájəblij ɪt pərfɔ́rmz. ðɪs stɛ́p hɛ́lps juw ʌ̀ndərstǽnd ɪf jɔr mɒ́dəl ɪz rɛ́dij tə sɒ́lv ríjəl-wɜ́rld prɒ́bləmz ɔr ɪf ɪt níjdz fɜ́rðər ɪmprúwvmənts."
    },
    {
        "Question": "You trained a model to predict ice cream sales based on outdoor temperature. But later you realize that your model didn't consider weekends or special events, which might also affect sales. These additional unnoticed factors are examples of what?",
        "RightAnswer": "Confounding Variables",
        "WrongAnswers": [
            "Overfitting",
            "Outliers",
            "Underfitting",
            "Feature Scaling",
            "Data Leakage"
        ],
        "Explanation": "Confounding variables are hidden or overlooked factors that affect the relationship between inputs and outputs in a machine learning model. In our example, weekends or special events are confounding variables because they influence ice cream sales independently of temperature. Overlooking these confounding variables can mislead the analysis or cause models to misinterpret the true relationship between variables.",
        "trans_Question": "juw tréjnd ə mɒ́dəl tə prədɪ́kt ájs kríjm séjlz béjst ɒn áwtdɔ̀r tɛ́mpərətʃər. bʌt léjtər juw ríjəlàjz ðət jɔr mɒ́dəl dɪ́dənt kənsɪ́dər wíjkɛ̀ndz ɔr spɛ́ʃəl əvɛ́nts, wɪ́tʃ majt ɔ́lsow əfɛ́kt séjlz. ðijz ədɪ́ʃənəl ʌ̀nnówtɪst fǽktərz ɑr əɡzǽmpəlz əv wɒt?",
        "trans_RightAnswer": "kənfáwndɪŋ vɛ́ərijəbəlz",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "áwtlajərz",
            "ʌ̀ndərfɪ́tɪŋ",
            "fíjtʃər skéjlɪŋ",
            "déjtə líjkɪdʒ"
        ],
        "trans_Explanation": "kənfáwndɪŋ vɛ́ərijəbəlz ɑr hɪ́dən ɔr ówvərlʊ̀kt fǽktərz ðət əfɛ́kt ðə rəléjʃənʃɪ̀p bijtwíjn ɪ́npʊ̀ts ənd áwtpʊ̀ts ɪn ə məʃíjn lɜ́rnɪŋ mɒ́dəl. ɪn awər əɡzǽmpəl, wíjkɛ̀ndz ɔr spɛ́ʃəl əvɛ́nts ɑr kənfáwndɪŋ vɛ́ərijəbəlz bəkɒ́z ðej ɪ́nfluwəns ájs kríjm séjlz ɪndəpɛ́ndəntlij əv tɛ́mpərətʃər. ówvərlʊ̀kɪŋ ðijz kənfáwndɪŋ vɛ́ərijəbəlz kən mɪ̀slíjd ðə ənǽlɪsɪs ɔr kɒ́z mɒ́dəlz tə mɪsɪntɜ́rprət ðə trúw rəléjʃənʃɪ̀p bijtwíjn vɛ́ərijəbəlz."
    },
    {
        "Question": "In machine learning, what do you call the situation when your model seems suspiciously good during training—because information it shouldn't know has accidentally made its way into the dataset?",
        "RightAnswer": "Data Leakage",
        "WrongAnswers": [
            "Overfitting",
            "Batch Normalization",
            "Data Augmentation",
            "Underfitting",
            "Feature Scaling"
        ],
        "Explanation": "Data leakage happens when your machine learning model unintentionally gains access to information it wouldn't have in a real-world situation. It's like knowing the answers before a test! This causes the model to perform incredibly well during training but poorly when applied to new data, since it didn’t really learn useful patterns—just shortcuts based on leaked information.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt dúw juw kɔ́l ðə sɪ̀tʃuwéjʃən wɛ́n jɔr mɒ́dəl síjmz səspɪ́ʃəslij ɡʊ́d dʊ́rɪŋ tréjnɪŋ—bəkɒ́z ɪnfərméjʃən ɪt ʃʊ́dənt nów həz æ̀ksvdɛ́ntəlij méjd ɪts wej ɪntə ðə déjtəsɛ̀t?",
        "trans_RightAnswer": "déjtə líjkɪdʒ",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "ʌ̀ndərfɪ́tɪŋ",
            "fíjtʃər skéjlɪŋ"
        ],
        "trans_Explanation": "déjtə líjkɪdʒ hǽpənz wɛ́n jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ʌ̀nɪntɛ́nʃənəlij ɡéjnz ǽksɛ̀s tə ɪnfərméjʃən ɪt wʊ́dənt həv ɪn ə ríjəl-wɜ́rld sɪ̀tʃuwéjʃən. ɪt's lájk nówɪŋ ðə ǽnsərz bəfɔ́r ə tɛ́st! ðɪs kɒ́zɪz ðə mɒ́dəl tə pərfɔ́rm ɪnkrɛ́dɪblij wɛ́l dʊ́rɪŋ tréjnɪŋ bʌt pɔ́rlij wɛ́n əplájd tə núw déjtə, sɪns ɪt dɪ́dənt ríjlij lɜ́rn júwsfəl pǽtərnz—dʒəst ʃɔ́rtkʌ̀ts béjst ɒn líjkt ɪnfərméjʃən."
    },
    {
        "Question": "In machine learning, when building classification models, which measure tells you clearly how well your model's predictions match the true classes, especially useful when predicting the likelihood of categories?",
        "RightAnswer": "Cross Entropy Loss",
        "WrongAnswers": [
            "Mean Squared Error",
            "Precision Score",
            "Gradient Descent",
            "Overfitting Metric",
            "Confusion Matrix"
        ],
        "Explanation": "Cross Entropy Loss is like a measuring stick that tells a classification model how accurately its predictions match true labels. It's especially helpful when a model predicts the probability of categories—showing clearly and simply how far off the model's guesses are from reality. The smaller the Cross Entropy Loss, the better the model is predicting!",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n bɪ́ldɪŋ klæ̀sɪfɪkéjʃən mɒ́dəlz, wɪ́tʃ mɛ́ʒər tɛ́lz juw klɪ́ərlij háw wɛ́l jɔr mɒ́dəl'z prədɪ́kʃənz mǽtʃ ðə trúw klǽsɪz, əspɛ́ʃəlij júwsfəl wɛ́n prədɪ́ktɪŋ ðə lájklijhʊ̀d əv kǽtəɡɔ̀rijz?",
        "trans_RightAnswer": "krɔ́s ɛ́ntrəpij lɔ́s",
        "trans_WrongAnswers": [
            "míjn skwɛ́ərd ɛ́ərər",
            "prəsɪ́ʒən skɔ́r",
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ mɛ́trɪk",
            "kənfjúwʒən méjtrɪks"
        ],
        "trans_Explanation": "krɔ́s ɛ́ntrəpij lɔ́s ɪz lájk ə mɛ́ʒərɪŋ stɪ́k ðət tɛ́lz ə klæ̀sɪfɪkéjʃən mɒ́dəl háw ǽkjərətlij ɪts prədɪ́kʃənz mǽtʃ trúw léjbəlz. ɪt's əspɛ́ʃəlij hɛ́lpfəl wɛ́n ə mɒ́dəl prədɪ́kts ðə prɒ̀bəbɪ́lɪtij əv kǽtəɡɔ̀rijz—ʃówɪŋ klɪ́ərlij ənd sɪ́mplij háw fɑ́r ɔ́f ðə mɒ́dəl'z ɡɛ́sɪz ɑr frəm rìjǽlɪtij. ðə smɔ́lər ðə krɔ́s ɛ́ntrəpij lɔ́s, ðə bɛ́tər ðə mɒ́dəl ɪz prədɪ́ktɪŋ!"
    },
    {
        "Question": "In machine learning, which loss function is commonly used in training support vector machines to encourage clear separation and maximize margins between different classes?",
        "RightAnswer": "Hinge Loss",
        "WrongAnswers": [
            "Cross Entropy Loss",
            "Mean Squared Error",
            "Huber Loss",
            "Cosine Similarity Loss",
            "Log Loss"
        ],
        "Explanation": "Hinge loss is a special type of loss function frequently used for training support vector machines and other models that focus on clearly separating data into different groups. Imagine it as a gentle-but-firm guide, penalizing predictions not only if they are incorrect but also if they aren't confidently enough correct. By minimizing hinge loss, the model learns to set strong, clear boundaries (these boundaries are called margins) between categories, helping to boost accuracy and confidence in predicting classifications.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ lɔ́s fʌ́ŋkʃən ɪz kɒ́mənlij júwzd ɪn tréjnɪŋ səpɔ́rt vɛ́ktər məʃíjnz tə ənkɜ́rɪdʒ klɪ́ər sɛ̀pərèjʃən ənd mǽksɪmàjz mɑ́rdʒɪnz bijtwíjn dɪ́fərənt klǽsɪz?",
        "trans_RightAnswer": "hɪ́ndʒ lɔ́s",
        "trans_WrongAnswers": [
            "krɔ́s ɛ́ntrəpij lɔ́s",
            "míjn skwɛ́ərd ɛ́ərər",
            "hjúwbər lɔ́s",
            "kówsajn sɪ̀mɪlɛ́ərɪtij lɔ́s",
            "lɔ́ɡ lɔ́s"
        ],
        "trans_Explanation": "hɪ́ndʒ lɔ́s ɪz ə spɛ́ʃəl tájp əv lɔ́s fʌ́ŋkʃən fríjkwəntlij júwzd fɔr tréjnɪŋ səpɔ́rt vɛ́ktər məʃíjnz ənd ʌ́ðər mɒ́dəlz ðət fówkəs ɒn klɪ́ərlij sɛ́pərèjtɪŋ déjtə ɪntə dɪ́fərənt ɡrúwps. ɪmǽdʒɪn ɪt æz ə dʒɛ́ntəl-bʌt-fɜ́rm ɡájd, píjnəlàjzɪŋ prədɪ́kʃənz nɒt ównlij ɪf ðej ɑr ɪ̀nkərɛ́kt bʌt ɔ́lsow ɪf ðej ɑrənt kɒ́nfɪdəntlij ənʌ́f kərɛ́kt. baj mɪ́nɪmàjzɪŋ hɪ́ndʒ lɔ́s, ðə mɒ́dəl lɜ́rnz tə sɛ́t strɔ́ŋ, klɪ́ər báwndərijz (ðijz báwndərijz ɑr kɔ́ld mɑ́rdʒɪnz) bijtwíjn kǽtəɡɔ̀rijz, hɛ́lpɪŋ tə búwst ǽkjərəsij ənd kɒ́nfɪdəns ɪn prədɪ́ktɪŋ klæ̀sɪfɪkéjʃənz."
    },
    {
        "Question": "In machine learning, especially in algorithms like Support Vector Machines (SVMs), there's an important concept used to separate different groups of data points clearly and confidently. What do we call this clear 'buffer' or gap between the dividing decision boundary and the nearest data points?",
        "RightAnswer": "Margin",
        "WrongAnswers": [
            "Boundary Layer",
            "Data Buffer Zone",
            "Confidence Gap",
            "Separation Band",
            "Decision Space"
        ],
        "Explanation": "Imagine you're drawing a line to separate apples from oranges on a table, but you want to be really sure they don't mix up. The 'Margin' is like the clear space you leave between your divider and the closest apples and oranges, ensuring confident and robust separation. In machine learning terms, it's the distance between the decision boundary (the dividing line) and the nearest data points. The bigger the margin, the clearer and safer the distinction made by your model.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij ɪn ǽlɡərɪ̀ðəmz lájk səpɔ́rt vɛ́ktər məʃíjnz (SVMs), ðɛər'z ən ɪmpɔ́rtənt kɒ́nsɛpt júwzd tə sɛ́pərət dɪ́fərənt ɡrúwps əv déjtə pɔ́jnts klɪ́ərlij ənd kɒ́nfɪdəntlij. wɒt dúw wij kɔ́l ðɪs klɪ́ər 'bʌ́fər' ɔr ɡǽp bijtwíjn ðə dɪvájdɪŋ dəsɪ́ʒən báwndərij ənd ðə nɪ́ərəst déjtə pɔ́jnts?",
        "trans_RightAnswer": "mɑ́rdʒɪn",
        "trans_WrongAnswers": [
            "báwndərij léjər",
            "déjtə bʌ́fər zówn",
            "kɒ́nfɪdəns ɡǽp",
            "sɛ̀pərèjʃən bǽnd",
            "dəsɪ́ʒən spéjs"
        ],
        "trans_Explanation": "ɪmǽdʒɪn júwr drɔ́jŋ ə lájn tə sɛ́pərət ǽpəlz frəm ɔ́rəndʒɪz ɒn ə téjbəl, bʌt juw wɒ́nt tə bij ríjlij ʃʊ́r ðej dównt mɪ́ks ʌp. ðə 'mɑ́rdʒɪn' ɪz lájk ðə klɪ́ər spéjs juw líjv bijtwíjn jɔr dɪvájdər ənd ðə klówsəst ǽpəlz ənd ɔ́rəndʒɪz, ɛnʃʊ́rɪŋ kɒ́nfɪdənt ənd rowbʌ́st sɛ̀pərèjʃən. ɪn məʃíjn lɜ́rnɪŋ tɜ́rmz, ɪt's ðə dɪ́stəns bijtwíjn ðə dəsɪ́ʒən báwndərij (ðə dɪvájdɪŋ lájn) ənd ðə nɪ́ərəst déjtə pɔ́jnts. ðə bɪ́ɡər ðə mɑ́rdʒɪn, ðə klɪ́ərər ənd séjfər ðə dɪstɪ́ŋkʃən méjd baj jɔr mɒ́dəl."
    },
    {
        "Question": "In machine learning, when an algorithm is classifying two groups—for example, cats versus dogs—it finds an imaginary line or curve that separates one category from the other. What is this dividing line called?",
        "RightAnswer": "Decision Boundary",
        "WrongAnswers": [
            "Activation Function",
            "Gradient Descent",
            "Training Set",
            "Regularization",
            "Loss Landscape"
        ],
        "Explanation": "Imagine you're sorting toys into two different baskets based on their features, like size and color. The decision boundary is like the imaginary line you use to separate toys clearly into their respective baskets. In machine learning, the decision boundary serves precisely this purpose—it’s a line or curve the algorithm draws to distinguish between different categories, ensuring each new data point is assigned to its correct group.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n ən ǽlɡərɪ̀ðəm ɪz klǽsɪfàjɪŋ túw ɡrúwps—fɔr əɡzǽmpəl, kǽts vɜ́rsəs dɒ́ɡz—ɪt fájndz ən ɪmǽdʒɪnɛ̀ərij lájn ɔr kɜ́rv ðət sɛ́pərèjts wʌ́n kǽtəɡɔ̀rij frəm ðə ʌ́ðər. wɒt ɪz ðɪs dɪvájdɪŋ lájn kɔ́ld?",
        "trans_RightAnswer": "dəsɪ́ʒən báwndərij",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "tréjnɪŋ sɛ́t",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "lɔ́s lǽnskèjp"
        ],
        "trans_Explanation": "ɪmǽdʒɪn júwr sɔ́rtɪŋ tɔ́jz ɪntə túw dɪ́fərənt bǽskəts béjst ɒn ðɛər fíjtʃərz, lájk sájz ənd kʌ́lər. ðə dəsɪ́ʒən báwndərij ɪz lájk ðə ɪmǽdʒɪnɛ̀ərij lájn juw juwz tə sɛ́pərət tɔ́jz klɪ́ərlij ɪntə ðɛər rəspɛ́ktɪv bǽskəts. ɪn məʃíjn lɜ́rnɪŋ, ðə dəsɪ́ʒən báwndərij sɜ́rvz prəsájslij ðɪs pɜ́rpəs—ɪt's ə lájn ɔr kɜ́rv ðə ǽlɡərɪ̀ðəm drɔ́z tə dɪstɪ́ŋɡwɪʃ bijtwíjn dɪ́fərənt kǽtəɡɔ̀rijz, ɛnʃʊ́rɪŋ ijtʃ núw déjtə pɔ́jnt ɪz əsájnd tə ɪts kərɛ́kt ɡrúwp."
    },
    {
        "Question": "In machine learning, Support Vector Machines often need to handle data that's tricky to separate because it doesn't play nicely in lower-dimensional space. What's the clever approach they use to transform this data into a higher-dimensional space where the boundaries become clear and the data becomes neatly separable?",
        "RightAnswer": "Kernel Trick",
        "WrongAnswers": [
            "Gradient Descent",
            "Feature Scaling",
            "Overfitting Adjustment",
            "Decision Boundary Optimization",
            "Regularization Method"
        ],
        "Explanation": "The Kernel Trick is like a shortcut magic trick in machine learning—it's used by algorithms, especially Support Vector Machines, to quickly transform complex data into a higher-dimensional space. Imagine your data points tangled up and inseparable. By cleverly projecting them into a new, larger space (without needing to compute each transformation explicitly), the Kernel Trick makes separation easy and efficient. This method helps algorithms find clear boundaries between classes in data that's tougher to distinguish in its original form, without significantly increasing computational costs.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, səpɔ́rt vɛ́ktər məʃíjnz ɔ́fən níjd tə hǽndəl déjtə ðət's trɪ́kij tə sɛ́pərət bəkɒ́z ɪt dʌ́zənt pléj nájslij ɪn lówər-dajmɛ́nʃənəl spéjs. wɒt's ðə klɛ́vər əprówtʃ ðej juwz tə trǽnsfɔrm ðɪs déjtə ɪntə ə hájər-dajmɛ́nʃənəl spéjs wɛ́ər ðə báwndərijz bəkʌ́m klɪ́ər ənd ðə déjtə bəkʌ́mz níjtlij sɛ́pərəbəl?",
        "trans_RightAnswer": "kɜ́rnəl trɪ́k",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "fíjtʃər skéjlɪŋ",
            "òwvərfɪ́tɪŋ ədʒʌ́stmənt",
            "dəsɪ́ʒən báwndərij ɒptɪmɪzéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən mɛ́θəd"
        ],
        "trans_Explanation": "ðə kɜ́rnəl trɪ́k ɪz lájk ə ʃɔ́rtkʌ̀t mǽdʒɪk trɪ́k ɪn məʃíjn lɜ́rnɪŋ—ɪt's júwzd baj ǽlɡərɪ̀ðəmz, əspɛ́ʃəlij səpɔ́rt vɛ́ktər məʃíjnz, tə kwɪ́klij trǽnsfɔrm kɒ́mplɛks déjtə ɪntə ə hájər-dajmɛ́nʃənəl spéjs. ɪmǽdʒɪn jɔr déjtə pɔ́jnts tǽŋɡəld ʌp ənd ɪ̀nsɛ́pərəbəl. baj klɛ́vərlij prədʒɛ́ktɪŋ ðɛm ɪntə ə núw, lɑ́rdʒər spéjs (wɪðáwt níjdɪŋ tə kəmpjúwt ijtʃ træ̀nsfərméjʃən əksplɪ́sɪtlij), ðə kɜ́rnəl trɪ́k méjks sɛ̀pərèjʃən íjzij ənd əfɪ́ʃənt. ðɪs mɛ́θəd hɛ́lps ǽlɡərɪ̀ðəmz fájnd klɪ́ər báwndərijz bijtwíjn klǽsɪz ɪn déjtə ðət's tʌ́fər tə dɪstɪ́ŋɡwɪʃ ɪn ɪts ərɪ́dʒɪnəl fɔ́rm, wɪðáwt sɪɡnɪ́fɪkəntlij ɪnkríjsɪŋ kɒ̀mpjuwtéjʃənəl kɒ́sts."
    },
    {
        "Question": "Imagine you have two groups of data points plotted on a simple graph. If you can clearly draw a single straight line to separate one group entirely from the other, how would you describe this property in machine learning terms?",
        "RightAnswer": "Linear Separability",
        "WrongAnswers": [
            "Gradient Descent",
            "Overfitting",
            "Clustering",
            "Backpropagation",
            "Regularization"
        ],
        "Explanation": "Linear separability means the data points from two different groups can be neatly separated by drawing a single straight line (or hyperplane, for higher dimensional data). Think of it like placing a fence on a field so all your cows are on one side, and all your sheep on the other—without any confusion or animals caught in the middle. In machine learning, linear separability is important because algorithms like basic perceptrons depend on it to correctly classify data.",
        "trans_Question": "ɪmǽdʒɪn juw həv túw ɡrúwps əv déjtə pɔ́jnts plɒ́tɪd ɒn ə sɪ́mpəl ɡrǽf. ɪf juw kən klɪ́ərlij drɔ́ ə sɪ́ŋɡəl stréjt lájn tə sɛ́pərət wʌ́n ɡrúwp əntájərlij frəm ðə ʌ́ðər, háw wʊd juw dəskrájb ðɪs prɒ́pərtij ɪn məʃíjn lɜ́rnɪŋ tɜ́rmz?",
        "trans_RightAnswer": "lɪ́nijər sèpərəbɪ́lətij",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ",
            "klʌ́stərɪŋ",
            "bǽkprəpəgéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "lɪ́nijər sèpərəbɪ́lətij míjnz ðə déjtə pɔ́jnts frəm túw dɪ́fərənt ɡrúwps kən bij níjtlij sɛ́pərèjtɪd baj drɔ́jŋ ə sɪ́ŋɡəl stréjt lájn (ɔr hájpərpléjn, fɔr hájər dajmɛ́nʃənəl déjtə). θɪ́ŋk əv ɪt lájk pléjsɪŋ ə fɛ́ns ɒn ə fíjld sow ɔl jɔr káwz ɑr ɒn wʌ́n sájd, ənd ɔl jɔr ʃíjp ɒn ðə ʌ́ðər—wɪðáwt ɛ́nij kənfjúwʒən ɔr ǽnɪməlz kɒ́t ɪn ðə mɪ́dəl. ɪn məʃíjn lɜ́rnɪŋ, lɪ́nijər sèpərəbɪ́lətij ɪz ɪmpɔ́rtənt bəkɒ́z ǽlɡərɪ̀ðəmz lájk béjsɪk pərsɛ́ptronz dəpɛ́nd ɒn ɪt tə kərɛ́ktlij klǽsɪfàj déjtə."
    },
    {
        "Question": "Imagine you're creating an AI model to automatically sort animal pictures into groups—cats, dogs, birds, and reptiles. What is this type of machine learning problem called?",
        "RightAnswer": "Multiclass Classification",
        "WrongAnswers": [
            "Binary Classification",
            "Regression Analysis",
            "Clustering",
            "Dimensionality Reduction",
            "Feature Extraction"
        ],
        "Explanation": "Multiclass classification is when a machine learning model needs to sort or identify items into several different categories or classes—more than just two. For example, identifying different animal species from pictures, like cats, dogs, birds, and reptiles, is a perfect example of a multiclass classification problem. It's like teaching your AI model how to organize things into multiple neat buckets!",
        "trans_Question": "ɪmǽdʒɪn júwr krijéjtɪŋ ən AI mɒ́dəl tə ɔ̀təmǽtɪklij sɔ́rt ǽnɪməl pɪ́ktʃərz ɪntə ɡrúwps—kǽts, dɒ́ɡz, bɜ́rdz, ənd rɛ́ptajlz. wɒt ɪz ðɪs tájp əv məʃíjn lɜ́rnɪŋ prɒ́bləm kɔ́ld?",
        "trans_RightAnswer": "mʌ̀ltijklǽs klæ̀sɪfɪkéjʃən",
        "trans_WrongAnswers": [
            "bájnərij klæ̀sɪfɪkéjʃən",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "fíjtʃər əkstrǽkʃən"
        ],
        "trans_Explanation": "mʌ̀ltijklǽs klæ̀sɪfɪkéjʃən ɪz wɛ́n ə məʃíjn lɜ́rnɪŋ mɒ́dəl níjdz tə sɔ́rt ɔr ajdɛ́ntɪfàj ájtəmz ɪntə sɛ́vərəl dɪ́fərənt kǽtəɡɔ̀rijz ɔr klǽsɪz—mɔr ðʌn dʒəst túw. fɔr əɡzǽmpəl, ajdɛ́ntɪfàjɪŋ dɪ́fərənt ǽnɪməl spíjʃijz frəm pɪ́ktʃərz, lájk kǽts, dɒ́ɡz, bɜ́rdz, ənd rɛ́ptajlz, ɪz ə pɜ́rfəkt əɡzǽmpəl əv ə mʌ̀ltijklǽs klæ̀sɪfɪkéjʃən prɒ́bləm. ɪt's lájk tíjtʃɪŋ jɔr AI mɒ́dəl háw tə ɔ́rɡənàjz θɪ́ŋz ɪntə mʌ́ltɪpəl níjt bʌ́kəts!"
    },
    {
        "Question": "In machine learning, there's a specific kind of task where you place data into just two distinct groups—like checking if an email is either 'spam' or 'not spam', or identifying if an image contains a cat or not. What is this type of classification known as?",
        "RightAnswer": "Binary Classification",
        "WrongAnswers": [
            "Clustering Method",
            "Multiple Regression",
            "Feature Engineering",
            "Neural Pruning",
            "Data Segmentation"
        ],
        "Explanation": "Binary classification is simply a machine learning approach where the goal is to categorize data points into exactly two distinct groups or labels. Think of it as a yes-or-no decision or a true-or-false scenario, like deciding whether an email is spam or a medical test result is positive or negative. This straightforward and common machine learning task helps computers make clear, decisive predictions based on data.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə spəsɪ́fɪk kájnd əv tǽsk wɛ́ər juw pléjs déjtə ɪntə dʒəst túw dɪstɪ́ŋkt ɡrúwps—lájk tʃɛ́kɪŋ ɪf ən íjmejl ɪz ájðər 'spǽm' ɔr 'nɒt spǽm', ɔr ajdɛ́ntɪfàjɪŋ ɪf ən ɪ́mɪdʒ kəntéjnz ə kǽt ɔr nɒt. wɒt ɪz ðɪs tájp əv klæ̀sɪfɪkéjʃən nówn æz?",
        "trans_RightAnswer": "bájnərij klæ̀sɪfɪkéjʃən",
        "trans_WrongAnswers": [
            "klʌ́stərɪŋ mɛ́θəd",
            "mʌ́ltɪpəl rəɡrɛ́ʃən",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "nʊ́rəl prúwnɪŋ",
            "déjtə sɛ̀ɡməntéjʃən"
        ],
        "trans_Explanation": "bájnərij klæ̀sɪfɪkéjʃən ɪz sɪ́mplij ə məʃíjn lɜ́rnɪŋ əprówtʃ wɛ́ər ðə ɡówl ɪz tə kǽtəɡəràjz déjtə pɔ́jnts ɪntə əɡzǽktlij túw dɪstɪ́ŋkt ɡrúwps ɔr léjbəlz. θɪ́ŋk əv ɪt æz ə jɛs-ɔr-now dəsɪ́ʒən ɔr ə trúw-ɔr-fɔ́ls sənɛ́ərijow, lájk dəsájdɪŋ wɛ́ðər ən íjmejl ɪz spǽm ɔr ə mɛ́dɪkəl tɛ́st rəzʌ́lt ɪz pɒ́zɪtɪv ɔr nɛ́ɡətɪv. ðɪs stréjtfɔ́rwərd ənd kɒ́mən məʃíjn lɜ́rnɪŋ tǽsk hɛ́lps kəmpjúwtərz méjk klɪ́ər, dəsájsɪv prədɪ́kʃənz béjst ɒn déjtə."
    },
    {
        "Question": "When working on a machine learning project with multiple categories, you have a classification method that compares each category individually against all others at once. What is this approach called?",
        "RightAnswer": "One-vs-All",
        "WrongAnswers": [
            "Multi-Step Classification",
            "Divide-and-Conquer",
            "Singular Classification",
            "Binary Reduction",
            "Cluster Comparison"
        ],
        "Explanation": "One-vs-All (or One-vs-Rest) is a straightforward yet powerful approach used when your task involves multiple categories. It works by turning your multi-category problem into multiple sets of simple 'yes/no' decisions. Each category gets its own classifier that asks, 'Is the input this category or any other?', making the problem simpler and easier to handle. At the end, the category with the strongest, most confident 'yes' wins. This method is popular due to its simplicity and effectiveness, especially when dealing with models inherently designed for binary tasks.",
        "trans_Question": "wɛ́n wɜ́rkɪŋ ɒn ə məʃíjn lɜ́rnɪŋ prɒ́dʒɛkt wɪð mʌ́ltɪpəl kǽtəɡɔ̀rijz, juw həv ə klæ̀sɪfɪkéjʃən mɛ́θəd ðət kəmpɛ́ərz ijtʃ kǽtəɡɔ̀rij ɪndɪvɪ́dʒəlij əɡéjnst ɔl ʌ́ðərz æt wʌ́ns. wɒt ɪz ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "wʌ́n-vɜ́rsəs-ɔl",
        "trans_WrongAnswers": [
            "mʌ́ltij-stɛ́p klæ̀sɪfɪkéjʃən",
            "dɪvájd-ənd-kɒ́ŋkər",
            "sɪ́ŋɡjələr klæ̀sɪfɪkéjʃən",
            "bájnərij rədʌ́kʃən",
            "klʌ́stər kəmpɛ́ərɪsən"
        ],
        "trans_Explanation": "wʌ́n-vɜ́rsəs-ɔl (ɔr wʌ́n-vɜ́rsəs-rɛ́st) ɪz ə stréjtfɔ́rwərd jɛt páwərfəl əprówtʃ júwzd wɛ́n jɔr tǽsk ɪnvɒ́lvz mʌ́ltɪpəl kǽtəɡɔ̀rijz. ɪt wɜ́rks baj tɜ́rnɪŋ jɔr mʌ́ltij-kǽtəɡɔ̀rij prɒ́bləm ɪntə mʌ́ltɪpəl sɛ́ts əv sɪ́mpəl 'jɛs/now' dəsɪ́ʒənz. ijtʃ kǽtəɡɔ̀rij ɡɛ́ts ɪts ówn klǽsɪfajər ðət ǽsks, 'ɪz ðə ɪ́npʊ̀t ðɪs kǽtəɡɔ̀rij ɔr ɛ́nij ʌ́ðər?', méjkɪŋ ðə prɒ́bləm sɪ́mplər ənd íjzijər tə hǽndəl. æt ðə ɛ́nd, ðə kǽtəɡɔ̀rij wɪð ðə strɔ́ŋɡəst, mówst kɒ́nfɪdənt 'jɛs' wɪ́nz. ðɪs mɛ́θəd ɪz pɒ́pjələr djúw tə ɪts sɪmplɪ́sɪtij ənd əfɛ́ktɪvnəs, əspɛ́ʃəlij wɛ́n díjlɪŋ wɪð mɒ́dəlz ɪnhɛ́ərəntlij dəzájnd fɔr bájnərij tǽsks."
    },
    {
        "Question": "When training a classifier for a problem with several different classes, what's the name of the method that builds separate models comparing every possible pair of classes individually, and then combines these pairwise predictions?",
        "RightAnswer": "One-vs-One",
        "WrongAnswers": [
            "Binary Classifier",
            "Bagging",
            "One-vs-All",
            "Decision Forest",
            "Hierarchical Clustering"
        ],
        "Explanation": "The 'One-vs-One' approach tackles multi-class classification in a straightforward way: it creates separate models that each focus on distinguishing between just two classes. Then, when making predictions, all these models 'voting' combined decides the final class. Imagine it as each model being an expert at differentiating just two choices, and then everyone's votes are counted to make the final decision. It's efficient and often quite accurate when dealing with multiple categories!",
        "trans_Question": "wɛ́n tréjnɪŋ ə klǽsɪfajər fɔr ə prɒ́bləm wɪð sɛ́vərəl dɪ́fərənt klǽsɪz, wɒt's ðə néjm əv ðə mɛ́θəd ðət bɪ́ldz sɛ́pərət mɒ́dəlz kəmpɛ́ərɪŋ ɛvərij pɒ́sɪbəl pɛ́ər əv klǽsɪz ɪndɪvɪ́dʒəlij, ənd ðɛn kəmbájnz ðijz pɛ́ərwajz prədɪ́kʃənz?",
        "trans_RightAnswer": "wʌ́n-vɜ́rsəs-wʌ́n",
        "trans_WrongAnswers": [
            "bájnərij klǽsɪfajər",
            "bǽɡɪŋ",
            "wʌ́n-vɜ́rsəs-ɔl",
            "dəsɪ́ʒən fɔ́rəst",
            "hàjərɑ́rkɪkəl klʌ́stərɪŋ"
        ],
        "trans_Explanation": "ðə 'wʌ́n-vɜ́rsəs-wʌ́n' əprówtʃ tǽkəlz mʌ́ltij-klǽs klæ̀sɪfɪkéjʃən ɪn ə stréjtfɔ́rwərd wej: ɪt krijéjts sɛ́pərət mɒ́dəlz ðət ijtʃ fówkəs ɒn dɪstɪ́ŋɡwɪʃɪŋ bijtwíjn dʒəst túw klǽsɪz. ðɛn, wɛ́n méjkɪŋ prədɪ́kʃənz, ɔl ðijz mɒ́dəlz 'vówtɪŋ' kəmbájnd dəsájdz ðə fájnəl klǽs. ɪmǽdʒɪn ɪt æz ijtʃ mɒ́dəl bíjɪŋ ən ɛ́kspərt æt dɪ̀fərɛ́nʃijèjtɪŋ dʒəst túw tʃɔ́jsɪz, ənd ðɛn ɛ́vrijwʌ̀n'z vówts ɑr káwntɪd tə méjk ðə fájnəl dəsɪ́ʒən. ɪt's əfɪ́ʃənt ənd ɔ́fən kwájt ǽkjərət wɛ́n díjlɪŋ wɪð mʌ́ltɪpəl kǽtəɡɔ̀rijz!"
    },
    {
        "Question": "In machine learning, imagine you're dealing not with simple yes-or-no predictions, but rather predicting complex outputs—like figuring out the best sentence structure or recognizing objects within an image while understanding how they relate to each other. Which term best describes these types of complex predictions?",
        "RightAnswer": "Structured Prediction",
        "WrongAnswers": [
            "Binary Classification",
            "Regression Analysis",
            "Unsupervised Clustering",
            "Gradient Boosting",
            "Feature Extraction"
        ],
        "Explanation": "Structured prediction refers to the machine learning task of predicting complex outputs, where the outputs are made up of multiple interrelated parts or structures. Unlike simple predictions (like classifying an email as spam or not), structured prediction tackles problems such as parsing sentences, labeling connected regions in images, or determining relationships between entities. Think of it as the difference between identifying an isolated object versus understanding how multiple items connect and relate to each other.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ɪmǽdʒɪn júwr díjlɪŋ nɒt wɪð sɪ́mpəl jɛs-ɔr-now prədɪ́kʃənz, bʌt rǽðər prədɪ́ktɪŋ kɒ́mplɛks áwtpʊ̀ts—lájk fɪ́ɡjərɪŋ awt ðə bɛ́st sɛ́ntəns strʌ́ktʃər ɔr rɛ́kəɡnàjzɪŋ ɒ́bdʒɛkts wɪðɪ́n ən ɪ́mɪdʒ wájl ʌ̀ndərstǽndɪŋ háw ðej rəléjt tə ijtʃ ʌ́ðər. wɪ́tʃ tɜ́rm bɛ́st dəskrájbz ðijz tájps əv kɒ́mplɛks prədɪ́kʃənz?",
        "trans_RightAnswer": "strʌ́ktʃərd prədɪ́kʃən",
        "trans_WrongAnswers": [
            "bájnərij klæ̀sɪfɪkéjʃən",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "ʌ̀nsúwpərvàjzd klʌ́stərɪŋ",
            "ɡréjdijənt búwstɪŋ",
            "fíjtʃər əkstrǽkʃən"
        ],
        "trans_Explanation": "strʌ́ktʃərd prədɪ́kʃən rəfɜ́rz tə ðə məʃíjn lɜ́rnɪŋ tǽsk əv prədɪ́ktɪŋ kɒ́mplɛks áwtpʊ̀ts, wɛ́ər ðə áwtpʊ̀ts ɑr méjd ʌp əv mʌ́ltɪpəl ɪ̀ntərrəléjtɪd pɑ́rts ɔr strʌ́ktʃərz. ʌ̀nlájk sɪ́mpəl prədɪ́kʃənz (lájk klǽsɪfàjɪŋ ən íjmejl æz spǽm ɔr nɒt), strʌ́ktʃərd prədɪ́kʃən tǽkəlz prɒ́bləmz sʌtʃ æz pɑ́rsɪŋ sɛ́ntənsɪz, léjbəlɪŋ kənɛ́ktɪd ríjdʒənz ɪn ɪ́mɪdʒɪz, ɔr dətɜ́rmɪnɪŋ rəléjʃənʃɪ̀ps bijtwíjn ɛ́ntɪtijz. θɪ́ŋk əv ɪt æz ðə dɪ́fərəns bijtwíjn ajdɛ́ntɪfàjɪŋ ən ájsəlèjtɪd ɒ́bdʒəkt vɜ́rsəs ʌ̀ndərstǽndɪŋ háw mʌ́ltɪpəl ájtəmz kənɛ́kt ənd rəléjt tə ijtʃ ʌ́ðər."
    },
    {
        "Question": "In machine learning, imagine a task where you identify distinct labels or categories for every individual element within a series, such as naming each word in a sentence with its grammatical role or identifying entities within text. What's this technique called?",
        "RightAnswer": "Sequence Labeling",
        "WrongAnswers": [
            "Clustering Analysis",
            "Regression Modeling",
            "Dimensionality Reduction",
            "Reinforcement Learning",
            "Ensemble Learning"
        ],
        "Explanation": "Sequence labeling is a method in machine learning where each element within a sequence (for example, each word in a sentence or each time step in speech recognition) is assigned a specific label or category. Think of it like putting tags or sticky notes on each item in a line—this is especially useful in natural language processing tasks, such as naming entities (like people or places) in sentences, or identifying the part-of-speech of each word individually.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ɪmǽdʒɪn ə tǽsk wɛ́ər juw ajdɛ́ntɪfàj dɪstɪ́ŋkt léjbəlz ɔr kǽtəɡɔ̀rijz fɔr ɛvərij ɪndɪvɪ́dʒəwəl ɛ́ləmənt wɪðɪ́n ə sɪ́ərijz, sʌtʃ æz néjmɪŋ ijtʃ wɜ́rd ɪn ə sɛ́ntəns wɪð ɪts ɡrəmǽtɪkəl rówl ɔr ajdɛ́ntɪfàjɪŋ ɛ́ntɪtijz wɪðɪ́n tɛ́kst. wɒt's ðɪs tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "síjkwəns léjbəlɪŋ",
        "trans_WrongAnswers": [
            "klʌ́stərɪŋ ənǽlɪsɪs",
            "rəɡrɛ́ʃən mɒ́dəlɪ̀ŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ"
        ],
        "trans_Explanation": "síjkwəns léjbəlɪŋ ɪz ə mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ijtʃ ɛ́ləmənt wɪðɪ́n ə síjkwəns (fɔr əɡzǽmpəl, ijtʃ wɜ́rd ɪn ə sɛ́ntəns ɔr ijtʃ tájm stɛ́p ɪn spíjtʃ rɛ̀kəɡnɪ́ʃən) ɪz əsájnd ə spəsɪ́fɪk léjbəl ɔr kǽtəɡɔ̀rij. θɪ́ŋk əv ɪt lájk pʊ́tɪŋ tǽɡz ɔr stɪ́kij nówts ɒn ijtʃ ájtəm ɪn ə lájn—ðɪs ɪz əspɛ́ʃəlij júwsfəl ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ tǽsks, sʌtʃ æz néjmɪŋ ɛ́ntɪtijz (lájk píjpəl ɔr pléjsɪz) ɪn sɛ́ntənsɪz, ɔr ajdɛ́ntɪfàjɪŋ ðə pɑ́rt-əv-spíjtʃ əv ijtʃ wɜ́rd ɪndɪvɪ́dʒəlij."
    },
    {
        "Question": "In machine learning, which model helps predict a series of hidden events or states from observed data, and is widely useful in fields like speech recognition, handwriting analysis, and bioinformatics?",
        "RightAnswer": "Hidden Markov Models",
        "WrongAnswers": [
            "Support Vector Machines",
            "Convolutional Neural Networks",
            "K-Means Clustering",
            "Decision Trees",
            "Linear Regression"
        ],
        "Explanation": "Hidden Markov Models (HMMs) are a type of statistical model used to analyze sequences. Think of them as detectives piecing together clues (observations) to figure out hidden events or states behind them. They are especially useful for analyzing data where the events we care about are not directly observable, such as interpreting spoken words from speech data, predicting genes from DNA sequences, or analyzing handwritten text.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ mɒ́dəl hɛ́lps prədɪ́kt ə sɪ́ərijz əv hɪ́dən əvɛ́nts ɔr stéjts frəm əbzɜ́rvd déjtə, ənd ɪz wájdlij júwsfəl ɪn fíjldz lájk spíjtʃ rɛ̀kəɡnɪ́ʃən, hǽndràjtɪŋ ənǽlɪsɪs, ənd bàjəɪnfərmǽtɪks?",
        "trans_RightAnswer": "hɪ́dən mɑ́rkowv mɒ́dəlz",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "k-míjnz klʌ́stərɪŋ",
            "dəsɪ́ʒən tríjz",
            "lɪ́nijər rəɡrɛ́ʃən"
        ],
        "trans_Explanation": "hɪ́dən mɑ́rkowv mɒ́dəlz (hmz) ɑr ə tájp əv stətɪ́stɪkəl mɒ́dəl júwzd tə ǽnəlàjz síjkwənsɪz. θɪ́ŋk əv ðɛm æz dətɛ́ktɪvz píjsɪŋ təɡɛ́ðər klúwz (ɒ̀bzərvéjʃənz) tə fɪ́ɡjər awt hɪ́dən əvɛ́nts ɔr stéjts bəhájnd ðɛm. ðej ɑr əspɛ́ʃəlij júwsfəl fɔr ǽnəlàjzɪŋ déjtə wɛ́ər ðə əvɛ́nts wij kɛ́ər əbawt ɑr nɒt dɪərɛ́klij əbzɜ́rvəbəl, sʌtʃ æz ɪntərprɛ́tɪŋ spówkən wɜ́rdz frəm spíjtʃ déjtə, prədɪ́ktɪŋ dʒíjnz frəm DNA síjkwənsɪz, ɔr ǽnəlàjzɪŋ hǽndrɪ̀tən tɛ́kst."
    },
    {
        "Question": "Imagine you're building a machine learning model that analyzes sentences for specific tags (like identifying whether each word is part of a name, place, or event). Which algorithm would help your model excel at capturing context between neighboring words and making accurate predictions for sequential data?",
        "RightAnswer": "Conditional Random Fields",
        "WrongAnswers": [
            "K-Means Clustering",
            "Gradient Boosting Trees",
            "Principal Component Analysis",
            "Support Vector Machines",
            "Convolutional Neural Networks"
        ],
        "Explanation": "Conditional Random Fields, often shortened to CRFs, are powerful algorithms tailored specifically for tasks involving sequences of information, such as text labeling (think of tagging each word in a sentence as a person, place, or brand). CRFs work by looking at how neighboring elements (like words in a sentence) connect, helping the model account for context—making predictions more accurate and cohesive. They're great at capturing relationships between steps in a sequence, making them ideal for natural language processing tasks or even analyzing biological sequences.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ðət ǽnəlàjzɪz sɛ́ntənsɪz fɔr spəsɪ́fɪk tǽɡz (lájk ajdɛ́ntɪfàjɪŋ wɛ́ðər ijtʃ wɜ́rd ɪz pɑ́rt əv ə néjm, pléjs, ɔr əvɛ́nt). wɪ́tʃ ǽlɡərɪ̀ðəm wʊd hɛ́lp jɔr mɒ́dəl əksɛ́l æt kǽptʃərɪŋ kɒ́ntɛkst bijtwíjn néjbərɪŋ wɜ́rdz ənd méjkɪŋ ǽkjərət prədɪ́kʃənz fɔr səkwɛ́nʃəl déjtə?",
        "trans_RightAnswer": "kəndɪ́ʃənəl rǽndəm fíjldz",
        "trans_WrongAnswers": [
            "k-míjnz klʌ́stərɪŋ",
            "ɡréjdijənt búwstɪŋ tríjz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "kəndɪ́ʃənəl rǽndəm fíjldz, ɔ́fən ʃɔ́rtənd tə krəfs, ɑr páwərfəl ǽlɡərɪ̀ðəmz téjlərd spəsɪ́fɪklij fɔr tǽsks ɪnvɒ́lvɪŋ síjkwənsɪz əv ɪnfərméjʃən, sʌtʃ æz tɛ́kst léjbəlɪŋ (θɪ́ŋk əv tǽɡɪŋ ijtʃ wɜ́rd ɪn ə sɛ́ntəns æz ə pɜ́rsən, pléjs, ɔr brǽnd). krəfs wɜ́rk baj lʊ́kɪŋ æt háw néjbərɪŋ ɛ́ləmənts (lájk wɜ́rdz ɪn ə sɛ́ntəns) kənɛ́kt, hɛ́lpɪŋ ðə mɒ́dəl əkáwnt fɔr kɒ́ntɛkst—méjkɪŋ prədɪ́kʃənz mɔr ǽkjərət ənd kowhíjsɪv. ðɛ́ər ɡréjt æt kǽptʃərɪŋ rəléjʃənʃɪ̀ps bijtwíjn stɛ́ps ɪn ə síjkwəns, méjkɪŋ ðɛm ajdíjəl fɔr nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ tǽsks ɔr íjvən ǽnəlàjzɪŋ bàjəlɒ́dʒɪkəl síjkwənsɪz."
    },
    {
        "Question": "Which machine learning method efficiently approximates complicated probability distributions by iteratively refining simpler distributions to capture essential details?",
        "RightAnswer": "Expectation Propagation",
        "WrongAnswers": [
            "Support Vector Machines",
            "Gradient Boosting",
            "Principal Component Analysis",
            "Bayesian Optimization",
            "Monte Carlo Sampling"
        ],
        "Explanation": "Expectation Propagation, often called EP, is a clever algorithm that helps us handle complicated probability problems. It works by repeatedly approximating complex, hard-to-use probability distributions with simpler, manageable ones, gradually making each simple approximation better and better. By focusing on the 'average' or expected aspects of the complicated solution, EP lets us efficiently capture important features of the original distribution—saving time and computational resources while providing reliable results.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ mɛ́θəd əfɪ́ʃəntlij əprɒ́ksəmèjts kɒ́mplɪkèjtɪd prɒ̀bəbɪ́lɪtij dɪ̀strəbjúwʃənz baj ɪ́tərətɪvlij rəfájnɪŋ sɪ́mplər dɪ̀strəbjúwʃənz tə kǽptʃər əsɛ́nʃəl díjtejlz?",
        "trans_RightAnswer": "ɛ̀kspɛktéjʃən prɒ̀pəɡéjʃən",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "ɡréjdijənt búwstɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "béjʒən ɒptɪmɪzéjʃən",
            "mɒ́ntij kɑ́rlow sǽmplɪŋ"
        ],
        "trans_Explanation": "ɛ̀kspɛktéjʃən prɒ̀pəɡéjʃən, ɔ́fən kɔ́ld EP, ɪz ə klɛ́vər ǽlɡərɪ̀ðəm ðət hɛ́lps ʌs hǽndəl kɒ́mplɪkèjtɪd prɒ̀bəbɪ́lɪtij prɒ́bləmz. ɪt wɜ́rks baj rəpíjtɪdlij əprɒ́ksɪmèjtɪŋ kɒ́mplɛks, hɑ́rd-tə-juwz prɒ̀bəbɪ́lɪtij dɪ̀strəbjúwʃənz wɪð sɪ́mplər, mǽnədʒəbəl wʌ́nz, ɡrǽdʒuwəlij méjkɪŋ ijtʃ sɪ́mpəl əprɒ̀ksəméjʃən bɛ́tər ənd bɛ́tər. baj fówkəsɪŋ ɒn ðə 'ǽvərɪdʒ' ɔr əkspɛ́ktɪd ǽspɛkts əv ðə kɒ́mplɪkèjtɪd səlúwʃən, EP lɛts ʌs əfɪ́ʃəntlij kǽptʃər ɪmpɔ́rtənt fíjtʃərz əv ðə ərɪ́dʒɪnəl dɪ̀strəbjúwʃən—séjvɪŋ tájm ənd kɒ̀mpjuwtéjʃənəl ríjsɔrsɪz wájl prəvájdɪŋ rəlájəbəl rəzʌ́lts."
    },
    {
        "Question": "What do you call a machine learning model inspired by the human brain, made up of multiple interconnected layers of artificial neurons, used to understand complex patterns and make predictions?",
        "RightAnswer": "Deep Neural Networks",
        "WrongAnswers": [
            "Decision Trees",
            "Support Vector Machines",
            "K-Nearest Neighbors",
            "Linear Regression",
            "Random Forests"
        ],
        "Explanation": "Deep Neural Networks are powerful machine learning models inspired by how our brains work. They consist of multiple layers of connected artificial neurons that learn from data by recognizing patterns. Because of their depth and complexity, these neural networks excel at solving challenging problems like voice recognition, image classification, and even beating humans in games like chess and Go.",
        "trans_Question": "wɒt dúw juw kɔ́l ə məʃíjn lɜ́rnɪŋ mɒ́dəl ɪnspájərd baj ðə hjúwmən bréjn, méjd ʌp əv mʌ́ltɪpəl ɪ̀ntərkənɛ́ktɪd léjərz əv ɑ̀rtɪfɪ́ʃəl nʊ́rɒnz, júwzd tə ʌ̀ndərstǽnd kɒ́mplɛks pǽtərnz ənd méjk prədɪ́kʃənz?",
        "trans_RightAnswer": "díjp nʊ́rəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "k-nɪ́ərəst néjbərz",
            "lɪ́nijər rəɡrɛ́ʃən",
            "rǽndəm fɔ́rəsts"
        ],
        "trans_Explanation": "díjp nʊ́rəl nɛ́twɜ̀rks ɑr páwərfəl məʃíjn lɜ́rnɪŋ mɒ́dəlz ɪnspájərd baj háw awər bréjnz wɜ́rk. ðej kənsɪ́st əv mʌ́ltɪpəl léjərz əv kənɛ́ktɪd ɑ̀rtɪfɪ́ʃəl nʊ́rɒnz ðət lɜ́rn frəm déjtə baj rɛ́kəɡnàjzɪŋ pǽtərnz. bəkɒ́z əv ðɛər dɛ́pθ ənd kəmplɛ́ksɪtij, ðijz nʊ́rəl nɛ́twɜ̀rks əksɛ́l æt sɒ́lvɪŋ tʃǽləndʒɪŋ prɒ́bləmz lájk vɔ́js rɛ̀kəɡnɪ́ʃən, ɪ́mɪdʒ klæ̀sɪfɪkéjʃən, ənd íjvən bíjtɪŋ hjúwmənz ɪn ɡéjmz lájk tʃɛ́s ənd ɡow."
    },
    {
        "Question": "In machine learning, training deep neural networks often becomes harder as they get deeper, but researchers introduced a smart approach that uses 'skip connections' to let the networks skip over some layers, making it easier to train very deep models. What is this approach called?",
        "RightAnswer": "Residual Networks",
        "WrongAnswers": [
            "Convolutional Clusters",
            "Adversarial Networks",
            "Dropout Networks",
            "Activation Loops",
            "Recurrent Paths"
        ],
        "Explanation": "Residual Networks, or ResNets, were introduced to help overcome the challenge of training very deep neural networks. Typically, when neural networks become very deep, it becomes difficult for them to learn efficiently, known as the 'vanishing gradient' problem. ResNets cleverly introduce 'skip connections' or shortcut pathways that allow information to bypass certain layers, helping to keep information flowing through the network smoothly and thus making it easier and more effective to train. Think of it as providing little shortcuts that not only save training effort but also help improve the performance of the network as it gets deeper and more complex!",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, tréjnɪŋ díjp nʊ́rəl nɛ́twɜ̀rks ɔ́fən bəkʌ́mz hɑ́rdər æz ðej ɡɛt díjpər, bʌt ríjsərtʃərz ɪntrədúwst ə smɑ́rt əprówtʃ ðət júwsɪz 'skɪ́p kənɛ́kʃənz' tə lɛt ðə nɛ́twɜ̀rks skɪ́p ówvər sʌm léjərz, méjkɪŋ ɪt íjzijər tə tréjn vɛ́ərij díjp mɒ́dəlz. wɒt ɪz ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "rəzɪ́dʒuwəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl klʌ́stərz",
            "æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
            "drɒ́pàwt nɛ́twɜ̀rks",
            "æ̀ktɪvéjʃən lúwps",
            "rəkɜ́rənt pǽðz"
        ],
        "trans_Explanation": "rəzɪ́dʒuwəl nɛ́twɜ̀rks, ɔr rɛ́znɛts, wɜ́r ɪntrədúwst tə hɛ́lp ówvərkʌ̀m ðə tʃǽləndʒ əv tréjnɪŋ vɛ́ərij díjp nʊ́rəl nɛ́twɜ̀rks. tɪ́pɪkəlij, wɛ́n nʊ́rəl nɛ́twɜ̀rks bəkʌ́m vɛ́ərij díjp, ɪt bəkʌ́mz dɪ́fɪkəlt fɔr ðɛm tə lɜ́rn əfɪ́ʃəntlij, nówn æz ðə 'vǽnɪʃɪŋ ɡréjdijənt' prɒ́bləm. rɛ́znɛts klɛ́vərlij ɪntrədúws 'skɪ́p kənɛ́kʃənz' ɔr ʃɔ́rtkʌ̀t pǽθwèjz ðət əláw ɪnfərméjʃən tə bájpæ̀s sɜ́rtən léjərz, hɛ́lpɪŋ tə kíjp ɪnfərméjʃən flówɪŋ θrúw ðə nɛ́twɜ̀rk smúwðlij ənd ðʌs méjkɪŋ ɪt íjzijər ənd mɔr əféktɪv tə tréjn. θɪ́ŋk əv ɪt æz prəvájdɪŋ lɪ́təl ʃɔ́rtkʌ̀ts ðət nɒt ównlij séjv tréjnɪŋ ɛ́fərt bʌt ɔ́lsow hɛ́lp ɪmprúwv ðə pərfɔ́rməns əv ðə nɛ́twɜ̀rk æz ɪt ɡɛ́ts díjpər ənd mɔr kɒ́mplɛks!"
    },
    {
        "Question": "Which of the following refers to a convolutional neural network architecture famous for connecting each layer directly to every other layer, improving the flow of information and helping to build deeper, more efficient models?",
        "RightAnswer": "DenseNet",
        "WrongAnswers": [
            "ResNet",
            "AlexNet",
            "VGGNet",
            "MobileNet",
            "LeNet"
        ],
        "Explanation": "DenseNet (short for Dense Convolutional Network) is an innovative type of neural network architecture known for its unique strategy of connecting every layer directly to every other layer. Imagine layers in a network talking directly to each other, sharing what they've learned at each step—this helps information flow smoothly, reduces the chance of losing useful details, and lets the network be both deeper and more efficient without becoming overly complex. It's widely admired in the machine learning community for enhancing the model's accuracy and efficiency, especially in computer vision tasks.",
        "trans_Question": "wɪ́tʃ əv ðə fɒ́lowɪŋ rəfɜ́rz tə ə kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rk ɑ́rkɪtɛ̀ktʃər féjməs fɔr kənɛ́ktɪŋ ijtʃ léjər dɪərɛ́klij tə ɛvərij ʌ́ðər léjər, ɪmprúwvɪŋ ðə flów əv ɪnfərméjʃən ənd hɛ́lpɪŋ tə bɪ́ld díjpər, mɔr əfɪ́ʃənt mɒ́dəlz?",
        "trans_RightAnswer": "dɛ́nsnɛt",
        "trans_WrongAnswers": [
            "RESNET",
            "ǽlɛksnɛ̀t",
            "vɪdʒìjdʒìjnɛ́t",
            "mówbɪlnɛ̀t",
            "lɛ́nət"
        ],
        "trans_Explanation": "dɛ́nsnɛt (ʃɔ́rt fɔr dɛ́ns kənvəlúwʃənəl nɛ́twɜ̀rk) ɪz ən ɪ́nəvejtɪv tájp əv nʊ́rəl nɛ́twɜ̀rk ɑ́rkɪtɛ̀ktʃər nówn fɔr ɪts juwnɪ́k strǽtədʒij əv kənɛ́ktɪŋ ɛvərij léjər dɪərɛ́klij tə ɛvərij ʌ́ðər léjər. ɪmǽdʒɪn léjərz ɪn ə nɛ́twɜ̀rk tɔ́kɪŋ dɪərɛ́klij tə ijtʃ ʌ́ðər, ʃɛ́ərɪŋ wɒt ðéjv lɜ́rnd æt ijtʃ stɛ́p—ðɪs hɛ́lps ɪnfərméjʃən flów smúwðlij, rədjúwsɪz ðə tʃǽns əv lúwzɪŋ júwsfəl díjtejlz, ənd lɛts ðə nɛ́twɜ̀rk bij bówθ díjpər ənd mɔr əfɪ́ʃənt wɪðáwt bəkʌ́mɪŋ ówvərlij kɒ́mplɛks. ɪt's wájdlij ədmájərd ɪn ðə məʃíjn lɜ́rnɪŋ kəmjúwnɪtij fɔr ɛnhǽnsɪŋ ðə mɒ́dəl'z ǽkjərəsij ənd əfɪ́ʃənsij, əspɛ́ʃəlij ɪn kəmpjúwtər vɪ́ʒən tǽsks."
    },
    {
        "Question": "Which machine learning model became famous for its clever use of parallel filtering paths, allowing computers to capture features from images at different scales simultaneously?",
        "RightAnswer": "Inception Network",
        "WrongAnswers": [
            "Generative Adversarial Network",
            "Support Vector Machine",
            "Recurrent Neural Network",
            "Autoencoder",
            "Random Forest"
        ],
        "Explanation": "An Inception Network is a specialized neural network architecture designed to efficiently learn features from images by simultaneously analyzing details at multiple scales. Think of it like taking different magnifying glasses to look at the same picture—each captures different levels of detail. This creative design helps the model perform better at tasks like image classification, recognizing patterns that might be missed if viewed from only one perspective.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ mɒ́dəl bijkéjm féjməs fɔr ɪts klɛ́vər juwz əv pǽrəlɛ̀l fɪ́ltərɪŋ pǽðz, əláwɪŋ kəmpjúwtərz tə kǽptʃər fíjtʃərz frəm ɪ́mɪdʒɪz æt dɪ́fərənt skéjlz sàjməltéjnijəslij?",
        "trans_RightAnswer": "ɪnsɛ́pʃən nɛ́twɜ̀rk",
        "trans_WrongAnswers": [
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rk",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rk",
            "ɔ̀towənkówdər",
            "rǽndəm fɔ́rəst"
        ],
        "trans_Explanation": "ən ɪnsɛ́pʃən nɛ́twɜ̀rk ɪz ə spɛ́ʃəlàjzd nʊ́rəl nɛ́twɜ̀rk ɑ́rkɪtɛ̀ktʃər dəzájnd tə əfɪ́ʃəntlij lɜ́rn fíjtʃərz frəm ɪ́mɪdʒɪz baj sàjməltéjnijəslij ǽnəlàjzɪŋ díjtejlz æt mʌ́ltɪpəl skéjlz. θɪ́ŋk əv ɪt lájk téjkɪŋ dɪ́fərənt mǽɡnɪfàjɪŋ ɡlǽsɪz tə lʊ́k æt ðə séjm pɪ́ktʃər—ijtʃ kǽptʃərz dɪ́fərənt lɛ́vəlz əv díjtejl. ðɪs krijéjtɪv dəzájn hɛ́lps ðə mɒ́dəl pərfɔ́rm bɛ́tər æt tǽsks lájk ɪ́mɪdʒ klæ̀sɪfɪkéjʃən, rɛ́kəɡnàjzɪŋ pǽtərnz ðət majt bij mɪ́st ɪf vjúwd frəm ównlij wʌ́n pərspɛ́ktɪv."
    },
    {
        "Question": "In machine learning, there's a groundbreaking architecture designed to handle sequences like sentences or paragraphs exceptionally well, powering models like ChatGPT and Google's BERT. Which term best describes this innovative architecture?",
        "RightAnswer": "Transformer Models",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Recurrent Neural Networks",
            "Decision Trees",
            "Support Vector Machines",
            "Generative Adversarial Networks"
        ],
        "Explanation": "Transformer models are advanced machine learning structures that effectively analyze sequences—such as words in sentences, or tokens of text—by looking at all the pieces simultaneously. Unlike older methods (like recurrent neural networks) that process sequences step-by-step, transformers use a technique called 'attention' to weigh the importance of different words and their relationships. This innovation makes them excellent at understanding context, capturing subtle nuances, and powering cutting-edge language tools like ChatGPT and Google's BERT.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə ɡráwnbrèjkɪŋ ɑ́rkɪtɛ̀ktʃər dəzájnd tə hǽndəl síjkwənsɪz lájk sɛ́ntənsɪz ɔr pǽrəɡræ̀fs əksɛ́pʃənəlij wɛ́l, páwərɪŋ mɒ́dəlz lájk tʃæt ənd ɡúwɡəl'z BERT. wɪ́tʃ tɜ́rm bɛ́st dəskrájbz ðɪs ɪ́nəvejtɪv ɑ́rkɪtɛ̀ktʃər?",
        "trans_RightAnswer": "trænsfɔ́rmər mɒ́dəlz",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "trænsfɔ́rmər mɒ́dəlz ɑr ədvǽnst məʃíjn lɜ́rnɪŋ strʌ́ktʃərz ðət əfɛ́ktɪvlij ǽnəlàjz síjkwənsɪz—sʌtʃ æz wɜ́rdz ɪn sɛ́ntənsɪz, ɔr tówkənz əv tɛ́kst—baj lʊ́kɪŋ æt ɔl ðə píjsɪz sàjməltéjnijəslij. ʌ̀nlájk ówldər mɛ́θədz (lájk rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks) ðət prɒ́sɛs síjkwənsɪz stɛ́p-baj-stɛ́p, trænsfɔ́rmərz juwz ə tɛkníjk kɔ́ld 'ətɛ́nʃən' tə wéj ðə ɪmpɔ́rtəns əv dɪ́fərənt wɜ́rdz ənd ðɛər rəléjʃənʃɪ̀ps. ðɪs ɪnəvéjʃən méjks ðɛm ɛ́ksələnt æt ʌ̀ndərstǽndɪŋ kɒ́ntɛkst, kǽptʃərɪŋ sʌ́təl njúwɑnsᵻz, ənd páwərɪŋ kʌ́tɪŋ-ɛ́dʒ lǽŋɡwədʒ túwlz lájk tʃæt ənd ɡúwɡəl'z BERT."
    },
    {
        "Question": "In machine learning, which technique helps neural networks selectively focus on specific parts of the incoming data, similar to how we naturally tune into what matters most?",
        "RightAnswer": "Attention Mechanism",
        "WrongAnswers": [
            "Gradient Descent",
            "Batch Normalization",
            "Dropout Technique",
            "Data Augmentation",
            "Random Forest Method"
        ],
        "Explanation": "An attention mechanism in machine learning allows neural networks to dynamically highlight and give importance to the most relevant parts of data—much like how we naturally pay more attention to important details and ignore distractions. This helps the model perform better especially on tasks like language translation, text summarization, or image captioning, because it can intelligently identify what's important in the data rather than treating all inputs equally.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ tɛkníjk hɛ́lps nʊ́rəl nɛ́twɜ̀rks səlɛ́ktɪvlij fówkəs ɒn spəsɪ́fɪk pɑ́rts əv ðə ɪ́nkʌ̀mɪŋ déjtə, sɪ́mɪlər tə háw wij nǽtʃərəlij túwn ɪntə wɒt mǽtərz mówst?",
        "trans_RightAnswer": "ətɛ́nʃən mɛ́kənɪzəm",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "drɒ́pàwt tɛkníjk",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "rǽndəm fɔ́rəst mɛ́θəd"
        ],
        "trans_Explanation": "ən ətɛ́nʃən mɛ́kənɪzəm ɪn məʃíjn lɜ́rnɪŋ əláwz nʊ́rəl nɛ́twɜ̀rks tə dajnǽmɪklìj hájlàjt ənd ɡɪ́v ɪmpɔ́rtəns tə ðə mówst rɛ́ləvənt pɑ́rts əv déjtə—mʌtʃ lájk háw wij nǽtʃərəlij péj mɔr ətɛ́nʃən tə ɪmpɔ́rtənt díjtejlz ənd ɪ̀ɡnɔ́r dɪstrǽkʃənz. ðɪs hɛ́lps ðə mɒ́dəl pərfɔ́rm bɛ́tər əspɛ́ʃəlij ɒn tǽsks lájk lǽŋɡwədʒ trænsléjʃən, tɛ́kst sʌ̀mərɪzéjʃən, ɔr ɪ́mɪdʒ kǽpʃənɪŋ, bəkɒ́z ɪt kən ɪntɛ́lɪdʒəntlij ajdɛ́ntɪfàj wɒt's ɪmpɔ́rtənt ɪn ðə déjtə rǽðər ðʌn tríjtɪŋ ɔl ɪ́npʊ̀ts íjkwəlij."
    },
    {
        "Question": "In machine learning, especially in modern language models, there's a powerful mechanism that allows a model to consider the importance of each part of a sequence relative to the others, helping it better understand context and relationships. What's this mechanism called?",
        "RightAnswer": "Self-Attention",
        "WrongAnswers": [
            "Backpropagation",
            "Gradient Descent",
            "Dropout",
            "Convolution",
            "Batch Normalization"
        ],
        "Explanation": "Imagine reading a sentence where to fully grasp the meaning of a word, you need to look back or ahead to other words for context (like knowing what 'it' refers to). Self-Attention is how a machine learning model imitates this process—it allows the model to determine how important different words (or elements) are relative to each other when making sense of data. This helps models like Transformers excel at tasks involving context understanding, translation, summarization, and more.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij ɪn mɒ́dərn lǽŋɡwədʒ mɒ́dəlz, ðɛər'z ə páwərfəl mɛ́kənɪzəm ðət əláwz ə mɒ́dəl tə kənsɪ́dər ðə ɪmpɔ́rtəns əv ijtʃ pɑ́rt əv ə síjkwəns rɛ́lətɪv tə ðə ʌ́ðərz, hɛ́lpɪŋ ɪt bɛ́tər ʌ̀ndərstǽnd kɒ́ntɛkst ənd rəléjʃənʃɪ̀ps. wɒt's ðɪs mɛ́kənɪzəm kɔ́ld?",
        "trans_RightAnswer": "sɛ́lf-ətɛ́nʃən",
        "trans_WrongAnswers": [
            "bǽkprəpəgéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "drɒ́pàwt",
            "kɒ́nvəlùwʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən"
        ],
        "trans_Explanation": "ɪmǽdʒɪn ríjdɪŋ ə sɛ́ntəns wɛ́ər tə fʊ́lij ɡrǽsp ðə míjnɪŋ əv ə wɜ́rd, juw níjd tə lʊ́k bǽk ɔr əhɛ́d tə ʌ́ðər wɜ́rdz fɔr kɒ́ntɛkst (lájk nówɪŋ wɒt 'ɪt' rəfɜ́rz tə). sɛ́lf-ətɛ́nʃən ɪz háw ə məʃíjn lɜ́rnɪŋ mɒ́dəl ɪ́mɪtèjts ðɪs prɒ́sɛs—ɪt əláwz ðə mɒ́dəl tə dətɜ́rmɪn háw ɪmpɔ́rtənt dɪ́fərənt wɜ́rdz (ɔr ɛ́ləmənts) ɑr rɛ́lətɪv tə ijtʃ ʌ́ðər wɛ́n méjkɪŋ sɛ́ns əv déjtə. ðɪs hɛ́lps mɒ́dəlz lájk trænsfɔ́rmərz əksɛ́l æt tǽsks ɪnvɒ́lvɪŋ kɒ́ntɛkst ʌ̀ndərstǽndɪŋ, trænsléjʃən, sʌ̀mərɪzéjʃən, ənd mɔr."
    },
    {
        "Question": "In machine learning, when you're teaching a model to transform a sentence from one language to another, there's a common architecture that processes and understands a sentence, then recreates it accurately in a different language. What do we call this special architecture?",
        "RightAnswer": "Encoder-Decoder",
        "WrongAnswers": [
            "Classifier-Normalizer",
            "Transformer-Regressor",
            "Predictor-Analyzer",
            "Mapper-Reducer",
            "Clusterer-Ensembler"
        ],
        "Explanation": "An Encoder-Decoder is a machine learning architecture commonly used for tasks like language translation. Think of it as a two-step translator: first, the encoder makes sense of the input (for example, understanding the meaning of a sentence), then the decoder reconstructs that meaning into a new output (for example, the same sentence translated into another language). It's like having a skilled interpreter who first carefully listens, understands, and then clearly conveys the intended message in a new language.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n júwr tíjtʃɪŋ ə mɒ́dəl tə trǽnsfɔrm ə sɛ́ntəns frəm wʌ́n lǽŋɡwədʒ tə ənʌ́ðər, ðɛər'z ə kɒ́mən ɑ́rkɪtɛ̀ktʃər ðət prɒ́sɛsɪz ənd ʌ̀ndərstǽndz ə sɛ́ntəns, ðɛn rɛ́krijèjts ɪt ǽkjərətlij ɪn ə dɪ́fərənt lǽŋɡwədʒ. wɒt dúw wij kɔ́l ðɪs spɛ́ʃəl ɑ́rkɪtɛ̀ktʃər?",
        "trans_RightAnswer": "ənkówdər-dəkówdər",
        "trans_WrongAnswers": [
            "klǽsɪfajər-nɔ́rməlajzər",
            "trænsfɔ́rmər-rɪɡrɛ́sər",
            "prədɪ́ktər-ǽnəlàjzər",
            "mǽpər-rɪdúwsər",
            "klʌ́stərər-ɛnsɛ́mblər"
        ],
        "trans_Explanation": "ən ənkówdər-dəkówdər ɪz ə məʃíjn lɜ́rnɪŋ ɑ́rkɪtɛ̀ktʃər kɒ́mənlij júwzd fɔr tǽsks lájk lǽŋɡwədʒ trænsléjʃən. θɪ́ŋk əv ɪt æz ə túw-stɛ́p trænsléjtər: fɜ́rst, ðə ənkówdər méjks sɛ́ns əv ðə ɪ́npʊ̀t (fɔr əɡzǽmpəl, ʌ̀ndərstǽndɪŋ ðə míjnɪŋ əv ə sɛ́ntəns), ðɛn ðə dəkówdər rìjkənstrʌ́kts ðət míjnɪŋ ɪntə ə núw áwtpʊ̀t (fɔr əɡzǽmpəl, ðə séjm sɛ́ntəns trænsléjtɪd ɪntə ənʌ́ðər lǽŋɡwədʒ). ɪt's lájk hǽvɪŋ ə skɪ́ld ɪntɜ́rprətər huw fɜ́rst kɛ́ərfəlij lɪ́sənz, ʌ̀ndərstǽndz, ənd ðɛn klɪ́ərlij kənvéjz ðə ɪntɛ́ndɪd mɛ́sɪdʒ ɪn ə núw lǽŋɡwədʒ."
    },
    {
        "Question": "Which of the following machine learning models helps computers understand the subtle contexts and meanings in human language by analyzing words in relation to each other from both left and right directions?",
        "RightAnswer": "BERT",
        "WrongAnswers": [
            "GPT-2",
            "TransformerXL",
            "FastText",
            "Word2Vec",
            "ELMo"
        ],
        "Explanation": "BERT (Bidirectional Encoder Representations from Transformers) is a powerful language model introduced by Google that helps computers grasp the nuances in human language by analyzing both the words before and after any given word. Unlike earlier models that could mainly read and understand text in just one direction, BERT is designed to consider surrounding context from both sides simultaneously, making it especially effective at tasks such as sentiment analysis, question-answering, and conversational AI.",
        "trans_Question": "wɪ́tʃ əv ðə fɒ́lowɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz hɛ́lps kəmpjúwtərz ʌ̀ndərstǽnd ðə sʌ́təl kɒ́ntɛ̀ksts ənd míjnɪŋz ɪn hjúwmən lǽŋɡwədʒ baj ǽnəlàjzɪŋ wɜ́rdz ɪn rəléjʃən tə ijtʃ ʌ́ðər frəm bówθ lɛ́ft ənd rájt dɪərɛ́kʃənz?",
        "trans_RightAnswer": "BERT",
        "trans_WrongAnswers": [
            "GPT-2",
            "trænsfɔ́rmər",
            "fǽsttɛ́kst",
            "wɜ́rrdtuwvɛk",
            "ɛ́lmow"
        ],
        "trans_Explanation": "BERT (bàjdɪərékʃənəl ənkówdər rɛ̀prəzəntéjʃənz frəm trænsfɔ́rmərz) ɪz ə páwərfəl lǽŋɡwədʒ mɒ́dəl ɪntrədúwst baj ɡúwɡəl ðət hɛ́lps kəmpjúwtərz ɡrǽsp ðə njúwɑnsᵻz ɪn hjúwmən lǽŋɡwədʒ baj ǽnəlàjzɪŋ bówθ ðə wɜ́rdz bəfɔ́r ənd ǽftər ɛ́nij ɡɪ́vən wɜ́rd. ʌ̀nlájk ɜ́rlijər mɒ́dəlz ðət kʊ́d méjnlij rɛ́d ənd ʌ̀ndərstǽnd tɛ́kst ɪn dʒəst wʌ́n dɪərɛ́kʃən, BERT ɪz dəzájnd tə kənsɪ́dər səráwndɪŋ kɒ́ntɛkst frəm bówθ sájdz sàjməltéjnijəslij, méjkɪŋ ɪt əspɛ́ʃəlij əféktɪv æt tǽsks sʌtʃ æz sɛ́ntɪmənt ənǽlɪsɪs, kwɛ́stʃən-ǽnsərɪŋ, ənd kɒ̀nvərséjʃənəl AI."
    },
    {
        "Question": "Which of the following refers to a widely-known AI model designed to produce human-like text, often used in chatbots and creative writing?",
        "RightAnswer": "GPT",
        "WrongAnswers": [
            "GAN",
            "CNN",
            "RNN",
            "SVM",
            "KNN"
        ],
        "Explanation": "GPT stands for 'Generative Pre-trained Transformer' and is a type of AI model capable of creating remarkably realistic text. GPT models like ChatGPT can answer questions, hold engaging conversations, and help with tasks like writing emails, poetry, or even stories. They're trained on vast amounts of text, enabling them to understand and produce language almost as naturally as a human would.",
        "trans_Question": "wɪ́tʃ əv ðə fɒ́lowɪŋ rəfɜ́rz tə ə wájdlij-nówn AI mɒ́dəl dəzájnd tə prədúws hjúwmən-lájk tɛ́kst, ɔ́fən júwzd ɪn tʃǽtbɔts ənd krijéjtɪv rájtɪŋ?",
        "trans_RightAnswer": "GPT",
        "trans_WrongAnswers": [
            "GAN",
            "CNN",
            "RNN",
            "SVM",
            "KNN"
        ],
        "trans_Explanation": "GPT stǽndz fɔr 'dʒɛ́nərətɪv príj-tréjnd trænsfɔ́rmər' ənd ɪz ə tájp əv AI mɒ́dəl kéjpəbəl əv krijéjtɪŋ rəmɑ́rkəblij rìjəlɪ́stɪk tɛ́kst. GPT mɒ́dəlz lájk tʃæt kən ǽnsər kwɛ́stʃənz, hówld ənɡéjdʒɪŋ kɒ̀nvərséjʃənz, ənd hɛ́lp wɪð tǽsks lájk rájtɪŋ íjmejlz, pówətrij, ɔr íjvən stɔ́rijz. ðɛ́ər tréjnd ɒn vǽst əmáwnts əv tɛ́kst, ɛnéjbəlɪŋ ðɛm tə ʌ̀ndərstǽnd ənd prədúws lǽŋɡwədʒ ɔ́lmowst æz nǽtʃərəlij æz ə hjúwmən wʊd."
    },
    {
        "Question": "In machine learning, when translating sentences from one language to another, what technique allows the model to take in a sequence (such as a sentence in English) and output another sequence (like the same sentence translated into French)?",
        "RightAnswer": "Sequence-to-Sequence",
        "WrongAnswers": [
            "Supervised Classification",
            "Clustering",
            "Dimensionality Reduction",
            "Generative Adversarial Network",
            "Regression Analysis"
        ],
        "Explanation": "Sequence-to-Sequence (often abbreviated as Seq2Seq) is a special type of machine learning model designed for tasks that involve converting one sequence into another, such as translating sentences, summarizing text, or responding to questions. It takes a series of inputs—like words in a sentence—and produces another sequence, reflecting meaning, order, and relevance, making it a great choice for language translation and conversational AI applications.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n trǽnslèjtɪŋ sɛ́ntənsɪz frəm wʌ́n lǽŋɡwədʒ tə ənʌ́ðər, wɒt tɛkníjk əláwz ðə mɒ́dəl tə téjk ɪn ə síjkwəns (sʌtʃ æz ə sɛ́ntəns ɪn ɪ́ŋɡlɪʃ) ənd áwtpʊ̀t ənʌ́ðər síjkwəns (lájk ðə séjm sɛ́ntəns trænsléjtɪd ɪntə frɛ́ntʃ)?",
        "trans_RightAnswer": "síjkwəns-tə-síjkwəns",
        "trans_WrongAnswers": [
            "súwpərvàjzd klæ̀sɪfɪkéjʃən",
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rk",
            "rəɡrɛ́ʃən ənǽlɪsɪs"
        ],
        "trans_Explanation": "síjkwəns-tə-síjkwəns (ɔ́fən əbríjvijèjtɪd æz sijk) ɪz ə spɛ́ʃəl tájp əv məʃíjn lɜ́rnɪŋ mɒ́dəl dəzájnd fɔr tǽsks ðət ɪnvɒ́lv kənvɜ́rtɪŋ wʌ́n síjkwəns ɪntə ənʌ́ðər, sʌtʃ æz trǽnslèjtɪŋ sɛ́ntənsɪz, sʌ́məràjzɪŋ tɛ́kst, ɔr rəspɒ́ndɪŋ tə kwɛ́stʃənz. ɪt téjks ə sɪ́ərijz əv ɪ́npʊ̀ts—lájk wɜ́rdz ɪn ə sɛ́ntəns—ənd prədúwsɪz ənʌ́ðər síjkwəns, rəflɛ́ktɪŋ míjnɪŋ, ɔ́rdər, ənd rɛ́ləvəns, méjkɪŋ ɪt ə ɡréjt tʃɔ́js fɔr lǽŋɡwədʒ trænsléjʃən ənd kɒ̀nvərséjʃənəl AI æ̀plɪkéjʃənz."
    },
    {
        "Question": "What do we call the machine learning technique that predicts the next word in a sequence of text, helping AI systems generate natural-sounding sentences and paragraphs?",
        "RightAnswer": "Language Modeling",
        "WrongAnswers": [
            "Text Classification",
            "Sentiment Analysis",
            "Speech Recognition",
            "Topic Modeling",
            "Named Entity Recognition"
        ],
        "Explanation": "Language modeling is a machine learning approach used to teach AI systems how language works. It helps predict what word is likely to follow another word or phrase, enabling tools like chatbots, predictive text features, and automatic text generators to create natural-sounding language that makes sense to human readers.",
        "trans_Question": "wɒt dúw wij kɔ́l ðə məʃíjn lɜ́rnɪŋ tɛkníjk ðət prədɪ́kts ðə nɛ́kst wɜ́rd ɪn ə síjkwəns əv tɛ́kst, hɛ́lpɪŋ AI sɪ́stəmz dʒɛ́nərèjt nǽtʃərəl-sáwndɪŋ sɛ́ntənsɪz ənd pǽrəɡræ̀fs?",
        "trans_RightAnswer": "lǽŋɡwədʒ mɒ́dəlɪ̀ŋ",
        "trans_WrongAnswers": [
            "tɛ́kst klæ̀sɪfɪkéjʃən",
            "sɛ́ntɪmənt ənǽlɪsɪs",
            "spíjtʃ rɛ̀kəɡnɪ́ʃən",
            "tɒ́pɪk mɒ́dəlɪ̀ŋ",
            "néjmd ɛ́ntɪtij rɛ̀kəɡnɪ́ʃən"
        ],
        "trans_Explanation": "lǽŋɡwədʒ mɒ́dəlɪ̀ŋ ɪz ə məʃíjn lɜ́rnɪŋ əprówtʃ júwzd tə tíjtʃ AI sɪ́stəmz háw lǽŋɡwədʒ wɜ́rks. ɪt hɛ́lps prədɪ́kt wɒt wɜ́rd ɪz lájklij tə fɒ́low ənʌ́ðər wɜ́rd ɔr fréjz, ɛnéjbəlɪŋ túwlz lájk tʃǽtbɔts, prədɪ́ktɪv tɛ́kst fíjtʃərz, ənd ɔ̀təmǽtɪk tɛ́kst dʒɛ́nərèjtərz tə krijéjt nǽtʃərəl-sáwndɪŋ lǽŋɡwədʒ ðət méjks sɛ́ns tə hjúwmən ríjdərz."
    },
    {
        "Question": "In machine learning, there's a technique where words are represented as numeric vectors that capture their meaning, relationships, and context. For instance, this method would recognize that 'king' relates to 'queen' similarly as 'man' relates to 'woman'. What's this fascinating method called?",
        "RightAnswer": "Word Embeddings",
        "WrongAnswers": [
            "Neural Translation",
            "Topic Modeling",
            "Sentiment Analysis",
            "Supervised Classification",
            "Bayesian Networks"
        ],
        "Explanation": "Word embeddings are numeric representations of words where each word is turned into a vector—a set of numbers. These vectors capture not only the meaning of words, but also the relationships between them. For example, words like 'king' and 'queen' appear close together in vector space, allowing the model to pick up meaningful analogies. This helps machines understand context and meaning, facilitating the learning and processing of natural language—making texts more understandable to computers.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə tɛkníjk wɛ́ər wɜ́rdz ɑr rɛ̀prəzɛ́ntɪd æz njuwmɛ́ərɪk vɛ́ktərz ðət kǽptʃər ðɛər míjnɪŋ, rəléjʃənʃɪ̀ps, ənd kɒ́ntɛkst. fɔr ɪ́nstəns, ðɪs mɛ́θəd wʊd rɛ́kəɡnàjz ðət 'kɪ́ŋ' rəléjts tə 'kwíjn' sɪ́mɪlərlij æz 'mǽn' rəléjts tə 'wʊ́mən'. wɒt's ðɪs fǽsɪnèjtɪŋ mɛ́θəd kɔ́ld?",
        "trans_RightAnswer": "wɜ́rd əmbɛ́dɪŋz",
        "trans_WrongAnswers": [
            "nʊ́rəl trænsléjʃən",
            "tɒ́pɪk mɒ́dəlɪ̀ŋ",
            "sɛ́ntɪmənt ənǽlɪsɪs",
            "súwpərvàjzd klæ̀sɪfɪkéjʃən",
            "béjʒən nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "wɜ́rd əmbɛ́dɪŋz ɑr njuwmɛ́ərɪk rɛ̀prəzəntéjʃənz əv wɜ́rdz wɛ́ər ijtʃ wɜ́rd ɪz tɜ́rnd ɪntə ə vɛ́ktər—ə sɛ́t əv nʌ́mbərz. ðijz vɛ́ktərz kǽptʃər nɒt ównlij ðə míjnɪŋ əv wɜ́rdz, bʌt ɔ́lsow ðə rəléjʃənʃɪ̀ps bijtwíjn ðɛm. fɔr əɡzǽmpəl, wɜ́rdz lájk 'kɪ́ŋ' ənd 'kwíjn' əpɪ́ər klóws təɡɛ́ðər ɪn vɛ́ktər spéjs, əláwɪŋ ðə mɒ́dəl tə pɪ́k ʌp míjnɪŋfəl ənǽlədʒijz. ðɪs hɛ́lps məʃíjnz ʌ̀ndərstǽnd kɒ́ntɛkst ənd míjnɪŋ, fəsɪ́lətèjtɪŋ ðə lɜ́rnɪŋ ənd prɒ́sɛsɪŋ əv nǽtʃərəl lǽŋɡwədʒ—méjkɪŋ tɛ́ksts mɔr ʌ̀ndərstǽndəbəl tə kəmpjúwtərz."
    },
    {
        "Question": "In machine learning, what's the name of the method that transforms words into numerical vectors, capturing the meaning and relationships between different words, often used to understand context and semantics in text analysis?",
        "RightAnswer": "Word2Vec",
        "WrongAnswers": [
            "TensorFlow",
            "Random Forest",
            "Gradient Boosting",
            "K-means Clustering",
            "Support Vector Machine"
        ],
        "Explanation": "Word2Vec is a popular machine learning technique used to map words into numbers, or rather vectors, helping computers 'understand' the meaning of words based on their relationships and context. Instead of just seeing words as separate, unrelated pieces, Word2Vec learns the relationships and context, so similar or related words end up close to each other in vector space. This powerful approach improves tasks like text classification, language translation, and sentiment analysis by better capturing the meaning behind words.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt's ðə néjm əv ðə mɛ́θəd ðət trænsfɔ́rmz wɜ́rdz ɪntə njuwmɛ́ərɪkəl vɛ́ktərz, kǽptʃərɪŋ ðə míjnɪŋ ənd rəléjʃənʃɪ̀ps bijtwíjn dɪ́fərənt wɜ́rdz, ɔ́fən júwzd tə ʌ̀ndərstǽnd kɒ́ntɛkst ənd səmǽntɪks ɪn tɛ́kst ənǽlɪsɪs?",
        "trans_RightAnswer": "wɜ́rrdtuwvɛk",
        "trans_WrongAnswers": [
            "tɛ́nsɔ̀rflòw",
            "rǽndəm fɔ́rəst",
            "ɡréjdijənt búwstɪŋ",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn"
        ],
        "trans_Explanation": "wɜ́rrdtuwvɛk ɪz ə pɒ́pjələr məʃíjn lɜ́rnɪŋ tɛkníjk júwzd tə mǽp wɜ́rdz ɪntə nʌ́mbərz, ɔr rǽðər vɛ́ktərz, hɛ́lpɪŋ kəmpjúwtərz 'ʌ̀ndərstǽnd' ðə míjnɪŋ əv wɜ́rdz béjst ɒn ðɛər rəléjʃənʃɪ̀ps ənd kɒ́ntɛkst. ɪnstɛ́d əv dʒəst síjɪŋ wɜ́rdz æz sɛ́pərət, ʌ̀nrəléjtɪd píjsɪz, wɜ́rrdtuwvɛk lɜ́rnz ðə rəléjʃənʃɪ̀ps ənd kɒ́ntɛkst, sow sɪ́mɪlər ɔr rəléjtɪd wɜ́rdz ɛ́nd ʌp klóws tə ijtʃ ʌ́ðər ɪn vɛ́ktər spéjs. ðɪs páwərfəl əprówtʃ ɪmprúwvz tǽsks lájk tɛ́kst klæ̀sɪfɪkéjʃən, lǽŋɡwədʒ trænsléjʃən, ənd sɛ́ntɪmənt ənǽlɪsɪs baj bɛ́tər kǽptʃərɪŋ ðə míjnɪŋ bəhájnd wɜ́rdz."
    },
    {
        "Question": "In natural language processing, researchers often want to understand how words relate to each other by mapping them into a meaningful, numeric form. Which of these is a popular method that combines global word frequency statistics with local context clues to create helpful word representations?",
        "RightAnswer": "GloVe",
        "WrongAnswers": [
            "TensorFlow",
            "BERT",
            "Hadoop",
            "AdaBoost",
            "XGBoost"
        ],
        "Explanation": "GloVe (short for Global Vectors for Word Representation) is a clever method that turns words into numerical vectors by combining global word-count statistics with local word-context statistics. This approach helps computers better understand word meanings and relationships. It's widely used in applications like chatbots, language translation, and sentiment analysis because it captures the richness of language effectively.",
        "trans_Question": "ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ, ríjsərtʃərz ɔ́fən wɒ́nt tə ʌ̀ndərstǽnd háw wɜ́rdz rəléjt tə ijtʃ ʌ́ðər baj mǽpɪŋ ðɛm ɪntə ə míjnɪŋfəl, njuwmɛ́ərɪk fɔ́rm. wɪ́tʃ əv ðijz ɪz ə pɒ́pjələr mɛ́θəd ðət kəmbájnz ɡlówbəl wɜ́rd fríjkwənsij stətɪ́stɪks wɪð lówkəl kɒ́ntɛkst klúwz tə krijéjt hɛ́lpfəl wɜ́rd rɛ̀prəzəntéjʃənz?",
        "trans_RightAnswer": "ɡlʌ́v",
        "trans_WrongAnswers": [
            "tɛ́nsɔ̀rflòw",
            "BERT",
            "hǽdúwp",
            "ADABOOST",
            "xgboost"
        ],
        "trans_Explanation": "ɡlʌ́v (ʃɔ́rt fɔr ɡlówbəl vɛ́ktərz fɔr wɜ́rd rɛ̀prəzɛntéjʃən) ɪz ə klɛ́vər mɛ́θəd ðət tɜ́rnz wɜ́rdz ɪntə njuwmɛ́ərɪkəl vɛ́ktərz baj kəmbájnɪŋ ɡlówbəl wɜ́rd-káwnt stətɪ́stɪks wɪð lówkəl wɜ́rd-kɒ́ntɛkst stətɪ́stɪks. ðɪs əprówtʃ hɛ́lps kəmpjúwtərz bɛ́tər ʌ̀ndərstǽnd wɜ́rd míjnɪŋz ənd rəléjʃənʃɪ̀ps. ɪt's wájdlij júwzd ɪn æ̀plɪkéjʃənz lájk tʃǽtbɔts, lǽŋɡwədʒ trænsléjʃən, ənd sɛ́ntɪmənt ənǽlɪsɪs bəkɒ́z ɪt kǽptʃərz ðə rɪ́tʃnəs əv lǽŋɡwədʒ əfɛ́ktɪvlij."
    },
    {
        "Question": "Imagine you need a word embedding technique that can quickly learn representations for words, even those unseen during training, by considering small parts within the words themselves. Which approach would you choose?",
        "RightAnswer": "FastText",
        "WrongAnswers": [
            "Word2Vec",
            "BERT",
            "GloVe",
            "Transformer",
            "Doc2Vec"
        ],
        "Explanation": "FastText is a clever machine learning method developed by Facebook researchers that builds word embeddings (word meanings represented as math vectors) by breaking words into smaller chunks, known as subwords. This allows FastText to quickly and effectively handle rare words or even words it hasn't seen before by understanding their parts. It's especially good at handling noisy data, misspellings, and multiple languages.",
        "trans_Question": "ɪmǽdʒɪn juw níjd ə wɜ́rd ɛmbɛ́dɪŋ tɛkníjk ðət kən kwɪ́klij lɜ́rn rɛ̀prəzəntéjʃənz fɔr wɜ́rdz, íjvən ðowz ʌ̀nsíjn dʊ́rɪŋ tréjnɪŋ, baj kənsɪ́dərɪŋ smɔ́l pɑ́rts wɪðɪ́n ðə wɜ́rdz ðəmsɛ́lvz. wɪ́tʃ əprówtʃ wʊd juw tʃúwz?",
        "trans_RightAnswer": "fǽsttɛ́kst",
        "trans_WrongAnswers": [
            "wɜ́rrdtuwvɛk",
            "BERT",
            "ɡlʌ́v",
            "trænsfɔ́rmər",
            "dɒk"
        ],
        "trans_Explanation": "fǽsttɛ́kst ɪz ə klɛ́vər məʃíjn lɜ́rnɪŋ mɛ́θəd dəvɛ́ləpt baj féjsbʊ̀k ríjsərtʃərz ðət bɪ́ldz wɜ́rd əmbɛ́dɪŋz (wɜ́rd míjnɪŋz rɛ̀prəzɛ́ntɪd æz mǽθ vɛ́ktərz) baj bréjkɪŋ wɜ́rdz ɪntə smɔ́lər tʃʌ́ŋks, nówn æz sʌ́bwərdz. ðɪs əláwz fǽsttɛ́kst tə kwɪ́klij ənd əfɛ́ktɪvlij hǽndəl rɛ́ər wɜ́rdz ɔr íjvən wɜ́rdz ɪt hǽzənt síjn bəfɔ́r baj ʌ̀ndərstǽndɪŋ ðɛər pɑ́rts. ɪt's əspɛ́ʃəlij ɡʊ́d æt hǽndəlɪŋ nɔ́jzij déjtə, mɪsspɛ́lɪŋz, ənd mʌ́ltɪpəl lǽŋɡwədʒɪz."
    },
    {
        "Question": "In machine learning language models, which technique provides word representations that change meaning based on the specific sentences and situations around a word, rather than giving the word one fixed meaning?",
        "RightAnswer": "Contextual Embeddings",
        "WrongAnswers": [
            "Static Embeddings",
            "Bag-of-Words Model",
            "Term Frequency-Inverse Document Frequency (TF-IDF)",
            "One-Hot Encoding",
            "Lexical Dictionaries"
        ],
        "Explanation": "Contextual embeddings are special types of word representations where a word's meaning isn't fixed—it can change depending on the surrounding words and the situation it's used in. Unlike traditional methods, which assign just one meaning to each word regardless of context, contextual embeddings allow computer models to understand subtle differences and nuances in language better, making them incredibly effective for tasks like machine translation, sentiment analysis, and conversational agents.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ lǽŋɡwədʒ mɒ́dəlz, wɪ́tʃ tɛkníjk prəvájdz wɜ́rd rɛ̀prəzəntéjʃənz ðət tʃéjndʒ míjnɪŋ béjst ɒn ðə spəsɪ́fɪk sɛ́ntənsɪz ənd sɪ̀tʃuwéjʃənz əráwnd ə wɜ́rd, rǽðər ðʌn ɡɪ́vɪŋ ðə wɜ́rd wʌ́n fɪ́kst míjnɪŋ?",
        "trans_RightAnswer": "kɒ̀ntɛ́kstʃùwəl əmbɛ́dɪŋz",
        "trans_WrongAnswers": [
            "stǽtɪk əmbɛ́dɪŋz",
            "bǽɡ-əv-wɜ́rdz mɒ́dəl",
            "tɜ́rm fríjkwənsij-ɪnvɜ́rs dɒ́kjəmɛnt fríjkwənsij (TF-IDF)",
            "wʌ́n-hɒ́t ɛnkówdɪŋ",
            "lɛ́ksɪkəl dɪ́kʃənɛ̀ərijz"
        ],
        "trans_Explanation": "kɒ̀ntɛ́kstʃùwəl əmbɛ́dɪŋz ɑr spɛ́ʃəl tájps əv wɜ́rd rɛ̀prəzəntéjʃənz wɛ́ər ə wɜ́rd'z míjnɪŋ ɪzənt fɪ́kst—ɪt kən tʃéjndʒ dəpɛ́ndɪŋ ɒn ðə səráwndɪŋ wɜ́rdz ənd ðə sɪ̀tʃuwéjʃən ɪt's júwzd ɪn. ʌ̀nlájk trədɪ́ʃənəl mɛ́θədz, wɪ́tʃ əsájn dʒəst wʌ́n míjnɪŋ tə ijtʃ wɜ́rd rəɡɑ́rdləs əv kɒ́ntɛkst, kɒ̀ntɛ́kstʃùwəl əmbɛ́dɪŋz əláw kəmpjúwtər mɒ́dəlz tə ʌ̀ndərstǽnd sʌ́təl dɪ́fərənsɪz ənd njúwɑnsᵻz ɪn lǽŋɡwədʒ bɛ́tər, méjkɪŋ ðɛm ɪnkrɛ́dɪblij əféktɪv fɔr tǽsks lájk məʃíjn trænsléjʃən, sɛ́ntɪmənt ənǽlɪsɪs, ənd kɒ̀nvərséjʃənəl éjdʒənts."
    },
    {
        "Question": "Which model in machine learning uses context-sensitive embeddings to improve the understanding of how meaning changes depending on the surrounding words?",
        "RightAnswer": "ELMo",
        "WrongAnswers": [
            "GPT",
            "FastText",
            "Word2Vec",
            "BERT",
            "Transformer"
        ],
        "Explanation": "ELMo (Embeddings from Language Models) is a machine learning approach designed to capture word meanings based on the context they're used in. Think of it like giving words the flexibility to mean different things based on their surroundings, just like how humans interpret meanings from context. Unlike simple word embeddings that provide one fixed representation, ELMo adapts to context, significantly improving understanding and accuracy in language-related tasks.",
        "trans_Question": "wɪ́tʃ mɒ́dəl ɪn məʃíjn lɜ́rnɪŋ júwsɪz kɒ́ntɛkst-sɛ́nsɪtɪv əmbɛ́dɪŋz tə ɪmprúwv ðə ʌ̀ndərstǽndɪŋ əv háw míjnɪŋ tʃéjndʒɪz dəpɛ́ndɪŋ ɒn ðə səráwndɪŋ wɜ́rdz?",
        "trans_RightAnswer": "ɛ́lmow",
        "trans_WrongAnswers": [
            "GPT",
            "fǽsttɛ́kst",
            "wɜ́rrdtuwvɛk",
            "BERT",
            "trænsfɔ́rmər"
        ],
        "trans_Explanation": "ɛ́lmow (əmbɛ́dɪŋz frəm lǽŋɡwədʒ mɒ́dəlz) ɪz ə məʃíjn lɜ́rnɪŋ əprówtʃ dəzájnd tə kǽptʃər wɜ́rd míjnɪŋz béjst ɒn ðə kɒ́ntɛkst ðɛ́ər júwzd ɪn. θɪ́ŋk əv ɪt lájk ɡɪ́vɪŋ wɜ́rdz ðə flɛ̀ksɪbɪ́lɪtij tə míjn dɪ́fərənt θɪ́ŋz béjst ɒn ðɛər səráwndɪŋz, dʒəst lájk háw hjúwmənz ɪntɜ́rprət míjnɪŋz frəm kɒ́ntɛkst. ʌ̀nlájk sɪ́mpəl wɜ́rd əmbɛ́dɪŋz ðət prəvájd wʌ́n fɪ́kst rɛ̀prəzɛntéjʃən, ɛ́lmow ədǽpts tə kɒ́ntɛkst, sɪɡnɪ́fɪkəntlij ɪmprúwvɪŋ ʌ̀ndərstǽndɪŋ ənd ǽkjərəsij ɪn lǽŋɡwədʒ-rəléjtɪd tǽsks."
    },
    {
        "Question": "In natural language processing (NLP), when training language models, we often need to handle words we've never encountered before. Which tokenization method breaks down rare or unfamiliar words into smaller pieces, allowing the model to handle them effectively?",
        "RightAnswer": "Subword Tokenization",
        "WrongAnswers": [
            "Word Embedding",
            "Sentence Tokenization",
            "Stemming",
            "Bag-of-Words Vectorization",
            "Stop-word Removal"
        ],
        "Explanation": "Subword Tokenization is an approach used in natural language processing that splits rare or unknown words into meaningful smaller units, called subwords. Instead of trying to handle endless word combinations, this method allows machine learning models to make educated guesses about new words, improving their ability to understand text that they haven't explicitly seen before. Think of it as breaking down complicated words into smaller puzzle pieces—making it easier for the model to put together meaning from building blocks it already knows.",
        "trans_Question": "ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ (NLP), wɛ́n tréjnɪŋ lǽŋɡwədʒ mɒ́dəlz, wij ɔ́fən níjd tə hǽndəl wɜ́rdz wíjv nɛ́vər ənkáwntərd bəfɔ́r. wɪ́tʃ tòwkənəzéjʃən mɛ́θəd bréjks dawn rɛ́ər ɔr ʌ̀nfəmɪ́ljər wɜ́rdz ɪntə smɔ́lər píjsɪz, əláwɪŋ ðə mɒ́dəl tə hǽndəl ðɛm əfɛ́ktɪvlij?",
        "trans_RightAnswer": "sʌ́bwərd tòwkənəzéjʃən",
        "trans_WrongAnswers": [
            "wɜ́rd ɛmbɛ́dɪŋ",
            "sɛ́ntəns tòwkənəzéjʃən",
            "stɛ́mɪŋ",
            "bǽɡ-əv-wɜ́rdz vɛ̀ktərɪzéjʃən",
            "stɒ́p-wɜ́rd rəmúwvəl"
        ],
        "trans_Explanation": "sʌ́bwərd tòwkənəzéjʃən ɪz ən əprówtʃ júwzd ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ ðət splɪ́ts rɛ́ər ɔr ʌ̀nnówn wɜ́rdz ɪntə míjnɪŋfəl smɔ́lər júwnɪts, kɔ́ld sʌ́bwərdz. ɪnstɛ́d əv trájɪŋ tə hǽndəl ɛ́ndləs wɜ́rd kɒ̀mbɪnéjʃənz, ðɪs mɛ́θəd əláwz məʃíjn lɜ́rnɪŋ mɒ́dəlz tə méjk ɛ́dʒəkèjtɪd ɡɛ́sɪz əbawt núw wɜ́rdz, ɪmprúwvɪŋ ðɛər əbɪ́lɪtij tə ʌ̀ndərstǽnd tɛ́kst ðət ðej hǽvən əksplɪ́sɪtlij síjn bəfɔ́r. θɪ́ŋk əv ɪt æz bréjkɪŋ dawn kɒ́mplɪkèjtɪd wɜ́rdz ɪntə smɔ́lər pʌ́zəl píjsɪz—méjkɪŋ ɪt íjzijər fɔr ðə mɒ́dəl tə pʊ́t təɡɛ́ðər míjnɪŋ frəm bɪ́ldɪŋ blɒ́ks ɪt ɔ̀lrɛ́dij nówz."
    },
    {
        "Question": "Which technique is widely used in modern NLP to turn complex words into smaller, reusable pieces, helping language models manage large vocabularies efficiently?",
        "RightAnswer": "Byte Pair Encoding",
        "WrongAnswers": [
            "Gradient Boosting",
            "Dropout Regularization",
            "Principal Component Analysis",
            "Transfer Learning",
            "Attention Mechanism"
        ],
        "Explanation": "Byte Pair Encoding is a clever way to simplify complex words for machine learning models. It breaks down words into smaller, frequently-occurring chunks, allowing the model to handle vast vocabularies with fewer tokens. Imagine instead of memorizing every word individually, the model combines smaller pieces (like 'learn' + 'ing' or 'train' + 'er')—making it efficient, adaptive, and better at handling new words.",
        "trans_Question": "wɪ́tʃ tɛkníjk ɪz wájdlij júwzd ɪn mɒ́dərn NLP tə tɜ́rn kɒ́mplɛks wɜ́rdz ɪntə smɔ́lər, rijúwzəbəl píjsɪz, hɛ́lpɪŋ lǽŋɡwədʒ mɒ́dəlz mǽnɪdʒ lɑ́rdʒ vowkǽbjələrijz əfɪ́ʃəntlij?",
        "trans_RightAnswer": "bájt pɛ́ər ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "trǽnsfər lɜ́rnɪŋ",
            "ətɛ́nʃən mɛ́kənɪzəm"
        ],
        "trans_Explanation": "bájt pɛ́ər ɛnkówdɪŋ ɪz ə klɛ́vər wej tə sɪ́mpləfaj kɒ́mplɛks wɜ́rdz fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz. ɪt bréjks dawn wɜ́rdz ɪntə smɔ́lər, fríjkwəntlij-əkɜ́rɪŋ tʃʌ́ŋks, əláwɪŋ ðə mɒ́dəl tə hǽndəl vǽst vowkǽbjələrijz wɪð fjúwər tówkənz. ɪmǽdʒɪn ɪnstɛ́d əv mɛ́məràjzɪŋ ɛvərij wɜ́rd ɪndɪvɪ́dʒəlij, ðə mɒ́dəl kəmbájnz smɔ́lər píjsɪz (lájk 'lɜ́rn' + 'ɪ́ŋ' ɔr 'tréjn' + 'ər')—méjkɪŋ ɪt əfɪ́ʃənt, ədǽptɪv, ənd bɛ́tər æt hǽndəlɪŋ núw wɜ́rdz."
    },
    {
        "Question": "In machine learning, which technique helps you represent entire sentences as numerical vectors, making it easier for computers to understand the meaning and relationships of sentences?",
        "RightAnswer": "Sentence Embeddings",
        "WrongAnswers": [
            "Gradient Descent",
            "Data Normalization",
            "Regularization",
            "Tokenization",
            "One-hot Encoding"
        ],
        "Explanation": "Sentence embeddings are numerical representations that capture the meaning of whole sentences in vector form, allowing computers to understand and compare sentences based on their semantic content. These embeddings help tasks like comparing sentence similarity, sentiment analysis, or searching through text effectively.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ tɛkníjk hɛ́lps juw rɛ̀prəzɛ́nt əntájər sɛ́ntənsɪz æz njuwmɛ́ərɪkəl vɛ́ktərz, méjkɪŋ ɪt íjzijər fɔr kəmpjúwtərz tə ʌ̀ndərstǽnd ðə míjnɪŋ ənd rəléjʃənʃɪ̀ps əv sɛ́ntənsɪz?",
        "trans_RightAnswer": "sɛ́ntəns əmbɛ́dɪŋz",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "déjtə nɔ̀rməlɪzéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "tòwkənəzéjʃən",
            "wʌ́n-hɒ́t ɛnkówdɪŋ"
        ],
        "trans_Explanation": "sɛ́ntəns əmbɛ́dɪŋz ɑr njuwmɛ́ərɪkəl rɛ̀prəzəntéjʃənz ðət kǽptʃər ðə míjnɪŋ əv hówl sɛ́ntənsɪz ɪn vɛ́ktər fɔ́rm, əláwɪŋ kəmpjúwtərz tə ʌ̀ndərstǽnd ənd kəmpɛ́ər sɛ́ntənsɪz béjst ɒn ðɛər səmǽntɪk kɒ́ntənt. ðijz əmbɛ́dɪŋz hɛ́lp tǽsks lájk kəmpɛ́ərɪŋ sɛ́ntəns sɪ̀mɪlɛ́ərɪtij, sɛ́ntɪmənt ənǽlɪsɪs, ɔr sɜ́rtʃɪŋ θrúw tɛ́kst əfɛ́ktɪvlij."
    },
    {
        "Question": "Imagine you're building a machine learning app to automatically sort through thousands of articles and find the most relevant ones based on certain keywords. Which of the following techniques could you use to measure how important specific words are in each article compared to their overall presence in all articles?",
        "RightAnswer": "TF-IDF",
        "WrongAnswers": [
            "Gradient Boosting",
            "Activation Function",
            "K-Means Clustering",
            "Feature Scaling",
            "Gradient Descent"
        ],
        "Explanation": "Think of TF-IDF (Term Frequency-Inverse Document Frequency) as a smart way to weigh the importance of words in documents. It boosts words that are common in a specific document but rare across all other documents. For example, if the word 'astronomy' appears often in a certain article but is rarely used elsewhere, TF-IDF signals that 'astronomy' is probably very important to that article's topic.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ ǽp tə ɔ̀təmǽtɪklij sɔ́rt θrúw θáwzəndz əv ɑ́rtɪkəlz ənd fájnd ðə mówst rɛ́ləvənt wʌ́nz béjst ɒn sɜ́rtən kíjwɜ̀rdz. wɪ́tʃ əv ðə fɒ́lowɪŋ tɛkníjks kʊ́d juw juwz tə mɛ́ʒər háw ɪmpɔ́rtənt spəsɪ́fɪk wɜ́rdz ɑr ɪn ijtʃ ɑ́rtɪkəl kəmpɛ́ərd tə ðɛər ówvərɔ̀l prɛ́zəns ɪn ɔl ɑ́rtɪkəlz?",
        "trans_RightAnswer": "TF-IDF",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "k-míjnz klʌ́stərɪŋ",
            "fíjtʃər skéjlɪŋ",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "θɪ́ŋk əv TF-IDF (tɜ́rm fríjkwənsij-ɪnvɜ́rs dɒ́kjəmɛnt fríjkwənsij) æz ə smɑ́rt wej tə wéj ðə ɪmpɔ́rtəns əv wɜ́rdz ɪn dɒ́kjəmənts. ɪt búwsts wɜ́rdz ðət ɑr kɒ́mən ɪn ə spəsɪ́fɪk dɒ́kjəmɛnt bʌt rɛ́ər əkrɔ́s ɔl ʌ́ðər dɒ́kjəmənts. fɔr əɡzǽmpəl, ɪf ðə wɜ́rd 'əstrɒ́nəmij' əpɪ́ərz ɔ́fən ɪn ə sɜ́rtən ɑ́rtɪkəl bʌt ɪz rɛ́ərlij júwzd ɛ́lswɛ̀ər, TF-IDF sɪ́ɡnəlz ðət 'əstrɒ́nəmij' ɪz prɒ́bəblìj vɛ́ərij ɪmpɔ́rtənt tə ðət ɑ́rtɪkəl'z tɒ́pɪk."
    },
    {
        "Question": "Imagine you're teaching your computer how to understand text by simply counting how many times each word appears, without worrying about their order or relationships. What is this straightforward approach called in machine learning?",
        "RightAnswer": "Bag-of-Words",
        "WrongAnswers": [
            "Word Embedding",
            "Decision Tree",
            "Neural Network",
            "Sentiment Analysis",
            "Topic Modeling"
        ],
        "Explanation": "The 'Bag-of-Words' approach is exactly what it sounds like: you toss all the words from your text into an imaginary bag, ignoring the order and relationships between them. Then, you simply count how often each word appears. It's a quick and simple way to represent text data numerically for machine learning tasks, like figuring out if an email is spam or categorizing news articles.",
        "trans_Question": "ɪmǽdʒɪn júwr tíjtʃɪŋ jɔr kəmpjúwtər háw tə ʌ̀ndərstǽnd tɛ́kst baj sɪ́mplij káwntɪŋ háw mɛ́nij tájmz ijtʃ wɜ́rd əpɪ́ərz, wɪðáwt wɜ́rijɪŋ əbawt ðɛər ɔ́rdər ɔr rəléjʃənʃɪ̀ps. wɒt ɪz ðɪs stréjtfɔ́rwərd əprówtʃ kɔ́ld ɪn məʃíjn lɜ́rnɪŋ?",
        "trans_RightAnswer": "bǽɡ-əv-wɜ́rdz",
        "trans_WrongAnswers": [
            "wɜ́rd ɛmbɛ́dɪŋ",
            "dəsɪ́ʒən tríj",
            "nʊ́rəl nɛ́twɜ̀rk",
            "sɛ́ntɪmənt ənǽlɪsɪs",
            "tɒ́pɪk mɒ́dəlɪ̀ŋ"
        ],
        "trans_Explanation": "ðə 'bǽɡ-əv-wɜ́rdz' əprówtʃ ɪz əɡzǽktlij wɒt ɪt sáwndz lájk: juw tɔ́s ɔl ðə wɜ́rdz frəm jɔr tɛ́kst ɪntə ən ɪmǽdʒɪnɛ̀ərij bǽɡ, ɪ̀ɡnɔ́rɪŋ ðə ɔ́rdər ənd rəléjʃənʃɪ̀ps bijtwíjn ðɛm. ðɛn, juw sɪ́mplij káwnt háw ɔ́fən ijtʃ wɜ́rd əpɪ́ərz. ɪt's ə kwɪ́k ənd sɪ́mpəl wej tə rɛ̀prəzɛ́nt tɛ́kst déjtə njuwmɛ́ərɪklij fɔr məʃíjn lɜ́rnɪŋ tǽsks, lájk fɪ́ɡjərɪŋ awt ɪf ən íjmejl ɪz spǽm ɔr kǽtəɡəràjzɪŋ nuws ɑ́rtɪkəlz."
    },
    {
        "Question": "When analyzing text data in machine learning, which term describes groups of words or characters that occur sequentially, helping the model understand context and patterns?",
        "RightAnswer": "N-grams",
        "WrongAnswers": [
            "Activation functions",
            "Decision boundaries",
            "Gradient descent",
            "Overfitting",
            "Dimensionality reduction"
        ],
        "Explanation": "N-grams are sequential groupings of words or characters used in machine learning to capture context and patterns in text data. By looking at combinations like pairs (bigrams) or triples (trigrams) of consecutive words or characters, models can better understand meaning and relationships within language. This helps improve text-based tasks like spell-checking, next-word prediction, and text classification.",
        "trans_Question": "wɛ́n ǽnəlàjzɪŋ tɛ́kst déjtə ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ tɜ́rm dəskrájbz ɡrúwps əv wɜ́rdz ɔr kǽrəktərz ðət əkɜ́r səkwɛ́nʃəlij, hɛ́lpɪŋ ðə mɒ́dəl ʌ̀ndərstǽnd kɒ́ntɛkst ənd pǽtərnz?",
        "trans_RightAnswer": "n-ɡrǽmz",
        "trans_WrongAnswers": [
            "æ̀ktɪvéjʃən fʌ́ŋkʃənz",
            "dəsɪ́ʒən báwndərijz",
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "n-ɡrǽmz ɑr səkwɛ́nʃəl ɡrúwpɪŋz əv wɜ́rdz ɔr kǽrəktərz júwzd ɪn məʃíjn lɜ́rnɪŋ tə kǽptʃər kɒ́ntɛkst ənd pǽtərnz ɪn tɛ́kst déjtə. baj lʊ́kɪŋ æt kɒ̀mbɪnéjʃənz lájk pɛ́ərz (bɪ́ɡræmz) ɔr trɪ́pəlz (trɪ́ɡræmz) əv kənsɛ́kjətɪv wɜ́rdz ɔr kǽrəktərz, mɒ́dəlz kən bɛ́tər ʌ̀ndərstǽnd míjnɪŋ ənd rəléjʃənʃɪ̀ps wɪðɪ́n lǽŋɡwədʒ. ðɪs hɛ́lps ɪmprúwv tɛ́kst-béjst tǽsks lájk spɛ́l-tʃɛ́kɪŋ, nɛ́kst-wɜ́rd prədɪ́kʃən, ənd tɛ́kst klæ̀sɪfɪkéjʃən."
    },
    {
        "Question": "You're building a system that automatically sorts emails into categories like 'work', 'spam', 'promotions', and 'personal'. Which machine learning task describes what you’re performing?",
        "RightAnswer": "Text Classification",
        "WrongAnswers": [
            "Image Recognition",
            "Sentiment Analysis",
            "Data Clustering",
            "Speech Recognition",
            "Reinforcement Learning"
        ],
        "Explanation": "Text Classification is a machine learning method where the program assigns labels or categories to text (like emails). It's like having a helpful assistant that quickly sorts through emails, posts, or documents and neatly places them into the right folders or categories for you.",
        "trans_Question": "júwr bɪ́ldɪŋ ə sɪ́stəm ðət ɔ̀təmǽtɪklij sɔ́rts íjmejlz ɪntə kǽtəɡɔ̀rijz lájk 'wɜ́rk', 'spǽm', 'prəmówʃənz', ənd 'pɜ́rsənəl'. wɪ́tʃ məʃíjn lɜ́rnɪŋ tǽsk dəskrájbz wɒt jʊr pərfɔ́rmɪŋ?",
        "trans_RightAnswer": "tɛ́kst klæ̀sɪfɪkéjʃən",
        "trans_WrongAnswers": [
            "ɪ́mɪdʒ rɛ̀kəɡnɪ́ʃən",
            "sɛ́ntɪmənt ənǽlɪsɪs",
            "déjtə klʌ́stərɪŋ",
            "spíjtʃ rɛ̀kəɡnɪ́ʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "tɛ́kst klæ̀sɪfɪkéjʃən ɪz ə məʃíjn lɜ́rnɪŋ mɛ́θəd wɛ́ər ðə prówɡræ̀m əsájnz léjbəlz ɔr kǽtəɡɔ̀rijz tə tɛ́kst (lájk íjmejlz). ɪt's lájk hǽvɪŋ ə hɛ́lpfəl əsɪ́stənt ðət kwɪ́klij sɔ́rts θrúw íjmejlz, pówsts, ɔr dɒ́kjəmənts ənd níjtlij pléjsɪz ðɛm ɪntə ðə rájt fówldərz ɔr kǽtəɡɔ̀rijz fɔr juw."
    },
    {
        "Question": "You have a huge set of documents (like thousands of online reviews or blog posts) and you want to uncover the main themes or topics that surface naturally from the text. Which machine learning technique is specifically designed to automatically identify these underlying themes?",
        "RightAnswer": "Topic Modeling",
        "WrongAnswers": [
            "Sentiment Analysis",
            "Clustering",
            "Classification",
            "Regression Analysis",
            "Anomaly Detection"
        ],
        "Explanation": "Topic Modeling is a type of machine learning method designed specifically to discover hidden themes or topics in large collections of text documents. Imagine it as a detective exploring thousands of texts and automatically grouping words that frequently appear together to uncover themes, like 'sports', 'food', or 'politics'. It's a great way to quickly understand and organize vast amounts of textual information without manually combing through each document.",
        "trans_Question": "juw həv ə hjúwdʒ sɛ́t əv dɒ́kjəmənts (lájk θáwzəndz əv ɔ́nlàjn rəvjúwz ɔr blɔ́ɡ pówsts) ənd juw wɒ́nt tə ʌ̀nkʌ́vər ðə méjn θíjmz ɔr tɒ́pɪks ðət sɜ́rfəs nǽtʃərəlij frəm ðə tɛ́kst. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪz spəsɪ́fɪklij dəzájnd tə ɔ̀təmǽtɪklij ajdɛ́ntɪfàj ðijz ʌ̀ndərlájɪŋ θíjmz?",
        "trans_RightAnswer": "tɒ́pɪk mɒ́dəlɪ̀ŋ",
        "trans_WrongAnswers": [
            "sɛ́ntɪmənt ənǽlɪsɪs",
            "klʌ́stərɪŋ",
            "klæ̀sɪfɪkéjʃən",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "ənɒ́məlij dətɛ́kʃən"
        ],
        "trans_Explanation": "tɒ́pɪk mɒ́dəlɪ̀ŋ ɪz ə tájp əv məʃíjn lɜ́rnɪŋ mɛ́θəd dəzájnd spəsɪ́fɪklij tə dɪskʌ́vər hɪ́dən θíjmz ɔr tɒ́pɪks ɪn lɑ́rdʒ kəlɛ́kʃənz əv tɛ́kst dɒ́kjəmənts. ɪmǽdʒɪn ɪt æz ə dətɛ́ktɪv əksplɔ́rɪŋ θáwzəndz əv tɛ́ksts ənd ɔ̀təmǽtɪklij ɡrúwpɪŋ wɜ́rdz ðət fríjkwəntlij əpɪ́ər təɡɛ́ðər tə ʌ̀nkʌ́vər θíjmz, lájk 'spɔ́rts', 'fúwd', ɔr 'pɒ́lɪtɪ̀ks'. ɪt's ə ɡréjt wej tə kwɪ́klij ʌ̀ndərstǽnd ənd ɔ́rɡənàjz vǽst əmáwnts əv tɛ́kstʃùwəl ɪnfərméjʃən wɪðáwt mǽnjuwəlij kówmɪŋ θrúw ijtʃ dɒ́kjəmɛnt."
    },
    {
        "Question": "Which machine learning technique allows you to automatically discover hidden topics within a large collection of text documents, grouping similar themes without needing human-labeled data?",
        "RightAnswer": "Latent Dirichlet Allocation",
        "WrongAnswers": [
            "Support Vector Machines",
            "K-Nearest Neighbors",
            "Gradient Boosting Machines",
            "Random Forests",
            "Principal Component Analysis"
        ],
        "Explanation": "Latent Dirichlet Allocation (LDA) is a technique used in natural language processing and machine learning to automatically discover hidden, or 'latent,' topics in large volumes of text data. Imagine having thousands of news articles but no clear way of organizing or labeling them by topic. LDA analyzes words across documents and groups them into themes based purely on their content, without needing human-defined labels. This helps researchers and businesses reveal underlying patterns in data, making sense of huge collections of texts easily and quickly.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk əláwz juw tə ɔ̀təmǽtɪklij dɪskʌ́vər hɪ́dən tɒ́pɪks wɪðɪ́n ə lɑ́rdʒ kəlɛ́kʃən əv tɛ́kst dɒ́kjəmənts, ɡrúwpɪŋ sɪ́mɪlər θíjmz wɪðáwt níjdɪŋ hjúwmən-léjbəld déjtə?",
        "trans_RightAnswer": "léjtənt dɪ́ərɪklejt æ̀ləkéjʃən",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "k-nɪ́ərəst néjbərz",
            "ɡréjdijənt búwstɪŋ məʃíjnz",
            "rǽndəm fɔ́rəsts",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "léjtənt dɪ́ərɪklejt æ̀ləkéjʃən (LDA) ɪz ə tɛkníjk júwzd ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ ənd məʃíjn lɜ́rnɪŋ tə ɔ̀təmǽtɪklij dɪskʌ́vər hɪ́dən, ɔr 'léjtənt,' tɒ́pɪks ɪn lɑ́rdʒ vɒ́ljuwmz əv tɛ́kst déjtə. ɪmǽdʒɪn hǽvɪŋ θáwzəndz əv nuws ɑ́rtɪkəlz bʌt now klɪ́ər wej əv ɔ́rɡənàjzɪŋ ɔr léjbəlɪŋ ðɛm baj tɒ́pɪk. LDA ǽnəlàjzɪz wɜ́rdz əkrɔ́s dɒ́kjəmənts ənd ɡrúwps ðɛm ɪntə θíjmz béjst pjʊ́rlij ɒn ðɛər kɒ́ntənt, wɪðáwt níjdɪŋ hjúwmən-dəfájnd léjbəlz. ðɪs hɛ́lps ríjsərtʃərz ənd bɪ́znəsɪz rəvíjl ʌ̀ndərlájɪŋ pǽtərnz ɪn déjtə, méjkɪŋ sɛ́ns əv hjúwdʒ kəlɛ́kʃənz əv tɛ́ksts íjzəlij ənd kwɪ́klij."
    },
    {
        "Question": "Imagine you're building a music recommendation system that groups similar songs together in a meaningful way. You're using an algorithm that decomposes your large playlist data into simpler, easier-to-interpret factors, ensuring that none of these simplified representations have negative numbers—making interpretation straightforward and intuitive. What machine learning technique does this best describe?",
        "RightAnswer": "Non-negative Matrix Factorization",
        "WrongAnswers": [
            "Principal Component Analysis",
            "Support Vector Machines",
            "Gradient Boosting",
            "K-means Clustering",
            "Bayesian Networks"
        ],
        "Explanation": "Non-negative Matrix Factorization (NMF) is a helpful and intuitive machine learning technique that breaks down complex datasets into simpler, meaningful parts. The unique thing about NMF is that it ensures the resulting components are never negative, making the data easier to interpret. It's popular in tasks like image processing, text topic discovery, and music recommendation because its output tends to align nicely with human intuition, such as identifying underlying patterns or themes without confusing negatives.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə mjúwzɪk rɛ̀kəməndéjʃən sɪ́stəm ðət ɡrúwps sɪ́mɪlər sɔ́ŋz təɡɛ́ðər ɪn ə míjnɪŋfəl wej. júwr júwzɪŋ ən ǽlɡərɪ̀ðəm ðət dìjkəmpówzɪz jɔr lɑ́rdʒ pléjlɪst déjtə ɪntə sɪ́mplər, íjzijər-tə-ɪntɜ́rprət fǽktərz, ɛnʃʊ́rɪŋ ðət nən əv ðijz sɪ́mpləfajd rɛ̀prəzəntéjʃənz həv nɛ́ɡətɪv nʌ́mbərz—méjkɪŋ ɪntɜ̀rprətéjʃən stréjtfɔ́rwərd ənd ɪntúwɪtɪv. wɒt məʃíjn lɜ́rnɪŋ tɛkníjk dʌz ðɪs bɛ́st dəskrájb?",
        "trans_RightAnswer": "nɒn-nɛ́ɡətɪv méjtrɪks fæ̀ktərajzéjʃən",
        "trans_WrongAnswers": [
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "ɡréjdijənt búwstɪŋ",
            "k-míjnz klʌ́stərɪŋ",
            "béjʒən nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "nɒn-nɛ́ɡətɪv méjtrɪks fæ̀ktərajzéjʃən (NMF) ɪz ə hɛ́lpfəl ənd ɪntúwɪtɪv məʃíjn lɜ́rnɪŋ tɛkníjk ðət bréjks dawn kɒ́mplɛks déjtəsɛ̀ts ɪntə sɪ́mplər, míjnɪŋfəl pɑ́rts. ðə juwnɪ́k θɪ́ŋ əbawt NMF ɪz ðət ɪt ənʃʊ́rz ðə rəzʌ́ltɪŋ kəmpównənts ɑr nɛ́vər nɛ́ɡətɪv, méjkɪŋ ðə déjtə íjzijər tə ɪntɜ́rprət. ɪt's pɒ́pjələr ɪn tǽsks lájk ɪ́mɪdʒ prɒ́sɛsɪŋ, tɛ́kst tɒ́pɪk dɪ̀skʌ́vrij, ənd mjúwzɪk rɛ̀kəməndéjʃən bəkɒ́z ɪts áwtpʊ̀t tɛ́ndz tə əlájn nájslij wɪð hjúwmən ɪntuwɪ́ʃən, sʌtʃ æz ajdɛ́ntɪfàjɪŋ ʌ̀ndərlájɪŋ pǽtərnz ɔr θíjmz wɪðáwt kənfjúwzɪŋ nɛ́ɡətɪvz."
    },
    {
        "Question": "You're exploring a new streaming platform and realize that its recommendations for movies you might enjoy are eerily accurate, based solely on your ratings and those of users with similar tastes. What machine learning approach is the platform likely using to make these personalized recommendations?",
        "RightAnswer": "Collaborative Filtering",
        "WrongAnswers": [
            "Decision Tree Classification",
            "Reinforcement Learning",
            "Principal Component Analysis",
            "Unsupervised Clustering",
            "Linear Regression"
        ],
        "Explanation": "Collaborative Filtering is a smart and intuitive method used by recommendation systems to suggest content based on the preferences of similar users. Instead of relying only on the features of items (like movie genres or actors), it observes patterns in how people with tastes similar to yours rate or interact with items. This helps personalize recommendations, offering suggestions you're likely to enjoy based on the shared interests and behaviors of others.",
        "trans_Question": "júwr əksplɔ́rɪŋ ə núw stríjmɪŋ plǽtfɔ̀rm ənd ríjəlàjz ðət ɪts rɛ̀kəməndéjʃənz fɔr múwvijz juw majt əndʒɔ́j ɑr íjərɪlij ǽkjərət, béjst sówlij ɒn jɔr réjtɪŋz ənd ðowz əv júwzərz wɪð sɪ́mɪlər téjsts. wɒt məʃíjn lɜ́rnɪŋ əprówtʃ ɪz ðə plǽtfɔ̀rm lájklij júwzɪŋ tə méjk ðijz pɜ́rsənəlàjzd rɛ̀kəməndéjʃənz?",
        "trans_RightAnswer": "kəlǽbərèjtɪv fɪ́ltərɪŋ",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríj klæ̀sɪfɪkéjʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "ʌ̀nsúwpərvàjzd klʌ́stərɪŋ",
            "lɪ́nijər rəɡrɛ́ʃən"
        ],
        "trans_Explanation": "kəlǽbərèjtɪv fɪ́ltərɪŋ ɪz ə smɑ́rt ənd ɪntúwɪtɪv mɛ́θəd júwzd baj rɛ̀kəməndéjʃən sɪ́stəmz tə sədʒɛ́st kɒ́ntənt béjst ɒn ðə prɛ́fərənsɪz əv sɪ́mɪlər júwzərz. ɪnstɛ́d əv rəlájɪŋ ównlij ɒn ðə fíjtʃərz əv ájtəmz (lájk múwvij ʒɒ́nrɪz ɔr ǽktərz), ɪt əbzɜ́rvz pǽtərnz ɪn háw píjpəl wɪð téjsts sɪ́mɪlər tə jɔrz réjt ɔr ɪ̀ntərǽkt wɪð ájtəmz. ðɪs hɛ́lps pɜ́rsənəlàjz rɛ̀kəməndéjʃənz, ɔ́fərɪŋ sədʒɛ́stʃənz júwr lájklij tə əndʒɔ́j béjst ɒn ðə ʃɛ́ərd ɪ́ntərəsts ənd bəhéjvjərz əv ʌ́ðərz."
    },
    {
        "Question": "When streaming your favorite show or shopping online, you often see suggestions like 'people who viewed this also liked...' or 'recommended for you'. Which machine learning technique is responsible for creating these personalized suggestions?",
        "RightAnswer": "Recommendation Systems",
        "WrongAnswers": [
            "Natural Language Processing",
            "Image Recognition Systems",
            "Clustering Algorithms",
            "Neural Networks",
            "Anomaly Detection"
        ],
        "Explanation": "Recommendation systems are specialized machine learning techniques that analyze your past behaviors, preferences, and interests, as well as the behaviors of other users, to suggest content, products, or services you might enjoy. They're the behind-the-scenes magic behind personalized movie recommendations, tailored product suggestions, or curated playlists based on your listening history.",
        "trans_Question": "wɛ́n stríjmɪŋ jɔr féjvərɪt ʃów ɔr ʃɒ́pɪŋ ɔ́nlàjn, juw ɔ́fən síj sədʒɛ́stʃənz lájk 'píjpəl huw vjúwd ðɪs ɔ́lsow lájkt..' ɔr 'rɛ̀kəmɛ́ndɪd fɔr juw'. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪz rəspɒ́nsɪbəl fɔr krijéjtɪŋ ðijz pɜ́rsənəlàjzd sədʒɛ́stʃənz?",
        "trans_RightAnswer": "rɛ̀kəməndéjʃən sɪ́stəmz",
        "trans_WrongAnswers": [
            "nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ",
            "ɪ́mɪdʒ rɛ̀kəɡnɪ́ʃən sɪ́stəmz",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz",
            "nʊ́rəl nɛ́twɜ̀rks",
            "ənɒ́məlij dətɛ́kʃən"
        ],
        "trans_Explanation": "rɛ̀kəməndéjʃən sɪ́stəmz ɑr spɛ́ʃəlàjzd məʃíjn lɜ́rnɪŋ tɛkníjks ðət ǽnəlàjz jɔr pǽst bəhéjvjərz, prɛ́fərənsɪz, ənd ɪ́ntərəsts, æz wɛ́l æz ðə bəhéjvjərz əv ʌ́ðər júwzərz, tə sədʒɛ́st kɒ́ntənt, prɒ́dəkts, ɔr sɜ́rvɪsɪz juw majt əndʒɔ́j. ðɛ́ər ðə bəhájnd-ðə-síjnz mǽdʒɪk bəhájnd pɜ́rsənəlàjzd múwvij rɛ̀kəməndéjʃənz, téjlərd prɒ́dəkt sədʒɛ́stʃənz, ɔr kjʊréjtɪd pléjlɪsts béjst ɒn jɔr lɪ́sənɪŋ hɪ́stərij."
    },
    {
        "Question": "Imagine you're using a movie streaming app, and it suggests new films to you because you enjoyed others featuring superheroes, action-packed plots, and adventure. Which term describes a recommendation system that suggests items based on their similarity to content you've liked before?",
        "RightAnswer": "Content-Based Filtering",
        "WrongAnswers": [
            "Collaborative Filtering",
            "Reinforcement Learning",
            "Neural Network Recommendation",
            "Clustering Algorithm",
            "Association Rule Learning"
        ],
        "Explanation": "Content-based filtering is a recommendation technique used by apps and services to show you content that closely matches what you've previously enjoyed. Instead of relying on choices made by other users, it focuses on analyzing the attributes or content of items you've liked in the past. For example, if you've rated superhero movies highly, the system will suggest more superhero films or other action-packed adventures similar in genre, storyline, or actors. Think of it as a knowledgeable friend who knows exactly your taste and gives you suggestions based purely on your favorites!",
        "trans_Question": "ɪmǽdʒɪn júwr júwzɪŋ ə múwvij stríjmɪŋ ǽp, ənd ɪt sədʒɛ́sts núw fɪ́lmz tə juw bəkɒ́z juw əndʒɔ́jd ʌ́ðərz fíjtʃərɪŋ sùwpərhíjərowz, ǽkʃən-pǽkt plɒ́ts, ənd ædvɛ́ntʃər. wɪ́tʃ tɜ́rm dəskrájbz ə rɛ̀kəməndéjʃən sɪ́stəm ðət sədʒɛ́sts ájtəmz béjst ɒn ðɛər sɪ̀mɪlɛ́ərɪtij tə kɒ́ntənt júwv lájkt bəfɔ́r?",
        "trans_RightAnswer": "kɒ́ntənt-béjst fɪ́ltərɪŋ",
        "trans_WrongAnswers": [
            "kəlǽbərèjtɪv fɪ́ltərɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "nʊ́rəl nɛ́twɜ̀rk rɛ̀kəməndéjʃən",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəm",
            "əsòwsijéjʃən rúwl lɜ́rnɪŋ"
        ],
        "trans_Explanation": "kɒ́ntənt-béjst fɪ́ltərɪŋ ɪz ə rɛ̀kəməndéjʃən tɛkníjk júwzd baj ǽps ənd sɜ́rvɪsɪz tə ʃów juw kɒ́ntənt ðət klówslij mǽtʃɪz wɒt júwv príjvijəslij əndʒɔ́jd. ɪnstɛ́d əv rəlájɪŋ ɒn tʃɔ́jsɪz méjd baj ʌ́ðər júwzərz, ɪt fówkəsɪz ɒn ǽnəlàjzɪŋ ðə ǽtrəbjùwts ɔr kɒ́ntənt əv ájtəmz júwv lájkt ɪn ðə pǽst. fɔr əɡzǽmpəl, ɪf júwv réjtɪd sùwpərhíjərow múwvijz hájlij, ðə sɪ́stəm wɪl sədʒɛ́st mɔr sùwpərhíjərow fɪ́lmz ɔr ʌ́ðər ǽkʃən-pǽkt ædvɛ́ntʃərz sɪ́mɪlər ɪn ʒɒ́nrə, stɔ́rijlàjn, ɔr ǽktərz. θɪ́ŋk əv ɪt æz ə nɒ́lɪdʒəbəl frɛ́nd huw nówz əɡzǽktlij jɔr téjst ənd ɡɪ́vz juw sədʒɛ́stʃənz béjst pjʊ́rlij ɒn jɔr féjvərɪts!"
    },
    {
        "Question": "If Netflix wants to predict what shows you'll enjoy based on what you've liked before and what similar users have enjoyed, which machine learning method might they be using to discover hidden patterns from users' ratings?",
        "RightAnswer": "Matrix Factorization",
        "WrongAnswers": [
            "Gradient Boosting",
            "Decision Trees",
            "K-means Clustering",
            "Linear Regression",
            "Random Forests"
        ],
        "Explanation": "Matrix Factorization is a method in machine learning that's commonly used for recommendation systems. It helps services like Netflix or Spotify uncover hidden patterns in user ratings or preferences. Basically, it takes a large table (or matrix) of users and items—like users and movies—and breaks it down into simpler, smaller parts. By doing this, the model predicts what you might like next based on your past choices and the preferences of people similar to you. It's like figuring out the secret ingredients behind your taste!",
        "trans_Question": "ɪf nɛ́tflɪks wɒ́nts tə prədɪ́kt wɒt ʃówz júwl əndʒɔ́j béjst ɒn wɒt júwv lájkt bəfɔ́r ənd wɒt sɪ́mɪlər júwzərz həv əndʒɔ́jd, wɪ́tʃ məʃíjn lɜ́rnɪŋ mɛ́θəd majt ðej bij júwzɪŋ tə dɪskʌ́vər hɪ́dən pǽtərnz frəm júwzərz' réjtɪŋz?",
        "trans_RightAnswer": "méjtrɪks fæ̀ktərajzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "dəsɪ́ʒən tríjz",
            "k-míjnz klʌ́stərɪŋ",
            "lɪ́nijər rəɡrɛ́ʃən",
            "rǽndəm fɔ́rəsts"
        ],
        "trans_Explanation": "méjtrɪks fæ̀ktərajzéjʃən ɪz ə mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ ðət's kɒ́mənlij júwzd fɔr rɛ̀kəməndéjʃən sɪ́stəmz. ɪt hɛ́lps sɜ́rvɪsɪz lájk nɛ́tflɪks ɔr spɔ́tɪfàj ʌ̀nkʌ́vər hɪ́dən pǽtərnz ɪn júwzər réjtɪŋz ɔr prɛ́fərənsɪz. béjsɪklij, ɪt téjks ə lɑ́rdʒ téjbəl (ɔr méjtrɪks) əv júwzərz ənd ájtəmz—lájk júwzərz ənd múwvijz—ənd bréjks ɪt dawn ɪntə sɪ́mplər, smɔ́lər pɑ́rts. baj dúwɪŋ ðɪs, ðə mɒ́dəl prədɪ́kts wɒt juw majt lájk nɛ́kst béjst ɒn jɔr pǽst tʃɔ́jsɪz ənd ðə prɛ́fərənsɪz əv píjpəl sɪ́mɪlər tə juw. ɪt's lájk fɪ́ɡjərɪŋ awt ðə síjkrət ɪnɡríjdijənts bəhájnd jɔr téjst!"
    },
    {
        "Question": "Which mathematical technique is frequently used in machine learning to reduce the dimensionality of data, simplifying large datasets by breaking them down into core features while preserving crucial information?",
        "RightAnswer": "Singular Value Decomposition",
        "WrongAnswers": [
            "Gradient Descent",
            "Activation Function",
            "Decision Tree Pruning",
            "Support Vector Machine",
            "Cross-validation"
        ],
        "Explanation": "Singular Value Decomposition, or SVD, is a powerful mathematical method that takes a large, complex dataset and breaks it down into simpler, more manageable pieces. It's like finding a few core messages in a lengthy book, helping machine learning algorithms to easily identify patterns, filter out noise, and improve overall performance. Commonly used for tasks like data compression or noise reduction, SVD preserves essential information while making the dataset easier and quicker to analyze.",
        "trans_Question": "wɪ́tʃ mæ̀θəmǽtɪkəl tɛkníjk ɪz fríjkwəntlij júwzd ɪn məʃíjn lɜ́rnɪŋ tə rədjúws ðə dajmɛ̀nʃənǽlɪtij əv déjtə, sɪ́mpləfajɪŋ lɑ́rdʒ déjtəsɛ̀ts baj bréjkɪŋ ðɛm dawn ɪntə kɔ́r fíjtʃərz wájl prəzɜ́rvɪŋ krúwʃəl ɪnfərméjʃən?",
        "trans_RightAnswer": "sɪ́ŋɡjələr vǽljuw dìjkəmpəzɪ́ʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "æ̀ktɪvéjʃən fʌ́ŋkʃən",
            "dəsɪ́ʒən tríj prúwnɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "krɔ́s-væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "sɪ́ŋɡjələr vǽljuw dìjkəmpəzɪ́ʃən, ɔr SVD, ɪz ə páwərfəl mæ̀θəmǽtɪkəl mɛ́θəd ðət téjks ə lɑ́rdʒ, kɒ́mplɛks déjtəsɛ̀t ənd bréjks ɪt dawn ɪntə sɪ́mplər, mɔr mǽnədʒəbəl píjsɪz. ɪt's lájk fájndɪŋ ə fjúw kɔ́r mɛ́sɪdʒɪz ɪn ə lɛ́ŋθij bʊ́k, hɛ́lpɪŋ məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz tə íjzəlij ajdɛ́ntɪfàj pǽtərnz, fɪ́ltər awt nɔ́jz, ənd ɪmprúwv ówvərɔ̀l pərfɔ́rməns. kɒ́mənlij júwzd fɔr tǽsks lájk déjtə kəmprɛ́ʃən ɔr nɔ́jz rədʌ́kʃən, SVD prəzɜ́rvz əsɛ́nʃəl ɪnfərméjʃən wájl méjkɪŋ ðə déjtəsɛ̀t íjzijər ənd kwɪ́kər tə ǽnəlàjz."
    },
    {
        "Question": "Which term describes technology that automatically selects and optimizes machine learning models, so you don't have to spend extensive time fine-tuning parameters manually?",
        "RightAnswer": "AutoML",
        "WrongAnswers": [
            "Deep Learning",
            "Reinforcement Learning",
            "Supervised Learning",
            "Feature Engineering",
            "Transfer Learning"
        ],
        "Explanation": "AutoML, short for Automated Machine Learning, is all about making machine learning accessible by automating the tricky parts of the process. Instead of manually experimenting with countless models and settings, AutoML helps select the most suitable machine learning models and fine-tunes their parameters automatically—saving you time and effort. Think of it like having a smart assistant who picks the best ingredients and recipes so you can quickly cook up great results!",
        "trans_Question": "wɪ́tʃ tɜ́rm dəskrájbz tɛknɒ́lədʒij ðət ɔ̀təmǽtɪklij səlɛ́kts ənd ɒ́ptɪmajzɪz məʃíjn lɜ́rnɪŋ mɒ́dəlz, sow juw dównt həv tə spɛ́nd əkstɛ́nsɪv tájm fájn-túwnɪŋ pərǽmətərz mǽnjuwəlij?",
        "trans_RightAnswer": "ɔ̀towɛ́mɛ́l",
        "trans_WrongAnswers": [
            "díjp lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "trǽnsfər lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ɔ̀towɛ́mɛ́l, ʃɔ́rt fɔr ɔ́təmèjtɪd məʃíjn lɜ́rnɪŋ, ɪz ɔl əbawt méjkɪŋ məʃíjn lɜ́rnɪŋ æksɛ́sɪbəl baj ɔ́təmèjtɪŋ ðə trɪ́kij pɑ́rts əv ðə prɒ́sɛs. ɪnstɛ́d əv mǽnjuwəlij əkspɛ́ərɪmɛ̀ntɪŋ wɪð káwntləs mɒ́dəlz ənd sɛ́tɪŋz, ɔ̀towɛ́mɛ́l hɛ́lps səlɛ́kt ðə mówst súwtəbəl məʃíjn lɜ́rnɪŋ mɒ́dəlz ənd fájn-túwnz ðɛər pərǽmətərz ɔ̀təmǽtɪklij—séjvɪŋ juw tájm ənd ɛ́fərt. θɪ́ŋk əv ɪt lájk hǽvɪŋ ə smɑ́rt əsɪ́stənt huw pɪ́ks ðə bɛ́st ɪnɡríjdijənts ənd rɛ́sɪpijz sow juw kən kwɪ́klij kʊ́k ʌp ɡréjt rəzʌ́lts!"
    },
    {
        "Question": "Which machine learning concept involves exploring large datasets to uncover hidden patterns, meaningful insights, and valuable information to make better decisions?",
        "RightAnswer": "Data Mining",
        "WrongAnswers": [
            "Neural Networks",
            "Feature Scaling",
            "Cross Validation",
            "Gradient Descent",
            "Overfitting"
        ],
        "Explanation": "Data mining is similar to being a detective: it involves digging deep into big sets of data to find interesting connections, trends, and valuable insights that were previously hidden. Instead of chasing criminals, however, it's all about using those discovered patterns to help make smarter decisions in business, research, and everyday life.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ kɒ́nsɛpt ɪnvɒ́lvz əksplɔ́rɪŋ lɑ́rdʒ déjtəsɛ̀ts tə ʌ̀nkʌ́vər hɪ́dən pǽtərnz, míjnɪŋfəl ɪ́nsàjts, ənd vǽljəbəl ɪnfərméjʃən tə méjk bɛ́tər dəsɪ́ʒənz?",
        "trans_RightAnswer": "déjtə májnɪŋ",
        "trans_WrongAnswers": [
            "nʊ́rəl nɛ́twɜ̀rks",
            "fíjtʃər skéjlɪŋ",
            "krɔ́s væ̀lɪdéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ"
        ],
        "trans_Explanation": "déjtə májnɪŋ ɪz sɪ́mɪlər tə bíjɪŋ ə dətɛ́ktɪv: ɪt ɪnvɒ́lvz dɪ́ɡɪŋ díjp ɪntə bɪ́ɡ sɛ́ts əv déjtə tə fájnd ɪ́ntərəstɪŋ kənɛ́kʃənz, trɛ́ndz, ənd vǽljəbəl ɪ́nsàjts ðət wɜ́r príjvijəslij hɪ́dən. ɪnstɛ́d əv tʃéjsɪŋ krɪ́mɪnəlz, hàwɛ́vər, ɪt's ɔl əbawt júwzɪŋ ðowz dɪskʌ́vərd pǽtərnz tə hɛ́lp méjk smɑ́rtər dəsɪ́ʒənz ɪn bɪ́znəs, ríjsərtʃ, ənd ɛ́vrijdéj lájf."
    },
    {
        "Question": "In machine learning, when you're trying to measure how mixed up or unpredictable a dataset is—like how uncertain you are about the category of random items—what term best describes this measure?",
        "RightAnswer": "Entropy",
        "WrongAnswers": [
            "Convergence",
            "Regression",
            "Gradient",
            "Overfitting",
            "Bias"
        ],
        "Explanation": "Entropy measures how messy or uncertain your data is. Imagine sorting out a big pile of colorful candies into jars—if you have many colors randomly mixed together, that chaos represents high entropy. On the other hand, if all candies in one jar are the same color, that's low entropy. In machine learning, entropy helps us measure uncertainty or disorder in our data, especially helpful when building decision trees or classification algorithms.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n júwr trájɪŋ tə mɛ́ʒər háw mɪ́kst ʌp ɔr ʌ̀nprədɪ́ktəbəl ə déjtəsɛ̀t ɪz—lájk háw ʌ̀nsɜ́rtən juw ɑr əbawt ðə kǽtəɡɔ̀rij əv rǽndəm ájtəmz—wɒt tɜ́rm bɛ́st dəskrájbz ðɪs mɛ́ʒər?",
        "trans_RightAnswer": "ɛ́ntrəpij",
        "trans_WrongAnswers": [
            "kənvɜ́rdʒəns",
            "rəɡrɛ́ʃən",
            "ɡréjdijənt",
            "òwvərfɪ́tɪŋ",
            "bájəs"
        ],
        "trans_Explanation": "ɛ́ntrəpij mɛ́ʒərz háw mɛ́sij ɔr ʌ̀nsɜ́rtən jɔr déjtə ɪz. ɪmǽdʒɪn sɔ́rtɪŋ awt ə bɪ́ɡ pájl əv kʌ́lərfəl kǽndijz ɪntə dʒɑ́rz—ɪf juw həv mɛ́nij kʌ́lərz rǽndəmlij mɪ́kst təɡɛ́ðər, ðət kéjɒs rɛ̀prəzɛ́nts háj ɛ́ntrəpij. ɒn ðə ʌ́ðər hǽnd, ɪf ɔl kǽndijz ɪn wʌ́n dʒɑ́r ɑr ðə séjm kʌ́lər, ðət's lów ɛ́ntrəpij. ɪn məʃíjn lɜ́rnɪŋ, ɛ́ntrəpij hɛ́lps ʌs mɛ́ʒər ʌ̀nsɜ́rtəntij ɔr dɪsɔ́rdər ɪn awər déjtə, əspɛ́ʃəlij hɛ́lpfəl wɛ́n bɪ́ldɪŋ dəsɪ́ʒən tríjz ɔr klæ̀sɪfɪkéjʃən ǽlɡərɪ̀ðəmz."
    },
    {
        "Question": "Imagine training a decision tree model and you need a way to assess which feature splits your data into more homogeneous groups, thereby making your tree smarter and more efficient. Which of the following machine learning concepts describes this measure best?",
        "RightAnswer": "Information Gain",
        "WrongAnswers": [
            "Gradient Descent",
            "Regularization",
            "Overfitting",
            "Dimensionality Reduction",
            "Confusion Matrix"
        ],
        "Explanation": "Information Gain is like having a helpful guide that tells your decision tree which features provide the clearest path to accurate predictions. It measures how much a particular feature improves the purity or clarity of your data splits. Simply put, the larger the Information Gain, the better that feature is at separating your data into meaningful groups.",
        "trans_Question": "ɪmǽdʒɪn tréjnɪŋ ə dəsɪ́ʒən tríj mɒ́dəl ənd juw níjd ə wej tə əsɛ́s wɪ́tʃ fíjtʃər splɪ́ts jɔr déjtə ɪntə mɔr hòwmədʒɛ́nijəs ɡrúwps, ðɛ́ərbáj méjkɪŋ jɔr tríj smɑ́rtər ənd mɔr əfɪ́ʃənt. wɪ́tʃ əv ðə fɒ́lowɪŋ məʃíjn lɜ́rnɪŋ kɒ́nsɛpts dəskrájbz ðɪs mɛ́ʒər bɛ́st?",
        "trans_RightAnswer": "ɪnfərméjʃən ɡéjn",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "òwvərfɪ́tɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "kənfjúwʒən méjtrɪks"
        ],
        "trans_Explanation": "ɪnfərméjʃən ɡéjn ɪz lájk hǽvɪŋ ə hɛ́lpfəl ɡájd ðət tɛ́lz jɔr dəsɪ́ʒən tríj wɪ́tʃ fíjtʃərz prəvájd ðə klɪ́ərəst pǽθ tə ǽkjərət prədɪ́kʃənz. ɪt mɛ́ʒərz háw mʌtʃ ə pərtɪ́kjələr fíjtʃər ɪmprúwvz ðə pjʊ́rɪtij ɔr klɛ́ərɪtij əv jɔr déjtə splɪ́ts. sɪ́mplij pʊ́t, ðə lɑ́rdʒər ðə ɪnfərméjʃən ɡéjn, ðə bɛ́tər ðət fíjtʃər ɪz æt sɛ́pərèjtɪŋ jɔr déjtə ɪntə míjnɪŋfəl ɡrúwps."
    },
    {
        "Question": "When building decision trees for machine learning models, you need a way to measure how mixed or diverse a group of samples is within a node. Which term describes this measure that estimates how likely it is to incorrectly label a randomly chosen sample from that node?",
        "RightAnswer": "Gini Impurity",
        "WrongAnswers": [
            "Gradient Descent",
            "Cross-Entropy Loss",
            "Variance Inflation Factor",
            "F1 Score",
            "Confusion Matrix"
        ],
        "Explanation": "Gini Impurity is used to measure how mixed up or messy a node in a decision tree is. Imagine you randomly pick an object from a basket; Gini Impurity tells you how likely you are to incorrectly guess its category based on what's in the basket. A low Gini Impurity means the samples are more similar to each other, and the node is getting closer to separating the data clearly.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ dəsɪ́ʒən tríjz fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz, juw níjd ə wej tə mɛ́ʒər háw mɪ́kst ɔr dajvɜ́rs ə ɡrúwp əv sǽmpəlz ɪz wɪðɪ́n ə nówd. wɪ́tʃ tɜ́rm dəskrájbz ðɪs mɛ́ʒər ðət ɛ́stɪmèjts háw lájklij ɪt ɪz tə ɪ̀nkərɛ́ktlij léjbəl ə rǽndəmlij tʃówzən sǽmpəl frəm ðət nówd?",
        "trans_RightAnswer": "dʒíjnij ɪ̀mpjʊ́rɪtij",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "krɔ́s-ɛ́ntrəpij lɔ́s",
            "vɛ́ərijəns ɪnfléjʃən fǽktər",
            "F1 skɔ́r",
            "kənfjúwʒən méjtrɪks"
        ],
        "trans_Explanation": "dʒíjnij ɪ̀mpjʊ́rɪtij ɪz júwzd tə mɛ́ʒər háw mɪ́kst ʌp ɔr mɛ́sij ə nówd ɪn ə dəsɪ́ʒən tríj ɪz. ɪmǽdʒɪn juw rǽndəmlij pɪ́k ən ɒ́bdʒəkt frəm ə bǽskət; dʒíjnij ɪ̀mpjʊ́rɪtij tɛ́lz juw háw lájklij juw ɑr tə ɪ̀nkərɛ́ktlij ɡɛ́s ɪts kǽtəɡɔ̀rij béjst ɒn wɒt's ɪn ðə bǽskət. ə lów dʒíjnij ɪ̀mpjʊ́rɪtij míjnz ðə sǽmpəlz ɑr mɔr sɪ́mɪlər tə ijtʃ ʌ́ðər, ənd ðə nówd ɪz ɡɛ́tɪŋ klówsər tə sɛ́pərèjtɪŋ ðə déjtə klɪ́ərlij."
    },
    {
        "Question": "In machine learning, what method helps simplify a complicated decision tree by removing branches that provide little help or might hurt the model's ability to generalize?",
        "RightAnswer": "Decision Tree Pruning",
        "WrongAnswers": [
            "Feature Extraction",
            "Gradient Descent",
            "Dimensionality Reduction",
            "Data Normalization",
            "Cross Validation"
        ],
        "Explanation": "Decision Tree Pruning is a process in machine learning where we trim down complex decision trees, pretty much the way gardeners prune trees by removing unnecessary branches. This helps the model perform better on new data by reducing complexity and minimizing the risk of overfitting (the machine learning equivalent of memorizing rather than learning from data).",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt mɛ́θəd hɛ́lps sɪ́mpləfaj ə kɒ́mplɪkèjtɪd dəsɪ́ʒən tríj baj rijmúwvɪŋ brǽntʃɪz ðət prəvájd lɪ́təl hɛ́lp ɔr majt hɜ́rt ðə mɒ́dəl'z əbɪ́lɪtij tə dʒɛ́nərəlàjz?",
        "trans_RightAnswer": "dəsɪ́ʒən tríj prúwnɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "ɡréjdijənt dəsɛ́nt",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "déjtə nɔ̀rməlɪzéjʃən",
            "krɔ́s væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "dəsɪ́ʒən tríj prúwnɪŋ ɪz ə prɒ́sɛs ɪn məʃíjn lɜ́rnɪŋ wɛ́ər wij trɪ́m dawn kɒ́mplɛks dəsɪ́ʒən tríjz, prɪ́tij mʌtʃ ðə wej ɡɑ́rdənərz prúwn tríjz baj rijmúwvɪŋ ʌ̀nnɛ́səsɛ̀ərij brǽntʃɪz. ðɪs hɛ́lps ðə mɒ́dəl pərfɔ́rm bɛ́tər ɒn núw déjtə baj rədjúwsɪŋ kəmplɛ́ksɪtij ənd mɪ́nɪmàjzɪŋ ðə rɪ́sk əv òwvərfɪ́tɪŋ (ðə məʃíjn lɜ́rnɪŋ əkwɪ́vələnt əv mɛ́məràjzɪŋ rǽðər ðʌn lɜ́rnɪŋ frəm déjtə)."
    },
    {
        "Question": "In ensemble machine learning, one interesting approach is to train multiple models—but instead of using the entire set of features for every model, each model learns from a randomly selected subset of features. What's this creative technique called?",
        "RightAnswer": "Random Subspace Method",
        "WrongAnswers": [
            "Gradient Boosting",
            "K-Means Clustering",
            "Support Vector Machines",
            "Backpropagation",
            "Random Walk Sampling"
        ],
        "Explanation": "Think of the Random Subspace Method as a group brainstorming approach: rather than having every participant (or model) think about everything at once, each member is given a randomly chosen smaller part of the overall information (a subset of features) to consider. This way, when their predictions are combined, you benefit from diverse perspectives and minimize overfitting, often leading to more robust and accurate results.",
        "trans_Question": "ɪn ɒnsɒ́mbəl məʃíjn lɜ́rnɪŋ, wʌ́n ɪ́ntərəstɪŋ əprówtʃ ɪz tə tréjn mʌ́ltɪpəl mɒ́dəlz—bʌt ɪnstɛ́d əv júwzɪŋ ðə əntájər sɛ́t əv fíjtʃərz fɔr ɛvərij mɒ́dəl, ijtʃ mɒ́dəl lɜ́rnz frəm ə rǽndəmlij səlɛ́ktɪd sʌ́bsɛ̀t əv fíjtʃərz. wɒt's ðɪs krijéjtɪv tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "rǽndəm sʌ́bspèjs mɛ́θəd",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "bǽkprəpəgéjʃən",
            "rǽndəm wɒ́k sǽmplɪŋ"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə rǽndəm sʌ́bspèjs mɛ́θəd æz ə ɡrúwp bréjnstɔ̀rmɪŋ əprówtʃ: rǽðər ðʌn hǽvɪŋ ɛvərij pɑrtɪ́səpənt (ɔr mɒ́dəl) θɪ́ŋk əbawt ɛ́vrijθɪ̀ŋ æt wʌ́ns, ijtʃ mɛ́mbər ɪz ɡɪ́vən ə rǽndəmlij tʃówzən smɔ́lər pɑ́rt əv ðə ówvərɔ̀l ɪnfərméjʃən (ə sʌ́bsɛ̀t əv fíjtʃərz) tə kənsɪ́dər. ðɪs wej, wɛ́n ðɛər prədɪ́kʃənz ɑr kəmbájnd, juw bɛ́nəfɪt frəm dajvɜ́rs pərspɛ́ktɪvz ənd mɪ́nɪmàjz òwvərfɪ́tɪŋ, ɔ́fən líjdɪŋ tə mɔr rowbʌ́st ənd ǽkjərət rəzʌ́lts."
    },
    {
        "Question": "In machine learning and AI systems, there's a technique that doesn't just classify things as strictly yes or no, true or false—instead, it embraces that there's often uncertainty or partial truth, similar to how human thinking works. What's this approach called?",
        "RightAnswer": "Fuzzy Logic",
        "WrongAnswers": [
            "Binary Logic",
            "Deep Learning",
            "Decision Trees",
            "Linear Regression",
            "Reinforcement Learning"
        ],
        "Explanation": "Fuzzy Logic is a way of reasoning that more closely mimics how humans think, recognizing uncertainty and partial truths. Unlike traditional logic—where an answer is strictly true or false—Fuzzy Logic allows for degrees of truth. It's especially useful when making decisions with incomplete information, helping machines operate in scenarios with ambiguity and complex choices, just as humans often must.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ ənd AI sɪ́stəmz, ðɛər'z ə tɛkníjk ðət dʌ́zənt dʒəst klǽsɪfàj θɪ́ŋz æz strɪ́ktlij jɛs ɔr now, trúw ɔr fɔ́ls—ɪnstɛ́d, ɪt ɛmbréjsɪz ðət ðɛər'z ɔ́fən ʌ̀nsɜ́rtəntij ɔr pɑ́rʃəl trúwθ, sɪ́mɪlər tə háw hjúwmən θɪ́ŋkɪŋ wɜ́rks. wɒt's ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "fʌ́zij lɒ́dʒɪk",
        "trans_WrongAnswers": [
            "bájnərij lɒ́dʒɪk",
            "díjp lɜ́rnɪŋ",
            "dəsɪ́ʒən tríjz",
            "lɪ́nijər rəɡrɛ́ʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "fʌ́zij lɒ́dʒɪk ɪz ə wej əv ríjzənɪŋ ðət mɔr klówslij mɪ́mɪks háw hjúwmənz θɪ́ŋk, rɛ́kəɡnàjzɪŋ ʌ̀nsɜ́rtəntij ənd pɑ́rʃəl trúwθs. ʌ̀nlájk trədɪ́ʃənəl lɒ́dʒɪk—wɛ́ər ən ǽnsər ɪz strɪ́ktlij trúw ɔr fɔ́ls—fʌ́zij lɒ́dʒɪk əláwz fɔr dəɡríjz əv trúwθ. ɪt's əspɛ́ʃəlij júwsfəl wɛ́n méjkɪŋ dəsɪ́ʒənz wɪð ɪ̀nkəmplíjt ɪnfərméjʃən, hɛ́lpɪŋ məʃíjnz ɒ́pərèjt ɪn sənɛ́ərijowz wɪð æ̀mbɪɡjúwɪtij ənd kɒ́mplɛks tʃɔ́jsɪz, dʒəst æz hjúwmənz ɔ́fən mʌst."
    },
    {
        "Question": "In machine learning, what do we call systems that make decisions by following explicitly defined instructions like 'if-then' rules, rather than learning patterns from data directly?",
        "RightAnswer": "Rule-Based Systems",
        "WrongAnswers": [
            "Neural Networks",
            "Reinforcement Learning Agents",
            "Decision Trees",
            "Support Vector Machines",
            "Genetic Algorithms"
        ],
        "Explanation": "Rule-based systems are like following a detailed cooking recipe—they rely on explicit 'if-then' rules set by humans to decide what to do. Instead of learning rules from data on their own, these systems strictly adhere to predefined instructions. They are typically easy to interpret but might struggle to adapt when facing new, unfamiliar situations.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt dúw wij kɔ́l sɪ́stəmz ðət méjk dəsɪ́ʒənz baj fɒ́lowɪŋ əksplɪ́sɪtlij dəfájnd ɪnstrʌ́kʃənz lájk 'ɪf-ðɛn' rúwlz, rǽðər ðʌn lɜ́rnɪŋ pǽtərnz frəm déjtə dɪərɛ́klij?",
        "trans_RightAnswer": "rúwl-béjst sɪ́stəmz",
        "trans_WrongAnswers": [
            "nʊ́rəl nɛ́twɜ̀rks",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ éjdʒənts",
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "dʒənɛ́tɪk ǽlɡərɪ̀ðəmz"
        ],
        "trans_Explanation": "rúwl-béjst sɪ́stəmz ɑr lájk fɒ́lowɪŋ ə dətéjld kʊ́kɪŋ rɛ́sɪpij—ðej rəláj ɒn əksplɪ́sɪt 'ɪf-ðɛn' rúwlz sɛ́t baj hjúwmənz tə dəsájd wɒt tə dúw. ɪnstɛ́d əv lɜ́rnɪŋ rúwlz frəm déjtə ɒn ðɛər ówn, ðijz sɪ́stəmz strɪ́ktlij ədhɪ́ər tə prìjdəfájnd ɪnstrʌ́kʃənz. ðej ɑr tɪ́pɪkəlij íjzij tə ɪntɜ́rprət bʌt majt strʌ́ɡəl tə ədǽpt wɛ́n féjsɪŋ núw, ʌ̀nfəmɪ́ljər sɪ̀tʃuwéjʃənz."
    },
    {
        "Question": "Which machine learning method allows an item to belong to multiple groups simultaneously, each with varying degrees of membership rather than being tied strictly to a single group?",
        "RightAnswer": "Fuzzy Clustering",
        "WrongAnswers": [
            "Hierarchical Clustering",
            "Decision Trees",
            "Linear Regression",
            "Support Vector Machines",
            "Principal Component Analysis"
        ],
        "Explanation": "Fuzzy Clustering is a method used in machine learning where data points aren't forced into a single category. Instead, points can partially belong to several groups, each with a degree of membership. Imagine organizing a large music library—one song could fit partly into 'rock', partly into 'jazz', and even partly into 'blues', rather than being forced into just one exclusive label. This approach mirrors human thinking more closely by recognizing complex, overlapping relationships in data.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ mɛ́θəd əláwz ən ájtəm tə bəlɔ́ŋ tə mʌ́ltɪpəl ɡrúwps sàjməltéjnijəslij, ijtʃ wɪð vɛ́ərijɪŋ dəɡríjz əv mɛ́mbərʃɪ̀p rǽðər ðʌn bíjɪŋ tájd strɪ́ktlij tə ə sɪ́ŋɡəl ɡrúwp?",
        "trans_RightAnswer": "fʌ́zij klʌ́stərɪŋ",
        "trans_WrongAnswers": [
            "hàjərɑ́rkɪkəl klʌ́stərɪŋ",
            "dəsɪ́ʒən tríjz",
            "lɪ́nijər rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "fʌ́zij klʌ́stərɪŋ ɪz ə mɛ́θəd júwzd ɪn məʃíjn lɜ́rnɪŋ wɛ́ər déjtə pɔ́jnts ɑrənt fɔ́rst ɪntə ə sɪ́ŋɡəl kǽtəɡɔ̀rij. ɪnstɛ́d, pɔ́jnts kən pɑ́rʃəlij bəlɔ́ŋ tə sɛ́vərəl ɡrúwps, ijtʃ wɪð ə dəɡríj əv mɛ́mbərʃɪ̀p. ɪmǽdʒɪn ɔ́rɡənàjzɪŋ ə lɑ́rdʒ mjúwzɪk lájbrɛərìj—wʌ́n sɔ́ŋ kʊ́d fɪ́t pɑ́rtlij ɪntə 'rɒ́k', pɑ́rtlij ɪntə 'dʒǽz', ənd íjvən pɑ́rtlij ɪntə 'blúwz', rǽðər ðʌn bíjɪŋ fɔ́rst ɪntə dʒəst wʌ́n əksklúwsɪv léjbəl. ðɪs əprówtʃ mɪ́ərərz hjúwmən θɪ́ŋkɪŋ mɔr klówslij baj rɛ́kəɡnàjzɪŋ kɒ́mplɛks, ówvərlæ̀pɪŋ rəléjʃənʃɪ̀ps ɪn déjtə."
    },
    {
        "Question": "What term describes a type of machine learning approach that focuses on finding patterns within data using probability and statistics to predict outcomes or reveal insights?",
        "RightAnswer": "Statistical Learning",
        "WrongAnswers": [
            "Deep Learning",
            "Reinforcement Learning",
            "Unsupervised Learning",
            "Neural Networks",
            "Evolutionary Algorithms"
        ],
        "Explanation": "Think of statistical learning as detective work where you sift through data to spot patterns and relationships. By using statistical tools and probability, it allows us to see insights or predict outcomes based on previous experiences. Unlike more complex approaches (such as neural networks), statistical learning methods emphasize simpler models, explainability, and gain insights through clear, mathematically supported patterns.",
        "trans_Question": "wɒt tɜ́rm dəskrájbz ə tájp əv məʃíjn lɜ́rnɪŋ əprówtʃ ðət fówkəsɪz ɒn fájndɪŋ pǽtərnz wɪðɪ́n déjtə júwzɪŋ prɒ̀bəbɪ́lɪtij ənd stətɪ́stɪks tə prədɪ́kt áwtkʌ̀mz ɔr rəvíjl ɪ́nsàjts?",
        "trans_RightAnswer": "stətɪ́stɪkəl lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "díjp lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "nʊ́rəl nɛ́twɜ̀rks",
            "ɛ̀vəlúwʃənɛ̀ərij ǽlɡərɪ̀ðəmz"
        ],
        "trans_Explanation": "θɪ́ŋk əv stətɪ́stɪkəl lɜ́rnɪŋ æz dətɛ́ktɪv wɜ́rk wɛ́ər juw sɪ́ft θrúw déjtə tə spɒ́t pǽtərnz ənd rəléjʃənʃɪ̀ps. baj júwzɪŋ stətɪ́stɪkəl túwlz ənd prɒ̀bəbɪ́lɪtij, ɪt əláwz ʌs tə síj ɪ́nsàjts ɔr prədɪ́kt áwtkʌ̀mz béjst ɒn príjvijəs əkspɪ́ərijənsijz. ʌ̀nlájk mɔr kɒ́mplɛks əprówtʃɪz (sʌtʃ æz nʊ́rəl nɛ́twɜ̀rks), stətɪ́stɪkəl lɜ́rnɪŋ mɛ́θədz ɛ́mfəsajz sɪ́mplər mɒ́dəlz, ɪksplèjnəbɪ́lətij, ənd ɡéjn ɪ́nsàjts θrúw klɪ́ər, mæ̀θəmǽtɪkəlij səpɔ́rtɪd pǽtərnz."
    },
    {
        "Question": "In machine learning, which concept involves figuring out whether one event or action actually leads to another, rather than just noticing they're connected?",
        "RightAnswer": "Causal Inference",
        "WrongAnswers": [
            "Feature Engineering",
            "Correlation Analysis",
            "Clustering Algorithms",
            "Dimensionality Reduction",
            "Supervised Learning"
        ],
        "Explanation": "Causal inference is all about understanding if one thing genuinely causes another—not just noticing they're linked. Imagine seeing ice cream sales increase alongside sunscreen usage. Rather than simply seeing they're related, causal inference tries to figure out whether one directly causes the other (spoiler: it doesn't—sunny weather causes both!). Machine learning often needs this technique to make especially reliable predictions and decisions.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ kɒ́nsɛpt ɪnvɒ́lvz fɪ́ɡjərɪŋ awt wɛ́ðər wʌ́n əvɛ́nt ɔr ǽkʃən ǽktʃùwəlij líjdz tə ənʌ́ðər, rǽðər ðʌn dʒəst nówtɪsɪŋ ðɛ́ər kənɛ́ktɪd?",
        "trans_RightAnswer": "kɔ́zəl ɪ́nfərəns",
        "trans_WrongAnswers": [
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "kɔ̀rəléjʃən ənǽlɪsɪs",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "súwpərvàjzd lɜ́rnɪŋ"
        ],
        "trans_Explanation": "kɔ́zəl ɪ́nfərəns ɪz ɔl əbawt ʌ̀ndərstǽndɪŋ ɪf wʌ́n θɪ́ŋ dʒénjuwɪnlij kɒ́zɪz ənʌ́ðər—nɒt dʒəst nówtɪsɪŋ ðɛ́ər lɪ́ŋkt. ɪmǽdʒɪn síjɪŋ ájs kríjm séjlz ɪnkríjs əlɔ́ŋsájd sʌ́nskrijn júwsɪdʒ. rǽðər ðʌn sɪ́mplij síjɪŋ ðɛ́ər rəléjtɪd, kɔ́zəl ɪ́nfərəns trájz tə fɪ́ɡjər awt wɛ́ðər wʌ́n dɪərɛ́klij kɒ́zɪz ðə ʌ́ðər (spɔ́jlər: ɪt dʌ́zənt—sʌ́nij wɛ́ðər kɒ́zɪz bówθ!). məʃíjn lɜ́rnɪŋ ɔ́fən níjdz ðɪs tɛkníjk tə méjk əspɛ́ʃəlij rəlájəbəl prədɪ́kʃənz ənd dəsɪ́ʒənz."
    },
    {
        "Question": "In machine learning, what's the name given to methods that represent and analyze complex relationships using nodes and edges, making it easier to visualize dependencies between random variables?",
        "RightAnswer": "Graphical Models",
        "WrongAnswers": [
            "Neural Networks",
            "Decision Trees",
            "Support Vector Machines",
            "Gradient Boosting Machines",
            "Reinforcement Learning"
        ],
        "Explanation": "Graphical models are diagram-based representations used in machine learning to clearly visualize dependencies and relationships between random variables. Imagine them as maps that help us see how different parts of a system interact or influence each other. By representing variables as nodes (or circles) and the relationships as edges (or connecting lines), graphical models simplify complex probability calculations and make it easier to understand and analyze intricate relationships within data.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt's ðə néjm ɡɪ́vən tə mɛ́θədz ðət rɛ̀prəzɛ́nt ənd ǽnəlàjz kɒ́mplɛks rəléjʃənʃɪ̀ps júwzɪŋ nówdz ənd ɛ́dʒɪz, méjkɪŋ ɪt íjzijər tə vɪ́ʒwəlàjz dəpɛ́ndənsijz bijtwíjn rǽndəm vɛ́ərijəbəlz?",
        "trans_RightAnswer": "ɡrǽfɪkəl mɒ́dəlz",
        "trans_WrongAnswers": [
            "nʊ́rəl nɛ́twɜ̀rks",
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "ɡréjdijənt búwstɪŋ məʃíjnz",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ɡrǽfɪkəl mɒ́dəlz ɑr dájəɡræ̀m-béjst rɛ̀prəzəntéjʃənz júwzd ɪn məʃíjn lɜ́rnɪŋ tə klɪ́ərlij vɪ́ʒwəlàjz dəpɛ́ndənsijz ənd rəléjʃənʃɪ̀ps bijtwíjn rǽndəm vɛ́ərijəbəlz. ɪmǽdʒɪn ðɛm æz mǽps ðət hɛ́lp ʌs síj háw dɪ́fərənt pɑ́rts əv ə sɪ́stəm ɪ̀ntərǽkt ɔr ɪ́nfluwəns ijtʃ ʌ́ðər. baj rɛ̀prəzɛ́ntɪŋ vɛ́ərijəbəlz æz nówdz (ɔr sɜ́rkəlz) ənd ðə rəléjʃənʃɪ̀ps æz ɛ́dʒɪz (ɔr kənɛ́ktɪŋ lájnz), ɡrǽfɪkəl mɒ́dəlz sɪ́mpləfaj kɒ́mplɛks prɒ̀bəbɪ́lɪtij kæ̀lkjəléjʃənz ənd méjk ɪt íjzijər tə ʌ̀ndərstǽnd ənd ǽnəlàjz ɪ́ntrɪkət rəléjʃənʃɪ̀ps wɪðɪ́n déjtə."
    },
    {
        "Question": "In machine learning, what's the name of the graphical tool that helps us represent how various events and variables influence each other using probabilities?",
        "RightAnswer": "Bayesian Networks",
        "WrongAnswers": [
            "Neural Decision Trees",
            "Support Vector Graphs",
            "Gradient Boosting Diagrams",
            "K-Means Charts",
            "Reinforcement Maps"
        ],
        "Explanation": "Bayesian Networks are simply diagrams that help machine learning models think probabilistically. They visually represent relationships between variables, clearly showing which factors rely on or influence others. Imagine a network of nodes (which represent events or variables) connected by arrows indicating how knowing one thing affects the likelihood of another—just like the intuitive thinking we do when guessing outcomes based on what we already know. This makes Bayesian Networks a powerful tool in AI systems, helping them handle uncertainty and make smarter predictions.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt's ðə néjm əv ðə ɡrǽfɪkəl túwl ðət hɛ́lps ʌs rɛ̀prəzɛ́nt háw vɛ́ərijəs əvɛ́nts ənd vɛ́ərijəbəlz ɪ́nfluwəns ijtʃ ʌ́ðər júwzɪŋ prɒ̀bəbɪ́lɪtìjz?",
        "trans_RightAnswer": "béjʒən nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "nʊ́rəl dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər ɡrǽfs",
            "ɡréjdijənt búwstɪŋ dájəɡræ̀mz",
            "k-míjnz tʃɑ́rts",
            "rìjɪnfɔ́rsmənt mǽps"
        ],
        "trans_Explanation": "béjʒən nɛ́twɜ̀rks ɑr sɪ́mplij dájəɡræ̀mz ðət hɛ́lp məʃíjn lɜ́rnɪŋ mɒ́dəlz θɪ́ŋk prɒ̀bəbɪlɪ́stɪklij. ðej vɪ́ʒwəlij rɛ̀prəzɛ́nt rəléjʃənʃɪ̀ps bijtwíjn vɛ́ərijəbəlz, klɪ́ərlij ʃówɪŋ wɪ́tʃ fǽktərz rəláj ɒn ɔr ɪ́nfluwəns ʌ́ðərz. ɪmǽdʒɪn ə nɛ́twɜ̀rk əv nówdz (wɪ́tʃ rɛ̀prəzɛ́nt əvɛ́nts ɔr vɛ́ərijəbəlz) kənɛ́ktɪd baj ǽrowz ɪ́ndɪkèjtɪŋ háw nówɪŋ wʌ́n θɪ́ŋ əfɛ́kts ðə lájklijhʊ̀d əv ənʌ́ðər—dʒəst lájk ðə ɪntúwɪtɪv θɪ́ŋkɪŋ wij dúw wɛ́n ɡɛ́sɪŋ áwtkʌ̀mz béjst ɒn wɒt wij ɔ̀lrɛ́dij nów. ðɪs méjks béjʒən nɛ́twɜ̀rks ə páwərfəl túwl ɪn AI sɪ́stəmz, hɛ́lpɪŋ ðɛm hǽndəl ʌ̀nsɜ́rtəntij ənd méjk smɑ́rtər prədɪ́kʃənz."
    },
    {
        "Question": "Which concept in machine learning involves modeling systems that change or evolve over time, such as tracking weather patterns or speech recognition across several time points?",
        "RightAnswer": "Dynamic Bayesian Networks",
        "WrongAnswers": [
            "Gradient Boosting Machines",
            "Neural Style Transfer",
            "Support Vector Machines",
            "Batch Normalization",
            "Convolutional Neural Networks"
        ],
        "Explanation": "Dynamic Bayesian Networks (DBNs) are machine learning models specialized in capturing systems that evolve or change over time. Imagine trying to predict the weather, track a moving object, or recognize speech sequences — DBNs allow us to model the connections and influences between variables at different time steps. They're essentially flexible and powerful tools for breaking down complex, evolving processes into simpler, interconnected events over a series of time points.",
        "trans_Question": "wɪ́tʃ kɒ́nsɛpt ɪn məʃíjn lɜ́rnɪŋ ɪnvɒ́lvz mɒ́dəlɪ̀ŋ sɪ́stəmz ðət tʃéjndʒ ɔr əvɒ́lv ówvər tájm, sʌtʃ æz trǽkɪŋ wɛ́ðər pǽtərnz ɔr spíjtʃ rɛ̀kəɡnɪ́ʃən əkrɔ́s sɛ́vərəl tájm pɔ́jnts?",
        "trans_RightAnswer": "dajnǽmɪk béjʒən nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ məʃíjnz",
            "nʊ́rəl stájl trǽnsfər",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "dajnǽmɪk béjʒən nɛ́twɜ̀rks (DBNz) ɑr məʃíjn lɜ́rnɪŋ mɒ́dəlz spɛ́ʃəlàjzd ɪn kǽptʃərɪŋ sɪ́stəmz ðət əvɒ́lv ɔr tʃéjndʒ ówvər tájm. ɪmǽdʒɪn trájɪŋ tə prədɪ́kt ðə wɛ́ðər, trǽk ə múwvɪŋ ɒ́bdʒəkt, ɔr rɛ́kəɡnàjz spíjtʃ síjkwənsɪz — DBNz əláw ʌs tə mɒ́dəl ðə kənɛ́kʃənz ənd ɪ́nfluwənsɪz bijtwíjn vɛ́ərijəbəlz æt dɪ́fərənt tájm stɛ́ps. ðɛ́ər əsɛ́nʃəlij flɛ́ksɪbəl ənd páwərfəl túwlz fɔr bréjkɪŋ dawn kɒ́mplɛks, əvɒ́lvɪŋ prɒ́sɛsɪz ɪntə sɪ́mplər, ɪ̀ntərkənɛ́ktɪd əvɛ́nts ówvər ə sɪ́ərijz əv tájm pɔ́jnts."
    },
    {
        "Question": "In machine learning, which approach uses diagrams composed of circles (nodes) representing random variables and arrows (edges) to capture the relationships and interdependencies between those variables, enabling clearer understanding and efficient reasoning about uncertainty?",
        "RightAnswer": "Probabilistic Graphical Models",
        "WrongAnswers": [
            "Support Vector Machines",
            "Convolutional Neural Networks",
            "Gradient Boosting Trees",
            "K-Means Clustering",
            "Principal Component Analysis"
        ],
        "Explanation": "Probabilistic Graphical Models are visualization tools and methods that represent complex probabilistic relationships between different variables using graphs. Imagine visually mapping out variables as nodes and their relationships as arrows—like a mind-map illustrating uncertainty and dependencies. This helps simplify complicated statistical reasoning, makes it intuitive to reason about uncertainty, and allows efficient prediction and decision-making processes within machine learning tasks.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ əprówtʃ júwsɪz dájəɡræ̀mz kəmpówzd əv sɜ́rkəlz (nówdz) rɛ̀prəzɛ́ntɪŋ rǽndəm vɛ́ərijəbəlz ənd ǽrowz (ɛ́dʒɪz) tə kǽptʃər ðə rəléjʃənʃɪ̀ps ənd ɪ̀ntərdəpɛ́ndənsijz bijtwíjn ðowz vɛ́ərijəbəlz, ɛnéjbəlɪŋ klɪ́ərər ʌ̀ndərstǽndɪŋ ənd əfɪ́ʃənt ríjzənɪŋ əbawt ʌ̀nsɜ́rtəntij?",
        "trans_RightAnswer": "prɒ̀bəbɪlɪ́stɪk ɡrǽfɪkəl mɒ́dəlz",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "ɡréjdijənt búwstɪŋ tríjz",
            "k-míjnz klʌ́stərɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "prɒ̀bəbɪlɪ́stɪk ɡrǽfɪkəl mɒ́dəlz ɑr vɪ̀ʒwəlɪzéjʃən túwlz ənd mɛ́θədz ðət rɛ̀prəzɛ́nt kɒ́mplɛks prɒ̀bəbɪlɪ́stɪk rəléjʃənʃɪ̀ps bijtwíjn dɪ́fərənt vɛ́ərijəbəlz júwzɪŋ ɡrǽfs. ɪmǽdʒɪn vɪ́ʒwəlij mǽpɪŋ awt vɛ́ərijəbəlz æz nówdz ənd ðɛər rəléjʃənʃɪ̀ps æz ǽrowz—lájk ə májnd-mǽp ɪ́ləstrèjtɪŋ ʌ̀nsɜ́rtəntij ənd dəpɛ́ndənsijz. ðɪs hɛ́lps sɪ́mpləfaj kɒ́mplɪkèjtɪd stətɪ́stɪkəl ríjzənɪŋ, méjks ɪt ɪntúwɪtɪv tə ríjzən əbawt ʌ̀nsɜ́rtəntij, ənd əláwz əfɪ́ʃənt prədɪ́kʃən ənd dəsɪ́ʒən-méjkɪŋ prɒ́sɛsɪz wɪðɪ́n məʃíjn lɜ́rnɪŋ tǽsks."
    },
    {
        "Question": "What is the term for machine learning models that uncover hidden or unobserved factors influencing observed data, helping to provide deeper understanding and structure to the data?",
        "RightAnswer": "Latent Variable Models",
        "WrongAnswers": [
            "Supervised Learning Algorithms",
            "Feature Scaling Techniques",
            "Gradient Boosting Methods",
            "Convolutional Neural Networks",
            "Data Augmentation Strategies"
        ],
        "Explanation": "Latent Variable Models are types of machine learning approaches designed to discover and represent hidden (latent) underlying structures or factors within observed data. Imagine trying to understand human mood using data about people's social activities; certain hidden factors like stress or health might shape these activities, although we never directly measure them. Latent variable models help find and explain these hidden influences, allowing for richer and more insightful interpretations of data.",
        "trans_Question": "wɒt ɪz ðə tɜ́rm fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz ðət ʌ̀nkʌ́vər hɪ́dən ɔr ʌ̀nəbzɜ́rvd fǽktərz ɪ́nfluwənsɪŋ əbzɜ́rvd déjtə, hɛ́lpɪŋ tə prəvájd díjpər ʌ̀ndərstǽndɪŋ ənd strʌ́ktʃər tə ðə déjtə?",
        "trans_RightAnswer": "léjtənt vɛ́ərijəbəl mɒ́dəlz",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ ǽlɡərɪ̀ðəmz",
            "fíjtʃər skéjlɪŋ tɛkníjks",
            "ɡréjdijənt búwstɪŋ mɛ́θədz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "déjtə ɒ̀ɡmɛntéjʃən strǽtədʒijz"
        ],
        "trans_Explanation": "léjtənt vɛ́ərijəbəl mɒ́dəlz ɑr tájps əv məʃíjn lɜ́rnɪŋ əprówtʃɪz dəzájnd tə dɪskʌ́vər ənd rɛ̀prəzɛ́nt hɪ́dən (léjtənt) ʌ̀ndərlájɪŋ strʌ́ktʃərz ɔr fǽktərz wɪðɪ́n əbzɜ́rvd déjtə. ɪmǽdʒɪn trájɪŋ tə ʌ̀ndərstǽnd hjúwmən múwd júwzɪŋ déjtə əbawt píjpəl'z sówʃəl æktɪ́vɪtijz; sɜ́rtən hɪ́dən fǽktərz lájk strɛ́s ɔr hɛ́lθ majt ʃéjp ðijz æktɪ́vɪtijz, ɔ̀lðów wij nɛ́vər dɪərɛ́klij mɛ́ʒər ðɛm. léjtənt vɛ́ərijəbəl mɒ́dəlz hɛ́lp fájnd ənd əkspléjn ðijz hɪ́dən ɪ́nfluwənsɪz, əláwɪŋ fɔr rɪ́tʃər ənd mɔr ɪ́nsàjtfəl ɪntɜ̀rprətéjʃənz əv déjtə."
    },
    {
        "Question": "Imagine you're exploring a large dataset filled with several related variables, such as people's responses to survey questions. You want to identify a smaller set of underlying concepts or hidden traits (like personality types, social attitudes, etc.) that explain the relationships between these variables. Which machine learning method would be your best tool to reduce complexity by grouping widespread variables into fewer underlying factors?",
        "RightAnswer": "Factor Analysis",
        "WrongAnswers": [
            "Support Vector Machine",
            "Random Forest",
            "Linear Regression",
            "K-Means Clustering",
            "Gradient Boosting"
        ],
        "Explanation": "Factor Analysis is a statistical technique frequently used in machine learning and data science that helps simplify complex datasets by uncovering underlying patterns or latent factors. Think of it as a detective method: it looks at many variables (like responses in a survey) and finds common 'hidden threads' connecting them. This lets you group multiple related variables under simpler, meaningful concepts. It's especially useful when exploring data and seeking hidden structures or dimensions beneath numerous observed variables.",
        "trans_Question": "ɪmǽdʒɪn júwr əksplɔ́rɪŋ ə lɑ́rdʒ déjtəsɛ̀t fɪ́ld wɪð sɛ́vərəl rəléjtɪd vɛ́ərijəbəlz, sʌtʃ æz píjpəl'z rəspɒ́nsɪz tə sɜ́rvej kwɛ́stʃənz. juw wɒ́nt tə ajdɛ́ntɪfàj ə smɔ́lər sɛ́t əv ʌ̀ndərlájɪŋ kɒ́nsɛpts ɔr hɪ́dən tréjts (lájk pɜ̀rsənǽlɪtij tájps, sówʃəl ǽtɪtùwdz, ɛ̀tsɛ́tərə.) ðət əkspléjn ðə rəléjʃənʃɪ̀ps bijtwíjn ðijz vɛ́ərijəbəlz. wɪ́tʃ məʃíjn lɜ́rnɪŋ mɛ́θəd wʊd bij jɔr bɛ́st túwl tə rədjúws kəmplɛ́ksɪtij baj ɡrúwpɪŋ wájdsprɛ́d vɛ́ərijəbəlz ɪntə fjúwər ʌ̀ndərlájɪŋ fǽktərz?",
        "trans_RightAnswer": "fǽktər ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "səpɔ́rt vɛ́ktər məʃíjn",
            "rǽndəm fɔ́rəst",
            "lɪ́nijər rəɡrɛ́ʃən",
            "k-míjnz klʌ́stərɪŋ",
            "ɡréjdijənt búwstɪŋ"
        ],
        "trans_Explanation": "fǽktər ənǽlɪsɪs ɪz ə stətɪ́stɪkəl tɛkníjk fríjkwəntlij júwzd ɪn məʃíjn lɜ́rnɪŋ ənd déjtə sájəns ðət hɛ́lps sɪ́mpləfaj kɒ́mplɛks déjtəsɛ̀ts baj ʌ̀nkʌ́vərɪŋ ʌ̀ndərlájɪŋ pǽtərnz ɔr léjtənt fǽktərz. θɪ́ŋk əv ɪt æz ə dətɛ́ktɪv mɛ́θəd: ɪt lʊ́ks æt mɛ́nij vɛ́ərijəbəlz (lájk rəspɒ́nsɪz ɪn ə sɜ́rvej) ənd fájndz kɒ́mən 'hɪ́dən θrɛ́dz' kənɛ́ktɪŋ ðɛm. ðɪs lɛts juw ɡrúwp mʌ́ltɪpəl rəléjtɪd vɛ́ərijəbəlz ʌ́ndər sɪ́mplər, míjnɪŋfəl kɒ́nsɛpts. ɪt's əspɛ́ʃəlij júwsfəl wɛ́n əksplɔ́rɪŋ déjtə ənd síjkɪŋ hɪ́dən strʌ́ktʃərz ɔr dajmɛ́nʃənz bəníjθ njúwmərəs əbzɜ́rvd vɛ́ərijəbəlz."
    },
    {
        "Question": "Imagine you're at a busy café, hearing many conversations at once. To clearly understand what each specific person is saying, you need a way to separate overlapping speech into distinct voices. Which machine learning technique is most similar to this scenario, helping you uncover independent sources of information hidden within noisy mixed signals?",
        "RightAnswer": "Independent Component Analysis",
        "WrongAnswers": [
            "Principal Component Analysis",
            "Linear Discriminant Analysis",
            "Random Forest Algorithm",
            "K-Means Clustering",
            "Support Vector Machines"
        ],
        "Explanation": "Independent Component Analysis (ICA) is like the process of separating mixed conversations into distinct voices. It takes combined signals—like overlapping voices or blended music instruments—and separates them into individual original sources, assuming each source is fundamentally independent. In machine learning, ICA helps reveal hidden, independent factors within mixed data, making it extremely useful in fields such as audio processing, neuroscience, and where understanding distinct sources helps make clearer sense of the data at hand.",
        "trans_Question": "ɪmǽdʒɪn júwr æt ə bɪ́zij kæfé, híjərɪŋ mɛ́nij kɒ̀nvərséjʃənz æt wʌ́ns. tə klɪ́ərlij ʌ̀ndərstǽnd wɒt ijtʃ spəsɪ́fɪk pɜ́rsən ɪz séjɪŋ, juw níjd ə wej tə sɛ́pərət ówvərlæ̀pɪŋ spíjtʃ ɪntə dɪstɪ́ŋkt vɔ́jsɪz. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪz mówst sɪ́mɪlər tə ðɪs sənɛ́ərijow, hɛ́lpɪŋ juw ʌ̀nkʌ́vər ɪndəpɛ́ndənt sɔ́rsɪz əv ɪnfərméjʃən hɪ́dən wɪðɪ́n nɔ́jzij mɪ́kst sɪ́ɡnəlz?",
        "trans_RightAnswer": "ɪndəpɛ́ndənt kəmpównənt ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "lɪ́nijər dɪskrɪ́mɪnət ənǽlɪsɪs",
            "rǽndəm fɔ́rəst ǽlɡərɪ̀ðəm",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjnz"
        ],
        "trans_Explanation": "ɪndəpɛ́ndənt kəmpównənt ənǽlɪsɪs (ICA) ɪz lájk ðə prɒ́sɛs əv sɛ́pərèjtɪŋ mɪ́kst kɒ̀nvərséjʃənz ɪntə dɪstɪ́ŋkt vɔ́jsɪz. ɪt téjks kəmbájnd sɪ́ɡnəlz—lájk ówvərlæ̀pɪŋ vɔ́jsɪz ɔr blɛ́ndɪd mjúwzɪk ɪ́nstrəmənts—ənd sɛ́pərèjts ðɛm ɪntə ɪndɪvɪ́dʒəwəl ərɪ́dʒɪnəl sɔ́rsɪz, əsúwmɪŋ ijtʃ sɔ́rs ɪz fʌ̀ndəmɛ́ntəlij ɪndəpɛ́ndənt. ɪn məʃíjn lɜ́rnɪŋ, ICA hɛ́lps rəvíjl hɪ́dən, ɪndəpɛ́ndənt fǽktərz wɪðɪ́n mɪ́kst déjtə, méjkɪŋ ɪt əkstríjmlij júwsfəl ɪn fíjldz sʌtʃ æz ɒ́dijòw prɒ́sɛsɪŋ, nʊ̀rowsájəns, ənd wɛ́ər ʌ̀ndərstǽndɪŋ dɪstɪ́ŋkt sɔ́rsɪz hɛ́lps méjk klɪ́ərər sɛ́ns əv ðə déjtə æt hǽnd."
    },
    {
        "Question": "You're building a prediction model for house prices, but you notice that individual models like decision trees and neural networks each have their own flaws. You decide to combine predictions from multiple different models and calculate their average outcomes to achieve better overall accuracy. What is this approach called?",
        "RightAnswer": "Ensemble Averaging",
        "WrongAnswers": [
            "Gradient Descent",
            "Model Normalization",
            "Overfitting Regularization",
            "Hyperparameter Tuning",
            "Feature Scaling"
        ],
        "Explanation": "Ensemble Averaging is like seeking multiple opinions before making a big decision. Instead of relying on just one model, you combine the predictions from several models and take their average. This way, you benefit from the strengths of each model while reducing the chance of any one model's mistakes dominating your final prediction. It's similar to averaging advice from multiple experts: you're usually wiser taking a balanced view rather than trusting just one perspective!",
        "trans_Question": "júwr bɪ́ldɪŋ ə prədɪ́kʃən mɒ́dəl fɔr haws prájsɪz, bʌt juw nówtɪs ðət ɪndɪvɪ́dʒəwəl mɒ́dəlz lájk dəsɪ́ʒən tríjz ənd nʊ́rəl nɛ́twɜ̀rks ijtʃ həv ðɛər ówn flɔ́z. juw dəsájd tə kɒ́mbajn prədɪ́kʃənz frəm mʌ́ltɪpəl dɪ́fərənt mɒ́dəlz ənd kǽlkjəlèjt ðɛər ǽvərɪdʒ áwtkʌ̀mz tə ətʃíjv bɛ́tər ówvərɔ̀l ǽkjərəsij. wɒt ɪz ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "ɒnsɒ́mbəl ǽvrɪdʒɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "mɒ́dəl nɔ̀rməlɪzéjʃən",
            "òwvərfɪ́tɪŋ rèɡjəlɛ̀ərɪzéjʃən",
            "hàjpərpǽrəmətər túwnɪŋ",
            "fíjtʃər skéjlɪŋ"
        ],
        "trans_Explanation": "ɒnsɒ́mbəl ǽvrɪdʒɪŋ ɪz lájk síjkɪŋ mʌ́ltɪpəl əpɪ́njənz bəfɔ́r méjkɪŋ ə bɪ́ɡ dəsɪ́ʒən. ɪnstɛ́d əv rəlájɪŋ ɒn dʒəst wʌ́n mɒ́dəl, juw kɒ́mbajn ðə prədɪ́kʃənz frəm sɛ́vərəl mɒ́dəlz ənd téjk ðɛər ǽvərɪdʒ. ðɪs wej, juw bɛ́nəfɪt frəm ðə strɛ́ŋθs əv ijtʃ mɒ́dəl wájl rədjúwsɪŋ ðə tʃǽns əv ɛ́nij wʌ́n mɒ́dəl'z mɪstéjks dɒ́mɪnèjtɪŋ jɔr fájnəl prədɪ́kʃən. ɪt's sɪ́mɪlər tə ǽvrɪdʒɪŋ ædvájs frəm mʌ́ltɪpəl ɛ́kspərts: júwr júwʒəlij wájzər téjkɪŋ ə bǽlənst vjúw rǽðər ðʌn trʌ́stɪŋ dʒəst wʌ́n pərspɛ́ktɪv!"
    },
    {
        "Question": "In machine learning, there's an ensemble technique where multiple models are first trained individually, and then their predictions become inputs for another model, which learns how to best combine these predictions for improved accuracy. What term describes this 'team-of-teams' method?",
        "RightAnswer": "Stacking",
        "WrongAnswers": [
            "Boosting",
            "Bagging",
            "Pruning",
            "Regularization",
            "Gradient Descent"
        ],
        "Explanation": "Think of stacking as assembling an expert panel: first, several independent 'expert' models each make their own predictions. Then, these predictions serve as input for a final 'meta-model' that learns the optimal way to trust each expert. This process—stacking—often results in better overall performance than relying on a single model alone, as it leverages the individual strengths of each base model.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ən ɒnsɒ́mbəl tɛkníjk wɛ́ər mʌ́ltɪpəl mɒ́dəlz ɑr fɜ́rst tréjnd ɪndɪvɪ́dʒəlij, ənd ðɛn ðɛər prədɪ́kʃənz bəkʌ́m ɪ́npʊ̀ts fɔr ənʌ́ðər mɒ́dəl, wɪ́tʃ lɜ́rnz háw tə bɛ́st kɒ́mbajn ðijz prədɪ́kʃənz fɔr ɪmprúwvd ǽkjərəsij. wɒt tɜ́rm dəskrájbz ðɪs 'tíjm-əv-tíjmz' mɛ́θəd?",
        "trans_RightAnswer": "stǽkɪŋ",
        "trans_WrongAnswers": [
            "búwstɪŋ",
            "bǽɡɪŋ",
            "prúwnɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "θɪ́ŋk əv stǽkɪŋ æz əsɛ́mbəlɪŋ ən ɛ́kspərt pǽnəl: fɜ́rst, sɛ́vərəl ɪndəpɛ́ndənt 'ɛ́kspərt' mɒ́dəlz ijtʃ méjk ðɛər ówn prədɪ́kʃənz. ðɛn, ðijz prədɪ́kʃənz sɜ́rv æz ɪ́npʊ̀t fɔr ə fájnəl 'mɛ́tə-mɒ́dəl' ðət lɜ́rnz ðə ɒ́ptɪməl wej tə trʌ́st ijtʃ ɛ́kspərt. ðɪs prɒ́sɛs—stǽkɪŋ—ɔ́fən rəzʌ́lts ɪn bɛ́tər ówvərɔ̀l pərfɔ́rməns ðʌn rəlájɪŋ ɒn ə sɪ́ŋɡəl mɒ́dəl əlówn, æz ɪt lɛ́vərɪdʒɪz ðə ɪndɪvɪ́dʒəwəl strɛ́ŋθs əv ijtʃ béjs mɒ́dəl."
    },
    {
        "Question": "In machine learning, when we ask multiple different models to make predictions separately and then choose the best answer based on majority consensus or combined wisdom of all these models, what is this combined model called?",
        "RightAnswer": "Voting Classifier",
        "WrongAnswers": [
            "Gradient Descent",
            "Cross Validation",
            "Feature Scaling",
            "Regularization Technique",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Think of a Voting Classifier like a panel of expert judges, each with unique viewpoints. Each 'judge' is a separate machine learning model making predictions independently. The Voting Classifier combines their individual predictions into one final decision, typically by going with the answer that most of the models agree on. This teamwork approach often creates better predictions than any single model alone, tapping into the collective wisdom and accuracy from multiple models.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n wij ǽsk mʌ́ltɪpəl dɪ́fərənt mɒ́dəlz tə méjk prədɪ́kʃənz sɛ́pərətlij ənd ðɛn tʃúwz ðə bɛ́st ǽnsər béjst ɒn mədʒɔ́rɪtij kənsɛ́nsəs ɔr kəmbájnd wɪ́zdəm əv ɔl ðijz mɒ́dəlz, wɒt ɪz ðɪs kəmbájnd mɒ́dəl kɔ́ld?",
        "trans_RightAnswer": "vówtɪŋ klǽsɪfajər",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "krɔ́s væ̀lɪdéjʃən",
            "fíjtʃər skéjlɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən tɛkníjk",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "θɪ́ŋk əv ə vówtɪŋ klǽsɪfajər lájk ə pǽnəl əv ɛ́kspərt dʒʌ́dʒɪz, ijtʃ wɪð juwnɪ́k vjúwpɔ̀jnts. ijtʃ 'dʒʌ́dʒ' ɪz ə sɛ́pərət məʃíjn lɜ́rnɪŋ mɒ́dəl méjkɪŋ prədɪ́kʃənz ɪndəpɛ́ndəntlij. ðə vówtɪŋ klǽsɪfajər kəmbájnz ðɛər ɪndɪvɪ́dʒəwəl prədɪ́kʃənz ɪntə wʌ́n fájnəl dəsɪ́ʒən, tɪ́pɪkəlij baj ɡówɪŋ wɪð ðə ǽnsər ðət mówst əv ðə mɒ́dəlz əɡríj ɒn. ðɪs tíjmwɜ̀rk əprówtʃ ɔ́fən krijéjts bɛ́tər prədɪ́kʃənz ðʌn ɛ́nij sɪ́ŋɡəl mɒ́dəl əlówn, tǽpɪŋ ɪntə ðə kəlɛ́ktɪv wɪ́zdəm ənd ǽkjərəsij frəm mʌ́ltɪpəl mɒ́dəlz."
    },
    {
        "Question": "You're training a Random Forest model and have partitioned data using bootstrapping. To evaluate the model without needing a separate validation set, you use samples left out of each tree's bootstrapped set. What term describes the evaluation approach you're using?",
        "RightAnswer": "Out-of-Bag Error",
        "WrongAnswers": [
            "Cross-Validation Error",
            "Bootstrap Bias",
            "Randomized Error Estimate",
            "Resampling Loss",
            "In-the-Bag Variance"
        ],
        "Explanation": "The Out-of-Bag (OOB) Error is a handy built-in validation technique in ensemble methods like Random Forests. Each tree in the Random Forest uses randomly selected data points to train (called bootstrap samples), leaving some data points unused—or 'out-of-bag'. These unused points can then act as a miniature validation set. Averaging results from these points lets you estimate your model's accuracy without needing separate validation data—a quick and practical way to assess your model performance.",
        "trans_Question": "júwr tréjnɪŋ ə rǽndəm fɔ́rəst mɒ́dəl ənd həv pɑrtɪ́ʃənd déjtə júwzɪŋ búwtstræ̀pɪŋ. tə əvǽljuwèjt ðə mɒ́dəl wɪðáwt níjdɪŋ ə sɛ́pərət væ̀lɪdéjʃən sɛ́t, juw juwz sǽmpəlz lɛ́ft awt əv ijtʃ tríj'z búwtstræpt sɛ́t. wɒt tɜ́rm dəskrájbz ðə əvæ̀ljuwéjʃən əprówtʃ júwr júwzɪŋ?",
        "trans_RightAnswer": "awt-əv-bǽɡ ɛ́ərər",
        "trans_WrongAnswers": [
            "krɔ́s-væ̀lɪdéjʃən ɛ́ərər",
            "búwtstræ̀p bájəs",
            "rǽndəmàjzd ɛ́ərər ɛ́stɪmèjt",
            "rijsǽmplɪŋ lɔ́s",
            "ɪn-ðə-bǽɡ vɛ́ərijəns"
        ],
        "trans_Explanation": "ðə awt-əv-bǽɡ (OOB) ɛ́ərər ɪz ə hǽndij bɪ́lt-ɪn væ̀lɪdéjʃən tɛkníjk ɪn ɒnsɒ́mbəl mɛ́θədz lájk rǽndəm fɔ́rəsts. ijtʃ tríj ɪn ðə rǽndəm fɔ́rəst júwsɪz rǽndəmlij səlɛ́ktɪd déjtə pɔ́jnts tə tréjn (kɔ́ld búwtstræ̀p sǽmpəlz), líjvɪŋ sʌm déjtə pɔ́jnts ʌ̀njúwzd—ɔr 'awt-əv-bǽɡ'. ðijz ʌ̀njúwzd pɔ́jnts kən ðɛn ǽkt æz ə mɪ́nijətʃʊ̀r væ̀lɪdéjʃən sɛ́t. ǽvrɪdʒɪŋ rəzʌ́lts frəm ðijz pɔ́jnts lɛts juw ɛ́stɪmèjt jɔr mɒ́dəl'z ǽkjərəsij wɪðáwt níjdɪŋ sɛ́pərət væ̀lɪdéjʃən déjtə—ə kwɪ́k ənd prǽktɪkəl wej tə əsɛ́s jɔr mɒ́dəl pərfɔ́rməns."
    },
    {
        "Question": "When you've trained a machine learning model, you often want to know how well it's learning by plotting its performance over time or through different amounts of training data. What's the name of the graphical representation used to show how the model improves or struggles as training progresses?",
        "RightAnswer": "Learning Curves",
        "WrongAnswers": [
            "Decision Boundaries",
            "Confusion Matrices",
            "Gradient Descent",
            "Activation Maps",
            "Feature Importance Chart"
        ],
        "Explanation": "Learning curves are visual graphs that help you understand how your machine learning model is performing as it tries to learn. Typically, they show how the model's accuracy or error rate changes as you provide it more data or train it for more cycles. By examining these curves, you can spot if your model is underfitting, overfitting, or if it needs more training data, guiding you to make better decisions about tweaking your model.",
        "trans_Question": "wɛ́n júwv tréjnd ə məʃíjn lɜ́rnɪŋ mɒ́dəl, juw ɔ́fən wɒ́nt tə nów háw wɛ́l ɪt's lɜ́rnɪŋ baj plɒ́tɪŋ ɪts pərfɔ́rməns ówvər tájm ɔr θrúw dɪ́fərənt əmáwnts əv tréjnɪŋ déjtə. wɒt's ðə néjm əv ðə ɡrǽfɪkəl rɛ̀prəzɛntéjʃən júwzd tə ʃów háw ðə mɒ́dəl ɪmprúwvz ɔr strʌ́ɡəlz æz tréjnɪŋ prɒ́ɡrɛ̀sɪz?",
        "trans_RightAnswer": "lɜ́rnɪŋ kɜ́rvz",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən báwndərijz",
            "kənfjúwʒən méjtrɪsɪz",
            "ɡréjdijənt dəsɛ́nt",
            "æ̀ktɪvéjʃən mǽps",
            "fíjtʃər ɪmpɔ́rtəns tʃɑ́rt"
        ],
        "trans_Explanation": "lɜ́rnɪŋ kɜ́rvz ɑr vɪ́ʒəwəl ɡrǽfs ðət hɛ́lp juw ʌ̀ndərstǽnd háw jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ɪz pərfɔ́rmɪŋ æz ɪt trájz tə lɜ́rn. tɪ́pɪkəlij, ðej ʃów háw ðə mɒ́dəl'z ǽkjərəsij ɔr ɛ́ərər réjt tʃéjndʒɪz æz juw prəvájd ɪt mɔr déjtə ɔr tréjn ɪt fɔr mɔr sájkəlz. baj əɡzǽmɪnɪŋ ðijz kɜ́rvz, juw kən spɒ́t ɪf jɔr mɒ́dəl ɪz ʌ̀ndərfɪ́tɪŋ, òwvərfɪ́tɪŋ, ɔr ɪf ɪt níjdz mɔr tréjnɪŋ déjtə, ɡájdɪŋ juw tə méjk bɛ́tər dəsɪ́ʒənz əbawt twíjkɪŋ jɔr mɒ́dəl."
    },
    {
        "Question": "When building machine learning models, you often assess different levels of a specific hyperparameter to find the sweet spot that balances complexity and performance. Which graphical method helps you visualize how model performance varies as you change the value of a hyperparameter?",
        "RightAnswer": "Validation Curve",
        "WrongAnswers": [
            "Learning Curve",
            "Confusion Matrix",
            "ROC Curve",
            "Cost Function",
            "Feature Importance Plot"
        ],
        "Explanation": "A validation curve is like tuning the dial on a radio to get the clearest sound possible. It visually shows how a machine learning model's accuracy changes as you adjust a specific hyperparameter—like model complexity, depth of a decision tree, or regularization strength. By looking at validation curves, you can easily spot if your model is too simple (underfitting) or too complicated (overfitting), helping you choose just the right hyperparameter setting to achieve optimal performance.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz, juw ɔ́fən əsɛ́s dɪ́fərənt lɛ́vəlz əv ə spəsɪ́fɪk hàjpərpǽrəmətər tə fájnd ðə swíjt spɒ́t ðət bǽlənsɪz kəmplɛ́ksɪtij ənd pərfɔ́rməns. wɪ́tʃ ɡrǽfɪkəl mɛ́θəd hɛ́lps juw vɪ́ʒwəlàjz háw mɒ́dəl pərfɔ́rməns vɛ́ərijz æz juw tʃéjndʒ ðə vǽljuw əv ə hàjpərpǽrəmətər?",
        "trans_RightAnswer": "væ̀lɪdéjʃən kɜ́rv",
        "trans_WrongAnswers": [
            "lɜ́rnɪŋ kɜ́rv",
            "kənfjúwʒən méjtrɪks",
            "ROC kɜ́rv",
            "kɒ́st fʌ́ŋkʃən",
            "fíjtʃər ɪmpɔ́rtəns plɒ́t"
        ],
        "trans_Explanation": "ə væ̀lɪdéjʃən kɜ́rv ɪz lájk túwnɪŋ ðə dájəl ɒn ə réjdijòw tə ɡɛt ðə klɪ́ərəst sáwnd pɒ́sɪbəl. ɪt vɪ́ʒwəlij ʃówz háw ə məʃíjn lɜ́rnɪŋ mɒ́dəl'z ǽkjərəsij tʃéjndʒɪz æz juw ədʒʌ́st ə spəsɪ́fɪk hàjpərpǽrəmətər—lájk mɒ́dəl kəmplɛ́ksɪtij, dɛ́pθ əv ə dəsɪ́ʒən tríj, ɔr rèɡjəlɛ̀ərɪzéjʃən strɛ́ŋθ. baj lʊ́kɪŋ æt væ̀lɪdéjʃən kɜ́rvz, juw kən íjzəlij spɒ́t ɪf jɔr mɒ́dəl ɪz túw sɪ́mpəl (ʌ̀ndərfɪ́tɪŋ) ɔr túw kɒ́mplɪkèjtɪd (òwvərfɪ́tɪŋ), hɛ́lpɪŋ juw tʃúwz dʒəst ðə rájt hàjpərpǽrəmətər sɛ́tɪŋ tə ətʃíjv ɒ́ptɪməl pərfɔ́rməns."
    },
    {
        "Question": "When training a machine learning model, you usually set aside some information from your original dataset as a 'testing' set to check how well your model performs on new data. What's the name given to this important step?",
        "RightAnswer": "Data Splitting",
        "WrongAnswers": [
            "Feature Extraction",
            "Model Tuning",
            "Cross-validation",
            "Data Normalization",
            "Hyperparameter Optimization"
        ],
        "Explanation": "Data splitting is the practice of dividing your data into two or more chunks, typically called training and testing data. By training your model on one portion and then testing it on another that's never been seen before, you can get an honest, unbiased idea of how well your model will likely perform when it encounters brand-new data in real life. Think of it like studying with practice problems first, and then testing yourself with unseen questions to truly assess your understanding!",
        "trans_Question": "wɛ́n tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, juw júwʒəlij sɛ́t əsájd sʌm ɪnfərméjʃən frəm jɔr ərɪ́dʒɪnəl déjtəsɛ̀t æz ə 'tɛ́stɪŋ' sɛ́t tə tʃɛ́k háw wɛ́l jɔr mɒ́dəl pərfɔ́rmz ɒn núw déjtə. wɒt's ðə néjm ɡɪ́vən tə ðɪs ɪmpɔ́rtənt stɛ́p?",
        "trans_RightAnswer": "déjtə splɪ́tɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "mɒ́dəl túwnɪŋ",
            "krɔ́s-væ̀lɪdéjʃən",
            "déjtə nɔ̀rməlɪzéjʃən",
            "hàjpərpǽrəmətər ɒptɪmɪzéjʃən"
        ],
        "trans_Explanation": "déjtə splɪ́tɪŋ ɪz ðə prǽktɪs əv dɪvájdɪŋ jɔr déjtə ɪntə túw ɔr mɔr tʃʌ́ŋks, tɪ́pɪkəlij kɔ́ld tréjnɪŋ ənd tɛ́stɪŋ déjtə. baj tréjnɪŋ jɔr mɒ́dəl ɒn wʌ́n pɔ́rʃən ənd ðɛn tɛ́stɪŋ ɪt ɒn ənʌ́ðər ðət's nɛ́vər bɪn síjn bəfɔ́r, juw kən ɡɛt ən ɒ́nəst, ʌ̀nbájəst ajdíjə əv háw wɛ́l jɔr mɒ́dəl wɪl lájklij pərfɔ́rm wɛ́n ɪt ənkáwntərz brǽnd-núw déjtə ɪn ríjəl lájf. θɪ́ŋk əv ɪt lájk stʌ́dijɪŋ wɪð prǽktɪs prɒ́bləmz fɜ́rst, ənd ðɛn tɛ́stɪŋ jɔrsɛ́lf wɪð ʌ̀nsíjn kwɛ́stʃənz tə trúwlij əsɛ́s jɔr ʌ̀ndərstǽndɪŋ!"
    },
    {
        "Question": "In machine learning, before your model makes accurate predictions on new situations, you first allow it to learn from examples you've already collected. What do you call the set of examples used to teach the model how to make predictions?",
        "RightAnswer": "Training Set",
        "WrongAnswers": [
            "Validation Set",
            "Testing Set",
            "Feature Set",
            "Output Set",
            "Evaluation Set"
        ],
        "Explanation": "Think of a training set as the 'classroom lessons' for machine learning models—it's a collection of examples where each item's correct answer is already known. The model studies these examples carefully, learning patterns and features, so it can later accurately tackle new situations or questions it hasn't seen before.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, bəfɔ́r jɔr mɒ́dəl méjks ǽkjərət prədɪ́kʃənz ɒn núw sɪ̀tʃuwéjʃənz, juw fɜ́rst əláw ɪt tə lɜ́rn frəm əɡzǽmpəlz júwv ɔ̀lrɛ́dij kəlɛ́ktɪd. wɒt dúw juw kɔ́l ðə sɛ́t əv əɡzǽmpəlz júwzd tə tíjtʃ ðə mɒ́dəl háw tə méjk prədɪ́kʃənz?",
        "trans_RightAnswer": "tréjnɪŋ sɛ́t",
        "trans_WrongAnswers": [
            "væ̀lɪdéjʃən sɛ́t",
            "tɛ́stɪŋ sɛ́t",
            "fíjtʃər sɛ́t",
            "áwtpʊ̀t sɛ́t",
            "əvæ̀ljuwéjʃən sɛ́t"
        ],
        "trans_Explanation": "θɪ́ŋk əv ə tréjnɪŋ sɛ́t æz ðə 'klǽsrùwm lɛ́sənz' fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz—ɪt's ə kəlɛ́kʃən əv əɡzǽmpəlz wɛ́ər ijtʃ ájtəm'z kərɛ́kt ǽnsər ɪz ɔ̀lrɛ́dij nówn. ðə mɒ́dəl stʌ́dijz ðijz əɡzǽmpəlz kɛ́ərfəlij, lɜ́rnɪŋ pǽtərnz ənd fíjtʃərz, sow ɪt kən léjtər ǽkjərətlij tǽkəl núw sɪ̀tʃuwéjʃənz ɔr kwɛ́stʃənz ɪt hǽzənt síjn bəfɔ́r."
    },
    {
        "Question": "In machine learning, we need a reliable way to see how well our trained model might perform on new and unseen data. What do we call the subset of data specifically set aside to fine-tune our algorithm and prevent overfitting, but isn't used during initial training?",
        "RightAnswer": "Validation Set",
        "WrongAnswers": [
            "Training Set",
            "Test Set",
            "Feature Set",
            "Hyperparameter Set",
            "Benchmark Set"
        ],
        "Explanation": "Think of a validation set as a trial run or practice test for your trained model. After learning from the training set, your model uses the validation set to gauge its performance and tweak decisions (like adjusting hyperparameters) before the final evaluation. It helps ensure your model doesn't just memorize training data (known as overfitting) and can genuinely handle new, unforeseen data smoothly.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wij níjd ə rəlájəbəl wej tə síj háw wɛ́l awər tréjnd mɒ́dəl majt pərfɔ́rm ɒn núw ənd ʌ̀nsíjn déjtə. wɒt dúw wij kɔ́l ðə sʌ́bsɛ̀t əv déjtə spəsɪ́fɪklij sɛ́t əsájd tə fájn-túwn awər ǽlɡərɪ̀ðəm ənd prəvɛ́nt òwvərfɪ́tɪŋ, bʌt ɪzənt júwzd dʊ́rɪŋ ɪnɪ́ʃəl tréjnɪŋ?",
        "trans_RightAnswer": "væ̀lɪdéjʃən sɛ́t",
        "trans_WrongAnswers": [
            "tréjnɪŋ sɛ́t",
            "tɛ́st sɛ́t",
            "fíjtʃər sɛ́t",
            "hàjpərpǽrəmətər sɛ́t",
            "bɛ́ntʃmɑ̀rk sɛ́t"
        ],
        "trans_Explanation": "θɪ́ŋk əv ə væ̀lɪdéjʃən sɛ́t æz ə trájəl rʌ́n ɔr prǽktɪs tɛ́st fɔr jɔr tréjnd mɒ́dəl. ǽftər lɜ́rnɪŋ frəm ðə tréjnɪŋ sɛ́t, jɔr mɒ́dəl júwsɪz ðə væ̀lɪdéjʃən sɛ́t tə ɡéjdʒ ɪts pərfɔ́rməns ənd twíjk dəsɪ́ʒənz (lájk ədʒʌ́stɪŋ hàjpərpǽrəmətərz) bəfɔ́r ðə fájnəl əvæ̀ljuwéjʃən. ɪt hɛ́lps ənʃʊ́r jɔr mɒ́dəl dʌ́zənt dʒəst mɛ́məràjz tréjnɪŋ déjtə (nówn æz òwvərfɪ́tɪŋ) ənd kən dʒénjuwɪnlij hǽndəl núw, ʌ̀nfɔrsíjn déjtə smúwðlij."
    },
    {
        "Question": "In machine learning, after you've trained your model using a given dataset, you need to evaluate how well it truly performs on new, unseen data. Which type of dataset is specifically used to objectively measure the performance of your trained model?",
        "RightAnswer": "Test Set",
        "WrongAnswers": [
            "Training Set",
            "Development Set",
            "Validation Set",
            "Feature Set",
            "Evaluation Set"
        ],
        "Explanation": "Think of the test set like a final exam for your machine learning model. It's a special dataset that's completely separate from the data your model saw during training. By evaluating your model with this 'final exam,' you can confidently assess how well it will perform on new, real-world data. This helps ensure your model hasn't just memorized answers from its training data but has genuinely learned to generalize.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ǽftər júwv tréjnd jɔr mɒ́dəl júwzɪŋ ə ɡɪ́vən déjtəsɛ̀t, juw níjd tə əvǽljuwèjt háw wɛ́l ɪt trúwlij pərfɔ́rmz ɒn núw, ʌ̀nsíjn déjtə. wɪ́tʃ tájp əv déjtəsɛ̀t ɪz spəsɪ́fɪklij júwzd tə ɒbdʒɛ́ktɪvlij mɛ́ʒər ðə pərfɔ́rməns əv jɔr tréjnd mɒ́dəl?",
        "trans_RightAnswer": "tɛ́st sɛ́t",
        "trans_WrongAnswers": [
            "tréjnɪŋ sɛ́t",
            "dəvɛ́ləpmənt sɛ́t",
            "væ̀lɪdéjʃən sɛ́t",
            "fíjtʃər sɛ́t",
            "əvæ̀ljuwéjʃən sɛ́t"
        ],
        "trans_Explanation": "θɪ́ŋk əv ðə tɛ́st sɛ́t lájk ə fájnəl əɡzǽm fɔr jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl. ɪt's ə spɛ́ʃəl déjtəsɛ̀t ðət's kəmplíjtlij sɛ́pərət frəm ðə déjtə jɔr mɒ́dəl sɔ́ dʊ́rɪŋ tréjnɪŋ. baj əvǽljuwèjtɪŋ jɔr mɒ́dəl wɪð ðɪs 'fájnəl əɡzǽm,' juw kən kɒ́nfɪdəntlij əsɛ́s háw wɛ́l ɪt wɪl pərfɔ́rm ɒn núw, ríjəl-wɜ́rld déjtə. ðɪs hɛ́lps ənʃʊ́r jɔr mɒ́dəl hǽzənt dʒəst mɛ́məràjzd ǽnsərz frəm ɪts tréjnɪŋ déjtə bʌt həz dʒénjuwɪnlij lɜ́rnd tə dʒɛ́nərəlàjz."
    },
    {
        "Question": "You're training a machine learning model but you're unsure if it might perform well only by accident or because of your training data. To make sure your model isn't just memorizing patterns from your training data, you decide to split your dataset multiple times into different subsets, training and testing repeatedly. What is this approach called?",
        "RightAnswer": "K-Fold Cross Validation",
        "WrongAnswers": [
            "Gradient Descent",
            "Random Forest Method",
            "Bootstrapping",
            "Reinforcement Learning",
            "Decision Tree Partitioning"
        ],
        "Explanation": "K-Fold Cross Validation is a popular machine learning technique where the data is divided into 'K' subsets. Your model is trained and evaluated K different times, each time using a different subset as the test data and the remaining subsets to train. By averaging the results from these many smaller validations, you gain a more reliable and unbiased estimate of how well your model performs. Think of it as letting your model take multiple different 'mini-tests' rather than one big test, reducing the chance that your results were simply a lucky or unlucky draw.",
        "trans_Question": "júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl bʌt júwr ʌ̀nʃʊ́r ɪf ɪt majt pərfɔ́rm wɛ́l ównlij baj ǽksɪdənt ɔr bəkɒ́z əv jɔr tréjnɪŋ déjtə. tə méjk ʃʊ́r jɔr mɒ́dəl ɪzənt dʒəst mɛ́məràjzɪŋ pǽtərnz frəm jɔr tréjnɪŋ déjtə, juw dəsájd tə splɪ́t jɔr déjtəsɛ̀t mʌ́ltɪpəl tájmz ɪntə dɪ́fərənt sʌ́bsɛ̀ts, tréjnɪŋ ənd tɛ́stɪŋ rəpíjtɪdlij. wɒt ɪz ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "k-fówld krɔ́s væ̀lɪdéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "rǽndəm fɔ́rəst mɛ́θəd",
            "búwtstræ̀pɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "dəsɪ́ʒən tríj pɑrtɪ́ʃənɪŋ"
        ],
        "trans_Explanation": "k-fówld krɔ́s væ̀lɪdéjʃən ɪz ə pɒ́pjələr məʃíjn lɜ́rnɪŋ tɛkníjk wɛ́ər ðə déjtə ɪz dɪvájdɪd ɪntə 'K' sʌ́bsɛ̀ts. jɔr mɒ́dəl ɪz tréjnd ənd əvǽljuwèjtɪd K dɪ́fərənt tájmz, ijtʃ tájm júwzɪŋ ə dɪ́fərənt sʌ́bsɛ̀t æz ðə tɛ́st déjtə ənd ðə rəméjnɪŋ sʌ́bsɛ̀ts tə tréjn. baj ǽvrɪdʒɪŋ ðə rəzʌ́lts frəm ðijz mɛ́nij smɔ́lər væ̀lɪdéjʃənz, juw ɡéjn ə mɔr rəlájəbəl ənd ʌ̀nbájəst ɛ́stɪmèjt əv háw wɛ́l jɔr mɒ́dəl pərfɔ́rmz. θɪ́ŋk əv ɪt æz lɛ́tɪŋ jɔr mɒ́dəl téjk mʌ́ltɪpəl dɪ́fərənt 'mɪ́nij-tɛ́sts' rǽðər ðʌn wʌ́n bɪ́ɡ tɛ́st, rədjúwsɪŋ ðə tʃǽns ðət jɔr rəzʌ́lts wɜ́r sɪ́mplij ə lʌ́kij ɔr ʌ̀nlʌ́kij drɔ́."
    },
    {
        "Question": "You're training a machine learning model with limited data and want a validation method that helps you use every data point efficiently. Each time, you hold back just a single data point as your test set and use the rest to train your model. Which validation method are you using?",
        "RightAnswer": "Leave-One-Out Cross Validation",
        "WrongAnswers": [
            "K-Fold Cross Validation",
            "Bootstrap Aggregation",
            "Random Hold-Out Validation",
            "Monte Carlo Cross Validation",
            "Time-Series Cross Validation"
        ],
        "Explanation": "Leave-One-Out Cross Validation is a method where we take turns using each data point exactly once as the 'test' example, while training the model on all the other data points. Because we go through each data point this way, it's an efficient way to validate our model when we have limited data. Think of it as giving each data point a special chance to 'shine' by itself, helping us spot potential errors more clearly.",
        "trans_Question": "júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl wɪð lɪ́mɪtɪd déjtə ənd wɒ́nt ə væ̀lɪdéjʃən mɛ́θəd ðət hɛ́lps juw juwz ɛvərij déjtə pɔ́jnt əfɪ́ʃəntlij. ijtʃ tájm, juw hówld bǽk dʒəst ə sɪ́ŋɡəl déjtə pɔ́jnt æz jɔr tɛ́st sɛ́t ənd juwz ðə rɛ́st tə tréjn jɔr mɒ́dəl. wɪ́tʃ væ̀lɪdéjʃən mɛ́θəd ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "líjv-wʌ́n-awt krɔ́s væ̀lɪdéjʃən",
        "trans_WrongAnswers": [
            "k-fówld krɔ́s væ̀lɪdéjʃən",
            "búwtstræ̀p æ̀ɡrəɡéjʃən",
            "rǽndəm hówld-awt væ̀lɪdéjʃən",
            "mɒ́ntij kɑ́rlow krɔ́s væ̀lɪdéjʃən",
            "tájm-sɪ́ərijz krɔ́s væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "líjv-wʌ́n-awt krɔ́s væ̀lɪdéjʃən ɪz ə mɛ́θəd wɛ́ər wij téjk tɜ́rnz júwzɪŋ ijtʃ déjtə pɔ́jnt əɡzǽktlij wʌ́ns æz ðə 'tɛ́st' əɡzǽmpəl, wájl tréjnɪŋ ðə mɒ́dəl ɒn ɔl ðə ʌ́ðər déjtə pɔ́jnts. bəkɒ́z wij ɡow θrúw ijtʃ déjtə pɔ́jnt ðɪs wej, ɪt's ən əfɪ́ʃənt wej tə vǽlɪdèjt awər mɒ́dəl wɛ́n wij həv lɪ́mɪtɪd déjtə. θɪ́ŋk əv ɪt æz ɡɪ́vɪŋ ijtʃ déjtə pɔ́jnt ə spɛ́ʃəl tʃǽns tə 'ʃájn' baj ɪtsɛ́lf, hɛ́lpɪŋ ʌs spɒ́t pətɛ́nʃəl ɛ́ərərz mɔr klɪ́ərlij."
    },
    {
        "Question": "When training a model, you want to ensure every subset of your data has roughly the same proportion of categories as the whole dataset. Which cross-validation strategy would be the perfect choice?",
        "RightAnswer": "Stratified K-Fold",
        "WrongAnswers": [
            "Randomized Grid Search",
            "Leave-One-Out Cross-Validation",
            "Bootstrap Aggregation",
            "Gradient Boosting",
            "Hold-Out Validation"
        ],
        "Explanation": "Imagine you're splitting your dataset to check your model's performance. If your data has different categories, you ideally want each subset to represent all categories fairly evenly. Stratified K-Fold cross-validation achieves exactly that—it divides your data into multiple smaller sets (folds), making sure each subset keeps roughly the same ratio of categories present in the original dataset. This method helps make your performance estimates realistic and reliable!",
        "trans_Question": "wɛ́n tréjnɪŋ ə mɒ́dəl, juw wɒ́nt tə ənʃʊ́r ɛvərij sʌ́bsɛ̀t əv jɔr déjtə həz rʌ́flij ðə séjm prəpɔ́rʃən əv kǽtəɡɔ̀rijz æz ðə hówl déjtəsɛ̀t. wɪ́tʃ krɔ́s-væ̀lɪdéjʃən strǽtədʒij wʊd bij ðə pɜ́rfəkt tʃɔ́js?",
        "trans_RightAnswer": "strǽtɪfàjd k-fówld",
        "trans_WrongAnswers": [
            "rǽndəmàjzd ɡrɪ́d sɜ́rtʃ",
            "líjv-wʌ́n-awt krɔ́s-væ̀lɪdéjʃən",
            "búwtstræ̀p æ̀ɡrəɡéjʃən",
            "ɡréjdijənt búwstɪŋ",
            "hówld-awt væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "ɪmǽdʒɪn júwr splɪ́tɪŋ jɔr déjtəsɛ̀t tə tʃɛ́k jɔr mɒ́dəl'z pərfɔ́rməns. ɪf jɔr déjtə həz dɪ́fərənt kǽtəɡɔ̀rijz, juw ajdíjəlij wɒ́nt ijtʃ sʌ́bsɛ̀t tə rɛ̀prəzɛ́nt ɔl kǽtəɡɔ̀rijz fɛ́ərlij íjvənlij. strǽtɪfàjd k-fówld krɔ́s-væ̀lɪdéjʃən ətʃíjvz əɡzǽktlij ðət—ɪt dɪvájdz jɔr déjtə ɪntə mʌ́ltɪpəl smɔ́lər sɛ́ts (fówldz), méjkɪŋ ʃʊ́r ijtʃ sʌ́bsɛ̀t kíjps rʌ́flij ðə séjm réjʃijòw əv kǽtəɡɔ̀rijz prɛ́zənt ɪn ðə ərɪ́dʒɪnəl déjtəsɛ̀t. ðɪs mɛ́θəd hɛ́lps méjk jɔr pərfɔ́rməns ɛ́stɪmèjts rìjəlɪ́stɪk ənd rəlájəbəl!"
    },
    {
        "Question": "In machine learning, you want to check if your model will perform well in real-life scenarios by setting aside a portion of your data beforehand. What's this method called?",
        "RightAnswer": "Holdout Method",
        "WrongAnswers": [
            "Gradient Checking",
            "Feature Scaling",
            "Cross-Validation",
            "Regularization",
            "Data Augmentation"
        ],
        "Explanation": "The holdout method is a straightforward and practical approach used in machine learning to test how well a model performs. You simply take your dataset, keep a portion of it separate (the \"holdout\"), train your model on the remaining data, and then test its performance on the held-out data. This gives a realistic idea of how your model might handle data it hasn't seen before—essentially a 'dry run' before going live.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, juw wɒ́nt tə tʃɛ́k ɪf jɔr mɒ́dəl wɪl pərfɔ́rm wɛ́l ɪn ríjəl-lájf sənɛ́ərijowz baj sɛ́tɪŋ əsájd ə pɔ́rʃən əv jɔr déjtə bəfɔ́rhæ̀nd. wɒt's ðɪs mɛ́θəd kɔ́ld?",
        "trans_RightAnswer": "hówldàwt mɛ́θəd",
        "trans_WrongAnswers": [
            "ɡréjdijənt tʃɛ́kɪŋ",
            "fíjtʃər skéjlɪŋ",
            "krɔ́s-væ̀lɪdéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "ðə hówldàwt mɛ́θəd ɪz ə stréjtfɔ́rwərd ənd prǽktɪkəl əprówtʃ júwzd ɪn məʃíjn lɜ́rnɪŋ tə tɛ́st háw wɛ́l ə mɒ́dəl pərfɔ́rmz. juw sɪ́mplij téjk jɔr déjtəsɛ̀t, kíjp ə pɔ́rʃən əv ɪt sɛ́pərət (ðə \"hówldàwt\"), tréjn jɔr mɒ́dəl ɒn ðə rəméjnɪŋ déjtə, ənd ðɛn tɛ́st ɪts pərfɔ́rməns ɒn ðə hɛ́ld-awt déjtə. ðɪs ɡɪ́vz ə rìjəlɪ́stɪk ajdíjə əv háw jɔr mɒ́dəl majt hǽndəl déjtə ɪt hǽzənt síjn bəfɔ́r—əsɛ́nʃəlij ə 'dráj rʌ́n' bəfɔ́r ɡówɪŋ lɪv."
    },
    {
        "Question": "Imagine you're training a machine learning model that uses features like age, income, and total spending. Age ranges from 0-100, income could be anywhere from thousands to millions, and spending from tens to thousands. What's the technique used to scale all these different data ranges into similar scales, helping your model perform better?",
        "RightAnswer": "Data Normalization",
        "WrongAnswers": [
            "Gradient Descent",
            "Overfitting",
            "Hyperparameter Tuning",
            "Feature Extraction",
            "Principal Component Analysis"
        ],
        "Explanation": "Data normalization is a helpful preprocessing technique in machine learning, used to scale different features (such as age, income, spending levels) into a common range (usually between 0 and 1). This process helps the algorithm understand and interpret data more fairly and efficiently, especially when features have significantly different scales. Without normalization, some features could disproportionately influence your model's learning process, leading to poorer performance or misleading results.",
        "trans_Question": "ɪmǽdʒɪn júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ðət júwsɪz fíjtʃərz lájk éjdʒ, ɪ́nkʌ̀m, ənd tówtəl spɛ́ndɪŋ. éjdʒ réjndʒɪz frəm 0-100, ɪ́nkʌ̀m kʊ́d bij ɛ́nijwɛ̀ər frəm θáwzəndz tə mɪ́ljənz, ənd spɛ́ndɪŋ frəm tɛ́nz tə θáwzəndz. wɒt's ðə tɛkníjk júwzd tə skéjl ɔl ðijz dɪ́fərənt déjtə réjndʒɪz ɪntə sɪ́mɪlər skéjlz, hɛ́lpɪŋ jɔr mɒ́dəl pərfɔ́rm bɛ́tər?",
        "trans_RightAnswer": "déjtə nɔ̀rməlɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "òwvərfɪ́tɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "fíjtʃər əkstrǽkʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "déjtə nɔ̀rməlɪzéjʃən ɪz ə hɛ́lpfəl prìjprʌ́ʊsɛsɪŋ tɛkníjk ɪn məʃíjn lɜ́rnɪŋ, júwzd tə skéjl dɪ́fərənt fíjtʃərz (sʌtʃ æz éjdʒ, ɪ́nkʌ̀m, spɛ́ndɪŋ lɛ́vəlz) ɪntə ə kɒ́mən réjndʒ (júwʒəlij bijtwíjn 0 ənd 1). ðɪs prɒ́sɛs hɛ́lps ðə ǽlɡərɪ̀ðəm ʌ̀ndərstǽnd ənd ɪntɜ́rprət déjtə mɔr fɛ́ərlij ənd əfɪ́ʃəntlij, əspɛ́ʃəlij wɛ́n fíjtʃərz həv sɪɡnɪ́fɪkəntlij dɪ́fərənt skéjlz. wɪðáwt nɔ̀rməlɪzéjʃən, sʌm fíjtʃərz kʊ́d dɪ̀sprəpɔ́rʃənətlij ɪ́nfluwəns jɔr mɒ́dəl'z lɜ́rnɪŋ prɒ́sɛs, líjdɪŋ tə pɔ́rər pərfɔ́rməns ɔr mɪ̀slíjdɪŋ rəzʌ́lts."
    },
    {
        "Question": "When preparing numerical data for a machine learning model, you want all your numbers to be consistently measured on the same scale, without biased importance due to size or scale. What is this common technique called?",
        "RightAnswer": "Data Standardization",
        "WrongAnswers": [
            "Feature Extraction",
            "Hyperparameter Tuning",
            "Model Regularization",
            "Data Augmentation",
            "Dimensionality Reduction"
        ],
        "Explanation": "Data Standardization is a method used in machine learning to bring all numerical data features to a common scale. Imagine trying to compare height in centimeters and age in years—these numbers are quite different and could skew your algorithm. Standardization ensures that each feature has a similar influence on your model by adjusting the data so that each feature has a mean of zero and a consistent range. This makes your model more fair, accurate, and quicker to train!",
        "trans_Question": "wɛ́n prəpɛ́ərɪŋ njuwmɛ́ərɪkəl déjtə fɔr ə məʃíjn lɜ́rnɪŋ mɒ́dəl, juw wɒ́nt ɔl jɔr nʌ́mbərz tə bij kənsɪ́stəntlij mɛ́ʒərd ɒn ðə séjm skéjl, wɪðáwt bájəst ɪmpɔ́rtəns djúw tə sájz ɔr skéjl. wɒt ɪz ðɪs kɒ́mən tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "déjtə stændərdɪzéjʃən",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "hàjpərpǽrəmətər túwnɪŋ",
            "mɒ́dəl rèɡjəlɛ̀ərɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "déjtə stændərdɪzéjʃən ɪz ə mɛ́θəd júwzd ɪn məʃíjn lɜ́rnɪŋ tə brɪ́ŋ ɔl njuwmɛ́ərɪkəl déjtə fíjtʃərz tə ə kɒ́mən skéjl. ɪmǽdʒɪn trájɪŋ tə kəmpɛ́ər hájt ɪn sɛ́ntɪmìjtərz ənd éjdʒ ɪn jɪ́ərz—ðijz nʌ́mbərz ɑr kwájt dɪ́fərənt ənd kʊ́d skjúw jɔr ǽlɡərɪ̀ðəm. stændərdɪzéjʃən ənʃʊ́rz ðət ijtʃ fíjtʃər həz ə sɪ́mɪlər ɪ́nfluwəns ɒn jɔr mɒ́dəl baj ədʒʌ́stɪŋ ðə déjtə sow ðət ijtʃ fíjtʃər həz ə míjn əv zíjərow ənd ə kənsɪ́stənt réjndʒ. ðɪs méjks jɔr mɒ́dəl mɔr fɛ́ər, ǽkjərət, ənd kwɪ́kər tə tréjn!"
    },
    {
        "Question": "You're working on a machine learning project, and you notice that some features—like age, income, and temperature—have very different numeric scales. To improve how quickly and accurately your algorithm learns, which preprocessing technique should you use to adjust these features into a more balanced numeric range?",
        "RightAnswer": "Feature Scaling",
        "WrongAnswers": [
            "Feature Extraction",
            "Hyperparameter Tuning",
            "Gradient Descent",
            "Dimensionality Reduction",
            "Data Augmentation"
        ],
        "Explanation": "Feature Scaling involves adjusting your data so that each feature (like age, salary, or temperature) is measured on a similar numeric scale. This helps your machine learning algorithm perform better and faster, especially when numeric values are vastly different. Think of it as making sure all measurements speak the same language—allowing your algorithm to learn more efficiently!",
        "trans_Question": "júwr wɜ́rkɪŋ ɒn ə məʃíjn lɜ́rnɪŋ prɒ́dʒɛkt, ənd juw nówtɪs ðət sʌm fíjtʃərz—lájk éjdʒ, ɪ́nkʌ̀m, ənd tɛ́mpərətʃər—həv vɛ́ərij dɪ́fərənt njuwmɛ́ərɪk skéjlz. tə ɪmprúwv háw kwɪ́klij ənd ǽkjərətlij jɔr ǽlɡərɪ̀ðəm lɜ́rnz, wɪ́tʃ prìjprʌ́ʊsɛsɪŋ tɛkníjk ʃʊd juw juwz tə ədʒʌ́st ðijz fíjtʃərz ɪntə ə mɔr bǽlənst njuwmɛ́ərɪk réjndʒ?",
        "trans_RightAnswer": "fíjtʃər skéjlɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "hàjpərpǽrəmətər túwnɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "fíjtʃər skéjlɪŋ ɪnvɒ́lvz ədʒʌ́stɪŋ jɔr déjtə sow ðət ijtʃ fíjtʃər (lájk éjdʒ, sǽlərij, ɔr tɛ́mpərətʃər) ɪz mɛ́ʒərd ɒn ə sɪ́mɪlər njuwmɛ́ərɪk skéjl. ðɪs hɛ́lps jɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm pərfɔ́rm bɛ́tər ənd fǽstər, əspɛ́ʃəlij wɛ́n njuwmɛ́ərɪk vǽljuwz ɑr vǽstlij dɪ́fərənt. θɪ́ŋk əv ɪt æz méjkɪŋ ʃʊ́r ɔl mɛ́ʒərmənts spíjk ðə séjm lǽŋɡwədʒ—əláwɪŋ jɔr ǽlɡərɪ̀ðəm tə lɜ́rn mɔr əfɪ́ʃəntlij!"
    },
    {
        "Question": "You're prepping your dataset for a machine learning model and notice that input features vary wildly in their ranges. There's a straightforward method you can apply that rescales every feature into a consistent, fixed range (such as 0 to 1). Which data preprocessing technique best describes this helpful normalization process?",
        "RightAnswer": "Min-Max Scaling",
        "WrongAnswers": [
            "Gradient Descent",
            "Random Forest",
            "One-Hot Encoding",
            "K-means Clustering",
            "Principal Component Analysis"
        ],
        "Explanation": "Min-Max Scaling is a helpful data preprocessing method that 'rescales' your features into a fixed, convenient range, often between 0 and 1, making it easier and quicker for machine learning models to learn. It does this by taking each feature's minimum value and mapping it to 0, and each feature's maximum value and mapping it to 1. This ensures each feature has an equal influence on the model and helps the model to learn more efficiently!",
        "trans_Question": "júwr prɛ́pɪŋ jɔr déjtəsɛ̀t fɔr ə məʃíjn lɜ́rnɪŋ mɒ́dəl ənd nówtɪs ðət ɪ́npʊ̀t fíjtʃərz vɛ́ərij wájldlij ɪn ðɛər réjndʒɪz. ðɛər'z ə stréjtfɔ́rwərd mɛ́θəd juw kən əpláj ðət rijskéjlz ɛvərij fíjtʃər ɪntə ə kənsɪ́stənt, fɪ́kst réjndʒ (sʌtʃ æz 0 tə 1). wɪ́tʃ déjtə prìjprʌ́ʊsɛsɪŋ tɛkníjk bɛ́st dəskrájbz ðɪs hɛ́lpfəl nɔ̀rməlɪzéjʃən prɒ́sɛs?",
        "trans_RightAnswer": "mɪ́n-mæks skéjlɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "rǽndəm fɔ́rəst",
            "wʌ́n-hɒ́t ɛnkówdɪŋ",
            "k-míjnz klʌ́stərɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "mɪ́n-mæks skéjlɪŋ ɪz ə hɛ́lpfəl déjtə prìjprʌ́ʊsɛsɪŋ mɛ́θəd ðət 'rijskéjlz' jɔr fíjtʃərz ɪntə ə fɪ́kst, kənvíjnjənt réjndʒ, ɔ́fən bijtwíjn 0 ənd 1, méjkɪŋ ɪt íjzijər ənd kwɪ́kər fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz tə lɜ́rn. ɪt dʌz ðɪs baj téjkɪŋ ijtʃ fíjtʃər'z mɪ́nɪməm vǽljuw ənd mǽpɪŋ ɪt tə 0, ənd ijtʃ fíjtʃər'z mǽksɪməm vǽljuw ənd mǽpɪŋ ɪt tə 1. ðɪs ənʃʊ́rz ijtʃ fíjtʃər həz ən íjkwəl ɪ́nfluwəns ɒn ðə mɒ́dəl ənd hɛ́lps ðə mɒ́dəl tə lɜ́rn mɔr əfɪ́ʃəntlij!"
    },
    {
        "Question": "In machine learning data preparation, you often encounter situations where your data varies a lot in magnitude—some values are huge, others tiny. Which data preprocessing technique helps you scale features so they have a mean of 0 and a standard deviation of 1, making all of your variables easier to compare directly?",
        "RightAnswer": "Z-Score Normalization",
        "WrongAnswers": [
            "Min-Max Scaling",
            "Logarithmic Transformation",
            "Robust Scaling",
            "Mean Absolute Scaling",
            "Decimal Scaling"
        ],
        "Explanation": "Z-Score Normalization is a handy method in machine learning that transforms your data, adjusting it so the new values have a mean of zero and a standard deviation of one. Basically, it helps features measured on entirely different scales become more comparable, which is super helpful for making sure algorithms perform well and fairly consider all features during classification or regression tasks.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ déjtə prɛ̀pəréjʃən, juw ɔ́fən ənkáwntər sɪ̀tʃuwéjʃənz wɛ́ər jɔr déjtə vɛ́ərijz ə lɒ́t ɪn mǽɡnɪtùwd—sʌm vǽljuwz ɑr hjúwdʒ, ʌ́ðərz tájnij. wɪ́tʃ déjtə prìjprʌ́ʊsɛsɪŋ tɛkníjk hɛ́lps juw skéjl fíjtʃərz sow ðej həv ə míjn əv 0 ənd ə stǽndərd dìjvijéjʃən əv 1, méjkɪŋ ɔl əv jɔr vɛ́ərijəbəlz íjzijər tə kəmpɛ́ər dɪərɛ́klij?",
        "trans_RightAnswer": "z-skɔ́r nɔ̀rməlɪzéjʃən",
        "trans_WrongAnswers": [
            "mɪ́n-mæks skéjlɪŋ",
            "lɒ̀ɡərɪ́ðmɪk træ̀nsfərméjʃən",
            "rowbʌ́st skéjlɪŋ",
            "míjn ǽbsəlùwt skéjlɪŋ",
            "dɛ́səməl skéjlɪŋ"
        ],
        "trans_Explanation": "z-skɔ́r nɔ̀rməlɪzéjʃən ɪz ə hǽndij mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ ðət trænsfɔ́rmz jɔr déjtə, ədʒʌ́stɪŋ ɪt sow ðə núw vǽljuwz həv ə míjn əv zíjərow ənd ə stǽndərd dìjvijéjʃən əv wʌ́n. béjsɪklij, ɪt hɛ́lps fíjtʃərz mɛ́ʒərd ɒn əntájərlij dɪ́fərənt skéjlz bəkʌ́m mɔr kɒ́mpərəbəl, wɪ́tʃ ɪz súwpər hɛ́lpfəl fɔr méjkɪŋ ʃʊ́r ǽlɡərɪ̀ðəmz pərfɔ́rm wɛ́l ənd fɛ́ərlij kənsɪ́dər ɔl fíjtʃərz dʊ́rɪŋ klæ̀sɪfɪkéjʃən ɔr rəɡrɛ́ʃən tǽsks."
    },
    {
        "Question": "Imagine you're preprocessing a dataset for your machine learning project, and you notice there are several extreme outliers in your numerical data. To make sure these extreme values don't distort your analysis, you choose a scaling method that uses medians and quartiles, making your preprocessing less sensitive to outliers. Which scaling approach are you using?",
        "RightAnswer": "Robust Scaling",
        "WrongAnswers": [
            "Feature Normalization",
            "Min-Max Scaling",
            "Standardization",
            "Log Transformation",
            "One-Hot Encoding"
        ],
        "Explanation": "Robust scaling is a helpful preprocessing method that uses statistical measures (like the median and the quartiles, which represent the middle values of your dataset) instead of mean and standard deviation. This makes robust scaling much less affected by outliers or extreme values compared to other methods. Think of robust scaling like adjusting the brightness of a photo: it makes the important parts clearer and prevents bright lights or shadows (outliers) from hiding the details.",
        "trans_Question": "ɪmǽdʒɪn júwr prìjprʌ́ʊsɛsɪŋ ə déjtəsɛ̀t fɔr jɔr məʃíjn lɜ́rnɪŋ prɒ́dʒɛkt, ənd juw nówtɪs ðɛər ɑr sɛ́vərəl əkstríjm áwtlajərz ɪn jɔr njuwmɛ́ərɪkəl déjtə. tə méjk ʃʊ́r ðijz əkstríjm vǽljuwz dównt dɪstɔ́rt jɔr ənǽlɪsɪs, juw tʃúwz ə skéjlɪŋ mɛ́θəd ðət júwsɪz míjdijənz ənd kwɔ́rtajlz, méjkɪŋ jɔr prìjprʌ́ʊsɛsɪŋ lɛ́s sɛ́nsɪtɪv tə áwtlajərz. wɪ́tʃ skéjlɪŋ əprówtʃ ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "rowbʌ́st skéjlɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər nɔ̀rməlɪzéjʃən",
            "mɪ́n-mæks skéjlɪŋ",
            "stændərdɪzéjʃən",
            "lɔ́ɡ træ̀nsfərméjʃən",
            "wʌ́n-hɒ́t ɛnkówdɪŋ"
        ],
        "trans_Explanation": "rowbʌ́st skéjlɪŋ ɪz ə hɛ́lpfəl prìjprʌ́ʊsɛsɪŋ mɛ́θəd ðət júwsɪz stətɪ́stɪkəl mɛ́ʒərz (lájk ðə míjdijən ənd ðə kwɔ́rtajlz, wɪ́tʃ rɛ̀prəzɛ́nt ðə mɪ́dəl vǽljuwz əv jɔr déjtəsɛ̀t) ɪnstɛ́d əv míjn ənd stǽndərd dìjvijéjʃən. ðɪs méjks rowbʌ́st skéjlɪŋ mʌtʃ lɛ́s əfɛ́ktɪd baj áwtlajərz ɔr əkstríjm vǽljuwz kəmpɛ́ərd tə ʌ́ðər mɛ́θədz. θɪ́ŋk əv rowbʌ́st skéjlɪŋ lájk ədʒʌ́stɪŋ ðə brájtnəs əv ə fówtòw: ɪt méjks ðə ɪmpɔ́rtənt pɑ́rts klɪ́ərər ənd prəvɛ́nts brájt lájts ɔr ʃǽdòwz (áwtlajərz) frəm hájdɪŋ ðə díjtejlz."
    },
    {
        "Question": "Before Alex feeds his dataset to the machine learning algorithm, he carefully reviews the data to remove errors, fix missing values, and standardize formats, making sure it's accurate and reliable. What is this important step called?",
        "RightAnswer": "Data Cleaning",
        "WrongAnswers": [
            "Feature Extraction",
            "Model Training",
            "Hyperparameter Tuning",
            "Cross Validation",
            "Algorithm Selection"
        ],
        "Explanation": "Data cleaning means carefully checking your data to find errors, missing details, or inconsistencies, and then fixing these issues before running any analysis or building models. Just like you organize and tidy up ingredients before cooking to make sure your meal turns out great, data cleaning helps ensure your data is accurate and ready for machine learning algorithms.",
        "trans_Question": "bəfɔ́r ǽlɛks fíjdz hɪz déjtəsɛ̀t tə ðə məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm, hij kɛ́ərfəlij rəvjúwz ðə déjtə tə rijmúwv ɛ́ərərz, fɪ́ks mɪ́sɪŋ vǽljuwz, ənd stǽndərdàjz fɔ́rmæ̀ts, méjkɪŋ ʃʊ́r ɪt's ǽkjərət ənd rəlájəbəl. wɒt ɪz ðɪs ɪmpɔ́rtənt stɛ́p kɔ́ld?",
        "trans_RightAnswer": "déjtə klíjnɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "mɒ́dəl tréjnɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "krɔ́s væ̀lɪdéjʃən",
            "ǽlɡərɪ̀ðəm səlɛ́kʃən"
        ],
        "trans_Explanation": "déjtə klíjnɪŋ míjnz kɛ́ərfəlij tʃɛ́kɪŋ jɔr déjtə tə fájnd ɛ́ərərz, mɪ́sɪŋ díjtejlz, ɔr ɪ̀ŋkɒ́nsɪstɛ̀nsijz, ənd ðɛn fɪ́ksɪŋ ðijz ɪ́ʃuwz bəfɔ́r rʌ́nɪŋ ɛ́nij ənǽlɪsɪs ɔr bɪ́ldɪŋ mɒ́dəlz. dʒəst lájk juw ɔ́rɡənàjz ənd tájdij ʌp ɪnɡríjdijənts bəfɔ́r kʊ́kɪŋ tə méjk ʃʊ́r jɔr míjl tɜ́rnz awt ɡréjt, déjtə klíjnɪŋ hɛ́lps ənʃʊ́r jɔr déjtə ɪz ǽkjərət ənd rɛ́dij fɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz."
    },
    {
        "Question": "You're preparing your dataset for training a machine learning model, but realize some data points are missing. To effectively handle this issue, you decide to fill in these missing spots with estimated or substituted values based on available data. What is this process called?",
        "RightAnswer": "Missing Value Imputation",
        "WrongAnswers": [
            "Feature Selection",
            "Data Augmentation",
            "Overfitting Reduction",
            "Data Labeling",
            "Model Validation"
        ],
        "Explanation": "Missing Value Imputation is the technique of filling in gaps or missing entries in a dataset with carefully chosen substitute values. Instead of discarding an entire row of data or ignoring important information, you fill in missing data using estimates such as average values, median values, or even predictions from other models. This ensures your machine learning model gets the most complete picture possible, allowing it to train and generalize more effectively.",
        "trans_Question": "júwr prəpɛ́ərɪŋ jɔr déjtəsɛ̀t fɔr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, bʌt ríjəlàjz sʌm déjtə pɔ́jnts ɑr mɪ́sɪŋ. tə əfɛ́ktɪvlij hǽndəl ðɪs ɪ́ʃuw, juw dəsájd tə fɪ́l ɪn ðijz mɪ́sɪŋ spɒ́ts wɪð ɛ́stɪmèjtɪd ɔr sʌ́bstɪtuwtɪd vǽljuwz béjst ɒn əvéjləbəl déjtə. wɒt ɪz ðɪs prɒ́sɛs kɔ́ld?",
        "trans_RightAnswer": "mɪ́sɪŋ vǽljuw ɪ̀mpjətéjʃən",
        "trans_WrongAnswers": [
            "fíjtʃər səlɛ́kʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "òwvərfɪ́tɪŋ rədʌ́kʃən",
            "déjtə léjbəlɪŋ",
            "mɒ́dəl væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "mɪ́sɪŋ vǽljuw ɪ̀mpjətéjʃən ɪz ðə tɛkníjk əv fɪ́lɪŋ ɪn ɡǽps ɔr mɪ́sɪŋ ɛ́ntrijz ɪn ə déjtəsɛ̀t wɪð kɛ́ərfəlij tʃówzən sʌ́bstɪtuwt vǽljuwz. ɪnstɛ́d əv dɪskɑ́rdɪŋ ən əntájər row əv déjtə ɔr ɪ̀ɡnɔ́rɪŋ ɪmpɔ́rtənt ɪnfərméjʃən, juw fɪ́l ɪn mɪ́sɪŋ déjtə júwzɪŋ ɛ́stɪmèjts sʌtʃ æz ǽvərɪdʒ vǽljuwz, míjdijən vǽljuwz, ɔr íjvən prədɪ́kʃənz frəm ʌ́ðər mɒ́dəlz. ðɪs ənʃʊ́rz jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ɡɛ́ts ðə mówst kəmplíjt pɪ́ktʃər pɒ́sɪbəl, əláwɪŋ ɪt tə tréjn ənd dʒɛ́nərəlàjz mɔr əfɛ́ktɪvlij."
    },
    {
        "Question": "When preparing your data for machine learning, you notice some of your dataset's features are categorical (such as colors, brands, or city names). To use these categories in your predictive models, you'll need to convert them into numerical values your algorithms can understand. What is this crucial step called?",
        "RightAnswer": "Feature Encoding",
        "WrongAnswers": [
            "Gradient Boosting",
            "Neural Decoding",
            "Data Augmentation",
            "Regularization",
            "Feature Selection"
        ],
        "Explanation": "Feature encoding is like translating data into a language your machine learning model can understand. Often, your dataset includes categorical variables—like cities or brand names—that can't directly feed into an algorithm. Feature encoding converts these categorical features into numerical formats, ensuring your model can process the data effectively and learn meaningful patterns.",
        "trans_Question": "wɛ́n prəpɛ́ərɪŋ jɔr déjtə fɔr məʃíjn lɜ́rnɪŋ, juw nówtɪs sʌm əv jɔr déjtəsɛ̀t's fíjtʃərz ɑr kæ̀təɡɑ́rɪkəl (sʌtʃ æz kʌ́lərz, brǽndz, ɔr sɪ́tij néjmz). tə juwz ðijz kǽtəɡɔ̀rijz ɪn jɔr prədɪ́ktɪv mɒ́dəlz, júwl níjd tə kɒ́nvɜrt ðɛm ɪntə njuwmɛ́ərɪkəl vǽljuwz jɔr ǽlɡərɪ̀ðəmz kən ʌ̀ndərstǽnd. wɒt ɪz ðɪs krúwʃəl stɛ́p kɔ́ld?",
        "trans_RightAnswer": "fíjtʃər ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "nʊ́rəl dəkówdɪŋ",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "fíjtʃər səlɛ́kʃən"
        ],
        "trans_Explanation": "fíjtʃər ɛnkówdɪŋ ɪz lájk trǽnslèjtɪŋ déjtə ɪntə ə lǽŋɡwədʒ jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl kən ʌ̀ndərstǽnd. ɔ́fən, jɔr déjtəsɛ̀t ɪnklúwdz kæ̀təɡɑ́rɪkəl vɛ́ərijəbəlz—lájk sɪ́tijz ɔr brǽnd néjmz—ðət kǽnt dɪərɛ́klij fíjd ɪntə ən ǽlɡərɪ̀ðəm. fíjtʃər ɛnkówdɪŋ kɒ́nvərts ðijz kæ̀təɡɑ́rɪkəl fíjtʃərz ɪntə njuwmɛ́ərɪkəl fɔ́rmæ̀ts, ɛnʃʊ́rɪŋ jɔr mɒ́dəl kən prɒ́sɛs ðə déjtə əfɛ́ktɪvlij ənd lɜ́rn míjnɪŋfəl pǽtərnz."
    },
    {
        "Question": "Imagine you're training a machine learning model to identify animal breeds using categorical data, such as colors or animal types. Which method would you use to convert categorical features, like breed or color, into a numerical format understandable by your model without confusing it into thinking one breed or color is numerically greater than another?",
        "RightAnswer": "One-Hot Encoding",
        "WrongAnswers": [
            "Feature Scaling",
            "Gradient Descent",
            "Dimensionality Reduction",
            "Batch Normalization",
            "Regularization"
        ],
        "Explanation": "One-Hot Encoding is a friendly and intuitive method used in machine learning to convert categorical data (like colors, animals, or cities) into a numerical format that machine learning models can understand. It assigns a unique binary column (1 or 0) to every category, so no single category is mistakenly interpreted as higher or lower in value. Think of it as giving each category its own spotlight so the model recognizes them as distinct and unrelated options rather than values on a numeric scale.",
        "trans_Question": "ɪmǽdʒɪn júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə ajdɛ́ntɪfàj ǽnɪməl bríjdz júwzɪŋ kæ̀təɡɑ́rɪkəl déjtə, sʌtʃ æz kʌ́lərz ɔr ǽnɪməl tájps. wɪ́tʃ mɛ́θəd wʊd juw juwz tə kɒ́nvɜrt kæ̀təɡɑ́rɪkəl fíjtʃərz, lájk bríjd ɔr kʌ́lər, ɪntə ə njuwmɛ́ərɪkəl fɔ́rmæ̀t ʌ̀ndərstǽndəbəl baj jɔr mɒ́dəl wɪðáwt kənfjúwzɪŋ ɪt ɪntə θɪ́ŋkɪŋ wʌ́n bríjd ɔr kʌ́lər ɪz njuwmɛ́ərɪklij ɡréjtər ðʌn ənʌ́ðər?",
        "trans_RightAnswer": "wʌ́n-hɒ́t ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "wʌ́n-hɒ́t ɛnkówdɪŋ ɪz ə frɛ́ndlij ənd ɪntúwɪtɪv mɛ́θəd júwzd ɪn məʃíjn lɜ́rnɪŋ tə kɒ́nvɜrt kæ̀təɡɑ́rɪkəl déjtə (lájk kʌ́lərz, ǽnɪməlz, ɔr sɪ́tijz) ɪntə ə njuwmɛ́ərɪkəl fɔ́rmæ̀t ðət məʃíjn lɜ́rnɪŋ mɒ́dəlz kən ʌ̀ndərstǽnd. ɪt əsájnz ə juwnɪ́k bájnərij kɒ́ləm (1 ɔr 0) tə ɛvərij kǽtəɡɔ̀rij, sow now sɪ́ŋɡəl kǽtəɡɔ̀rij ɪz mɪstéjkənlij ɪntɜ́rprətɪd æz hájər ɔr lówər ɪn vǽljuw. θɪ́ŋk əv ɪt æz ɡɪ́vɪŋ ijtʃ kǽtəɡɔ̀rij ɪts ówn spɒ́tlàjt sow ðə mɒ́dəl rɛ́kəɡnàjzɪz ðɛm æz dɪstɪ́ŋkt ənd ʌ̀nrəléjtɪd ɒ́pʃənz rǽðər ðʌn vǽljuwz ɒn ə njuwmɛ́ərɪk skéjl."
    },
    {
        "Question": "In machine learning, what do we call the method of transforming categorical data, like names of fruits (\"apple\", \"banana\", \"kiwi\"), into numerical values like (0, 1, 2) to help algorithms understand them better?",
        "RightAnswer": "Label Encoding",
        "WrongAnswers": [
            "Feature Scaling",
            "Gradient Descent",
            "One-Hot Encoding",
            "Cross Validation",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Label Encoding is a straightforward technique in machine learning where categorical variables, which are usually text-based labels, are converted into numeric values. Suppose you're categorizing fruits like apple, banana, and kiwi—instead of their names, the machine learning algorithm sees numbers like 0, 1, and 2. This helps algorithms work easily with categorical data by turning words into numbers.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt dúw wij kɔ́l ðə mɛ́θəd əv trænsfɔ́rmɪŋ kæ̀təɡɑ́rɪkəl déjtə, lájk néjmz əv frúwts (\"ǽpəl\", \"bənǽnə\", \"kíjwij\"), ɪntə njuwmɛ́ərɪkəl vǽljuwz lájk (0, 1, 2) tə hɛ́lp ǽlɡərɪ̀ðəmz ʌ̀ndərstǽnd ðɛm bɛ́tər?",
        "trans_RightAnswer": "léjbəl ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "wʌ́n-hɒ́t ɛnkówdɪŋ",
            "krɔ́s væ̀lɪdéjʃən",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "léjbəl ɛnkówdɪŋ ɪz ə stréjtfɔ́rwərd tɛkníjk ɪn məʃíjn lɜ́rnɪŋ wɛ́ər kæ̀təɡɑ́rɪkəl vɛ́ərijəbəlz, wɪ́tʃ ɑr júwʒəlij tɛ́kst-béjst léjbəlz, ɑr kənvɜ́rtɪd ɪntə njuwmɛ́ərɪk vǽljuwz. səpówz júwr kǽtəɡəràjzɪŋ frúwts lájk ǽpəl, bənǽnə, ənd kíjwij—ɪnstɛ́d əv ðɛər néjmz, ðə məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm síjz nʌ́mbərz lájk 0, 1, ənd 2. ðɪs hɛ́lps ǽlɡərɪ̀ðəmz wɜ́rk íjzəlij wɪð kæ̀təɡɑ́rɪkəl déjtə baj tɜ́rnɪŋ wɜ́rdz ɪntə nʌ́mbərz."
    },
    {
        "Question": "When you're preparing categorical data like 'Small', 'Medium', and 'Large' shirt sizes for a machine learning algorithm, which encoding technique converts these categories into numbers based on their natural ordered relationship?",
        "RightAnswer": "Ordinal Encoding",
        "WrongAnswers": [
            "One-Hot Encoding",
            "Binary Encoding",
            "Label Encoding",
            "Frequency Encoding",
            "Target Encoding"
        ],
        "Explanation": "Ordinal Encoding assigns integer values to categorical variables according to their natural, ordered relationships. For example, 'small' as 1, 'medium' as 2, and 'large' as 3. It is especially useful for categorical variables where the category carries meaningful order or ranking.",
        "trans_Question": "wɛ́n júwr prəpɛ́ərɪŋ kæ̀təɡɑ́rɪkəl déjtə lájk 'smɔ́l', 'míjdijəm', ənd 'lɑ́rdʒ' ʃɜ́rt sájzɪz fɔr ə məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm, wɪ́tʃ ɛnkówdɪŋ tɛkníjk kɒ́nvərts ðijz kǽtəɡɔ̀rijz ɪntə nʌ́mbərz béjst ɒn ðɛər nǽtʃərəl ɔ́rdərd rəléjʃənʃɪ̀p?",
        "trans_RightAnswer": "ɔ́rdɪnəl ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "wʌ́n-hɒ́t ɛnkówdɪŋ",
            "bájnərij ɛnkówdɪŋ",
            "léjbəl ɛnkówdɪŋ",
            "fríjkwənsij ɛnkówdɪŋ",
            "tɑ́rɡət ɛnkówdɪŋ"
        ],
        "trans_Explanation": "ɔ́rdɪnəl ɛnkówdɪŋ əsájnz ɪ́ntədʒər vǽljuwz tə kæ̀təɡɑ́rɪkəl vɛ́ərijəbəlz əkɔ́rdɪŋ tə ðɛər nǽtʃərəl, ɔ́rdərd rəléjʃənʃɪ̀ps. fɔr əɡzǽmpəl, 'smɔ́l' æz 1, 'míjdijəm' æz 2, ənd 'lɑ́rdʒ' æz 3. ɪt ɪz əspɛ́ʃəlij júwsfəl fɔr kæ̀təɡɑ́rɪkəl vɛ́ərijəbəlz wɛ́ər ðə kǽtəɡɔ̀rij kǽrijz míjnɪŋfəl ɔ́rdər ɔr rǽŋkɪŋ."
    },
    {
        "Question": "You're preparing categorical variables for your machine learning model and come across a method where categories are replaced by how often they appear in the dataset. What's the name of this encoding technique?",
        "RightAnswer": "Count Encoding",
        "WrongAnswers": [
            "Frequency Scaling",
            "One-Hot Encoding",
            "Ordinal Encoding",
            "Hash Encoding",
            "Label Encoding"
        ],
        "Explanation": "Count Encoding is a nifty categorical encoding technique where each category is replaced by the number of times (count) it shows up in the dataset. It's super helpful as it highlights category frequency, potentially informing the model about common or rare categories without creating too many extra features.",
        "trans_Question": "júwr prəpɛ́ərɪŋ kæ̀təɡɑ́rɪkəl vɛ́ərijəbəlz fɔr jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ənd kʌ́m əkrɔ́s ə mɛ́θəd wɛ́ər kǽtəɡɔ̀rijz ɑr rìjpléjst baj háw ɔ́fən ðej əpɪ́ər ɪn ðə déjtəsɛ̀t. wɒt's ðə néjm əv ðɪs ɛnkówdɪŋ tɛkníjk?",
        "trans_RightAnswer": "káwnt ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "fríjkwənsij skéjlɪŋ",
            "wʌ́n-hɒ́t ɛnkówdɪŋ",
            "ɔ́rdɪnəl ɛnkówdɪŋ",
            "hǽʃ ɛnkówdɪŋ",
            "léjbəl ɛnkówdɪŋ"
        ],
        "trans_Explanation": "káwnt ɛnkówdɪŋ ɪz ə nɪ́ftij kæ̀təɡɑ́rɪkəl ɛnkówdɪŋ tɛkníjk wɛ́ər ijtʃ kǽtəɡɔ̀rij ɪz rìjpléjst baj ðə nʌ́mbər əv tájmz (káwnt) ɪt ʃówz ʌp ɪn ðə déjtəsɛ̀t. ɪt's súwpər hɛ́lpfəl æz ɪt hájlàjts kǽtəɡɔ̀rij fríjkwənsij, pətɛ́nʃəlij ɪnfɔ́rmɪŋ ðə mɒ́dəl əbawt kɒ́mən ɔr rɛ́ər kǽtəɡɔ̀rijz wɪðáwt krijéjtɪŋ túw mɛ́nij ɛ́kstrə fíjtʃərz."
    },
    {
        "Question": "You're building a machine learning model, and one of your categorical features has thousands of unique categories, making typical encoding methods inefficient. You decide to replace each category with the average of the target variable for that category. What is this encoding technique called?",
        "RightAnswer": "Target Encoding",
        "WrongAnswers": [
            "One-Hot Encoding",
            "Ordinal Encoding",
            "Frequency Encoding",
            "Binary Encoding",
            "Hashing Encoding"
        ],
        "Explanation": "Target Encoding is a clever approach used when you have categorical variables (like city names or product categories) with many distinct values. Instead of creating numerous new columns or arbitrary numbers, target encoding replaces each category with the average target variable (like average sales, likelihood of clicking, or any outcome you're predicting) for that particular category. This way, the encoded feature carries relevant information directly related to your prediction target, helping your machine learning model perform better.",
        "trans_Question": "júwr bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, ənd wʌ́n əv jɔr kæ̀təɡɑ́rɪkəl fíjtʃərz həz θáwzəndz əv juwnɪ́k kǽtəɡɔ̀rijz, méjkɪŋ tɪ́pɪkəl ɛnkówdɪŋ mɛ́θədz ɪ̀nəfɪ́ʃənt. juw dəsájd tə rìjpléjs ijtʃ kǽtəɡɔ̀rij wɪð ðə ǽvərɪdʒ əv ðə tɑ́rɡət vɛ́ərijəbəl fɔr ðət kǽtəɡɔ̀rij. wɒt ɪz ðɪs ɛnkówdɪŋ tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "tɑ́rɡət ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "wʌ́n-hɒ́t ɛnkówdɪŋ",
            "ɔ́rdɪnəl ɛnkówdɪŋ",
            "fríjkwənsij ɛnkówdɪŋ",
            "bájnərij ɛnkówdɪŋ",
            "hǽʃɪŋ ɛnkówdɪŋ"
        ],
        "trans_Explanation": "tɑ́rɡət ɛnkówdɪŋ ɪz ə klɛ́vər əprówtʃ júwzd wɛ́n juw həv kæ̀təɡɑ́rɪkəl vɛ́ərijəbəlz (lájk sɪ́tij néjmz ɔr prɒ́dəkt kǽtəɡɔ̀rijz) wɪð mɛ́nij dɪstɪ́ŋkt vǽljuwz. ɪnstɛ́d əv krijéjtɪŋ njúwmərəs núw kɒ́ləmz ɔr ɑ́rbɪtrɛ̀ərij nʌ́mbərz, tɑ́rɡət ɛnkówdɪŋ rəpléjsɪz ijtʃ kǽtəɡɔ̀rij wɪð ðə ǽvərɪdʒ tɑ́rɡət vɛ́ərijəbəl (lájk ǽvərɪdʒ séjlz, lájklijhʊ̀d əv klɪ́kɪŋ, ɔr ɛ́nij áwtkʌ̀m júwr prədɪ́ktɪŋ) fɔr ðət pərtɪ́kjələr kǽtəɡɔ̀rij. ðɪs wej, ðə ɛnkówdɪd fíjtʃər kǽrijz rɛ́ləvənt ɪnfərméjʃən dɪərɛ́klij rəléjtɪd tə jɔr prədɪ́kʃən tɑ́rɡət, hɛ́lpɪŋ jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl pərfɔ́rm bɛ́tər."
    },
    {
        "Question": "In machine learning, sometimes datasets have numerous features, but many features have zero or missing values. This type of dataset, where only a small fraction of features have meaningful or non-empty values, is known as what?",
        "RightAnswer": "Sparse Data",
        "WrongAnswers": [
            "Dense Data",
            "Continuous Data",
            "Correlated Data",
            "Normalized Data",
            "Balanced Data"
        ],
        "Explanation": "Sparse data is a term used when your dataset contains lots of zeros or missing values scattered throughout the data points. Imagine a massive spreadsheet where most cells are empty or zero, with only a handful containing useful numbers. Such data can make analysis challenging, but machine learning techniques exist to efficiently handle this kind of sparse dataset and extract valuable insights from it.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, sʌ́mtàjmz déjtəsɛ̀ts həv njúwmərəs fíjtʃərz, bʌt mɛ́nij fíjtʃərz həv zíjərow ɔr mɪ́sɪŋ vǽljuwz. ðɪs tájp əv déjtəsɛ̀t, wɛ́ər ównlij ə smɔ́l frǽkʃən əv fíjtʃərz həv míjnɪŋfəl ɔr nɒn-ɛ́mptij vǽljuwz, ɪz nówn æz wɒt?",
        "trans_RightAnswer": "spɑ́rs déjtə",
        "trans_WrongAnswers": [
            "dɛ́ns déjtə",
            "kəntɪ́njuwəs déjtə",
            "kɔ́rəlèjtɪd déjtə",
            "nɔ́rməlàjzd déjtə",
            "bǽlənst déjtə"
        ],
        "trans_Explanation": "spɑ́rs déjtə ɪz ə tɜ́rm júwzd wɛ́n jɔr déjtəsɛ̀t kəntéjnz lɒ́ts əv zɪ́ərowz ɔr mɪ́sɪŋ vǽljuwz skǽtərd θruwáwt ðə déjtə pɔ́jnts. ɪmǽdʒɪn ə mǽsɪv sprɛ́dʃìjt wɛ́ər mówst sɛ́lz ɑr ɛ́mptij ɔr zíjərow, wɪð ównlij ə hǽndfʊ̀l kəntéjnɪŋ júwsfəl nʌ́mbərz. sʌtʃ déjtə kən méjk ənǽlɪsɪs tʃǽləndʒɪŋ, bʌt məʃíjn lɜ́rnɪŋ tɛkníjks əɡzɪ́st tə əfɪ́ʃəntlij hǽndəl ðɪs kájnd əv spɑ́rs déjtəsɛ̀t ənd ɛ́kstrəkt vǽljəbəl ɪ́nsàjts frəm ɪt."
    },
    {
        "Question": "What do we call datasets in machine learning that have many different features or attributes, making the data complex to analyze and visualize?",
        "RightAnswer": "High-Dimensional Data",
        "WrongAnswers": [
            "Low-Variance Data",
            "Sparse-Matrix Data",
            "Polynomial Data",
            "Binary-Class Data",
            "Nonlinear Data"
        ],
        "Explanation": "High-dimensional data refers to datasets with numerous features—often tens, hundreds, or even thousands of different attributes. Imagine trying to visualize more than three dimensions on paper; it becomes nearly impossible. Similarly, when analyzing such data, algorithms and visualizations struggle with this complexity, leading to challenges known as the 'curse of dimensionality'. Understanding and managing high-dimensional data is an important skill in machine learning, requiring specific techniques designed to simplify, organize, or interpret these complex datasets effectively.",
        "trans_Question": "wɒt dúw wij kɔ́l déjtəsɛ̀ts ɪn məʃíjn lɜ́rnɪŋ ðət həv mɛ́nij dɪ́fərənt fíjtʃərz ɔr ǽtrəbjùwts, méjkɪŋ ðə déjtə kɒ́mplɛks tə ǽnəlàjz ənd vɪ́ʒwəlàjz?",
        "trans_RightAnswer": "háj-dajmɛ́nʃənəl déjtə",
        "trans_WrongAnswers": [
            "lów-vɛ́ərijəns déjtə",
            "spɑ́rs-méjtrɪks déjtə",
            "pɒ̀lijnówmijəl déjtə",
            "bájnərij-klǽs déjtə",
            "nɒnlɪ́nìjər déjtə"
        ],
        "trans_Explanation": "háj-dajmɛ́nʃənəl déjtə rəfɜ́rz tə déjtəsɛ̀ts wɪð njúwmərəs fíjtʃərz—ɔ́fən tɛ́nz, hʌ́ndərdz, ɔr íjvən θáwzəndz əv dɪ́fərənt ǽtrəbjùwts. ɪmǽdʒɪn trájɪŋ tə vɪ́ʒwəlàjz mɔr ðʌn θríj dajmɛ́nʃənz ɒn péjpər; ɪt bəkʌ́mz nɪ́ərlij ɪ̀mpɒ́sɪbəl. sɪ́mɪlərlij, wɛ́n ǽnəlàjzɪŋ sʌtʃ déjtə, ǽlɡərɪ̀ðəmz ənd vɪ̀ʒwəlɪzéjʃənz strʌ́ɡəl wɪð ðɪs kəmplɛ́ksɪtij, líjdɪŋ tə tʃǽləndʒɪz nówn æz ðə 'kɜ́rs əv dajmɛ̀nʃənǽlɪtij'. ʌ̀ndərstǽndɪŋ ənd mǽnɪdʒɪŋ háj-dajmɛ́nʃənəl déjtə ɪz ən ɪmpɔ́rtənt skɪ́l ɪn məʃíjn lɜ́rnɪŋ, rijkwájərɪŋ spəsɪ́fɪk tɛkníjks dəzájnd tə sɪ́mpləfaj, ɔ́rɡənàjz, ɔr ɪntɜ́rprət ðijz kɒ́mplɛks déjtəsɛ̀ts əfɛ́ktɪvlij."
    },
    {
        "Question": "When developing a machine learning solution, what quality ensures you can clearly understand and explain how the model made each prediction, allowing you to trust its decisions?",
        "RightAnswer": "Model Interpretability",
        "WrongAnswers": [
            "Feature Engineering",
            "Model Optimization",
            "Hyperparameter Tuning",
            "Data Normalization",
            "Overfitting Prevention"
        ],
        "Explanation": "Model interpretability describes the clarity with which a human can understand why and how a machine learning model makes certain predictions. It's crucial because it builds user trust, makes it easier to spot errors, and helps stakeholders confidently rely on the model's decisions in real-world applications.",
        "trans_Question": "wɛ́n dəvɛ́ləpɪŋ ə məʃíjn lɜ́rnɪŋ səlúwʃən, wɒt kwɑ́lᵻtij ənʃʊ́rz juw kən klɪ́ərlij ʌ̀ndərstǽnd ənd əkspléjn háw ðə mɒ́dəl méjd ijtʃ prədɪ́kʃən, əláwɪŋ juw tə trʌ́st ɪts dəsɪ́ʒənz?",
        "trans_RightAnswer": "mɒ́dəl ɪntɜ̀rprɛtəbɪ́lɪtij",
        "trans_WrongAnswers": [
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "mɒ́dəl ɒptɪmɪzéjʃən",
            "hàjpərpǽrəmətər túwnɪŋ",
            "déjtə nɔ̀rməlɪzéjʃən",
            "òwvərfɪ́tɪŋ prəvɛ́nʃən"
        ],
        "trans_Explanation": "mɒ́dəl ɪntɜ̀rprɛtəbɪ́lɪtij dəskrájbz ðə klɛ́ərɪtij wɪð wɪ́tʃ ə hjúwmən kən ʌ̀ndərstǽnd wáj ənd háw ə məʃíjn lɜ́rnɪŋ mɒ́dəl méjks sɜ́rtən prədɪ́kʃənz. ɪt's krúwʃəl bəkɒ́z ɪt bɪ́ldz júwzər trʌ́st, méjks ɪt íjzijər tə spɒ́t ɛ́ərərz, ənd hɛ́lps stéjkhòwldərz kɒ́nfɪdəntlij rəláj ɒn ðə mɒ́dəl'z dəsɪ́ʒənz ɪn ríjəl-wɜ́rld æ̀plɪkéjʃənz."
    },
    {
        "Question": "In machine learning, there's growing importance around developing technologies that help us really understand how algorithms make decisions. What's the common term for AI systems designed to clearly show their reasoning and decision-making processes in ways humans can understand?",
        "RightAnswer": "Explainable AI",
        "WrongAnswers": [
            "Generative AI",
            "Supervised Learning",
            "Deep Reinforcement Learning",
            "Federated Learning",
            "Clustering Algorithms"
        ],
        "Explanation": "Explainable AI refers to artificial intelligence systems designed to clearly reveal their decision-making processes and logic in a way humans can easily follow and trust. Unlike many advanced AI models that act like mysterious 'black boxes,' explainable AI lets us peek inside and understand why certain predictions or choices were made. This helps us use AI safely, responsibly, and confidently in sensitive areas like healthcare, finance, and social services.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ɡrówɪŋ ɪmpɔ́rtəns əráwnd dəvɛ́ləpɪŋ tɛknɒ́lədʒijz ðət hɛ́lp ʌs ríjlij ʌ̀ndərstǽnd háw ǽlɡərɪ̀ðəmz méjk dəsɪ́ʒənz. wɒt's ðə kɒ́mən tɜ́rm fɔr AI sɪ́stəmz dəzájnd tə klɪ́ərlij ʃów ðɛər ríjzənɪŋ ənd dəsɪ́ʒən-méjkɪŋ prɒ́sɛsɪz ɪn wéjz hjúwmənz kən ʌ̀ndərstǽnd?",
        "trans_RightAnswer": "əkspléjnəbəl AI",
        "trans_WrongAnswers": [
            "dʒɛ́nərətɪv AI",
            "súwpərvàjzd lɜ́rnɪŋ",
            "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "fɛ́dərèjtɪd lɜ́rnɪŋ",
            "klʌ́stərɪŋ ǽlɡərɪ̀ðəmz"
        ],
        "trans_Explanation": "əkspléjnəbəl AI rəfɜ́rz tə ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns sɪ́stəmz dəzájnd tə klɪ́ərlij rəvíjl ðɛər dəsɪ́ʒən-méjkɪŋ prɒ́sɛsɪz ənd lɒ́dʒɪk ɪn ə wej hjúwmənz kən íjzəlij fɒ́low ənd trʌ́st. ʌ̀nlájk mɛ́nij ədvǽnst AI mɒ́dəlz ðət ǽkt lájk mɪstɪ́ərijəs 'blǽk bɒ́ksɪz,' əkspléjnəbəl AI lɛts ʌs píjk ɪnsájd ənd ʌ̀ndərstǽnd wáj sɜ́rtən prədɪ́kʃənz ɔr tʃɔ́jsɪz wɜ́r méjd. ðɪs hɛ́lps ʌs juwz AI séjflij, rəspɒ́nsɪblij, ənd kɒ́nfɪdəntlij ɪn sɛ́nsɪtɪv ɛ́ərijəz lájk hɛ́lθkɛ̀ər, fájnæ̀ns, ənd sówʃəl sɜ́rvɪsɪz."
    },
    {
        "Question": "Imagine you've built a sophisticated machine learning model that's behaving like a 'black box' and you have no clear idea why it's making certain predictions. Which of the following methods could help you peek inside your model and understand how each feature influences its predictions on individual examples?",
        "RightAnswer": "LIME",
        "WrongAnswers": [
            "Gradient Descent",
            "K-Fold Cross-Validation",
            "Principal Component Analysis (PCA)",
            "Random Forest",
            "Hyperparameter Tuning"
        ],
        "Explanation": "LIME stands for 'Local Interpretable Model-Agnostic Explanations.' Think of it as a flashlight that shines light into the mysterious decision-making of complex machine learning models. Even if your model seems complicated or opaque (like a 'black box'), LIME lets you clearly identify how each feature contributes to individual predictions by creating simpler, understandable models around specific examples. It's a handy method for getting insights into model behavior without requiring in-depth understanding of the complex model itself.",
        "trans_Question": "ɪmǽdʒɪn júwv bɪ́lt ə səfɪ́stɪkèjtɪd məʃíjn lɜ́rnɪŋ mɒ́dəl ðət's bəhéjvɪŋ lájk ə 'blǽk bɒ́ks' ənd juw həv now klɪ́ər ajdíjə wáj ɪt's méjkɪŋ sɜ́rtən prədɪ́kʃənz. wɪ́tʃ əv ðə fɒ́lowɪŋ mɛ́θədz kʊ́d hɛ́lp juw píjk ɪnsájd jɔr mɒ́dəl ənd ʌ̀ndərstǽnd háw ijtʃ fíjtʃər ɪ́nfluwənsɪz ɪts prədɪ́kʃənz ɒn ɪndɪvɪ́dʒəwəl əɡzǽmpəlz?",
        "trans_RightAnswer": "LIME",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "k-fówld krɔ́s-væ̀lɪdéjʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs (PCA)",
            "rǽndəm fɔ́rəst",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "LIME stǽndz fɔr 'lówkəl ɪntɜ́rprətəbəl mɒ́dəl-æɡnɒ́stɪk ɛ̀ksplənéjʃənz.' θɪ́ŋk əv ɪt æz ə flǽʃlàjt ðət ʃájnz lájt ɪntə ðə mɪstɪ́ərijəs dəsɪ́ʒən-méjkɪŋ əv kɒ́mplɛks məʃíjn lɜ́rnɪŋ mɒ́dəlz. íjvən ɪf jɔr mɒ́dəl síjmz kɒ́mplɪkèjtɪd ɔr owpéjk (lájk ə 'blǽk bɒ́ks'), LIME lɛts juw klɪ́ərlij ajdɛ́ntɪfàj háw ijtʃ fíjtʃər kəntrɪ́bjuwts tə ɪndɪvɪ́dʒəwəl prədɪ́kʃənz baj krijéjtɪŋ sɪ́mplər, ʌ̀ndərstǽndəbəl mɒ́dəlz əráwnd spəsɪ́fɪk əɡzǽmpəlz. ɪt's ə hǽndij mɛ́θəd fɔr ɡɛ́tɪŋ ɪ́nsàjts ɪntə mɒ́dəl bəhéjvjər wɪðáwt rijkwájərɪŋ ɪn-dɛ́pθ ʌ̀ndərstǽndɪŋ əv ðə kɒ́mplɛks mɒ́dəl ɪtsɛ́lf."
    },
    {
        "Question": "You're working with machine learning and need to understand how each feature influences your model's predictions. Which of the following methods helps explain individual predictions by measuring the contribution of each feature?",
        "RightAnswer": "SHAP",
        "WrongAnswers": [
            "Gradient boosting",
            "Hyperparameter tuning",
            "K-fold cross-validation",
            "Batch normalization",
            "Stochastic gradient descent"
        ],
        "Explanation": "SHAP (SHapley Additive exPlanations) is a user-friendly approach in machine learning designed to show clearly and intuitively how each feature affects your model's predictions. Inspired by cooperative game theory, SHAP assigns each feature a value showing whether it pushes the outcome up or down, making complex models easy and accessible to interpret.",
        "trans_Question": "júwr wɜ́rkɪŋ wɪð məʃíjn lɜ́rnɪŋ ənd níjd tə ʌ̀ndərstǽnd háw ijtʃ fíjtʃər ɪ́nfluwənsɪz jɔr mɒ́dəl'z prədɪ́kʃənz. wɪ́tʃ əv ðə fɒ́lowɪŋ mɛ́θədz hɛ́lps əkspléjn ɪndɪvɪ́dʒəwəl prədɪ́kʃənz baj mɛ́ʒərɪŋ ðə kɒ̀ntrəbjúwʃən əv ijtʃ fíjtʃər?",
        "trans_RightAnswer": "SHAP",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "k-fówld krɔ́s-væ̀lɪdéjʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "stowkǽstɪk ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "SHAP (ʃǽplij ǽdɪtɪv ɛ̀ksplənéjʃənz) ɪz ə júwzər-frɛ́ndlij əprówtʃ ɪn məʃíjn lɜ́rnɪŋ dəzájnd tə ʃów klɪ́ərlij ənd ɪntúwɪtɪvlij háw ijtʃ fíjtʃər əfɛ́kts jɔr mɒ́dəl'z prədɪ́kʃənz. ɪnspájərd baj kowɒ́pərətɪv ɡéjm θíjərij, SHAP əsájnz ijtʃ fíjtʃər ə vǽljuw ʃówɪŋ wɛ́ðər ɪt pʊ́ʃɪz ðə áwtkʌ̀m ʌp ɔr dawn, méjkɪŋ kɒ́mplɛks mɒ́dəlz íjzij ənd æksɛ́sɪbəl tə ɪntɜ́rprət."
    },
    {
        "Question": "You've built a machine learning model but want to understand how the prediction changes when you alter a single feature, keeping all other features fixed. Which visualization would help you clearly see this relationship?",
        "RightAnswer": "Partial Dependence Plot",
        "WrongAnswers": [
            "Confusion Matrix",
            "ROC Curve",
            "Learning Curve",
            "Residual Plot",
            "Feature Importance Bar Chart"
        ],
        "Explanation": "A Partial Dependence Plot (PDP) is a handy visualization that shows you how changes in a single feature affect the model's predictions on average, holding all other features constant. Think of it like turning one dial at a time in a complex machine to clearly see how it impacts outcomes. This makes PDPs incredibly helpful for understanding individual features and gaining intuitive insights into your machine learning model.",
        "trans_Question": "júwv bɪ́lt ə məʃíjn lɜ́rnɪŋ mɒ́dəl bʌt wɒ́nt tə ʌ̀ndərstǽnd háw ðə prədɪ́kʃən tʃéjndʒɪz wɛ́n juw ɔ́ltər ə sɪ́ŋɡəl fíjtʃər, kíjpɪŋ ɔl ʌ́ðər fíjtʃərz fɪ́kst. wɪ́tʃ vɪ̀ʒwəlɪzéjʃən wʊd hɛ́lp juw klɪ́ərlij síj ðɪs rəléjʃənʃɪ̀p?",
        "trans_RightAnswer": "pɑ́rʃəl dəpɛ́ndəns plɒ́t",
        "trans_WrongAnswers": [
            "kənfjúwʒən méjtrɪks",
            "ROC kɜ́rv",
            "lɜ́rnɪŋ kɜ́rv",
            "rəzɪ́dʒuwəl plɒ́t",
            "fíjtʃər ɪmpɔ́rtəns bɑ́r tʃɑ́rt"
        ],
        "trans_Explanation": "ə pɑ́rʃəl dəpɛ́ndəns plɒ́t (PDP) ɪz ə hǽndij vɪ̀ʒwəlɪzéjʃən ðət ʃówz juw háw tʃéjndʒɪz ɪn ə sɪ́ŋɡəl fíjtʃər əfɛ́kt ðə mɒ́dəl'z prədɪ́kʃənz ɒn ǽvərɪdʒ, hówldɪŋ ɔl ʌ́ðər fíjtʃərz kɒ́nstənt. θɪ́ŋk əv ɪt lájk tɜ́rnɪŋ wʌ́n dájəl æt ə tájm ɪn ə kɒ́mplɛks məʃíjn tə klɪ́ərlij síj háw ɪt ɪ́mpækts áwtkʌ̀mz. ðɪs méjks pijdijpijɛs ɪnkrɛ́dɪblij hɛ́lpfəl fɔr ʌ̀ndərstǽndɪŋ ɪndɪvɪ́dʒəwəl fíjtʃərz ənd ɡéjnɪŋ ɪntúwɪtɪv ɪ́nsàjts ɪntə jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl."
    },
    {
        "Question": "When evaluating a machine learning model, which technique helps identify the importance of each feature by measuring how the model's performance changes if we randomly shuffle the values of that feature?",
        "RightAnswer": "Permutation Importance",
        "WrongAnswers": [
            "Gradient Boosting",
            "Cross-validation",
            "Feature Scaling",
            "Regularization",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Permutation Importance measures the importance of features by checking how much a model's performance drops when a specific feature's values are randomly shuffled. The more the model performance deteriorates due to this shuffle, the more important that particular feature is. This helps you quickly discover which features have the most significant contribution to your model's predictive abilities.",
        "trans_Question": "wɛ́n əvǽljuwèjtɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, wɪ́tʃ tɛkníjk hɛ́lps ajdɛ́ntɪfàj ðə ɪmpɔ́rtəns əv ijtʃ fíjtʃər baj mɛ́ʒərɪŋ háw ðə mɒ́dəl'z pərfɔ́rməns tʃéjndʒɪz ɪf wij rǽndəmlij ʃʌ́fəl ðə vǽljuwz əv ðət fíjtʃər?",
        "trans_RightAnswer": "pɜ̀rmjuwtéjʃən ɪmpɔ́rtəns",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "krɔ́s-væ̀lɪdéjʃən",
            "fíjtʃər skéjlɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "pɜ̀rmjuwtéjʃən ɪmpɔ́rtəns mɛ́ʒərz ðə ɪmpɔ́rtəns əv fíjtʃərz baj tʃɛ́kɪŋ háw mʌtʃ ə mɒ́dəl'z pərfɔ́rməns drɒ́ps wɛ́n ə spəsɪ́fɪk fíjtʃər'z vǽljuwz ɑr rǽndəmlij ʃʌ́fəld. ðə mɔr ðə mɒ́dəl pərfɔ́rməns dətɪ́ərijərèjts djúw tə ðɪs ʃʌ́fəl, ðə mɔr ɪmpɔ́rtənt ðət pərtɪ́kjələr fíjtʃər ɪz. ðɪs hɛ́lps juw kwɪ́klij dɪskʌ́vər wɪ́tʃ fíjtʃərz həv ðə mówst sɪɡnɪ́fɪkənt kɒ̀ntrəbjúwʃən tə jɔr mɒ́dəl'z prədɪ́ktɪv əbɪ́lɪtìjz."
    },
    {
        "Question": "When working on a machine learning model, you wonder how small changes in your features or parameters might affect your model's predictions. Which method would you use to systematically explore these effects and find which inputs most strongly influence your outcomes?",
        "RightAnswer": "Sensitivity Analysis",
        "WrongAnswers": [
            "Cross-Validation",
            "Feature Scaling",
            "Hyperparameter Tuning",
            "Dimensionality Reduction",
            "Bias-Variance Tradeoff"
        ],
        "Explanation": "Sensitivity analysis in machine learning is like asking 'what if?' questions about your model. It involves systematically tweaking inputs or parameters to see how the output predictions shift. By doing so, you learn which variables have the biggest impact on your results. This helps you understand your model better, identify key features influencing predictions, and build more reliable and robust models.",
        "trans_Question": "wɛ́n wɜ́rkɪŋ ɒn ə məʃíjn lɜ́rnɪŋ mɒ́dəl, juw wʌ́ndər háw smɔ́l tʃéjndʒɪz ɪn jɔr fíjtʃərz ɔr pərǽmətərz majt əfɛ́kt jɔr mɒ́dəl'z prədɪ́kʃənz. wɪ́tʃ mɛ́θəd wʊd juw juwz tə sɪ̀stəmǽtɪklij əksplɔ́r ðijz əfɛ́kts ənd fájnd wɪ́tʃ ɪ́npʊ̀ts mówst strɔ́ŋlij ɪ́nfluwəns jɔr áwtkʌ̀mz?",
        "trans_RightAnswer": "sɛ̀nsɪtɪ́vɪtij ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "krɔ́s-væ̀lɪdéjʃən",
            "fíjtʃər skéjlɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "bájəs-vɛ́ərijəns tréjdɔ̀f"
        ],
        "trans_Explanation": "sɛ̀nsɪtɪ́vɪtij ənǽlɪsɪs ɪn məʃíjn lɜ́rnɪŋ ɪz lájk ǽskɪŋ 'wɒt ɪf?' kwɛ́stʃənz əbawt jɔr mɒ́dəl. ɪt ɪnvɒ́lvz sɪ̀stəmǽtɪklij twíjkɪŋ ɪ́npʊ̀ts ɔr pərǽmətərz tə síj háw ðə áwtpʊ̀t prədɪ́kʃənz ʃɪ́ft. baj dúwɪŋ sow, juw lɜ́rn wɪ́tʃ vɛ́ərijəbəlz həv ðə bɪ́ɡəst ɪ́mpækt ɒn jɔr rəzʌ́lts. ðɪs hɛ́lps juw ʌ̀ndərstǽnd jɔr mɒ́dəl bɛ́tər, ajdɛ́ntɪfàj kíj fíjtʃərz ɪ́nfluwənsɪŋ prədɪ́kʃənz, ənd bɪ́ld mɔr rəlájəbəl ənd rowbʌ́st mɒ́dəlz."
    },
    {
        "Question": "Imagine you launched a new feature on your mobile app, and now you want to measure exactly how much this new feature contributed to increasing user engagement, while accounting for trends and other factors. Which machine learning technique is designed specifically to help you measure this kind of direct effect?",
        "RightAnswer": "Causal Impact",
        "WrongAnswers": [
            "Random Forest",
            "Neural Network",
            "Clustering",
            "Time Series Forecasting",
            "Dimensionality Reduction"
        ],
        "Explanation": "Causal Impact is a machine learning method designed specifically to measure how much a certain change (like launching a new feature or starting a promotional campaign) actually affects an outcome. It carefully separates out other influences—such as seasonal patterns, market trends, or random noise—to reveal the genuine effect of your action. Think of it as the difference between \"Did my feature actually cause users to engage more, or was that just a coincidence?\" Causal impact helps you clearly pinpoint the real reason behind changes you observe.",
        "trans_Question": "ɪmǽdʒɪn juw lɔ́ntʃt ə núw fíjtʃər ɒn jɔr mówbajl ǽp, ənd náw juw wɒ́nt tə mɛ́ʒər əɡzǽktlij háw mʌtʃ ðɪs núw fíjtʃər kəntrɪ́bjuwtɪd tə ɪnkríjsɪŋ júwzər ənɡéjdʒmənt, wájl əkáwntɪŋ fɔr trɛ́ndz ənd ʌ́ðər fǽktərz. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪz dəzájnd spəsɪ́fɪklij tə hɛ́lp juw mɛ́ʒər ðɪs kájnd əv dɪərɛ́kt əfɛ́kt?",
        "trans_RightAnswer": "kɔ́zəl ɪ́mpækt",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəst",
            "nʊ́rəl nɛ́twɜ̀rk",
            "klʌ́stərɪŋ",
            "tájm sɪ́ərijz fɔ́rkæ̀stɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "kɔ́zəl ɪ́mpækt ɪz ə məʃíjn lɜ́rnɪŋ mɛ́θəd dəzájnd spəsɪ́fɪklij tə mɛ́ʒər háw mʌtʃ ə sɜ́rtən tʃéjndʒ (lájk lɔ́ntʃɪŋ ə núw fíjtʃər ɔr stɑ́rtɪŋ ə prəmówʃənəl kæmpéjn) ǽktʃùwəlij əfɛ́kts ən áwtkʌ̀m. ɪt kɛ́ərfəlij sɛ́pərèjts awt ʌ́ðər ɪ́nfluwənsɪz—sʌtʃ æz síjzənəl pǽtərnz, mɑ́rkət trɛ́ndz, ɔr rǽndəm nɔ́jz—tə rəvíjl ðə dʒénjuwɪn əfɛ́kt əv jɔr ǽkʃən. θɪ́ŋk əv ɪt æz ðə dɪ́fərəns bijtwíjn \"dɪd máj fíjtʃər ǽktʃùwəlij kɒ́z júwzərz tə ənɡéjdʒ mɔr, ɔr wɒz ðət dʒəst ə kowɪ́nsɪdəns?\" kɔ́zəl ɪ́mpækt hɛ́lps juw klɪ́ərlij pɪ́npɔ̀jnt ðə ríjəl ríjzən bəhájnd tʃéjndʒɪz juw əbzɜ́rv."
    },
    {
        "Question": "You're building a new machine learning model. After training it, you realize it's not performing as expected. You start examining what's causing errors, checking the data, reviewing code, and looking at model predictions to spot issues. What's this process called?",
        "RightAnswer": "Model Debugging",
        "WrongAnswers": [
            "Feature Scaling",
            "Hyperparameter Tuning",
            "Data Augmentation",
            "Model Ensembling",
            "Cross Validation"
        ],
        "Explanation": "Model debugging means finding and fixing problems in your machine learning model. Imagine you're a detective investigating why your model isn't performing well—this involves examining the input data, looking closely at predictions your model is making, reviewing the training approach, and identifying mistakes or unexpected behaviors. Essentially, it's troubleshooting your model to improve its performance.",
        "trans_Question": "júwr bɪ́ldɪŋ ə núw məʃíjn lɜ́rnɪŋ mɒ́dəl. ǽftər tréjnɪŋ ɪt, juw ríjəlàjz ɪt's nɒt pərfɔ́rmɪŋ æz əkspɛ́ktɪd. juw stɑ́rt əɡzǽmɪnɪŋ wɒt's kɒ́zɪŋ ɛ́ərərz, tʃɛ́kɪŋ ðə déjtə, rijvjúwɪŋ kówd, ənd lʊ́kɪŋ æt mɒ́dəl prədɪ́kʃənz tə spɒ́t ɪ́ʃuwz. wɒt's ðɪs prɒ́sɛs kɔ́ld?",
        "trans_RightAnswer": "mɒ́dəl dijbʌ́ɡɪŋ",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "mɒ́dəl ɒnsɛ́mbəlɪŋ",
            "krɔ́s væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "mɒ́dəl dijbʌ́ɡɪŋ míjnz fájndɪŋ ənd fɪ́ksɪŋ prɒ́bləmz ɪn jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl. ɪmǽdʒɪn júwr ə dətɛ́ktɪv ɪnvɛ́stɪɡèjtɪŋ wáj jɔr mɒ́dəl ɪzənt pərfɔ́rmɪŋ wɛ́l—ðɪs ɪnvɒ́lvz əɡzǽmɪnɪŋ ðə ɪ́npʊ̀t déjtə, lʊ́kɪŋ klówslij æt prədɪ́kʃənz jɔr mɒ́dəl ɪz méjkɪŋ, rijvjúwɪŋ ðə tréjnɪŋ əprówtʃ, ənd ajdɛ́ntɪfàjɪŋ mɪstéjks ɔr ʌ̀nəkspɛ́ktɪd bəhéjvjərz. əsɛ́nʃəlij, ɪt's trʌ́bəlʃùwtɪŋ jɔr mɒ́dəl tə ɪmprúwv ɪts pərfɔ́rməns."
    },
    {
        "Question": "When training neural networks, you might initially set your learning rate relatively high to speed up the network's progress. However, keeping a high rate throughout training might cause instability. To avoid overshooting or missing the optimal solution, you gradually lower the learning rate as training proceeds. What's the term for this gradual lowering of the learning rate?",
        "RightAnswer": "Learning Rate Decay",
        "WrongAnswers": [
            "Gradient Descent Acceleration",
            "Learning Momentum",
            "Regularization Adjustment",
            "Weight Initialization",
            "Early Stopping"
        ],
        "Explanation": "Learning Rate Decay is a method used in machine learning where the learning rate—the step size determining how much the model adjusts at each training iteration—is gradually decreased during training. Think of it like slowing down your car as you approach your destination to avoid missing the final turn. This approach helps models fine-tune their weights, improving results and preventing issues like overshooting the best solution.",
        "trans_Question": "wɛ́n tréjnɪŋ nʊ́rəl nɛ́twɜ̀rks, juw majt ɪnɪ́ʃəlij sɛ́t jɔr lɜ́rnɪŋ réjt rɛ́lətɪvlij háj tə spíjd ʌp ðə nɛ́twɜ̀rk'z prɒ́ɡrɛ̀s. hàwɛ́vər, kíjpɪŋ ə háj réjt θruwáwt tréjnɪŋ majt kɒ́z ɪnstəbɪ́lɪtij. tə əvɔ́jd ówvərʃùwtɪŋ ɔr mɪ́sɪŋ ðə ɒ́ptɪməl səlúwʃən, juw ɡrǽdʒuwəlij lówər ðə lɜ́rnɪŋ réjt æz tréjnɪŋ prəsíjdz. wɒt's ðə tɜ́rm fɔr ðɪs ɡrǽdʒuwəl lówərɪŋ əv ðə lɜ́rnɪŋ réjt?",
        "trans_RightAnswer": "lɜ́rnɪŋ réjt dəkéj",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt æ̀ksɛ̀ləréjʃən",
            "lɜ́rnɪŋ mowmɛ́ntəm",
            "rèɡjəlɛ̀ərɪzéjʃən ədʒʌ́stmənt",
            "wéjt ɪnɪ́ʃəlɪzéjʃən",
            "ɜ́rlij stɒ́pɪŋ"
        ],
        "trans_Explanation": "lɜ́rnɪŋ réjt dəkéj ɪz ə mɛ́θəd júwzd ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ðə lɜ́rnɪŋ réjt—ðə stɛ́p sájz dətɜ́rmɪnɪŋ háw mʌtʃ ðə mɒ́dəl ədʒʌ́sts æt ijtʃ tréjnɪŋ ɪ̀təréjʃən—ɪz ɡrǽdʒuwəlij díjkrìjst dʊ́rɪŋ tréjnɪŋ. θɪ́ŋk əv ɪt lájk slówɪŋ dawn jɔr kɑ́r æz juw əprówtʃ jɔr dɛ̀stɪnéjʃən tə əvɔ́jd mɪ́sɪŋ ðə fájnəl tɜ́rn. ðɪs əprówtʃ hɛ́lps mɒ́dəlz fájn-túwn ðɛər wéjts, ɪmprúwvɪŋ rəzʌ́lts ənd prəvɛ́ntɪŋ ɪ́ʃuwz lájk ówvərʃùwtɪŋ ðə bɛ́st səlúwʃən."
    },
    {
        "Question": "In training machine learning models, we often face the risk of our model becoming overly complex and memorizing the training data instead of recognizing patterns. A helpful approach is to slightly shrink the model's parameters gradually during training, encouraging simpler models that avoid excessive complexity. What is this helpful technique called?",
        "RightAnswer": "Weight Decay",
        "WrongAnswers": [
            "Gradient Clipping",
            "Early Stopping",
            "Dropout Regularization",
            "Learning Rate Decay",
            "Batch Normalization"
        ],
        "Explanation": "Weight Decay is a regularization technique used in machine learning to help models avoid becoming overly complicated or memorizing training data. It involves gradually shrinking the values of the model parameters (weights) during training, prompting the model to find simpler and smoother patterns. Think of it as gently nudging your model towards simpler solutions that generalize better and perform well on new, unseen data.",
        "trans_Question": "ɪn tréjnɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz, wij ɔ́fən féjs ðə rɪ́sk əv awər mɒ́dəl bəkʌ́mɪŋ ówvərlij kɒ́mplɛks ənd mɛ́məràjzɪŋ ðə tréjnɪŋ déjtə ɪnstɛ́d əv rɛ́kəɡnàjzɪŋ pǽtərnz. ə hɛ́lpfəl əprówtʃ ɪz tə slájtlij ʃrɪ́ŋk ðə mɒ́dəl'z pərǽmətərz ɡrǽdʒuwəlij dʊ́rɪŋ tréjnɪŋ, ənkɜ́rɪdʒɪŋ sɪ́mplər mɒ́dəlz ðət əvɔ́jd əksɛ́sɪv kəmplɛ́ksɪtij. wɒt ɪz ðɪs hɛ́lpfəl tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "wéjt dəkéj",
        "trans_WrongAnswers": [
            "ɡréjdijənt klɪ́pɪŋ",
            "ɜ́rlij stɒ́pɪŋ",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən",
            "lɜ́rnɪŋ réjt dəkéj",
            "bǽtʃ nɔ̀rməlɪzéjʃən"
        ],
        "trans_Explanation": "wéjt dəkéj ɪz ə rèɡjəlɛ̀ərɪzéjʃən tɛkníjk júwzd ɪn məʃíjn lɜ́rnɪŋ tə hɛ́lp mɒ́dəlz əvɔ́jd bəkʌ́mɪŋ ówvərlij kɒ́mplɪkèjtɪd ɔr mɛ́məràjzɪŋ tréjnɪŋ déjtə. ɪt ɪnvɒ́lvz ɡrǽdʒuwəlij ʃrɪ́ŋkɪŋ ðə vǽljuwz əv ðə mɒ́dəl pərǽmətərz (wéjts) dʊ́rɪŋ tréjnɪŋ, prɒ́mptɪŋ ðə mɒ́dəl tə fájnd sɪ́mplər ənd smúwðər pǽtərnz. θɪ́ŋk əv ɪt æz dʒɛ́ntlij nʌ́dʒɪŋ jɔr mɒ́dəl təwɔ́rdz sɪ́mplər səlúwʃənz ðət dʒɛ́nərəlàjz bɛ́tər ənd pərfɔ́rm wɛ́l ɒn núw, ʌ̀nsíjn déjtə."
    },
    {
        "Question": "When a machine learning model learns insights from one dataset or domain and successfully applies them to another related dataset or domain, what is this helpful property called?",
        "RightAnswer": "Transferability",
        "WrongAnswers": [
            "Overfitting",
            "Regularization",
            "Gradient Descent",
            "Bias-Variance Tradeoff",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Transferability means the ability of a machine learning model or its learned insights to apply knowledge learned from one scenario or dataset effectively to another, different but related, scenario or dataset. Think of it as being similar to how your knowledge from riding a bicycle can help you when learning to ride a scooter—you're transferring what you've previously learned to something slightly different.",
        "trans_Question": "wɛ́n ə məʃíjn lɜ́rnɪŋ mɒ́dəl lɜ́rnz ɪ́nsàjts frəm wʌ́n déjtəsɛ̀t ɔr dowméjn ənd səksɛ́sfəlij əplájz ðɛm tə ənʌ́ðər rəléjtɪd déjtəsɛ̀t ɔr dowméjn, wɒt ɪz ðɪs hɛ́lpfəl prɒ́pərtij kɔ́ld?",
        "trans_RightAnswer": "træ̀nsfərəbɪ́lɪtij",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "bájəs-vɛ́ərijəns tréjdɔ̀f",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "træ̀nsfərəbɪ́lɪtij míjnz ðə əbɪ́lɪtij əv ə məʃíjn lɜ́rnɪŋ mɒ́dəl ɔr ɪts lɜ́rnd ɪ́nsàjts tə əpláj nɒ́lɪdʒ lɜ́rnd frəm wʌ́n sənɛ́ərijow ɔr déjtəsɛ̀t əfɛ́ktɪvlij tə ənʌ́ðər, dɪ́fərənt bʌt rəléjtɪd, sənɛ́ərijow ɔr déjtəsɛ̀t. θɪ́ŋk əv ɪt æz bíjɪŋ sɪ́mɪlər tə háw jɔr nɒ́lɪdʒ frəm rájdɪŋ ə bájsɪkəl kən hɛ́lp juw wɛ́n lɜ́rnɪŋ tə rájd ə skúwtər—júwr trænsfɜ́rɪŋ wɒt júwv príjvijəslij lɜ́rnd tə sʌ́mθɪŋ slájtlij dɪ́fərənt."
    },
    {
        "Question": "In machine learning, imagine you've built a model to recognize animals from clear daytime photos but now need it to work on dark nighttime images. Instead of retraining the entire model from scratch for nighttime conditions, you apply a strategy to help your model adjust and perform well in this new situation. What's this smart strategy called?",
        "RightAnswer": "Domain Adaptation",
        "WrongAnswers": [
            "Hyperparameter Tuning",
            "Feature Engineering",
            "Model Regularization",
            "Data Augmentation",
            "Supervised Classification"
        ],
        "Explanation": "Domain Adaptation is a machine learning approach used when you have a model trained in one situation (called source domain) that you want to use effectively in a slightly different situation (called target domain). Rather than retraining from scratch, domain adaptation techniques help your existing model adapt by minimizing the differences between the two domains—saving time, resources, and data collection efforts. This technique is especially useful when gathering enough labeled data in the new domain isn't practical.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ɪmǽdʒɪn júwv bɪ́lt ə mɒ́dəl tə rɛ́kəɡnàjz ǽnɪməlz frəm klɪ́ər déjtàjm fówtòwz bʌt náw níjd ɪt tə wɜ́rk ɒn dɑ́rk nájttàjm ɪ́mɪdʒɪz. ɪnstɛ́d əv rijtréjnɪŋ ðə əntájər mɒ́dəl frəm skrǽtʃ fɔr nájttàjm kəndɪ́ʃənz, juw əpláj ə strǽtədʒij tə hɛ́lp jɔr mɒ́dəl ədʒʌ́st ənd pərfɔ́rm wɛ́l ɪn ðɪs núw sɪ̀tʃuwéjʃən. wɒt's ðɪs smɑ́rt strǽtədʒij kɔ́ld?",
        "trans_RightAnswer": "dowméjn æ̀dəptéjʃən",
        "trans_WrongAnswers": [
            "hàjpərpǽrəmətər túwnɪŋ",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "mɒ́dəl rèɡjəlɛ̀ərɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "súwpərvàjzd klæ̀sɪfɪkéjʃən"
        ],
        "trans_Explanation": "dowméjn æ̀dəptéjʃən ɪz ə məʃíjn lɜ́rnɪŋ əprówtʃ júwzd wɛ́n juw həv ə mɒ́dəl tréjnd ɪn wʌ́n sɪ̀tʃuwéjʃən (kɔ́ld sɔ́rs dowméjn) ðət juw wɒ́nt tə juwz əfɛ́ktɪvlij ɪn ə slájtlij dɪ́fərənt sɪ̀tʃuwéjʃən (kɔ́ld tɑ́rɡət dowméjn). rǽðər ðʌn rijtréjnɪŋ frəm skrǽtʃ, dowméjn æ̀dəptéjʃən tɛkníjks hɛ́lp jɔr əɡzɪ́stɪŋ mɒ́dəl ədǽpt baj mɪ́nɪmàjzɪŋ ðə dɪ́fərənsɪz bijtwíjn ðə túw dowméjnz—séjvɪŋ tájm, ríjsɔrsɪz, ənd déjtə kəlɛ́kʃən ɛ́fərts. ðɪs tɛkníjk ɪz əspɛ́ʃəlij júwsfəl wɛ́n ɡǽðərɪŋ ənʌ́f léjbəld déjtə ɪn ðə núw dowméjn ɪzənt prǽktɪkəl."
    },
    {
        "Question": "What do you call the phenomenon when a machine learning model's performance deteriorates over time because the underlying data patterns or relationships change?",
        "RightAnswer": "Concept Drift",
        "WrongAnswers": [
            "Overfitting",
            "Data Leakage",
            "Vanishing Gradient",
            "Curse of Dimensionality",
            "Class Imbalance"
        ],
        "Explanation": "Concept Drift occurs when the relationships or patterns the model learned during training gradually or abruptly change over time, causing the model's predictions to become increasingly outdated or incorrect. For instance, customer preferences can shift, or market conditions may evolve, so models need continuous updating or adjustments to stay effective and accurate.",
        "trans_Question": "wɒt dúw juw kɔ́l ðə fənɒ́mənɒn wɛ́n ə məʃíjn lɜ́rnɪŋ mɒ́dəl'z pərfɔ́rməns dətɪ́ərijərèjts ówvər tájm bəkɒ́z ðə ʌ̀ndərlájɪŋ déjtə pǽtərnz ɔr rəléjʃənʃɪ̀ps tʃéjndʒ?",
        "trans_RightAnswer": "kɒ́nsɛpt drɪ́ft",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "déjtə líjkɪdʒ",
            "vǽnɪʃɪŋ ɡréjdijənt",
            "kɜ́rs əv dajmɛ̀nʃənǽlɪtij",
            "klǽs ɪmbǽləns"
        ],
        "trans_Explanation": "kɒ́nsɛpt drɪ́ft əkɜ́rz wɛ́n ðə rəléjʃənʃɪ̀ps ɔr pǽtərnz ðə mɒ́dəl lɜ́rnd dʊ́rɪŋ tréjnɪŋ ɡrǽdʒuwəlij ɔr əbrʌ́ptlij tʃéjndʒ ówvər tájm, kɒ́zɪŋ ðə mɒ́dəl'z prədɪ́kʃənz tə bəkʌ́m ɪnkríjsɪŋɡlij áwtdèjtɪd ɔr ɪ̀nkərɛ́kt. fɔr ɪ́nstəns, kʌ́stəmər prɛ́fərənsɪz kən ʃɪ́ft, ɔr mɑ́rkət kəndɪ́ʃənz mej əvɒ́lv, sow mɒ́dəlz níjd kəntɪ́njuwəs ʌ́pdèjtɪŋ ɔr ədʒʌ́stmənts tə stéj əféktɪv ənd ǽkjərət."
    },
    {
        "Question": "Imagine you're using a machine learning model to predict customer preferences based on past behavior, but over time customer behaviors change, causing older predictions to be less accurate. What term describes this gradual shift in the input data distribution?",
        "RightAnswer": "Data Drift",
        "WrongAnswers": [
            "Overfitting",
            "Feature Engineering",
            "Hyperparameter Tuning",
            "Regularization",
            "Dimensionality Reduction"
        ],
        "Explanation": "Data drift is when the data your machine learning model encounters gradually shifts or changes over time. For example, imagine a model trained to detect customer preferences based on historical behavior; as customer habits and preferences change, the model's input data shifts from its original training conditions. This causes the model's predictions to become less accurate, making it crucial to detect and adjust for these shifts regularly.",
        "trans_Question": "ɪmǽdʒɪn júwr júwzɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə prədɪ́kt kʌ́stəmər prɛ́fərənsɪz béjst ɒn pǽst bəhéjvjər, bʌt ówvər tájm kʌ́stəmər bəhéjvjərz tʃéjndʒ, kɒ́zɪŋ ówldər prədɪ́kʃənz tə bij lɛ́s ǽkjərət. wɒt tɜ́rm dəskrájbz ðɪs ɡrǽdʒuwəl ʃɪ́ft ɪn ðə ɪ́npʊ̀t déjtə dɪ̀strəbjúwʃən?",
        "trans_RightAnswer": "déjtə drɪ́ft",
        "trans_WrongAnswers": [
            "òwvərfɪ́tɪŋ",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "déjtə drɪ́ft ɪz wɛ́n ðə déjtə jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl ənkáwntərz ɡrǽdʒuwəlij ʃɪ́fts ɔr tʃéjndʒɪz ówvər tájm. fɔr əɡzǽmpəl, ɪmǽdʒɪn ə mɒ́dəl tréjnd tə dətɛ́kt kʌ́stəmər prɛ́fərənsɪz béjst ɒn hɪstɔ́rɪkəl bəhéjvjər; æz kʌ́stəmər hǽbɪts ənd prɛ́fərənsɪz tʃéjndʒ, ðə mɒ́dəl'z ɪ́npʊ̀t déjtə ʃɪ́fts frəm ɪts ərɪ́dʒɪnəl tréjnɪŋ kəndɪ́ʃənz. ðɪs kɒ́zɪz ðə mɒ́dəl'z prədɪ́kʃənz tə bəkʌ́m lɛ́s ǽkjərət, méjkɪŋ ɪt krúwʃəl tə dətɛ́kt ənd ədʒʌ́st fɔr ðijz ʃɪ́fts rɛ́ɡjələrlij."
    },
    {
        "Question": "What do we call the machine learning approach where the model continuously updates and improves by learning from new information over time without needing to start again from scratch?",
        "RightAnswer": "Incremental Learning",
        "WrongAnswers": [
            "Batch Processing",
            "Supervised Learning",
            "Transfer Learning",
            "Offline Learning",
            "Ensemble Learning"
        ],
        "Explanation": "Incremental learning is a practical and dynamic approach in machine learning where the model is flexible enough to keep getting smarter as new data comes in, without needing to be retrained completely from zero every time. This approach is especially valuable when dealing with data streams that continuously grow or change, allowing the model to adapt smoothly and efficiently.",
        "trans_Question": "wɒt dúw wij kɔ́l ðə məʃíjn lɜ́rnɪŋ əprówtʃ wɛ́ər ðə mɒ́dəl kəntɪ́njuwəslij ʌ́pdèjts ənd ɪmprúwvz baj lɜ́rnɪŋ frəm núw ɪnfərméjʃən ówvər tájm wɪðáwt níjdɪŋ tə stɑ́rt əɡéjn frəm skrǽtʃ?",
        "trans_RightAnswer": "ɪnkrəmɛ́ntəl lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "bǽtʃ prɒ́sɛsɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "ɔ́flàjn lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ɪnkrəmɛ́ntəl lɜ́rnɪŋ ɪz ə prǽktɪkəl ənd dajnǽmɪk əprówtʃ ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ðə mɒ́dəl ɪz flɛ́ksɪbəl ənʌ́f tə kíjp ɡɛ́tɪŋ smɑ́rtər æz núw déjtə kʌ́mz ɪn, wɪðáwt níjdɪŋ tə bij rijtréjnd kəmplíjtlij frəm zíjərow ɛvərij tájm. ðɪs əprówtʃ ɪz əspɛ́ʃəlij vǽljəbəl wɛ́n díjlɪŋ wɪð déjtə stríjmz ðət kəntɪ́njuwəslij ɡrów ɔr tʃéjndʒ, əláwɪŋ ðə mɒ́dəl tə ədǽpt smúwðlij ənd əfɪ́ʃəntlij."
    },
    {
        "Question": "Which term describes a machine learning approach where the model learns continuously by updating itself incrementally with new data as it arrives, rather than being trained once on a static dataset?",
        "RightAnswer": "Online Learning",
        "WrongAnswers": [
            "Batch Learning",
            "Supervised Learning",
            "Transfer Learning",
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "Explanation": "Online Learning refers to a flexible approach where machine learning models update themselves and get smarter continuously, learning step-by-step with new information. It's like how a student regularly adjusts what they understand after each class session, instead of trying to learn everything at once just before a test.",
        "trans_Question": "wɪ́tʃ tɜ́rm dəskrájbz ə məʃíjn lɜ́rnɪŋ əprówtʃ wɛ́ər ðə mɒ́dəl lɜ́rnz kəntɪ́njuwəslij baj ʌ́pdèjtɪŋ ɪtsɛ́lf ɪnkrəmɛ́ntəlìj wɪð núw déjtə æz ɪt ərájvz, rǽðər ðʌn bíjɪŋ tréjnd wʌ́ns ɒn ə stǽtɪk déjtəsɛ̀t?",
        "trans_RightAnswer": "ɔ́nlàjn lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "bǽtʃ lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ɔ́nlàjn lɜ́rnɪŋ rəfɜ́rz tə ə flɛ́ksɪbəl əprówtʃ wɛ́ər məʃíjn lɜ́rnɪŋ mɒ́dəlz əpdéjt ðəmsɛ́lvz ənd ɡɛt smɑ́rtər kəntɪ́njuwəslij, lɜ́rnɪŋ stɛ́p-baj-stɛ́p wɪð núw ɪnfərméjʃən. ɪt's lájk háw ə stúwdənt rɛ́ɡjələrlij ədʒʌ́sts wɒt ðej ʌ̀ndərstǽnd ǽftər ijtʃ klǽs sɛ́ʃən, ɪnstɛ́d əv trájɪŋ tə lɜ́rn ɛ́vrijθɪ̀ŋ æt wʌ́ns dʒəst bəfɔ́r ə tɛ́st."
    },
    {
        "Question": "In machine learning, which term describes data that is continuously generated in real-time, arriving rapidly and needing immediate analysis rather than stored and processed later?",
        "RightAnswer": "Streaming Data",
        "WrongAnswers": [
            "Batch Data",
            "Structured Data",
            "Historical Data",
            "Static Data",
            "Offline Data"
        ],
        "Explanation": "Streaming data is like a flowing river of information—it continuously arrives in real-time, requiring quick processing and analysis right away rather than later. Examples include sensor readings, social media updates, and stock market feeds. Unlike batch or static data, which sits still until you're ready to use it, streaming data needs machine learning models to respond right away, keeping you up-to-date as things happen.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ tɜ́rm dəskrájbz déjtə ðət ɪz kəntɪ́njuwəslij dʒɛ́nərèjtɪd ɪn ríjəl-tájm, ərájvɪŋ rǽpɪdlij ənd níjdɪŋ ɪmíjdijət ənǽlɪsɪs rǽðər ðʌn stɔ́rd ənd prɒ́sɛst léjtər?",
        "trans_RightAnswer": "stríjmɪŋ déjtə",
        "trans_WrongAnswers": [
            "bǽtʃ déjtə",
            "strʌ́ktʃərd déjtə",
            "hɪstɔ́rɪkəl déjtə",
            "stǽtɪk déjtə",
            "ɔ́flàjn déjtə"
        ],
        "trans_Explanation": "stríjmɪŋ déjtə ɪz lájk ə flówɪŋ rɪ́vər əv ɪnfərméjʃən—ɪt kəntɪ́njuwəslij ərájvz ɪn ríjəl-tájm, rijkwájərɪŋ kwɪ́k prɒ́sɛsɪŋ ənd ənǽlɪsɪs rájt əwéj rǽðər ðʌn léjtər. əɡzǽmpəlz ɪnklúwd sɛ́nsər ríjdɪŋz, sówʃəl míjdijə ʌ́pdèjts, ənd stɒ́k mɑ́rkət fíjdz. ʌ̀nlájk bǽtʃ ɔr stǽtɪk déjtə, wɪ́tʃ sɪ́ts stɪ́l əntɪ́l júwr rɛ́dij tə juwz ɪt, stríjmɪŋ déjtə níjdz məʃíjn lɜ́rnɪŋ mɒ́dəlz tə rəspɒ́nd rájt əwéj, kíjpɪŋ juw ʌp-tə-déjt æz θɪ́ŋz hǽpən."
    },
    {
        "Question": "What term describes a machine learning approach where the model is trained using all available data at once, rather than continuously learning from incoming data?",
        "RightAnswer": "Batch Learning",
        "WrongAnswers": [
            "Incremental Learning",
            "Online Learning",
            "Reinforcement Learning",
            "Supervised Learning",
            "Transfer Learning"
        ],
        "Explanation": "Batch learning is like preparing a recipe by assembling all ingredients beforehand and then cooking everything at once. In machine learning, batch learning involves training the model on the entire dataset at one time, without immediate updates from new data. This contrasts with online or incremental learning, where the model continuously learns and adapts as new data comes in, similar to tasting and adjusting a recipe repeatedly as you go.",
        "trans_Question": "wɒt tɜ́rm dəskrájbz ə məʃíjn lɜ́rnɪŋ əprówtʃ wɛ́ər ðə mɒ́dəl ɪz tréjnd júwzɪŋ ɔl əvéjləbəl déjtə æt wʌ́ns, rǽðər ðʌn kəntɪ́njuwəslij lɜ́rnɪŋ frəm ɪ́nkʌ̀mɪŋ déjtə?",
        "trans_RightAnswer": "bǽtʃ lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "ɪnkrəmɛ́ntəl lɜ́rnɪŋ",
            "ɔ́nlàjn lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ"
        ],
        "trans_Explanation": "bǽtʃ lɜ́rnɪŋ ɪz lájk prəpɛ́ərɪŋ ə rɛ́sɪpij baj əsɛ́mbəlɪŋ ɔl ɪnɡríjdijənts bəfɔ́rhæ̀nd ənd ðɛn kʊ́kɪŋ ɛ́vrijθɪ̀ŋ æt wʌ́ns. ɪn məʃíjn lɜ́rnɪŋ, bǽtʃ lɜ́rnɪŋ ɪnvɒ́lvz tréjnɪŋ ðə mɒ́dəl ɒn ðə əntájər déjtəsɛ̀t æt wʌ́n tájm, wɪðáwt ɪmíjdijət ʌ́pdèjts frəm núw déjtə. ðɪs kɒ́ntræs wɪð ɔ́nlàjn ɔr ɪnkrəmɛ́ntəl lɜ́rnɪŋ, wɛ́ər ðə mɒ́dəl kəntɪ́njuwəslij lɜ́rnz ənd ədǽpts æz núw déjtə kʌ́mz ɪn, sɪ́mɪlər tə téjstɪŋ ənd ədʒʌ́stɪŋ ə rɛ́sɪpij rəpíjtɪdlij æz juw ɡow."
    },
    {
        "Question": "You're training a powerful machine learning model but have only limited labeled data available. To optimize the annotation budget, you decide to strategically select only the most uncertain or informative unlabeled examples and have human annotators label those examples first. What machine learning approach are you using?",
        "RightAnswer": "Active Learning",
        "WrongAnswers": [
            "Transfer Learning",
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Semi-Supervised Learning",
            "Batch Learning"
        ],
        "Explanation": "Active learning is like smart asking—it's an approach where your machine learning algorithm actively selects the most useful, uncertain, or informative examples to label next, rather than passively waiting to learn from whatever labeled data it receives. This can save significant time and resources, especially when labeling data costs money and effort.",
        "trans_Question": "júwr tréjnɪŋ ə páwərfəl məʃíjn lɜ́rnɪŋ mɒ́dəl bʌt həv ównlij lɪ́mɪtɪd léjbəld déjtə əvéjləbəl. tə ɒ́ptɪmàjz ðə æ̀nətéjʃən bʌ́dʒət, juw dəsájd tə strətíjdʒɪklij səlɛ́kt ównlij ðə mówst ʌ̀nsɜ́rtən ɔr ɪnfɔ́rmətɪv ʌ̀nléjbəld əɡzǽmpəlz ənd həv hjúwmən æ̀nətéjtərz léjbəl ðowz əɡzǽmpəlz fɜ́rst. wɒt məʃíjn lɜ́rnɪŋ əprówtʃ ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "ǽktɪv lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "trǽnsfər lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
            "bǽtʃ lɜ́rnɪŋ"
        ],
        "trans_Explanation": "ǽktɪv lɜ́rnɪŋ ɪz lájk smɑ́rt ǽskɪŋ—ɪt's ən əprówtʃ wɛ́ər jɔr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm ǽktɪvlij səlɛ́kts ðə mówst júwsfəl, ʌ̀nsɜ́rtən, ɔr ɪnfɔ́rmətɪv əɡzǽmpəlz tə léjbəl nɛ́kst, rǽðər ðʌn pǽsɪvlij wéjtɪŋ tə lɜ́rn frəm wʌ̀tɛ́vər léjbəld déjtə ɪt rəsíjvz. ðɪs kən séjv sɪɡnɪ́fɪkənt tájm ənd ríjsɔrsɪz, əspɛ́ʃəlij wɛ́n léjbəlɪŋ déjtə kɒ́sts mʌ́nij ənd ɛ́fərt."
    },
    {
        "Question": "In machine learning, which type of learning involves the model cleverly using parts of the data itself as guidance, rather than relying on explicit labels provided by humans?",
        "RightAnswer": "Self-Supervised Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Semi-Supervised Learning",
            "Active Learning"
        ],
        "Explanation": "Self-supervised learning happens when the model smartly generates 'labels' from the data itself, without humans explicitly labeling every piece of information. For example, imagine asking a model to predict the next word in a sentence or fill in a missing pixel in an image using only available data. This approach allows machines to learn rich patterns and useful representations from huge amounts of available data, without depending heavily on human-generated labels.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ tájp əv lɜ́rnɪŋ ɪnvɒ́lvz ðə mɒ́dəl klɛ́vərlij júwzɪŋ pɑ́rts əv ðə déjtə ɪtsɛ́lf æz ɡájdəns, rǽðər ðʌn rəlájɪŋ ɒn əksplɪ́sɪt léjbəlz prəvájdɪd baj hjúwmənz?",
        "trans_RightAnswer": "sɛ́lf-súwpərvàjzd lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
            "ǽktɪv lɜ́rnɪŋ"
        ],
        "trans_Explanation": "sɛ́lf-súwpərvàjzd lɜ́rnɪŋ hǽpənz wɛ́n ðə mɒ́dəl smɑ́rtlij dʒɛ́nərèjts 'léjbəlz' frəm ðə déjtə ɪtsɛ́lf, wɪðáwt hjúwmənz əksplɪ́sɪtlij léjbəlɪŋ ɛvərij píjs əv ɪnfərméjʃən. fɔr əɡzǽmpəl, ɪmǽdʒɪn ǽskɪŋ ə mɒ́dəl tə prədɪ́kt ðə nɛ́kst wɜ́rd ɪn ə sɛ́ntəns ɔr fɪ́l ɪn ə mɪ́sɪŋ pɪ́ksəl ɪn ən ɪ́mɪdʒ júwzɪŋ ównlij əvéjləbəl déjtə. ðɪs əprówtʃ əláwz məʃíjnz tə lɜ́rn rɪ́tʃ pǽtərnz ənd júwsfəl rɛ̀prəzəntéjʃənz frəm hjúwdʒ əmáwnts əv əvéjləbəl déjtə, wɪðáwt dəpɛ́ndɪŋ hɛ́vɪlij ɒn hjúwmən-dʒɛ́nərèjtɪd léjbəlz."
    },
    {
        "Question": "In machine learning, what term describes a technique where a model learns by identifying similarities and differences between pairs of examples, typically aiming to distinguish related examples from unrelated ones?",
        "RightAnswer": "Contrastive Learning",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Supervised Learning",
            "Transfer Learning",
            "Federated Learning",
            "Curriculum Learning"
        ],
        "Explanation": "Contrastive learning is a way of training machine learning models by teaching them to identify what's similar and what's different among examples. Imagine it as training by providing the model 'pairs' of examples, where it learns to recognize related items (like similar images or audio clips) and distinguish them from unrelated ones. This method helps models build a deeper understanding of features and can significantly improve their ability to recognize patterns.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tɜ́rm dəskrájbz ə tɛkníjk wɛ́ər ə mɒ́dəl lɜ́rnz baj ajdɛ́ntɪfàjɪŋ sɪ̀mɪlɛ́ərɪtijz ənd dɪ́fərənsɪz bijtwíjn pɛ́ərz əv əɡzǽmpəlz, tɪ́pɪkəlij éjmɪŋ tə dɪstɪ́ŋɡwɪʃ rəléjtɪd əɡzǽmpəlz frəm ʌ̀nrəléjtɪd wʌ́nz?",
        "trans_RightAnswer": "kəntrǽstɪv lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "fɛ́dərèjtɪd lɜ́rnɪŋ",
            "kərɪ́kjələm lɜ́rnɪŋ"
        ],
        "trans_Explanation": "kəntrǽstɪv lɜ́rnɪŋ ɪz ə wej əv tréjnɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz baj tíjtʃɪŋ ðɛm tə ajdɛ́ntɪfàj wɒt's sɪ́mɪlər ənd wɒt's dɪ́fərənt əmʌ́ŋ əɡzǽmpəlz. ɪmǽdʒɪn ɪt æz tréjnɪŋ baj prəvájdɪŋ ðə mɒ́dəl 'pɛ́ərz' əv əɡzǽmpəlz, wɛ́ər ɪt lɜ́rnz tə rɛ́kəɡnàjz rəléjtɪd ájtəmz (lájk sɪ́mɪlər ɪ́mɪdʒɪz ɔr ɒ́dijòw klɪ́ps) ənd dɪstɪ́ŋɡwɪʃ ðɛm frəm ʌ̀nrəléjtɪd wʌ́nz. ðɪs mɛ́θəd hɛ́lps mɒ́dəlz bɪ́ld ə díjpər ʌ̀ndərstǽndɪŋ əv fíjtʃərz ənd kən sɪɡnɪ́fɪkəntlij ɪmprúwv ðɛər əbɪ́lɪtij tə rɛ́kəɡnàjz pǽtərnz."
    },
    {
        "Question": "In machine learning, researchers often create systems that uncover helpful ways to represent raw data—such as turning pixels of images into meaningful features. What's the term for this approach where models discover efficient and insightful ways to represent data automatically?",
        "RightAnswer": "Representation Learning",
        "WrongAnswers": [
            "Hyperparameter Optimization",
            "Model Compression",
            "Active Learning",
            "Transfer Learning",
            "Supervised Classification"
        ],
        "Explanation": "Representation learning is about training machine learning models to automatically figure out the best ways to represent data—in other words, they find hidden structures or patterns to simplify and clarify information. Instead of relying on handcrafted features, these models learn their own helpful ways to look at data, making it easier and more effective to solve complex tasks like recognizing images or text.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ríjsərtʃərz ɔ́fən krijéjt sɪ́stəmz ðət ʌ̀nkʌ́vər hɛ́lpfəl wéjz tə rɛ̀prəzɛ́nt rɔ́ déjtə—sʌtʃ æz tɜ́rnɪŋ pɪ́ksəlz əv ɪ́mɪdʒɪz ɪntə míjnɪŋfəl fíjtʃərz. wɒt's ðə tɜ́rm fɔr ðɪs əprówtʃ wɛ́ər mɒ́dəlz dɪskʌ́vər əfɪ́ʃənt ənd ɪ́nsàjtfəl wéjz tə rɛ̀prəzɛ́nt déjtə ɔ̀təmǽtɪklij?",
        "trans_RightAnswer": "rɛ̀prəzɛntéjʃən lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "hàjpərpǽrəmətər ɒptɪmɪzéjʃən",
            "mɒ́dəl kəmprɛ́ʃən",
            "ǽktɪv lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "súwpərvàjzd klæ̀sɪfɪkéjʃən"
        ],
        "trans_Explanation": "rɛ̀prəzɛntéjʃən lɜ́rnɪŋ ɪz əbawt tréjnɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz tə ɔ̀təmǽtɪklij fɪ́ɡjər awt ðə bɛ́st wéjz tə rɛ̀prəzɛ́nt déjtə—ɪn ʌ́ðər wɜ́rdz, ðej fájnd hɪ́dən strʌ́ktʃərz ɔr pǽtərnz tə sɪ́mpləfaj ənd klǽrɪfàj ɪnfərméjʃən. ɪnstɛ́d əv rəlájɪŋ ɒn hǽndkræ̀ftɪd fíjtʃərz, ðijz mɒ́dəlz lɜ́rn ðɛər ówn hɛ́lpfəl wéjz tə lʊ́k æt déjtə, méjkɪŋ ɪt íjzijər ənd mɔr əféktɪv tə sɒ́lv kɒ́mplɛks tǽsks lájk rɛ́kəɡnàjzɪŋ ɪ́mɪdʒɪz ɔr tɛ́kst."
    },
    {
        "Question": "Sometimes, complex data actually lives on a simpler shape within its original high-dimensional space. Which machine learning technique helps uncover these simpler, underlying structures or shapes to better understand and visualize data?",
        "RightAnswer": "Manifold Learning",
        "WrongAnswers": [
            "Supervised Learning",
            "Reinforcement Learning",
            "Transfer Learning",
            "Ensemble Learning",
            "Gradient Descent"
        ],
        "Explanation": "Imagine you have data scattered across many different dimensions, making it hard to visualize or find patterns easily. Manifold learning helps you discover simpler, lower-dimensional shapes hiding inside that complex data. By extracting these simpler structures (or 'manifolds') from your data, manifold learning makes it easier to visualize, analyze, and gain insights from something that was originally hard to grasp due to its complexity.",
        "trans_Question": "sʌ́mtàjmz, kɒ́mplɛks déjtə ǽktʃùwəlij lájvz ɒn ə sɪ́mplər ʃéjp wɪðɪ́n ɪts ərɪ́dʒɪnəl háj-dajmɛ́nʃənəl spéjs. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk hɛ́lps ʌ̀nkʌ́vər ðijz sɪ́mplər, ʌ̀ndərlájɪŋ strʌ́ktʃərz ɔr ʃéjps tə bɛ́tər ʌ̀ndərstǽnd ənd vɪ́ʒwəlàjz déjtə?",
        "trans_RightAnswer": "mǽnɪfowld lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "ɪmǽdʒɪn juw həv déjtə skǽtərd əkrɔ́s mɛ́nij dɪ́fərənt dajmɛ́nʃənz, méjkɪŋ ɪt hɑ́rd tə vɪ́ʒwəlàjz ɔr fájnd pǽtərnz íjzəlij. mǽnɪfowld lɜ́rnɪŋ hɛ́lps juw dɪskʌ́vər sɪ́mplər, lówər-dajmɛ́nʃənəl ʃéjps hájdɪŋ ɪnsájd ðət kɒ́mplɛks déjtə. baj əkstrǽktɪŋ ðijz sɪ́mplər strʌ́ktʃərz (ɔr 'mǽnɪfowldz') frəm jɔr déjtə, mǽnɪfowld lɜ́rnɪŋ méjks ɪt íjzijər tə vɪ́ʒwəlàjz, ǽnəlàjz, ənd ɡéjn ɪ́nsàjts frəm sʌ́mθɪŋ ðət wɒz ərɪ́dʒɪnəlij hɑ́rd tə ɡrǽsp djúw tə ɪts kəmplɛ́ksɪtij."
    },
    {
        "Question": "You have a complex dataset with many features and need an engaging and intuitive visualization of its structure by reducing dimensions. Which popular machine learning technique would you use to visualize data clusters clearly and effectively?",
        "RightAnswer": "t-SNE",
        "WrongAnswers": [
            "Random Forest",
            "Gradient Boosting",
            "Support Vector Machine",
            "Backpropagation",
            "Reinforcement Learning"
        ],
        "Explanation": "t-SNE (t-distributed Stochastic Neighbor Embedding) is a fun and insightful technique used in machine learning specifically for visualizing complex data. It neatly compresses high-dimensional data down to two or three dimensions. This helps you spot groups, patterns, and clusters intuitively, making complex datasets far easier and much more exciting to explore visually.",
        "trans_Question": "juw həv ə kɒ́mplɛks déjtəsɛ̀t wɪð mɛ́nij fíjtʃərz ənd níjd ən ənɡéjdʒɪŋ ənd ɪntúwɪtɪv vɪ̀ʒwəlɪzéjʃən əv ɪts strʌ́ktʃər baj rədjúwsɪŋ dajmɛ́nʃənz. wɪ́tʃ pɒ́pjələr məʃíjn lɜ́rnɪŋ tɛkníjk wʊd juw juwz tə vɪ́ʒwəlàjz déjtə klʌ́stərz klɪ́ərlij ənd əfɛ́ktɪvlij?",
        "trans_RightAnswer": "t-SNE",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəst",
            "ɡréjdijənt búwstɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "bǽkprəpəgéjʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "t-SNE (t-dɪstrɪ́bjətɪd stowkǽstɪk néjbər ɛmbɛ́dɪŋ) ɪz ə fʌ́n ənd ɪ́nsàjtfəl tɛkníjk júwzd ɪn məʃíjn lɜ́rnɪŋ spəsɪ́fɪklij fɔr vɪ́ʒwəlàjzɪŋ kɒ́mplɛks déjtə. ɪt níjtlij kɒ́mprɛsɪz háj-dajmɛ́nʃənəl déjtə dawn tə túw ɔr θríj dajmɛ́nʃənz. ðɪs hɛ́lps juw spɒ́t ɡrúwps, pǽtərnz, ənd klʌ́stərz ɪntúwɪtɪvlij, méjkɪŋ kɒ́mplɛks déjtəsɛ̀ts fɑ́r íjzijər ənd mʌtʃ mɔr əksájtɪŋ tə əksplɔ́r vɪ́ʒwəlij."
    },
    {
        "Question": "Which machine learning clustering technique first represents data as a graph, analyzes the connections between points, and then separates the graph into groups based upon these connections?",
        "RightAnswer": "Spectral Clustering",
        "WrongAnswers": [
            "K-Means Clustering",
            "Density-Based Clustering (DBSCAN)",
            "Hierarchical Clustering",
            "Gaussian Mixture Models",
            "Mean Shift Clustering"
        ],
        "Explanation": "Spectral Clustering is a unique clustering method in machine learning that first treats data points as nodes in a network (or graph) and examines the relationships between them. Instead of directly looking at how close points are in space, it analyzes the connections between these points to identify meaningful clusters. By examining properties (technically, called eigenvectors) of the graph, Spectral Clustering cleverly finds natural groupings or communities within the data. It's especially powerful when clusters might not form simple shapes.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ klʌ́stərɪŋ tɛkníjk fɜ́rst rɛ̀prəzɛ́nts déjtə æz ə ɡrǽf, ǽnəlàjzɪz ðə kənɛ́kʃənz bijtwíjn pɔ́jnts, ənd ðɛn sɛ́pərèjts ðə ɡrǽf ɪntə ɡrúwps béjst əpɒ́n ðijz kənɛ́kʃənz?",
        "trans_RightAnswer": "spɛ́ktrəl klʌ́stərɪŋ",
        "trans_WrongAnswers": [
            "k-míjnz klʌ́stərɪŋ",
            "dɛ́nsɪtij-béjst klʌ́stərɪŋ (DBSCAN)",
            "hàjərɑ́rkɪkəl klʌ́stərɪŋ",
            "ɡáwsijən mɪ́kstʃər mɒ́dəlz",
            "míjn ʃɪ́ft klʌ́stərɪŋ"
        ],
        "trans_Explanation": "spɛ́ktrəl klʌ́stərɪŋ ɪz ə juwnɪ́k klʌ́stərɪŋ mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ ðət fɜ́rst tríjts déjtə pɔ́jnts æz nówdz ɪn ə nɛ́twɜ̀rk (ɔr ɡrǽf) ənd əɡzǽmɪnz ðə rəléjʃənʃɪ̀ps bijtwíjn ðɛm. ɪnstɛ́d əv dɪərɛ́klij lʊ́kɪŋ æt háw klóws pɔ́jnts ɑr ɪn spéjs, ɪt ǽnəlàjzɪz ðə kənɛ́kʃənz bijtwíjn ðijz pɔ́jnts tə ajdɛ́ntɪfàj míjnɪŋfəl klʌ́stərz. baj əɡzǽmɪnɪŋ prɒ́pərtijz (tɛ́knɪkəlij, kɔ́ld ajɡənvɛ̀ktərz) əv ðə ɡrǽf, spɛ́ktrəl klʌ́stərɪŋ klɛ́vərlij fájndz nǽtʃərəl ɡrúwpɪŋz ɔr kəmjúwnɪtijz wɪðɪ́n ðə déjtə. ɪt's əspɛ́ʃəlij páwərfəl wɛ́n klʌ́stərz majt nɒt fɔ́rm sɪ́mpəl ʃéjps."
    },
    {
        "Question": "In machine learning, what type of neural networks are specifically designed to handle data structures where relationships between entities play a key role, such as social networks, molecular structures, or transportation routes?",
        "RightAnswer": "Graph Neural Networks",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Recurrent Neural Networks",
            "Generative Adversarial Networks",
            "Feedforward Neural Networks",
            "Autoencoder Networks"
        ],
        "Explanation": "Graph Neural Networks, often abbreviated as GNNs, are a type of neural network designed specifically to work with data that's organized as graphs. In simple terms, they shine when information is structured around connections or relationships—think social networks like friendships on Facebook, chemical molecules linked by chemical bonds, or even maps of transportation routes and their intersections. Unlike other neural networks that mainly focus on rows and columns, images, or sequences, GNNs understand and utilize relationships between data points to make meaningful predictions or insights.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tájp əv nʊ́rəl nɛ́twɜ̀rks ɑr spəsɪ́fɪklij dəzájnd tə hǽndəl déjtə strʌ́ktʃərz wɛ́ər rəléjʃənʃɪ̀ps bijtwíjn ɛ́ntɪtijz pléj ə kíj rówl, sʌtʃ æz sówʃəl nɛ́twɜ̀rks, məlɛ́kjələr strʌ́ktʃərz, ɔr træ̀nspərtéjʃən ráwts?",
        "trans_RightAnswer": "ɡrǽf nʊ́rəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
            "fíjdfɔ̀rwərd nʊ́rəl nɛ́twɜ̀rks",
            "ɔ̀towənkówdər nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "ɡrǽf nʊ́rəl nɛ́twɜ̀rks, ɔ́fən əbríjvijèjtɪd æz gnnz, ɑr ə tájp əv nʊ́rəl nɛ́twɜ̀rk dəzájnd spəsɪ́fɪklij tə wɜ́rk wɪð déjtə ðət's ɔ́rɡənàjzd æz ɡrǽfs. ɪn sɪ́mpəl tɜ́rmz, ðej ʃájn wɛ́n ɪnfərméjʃən ɪz strʌ́ktʃərd əráwnd kənɛ́kʃənz ɔr rəléjʃənʃɪ̀ps—θɪ́ŋk sówʃəl nɛ́twɜ̀rks lájk frɛ́ndʃɪps ɒn féjsbʊ̀k, kɛ́mɪkəl mɒ́ləkjùwlz lɪ́ŋkt baj kɛ́mɪkəl bɒ́ndz, ɔr íjvən mǽps əv træ̀nspərtéjʃən ráwts ənd ðɛər ɪ̀ntərsɛ́kʃənz. ʌ̀nlájk ʌ́ðər nʊ́rəl nɛ́twɜ̀rks ðət méjnlij fówkəs ɒn rówz ənd kɒ́ləmz, ɪ́mɪdʒɪz, ɔr síjkwənsɪz, gnnz ʌ̀ndərstǽnd ənd júwtɪlàjz rəléjʃənʃɪ̀ps bijtwíjn déjtə pɔ́jnts tə méjk míjnɪŋfəl prədɪ́kʃənz ɔr ɪ́nsàjts."
    },
    {
        "Question": "Imagine you're trying to teach a machine learning system not only to recognize individual objects but also to understand how these objects interact or relate with each other, such as 'a person riding a bicycle' or 'books sitting on a shelf'. Which type of machine learning specifically emphasizes understanding these relationships and structures between entities?",
        "RightAnswer": "Relational Learning",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Supervised Learning",
            "Unsupervised Learning",
            "Transfer Learning",
            "Deep Learning"
        ],
        "Explanation": "Relational Learning is a type of machine learning that aims to understand and represent complex relationships between objects or entities rather than dealing with them individually. Think of it as how we humans naturally identify connections and associations between things—like knowing a doctor is related to a hospital or figuring out context from relationships like 'a bird perched on a tree'. Unlike some learning types focused only on individual items, Relational Learning really shines at uncovering meaningful patterns of interaction and relationships.",
        "trans_Question": "ɪmǽdʒɪn júwr trájɪŋ tə tíjtʃ ə məʃíjn lɜ́rnɪŋ sɪ́stəm nɒt ównlij tə rɛ́kəɡnàjz ɪndɪvɪ́dʒəwəl ɒ́bdʒɛkts bʌt ɔ́lsow tə ʌ̀ndərstǽnd háw ðijz ɒ́bdʒɛkts ɪ̀ntərǽkt ɔr rəléjt wɪð ijtʃ ʌ́ðər, sʌtʃ æz 'ə pɜ́rsən rájdɪŋ ə bájsɪkəl' ɔr 'bʊ́ks sɪ́tɪŋ ɒn ə ʃɛ́lf'. wɪ́tʃ tájp əv məʃíjn lɜ́rnɪŋ spəsɪ́fɪklij ɛ́mfəsajzɪz ʌ̀ndərstǽndɪŋ ðijz rəléjʃənʃɪ̀ps ənd strʌ́ktʃərz bijtwíjn ɛ́ntɪtijz?",
        "trans_RightAnswer": "rəléjʃənəl lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ"
        ],
        "trans_Explanation": "rəléjʃənəl lɜ́rnɪŋ ɪz ə tájp əv məʃíjn lɜ́rnɪŋ ðət éjmz tə ʌ̀ndərstǽnd ənd rɛ̀prəzɛ́nt kɒ́mplɛks rəléjʃənʃɪ̀ps bijtwíjn ɒ́bdʒɛkts ɔr ɛ́ntɪtijz rǽðər ðʌn díjlɪŋ wɪð ðɛm ɪndɪvɪ́dʒəlij. θɪ́ŋk əv ɪt æz háw wij hjúwmənz nǽtʃərəlij ajdɛ́ntɪfàj kənɛ́kʃənz ənd əsòwsijéjʃənz bijtwíjn θɪ́ŋz—lájk nówɪŋ ə dɒ́ktər ɪz rəléjtɪd tə ə hɒ́spɪ̀təl ɔr fɪ́ɡjərɪŋ awt kɒ́ntɛkst frəm rəléjʃənʃɪ̀ps lájk 'ə bɜ́rd pɜ́rtʃt ɒn ə tríj'. ʌ̀nlájk sʌm lɜ́rnɪŋ tájps fówkəst ównlij ɒn ɪndɪvɪ́dʒəwəl ájtəmz, rəléjʃənəl lɜ́rnɪŋ ríjlij ʃájnz æt ʌ̀nkʌ́vərɪŋ míjnɪŋfəl pǽtərnz əv ɪ̀ntərǽkʃən ənd rəléjʃənʃɪ̀ps."
    },
    {
        "Question": "Imagine you're building a model that can look at a picture and decide if it contains multiple objects simultaneously—for instance, identifying both a dog and a ball in the same image. What type of machine learning classification are you performing?",
        "RightAnswer": "Multi-Label Classification",
        "WrongAnswers": [
            "Binary Classification",
            "Multi-Class Classification",
            "Regression Analysis",
            "Unsupervised Learning",
            "Clustering"
        ],
        "Explanation": "Multi-label classification is a type of machine learning task where the goal is to assign multiple possible labels (categories) to a single item. Instead of just identifying one single category (like 'cat' OR 'dog'), the model can identify several categories simultaneously, such as recognizing that an image contains both a dog AND a ball. It's especially useful in real-world scenarios, like tagging people and objects in social media images, where a single picture often involves many elements.",
        "trans_Question": "ɪmǽdʒɪn júwr bɪ́ldɪŋ ə mɒ́dəl ðət kən lʊ́k æt ə pɪ́ktʃər ənd dəsájd ɪf ɪt kəntéjnz mʌ́ltɪpəl ɒ́bdʒɛkts sàjməltéjnijəslij—fɔr ɪ́nstəns, ajdɛ́ntɪfàjɪŋ bówθ ə dɔ́ɡ ənd ə bɔ́l ɪn ðə séjm ɪ́mɪdʒ. wɒt tájp əv məʃíjn lɜ́rnɪŋ klæ̀sɪfɪkéjʃən ɑr juw pərfɔ́rmɪŋ?",
        "trans_RightAnswer": "mʌ́ltij-léjbəl klæ̀sɪfɪkéjʃən",
        "trans_WrongAnswers": [
            "bájnərij klæ̀sɪfɪkéjʃən",
            "mʌ́ltij-klǽs klæ̀sɪfɪkéjʃən",
            "rəɡrɛ́ʃən ənǽlɪsɪs",
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "klʌ́stərɪŋ"
        ],
        "trans_Explanation": "mʌ́ltij-léjbəl klæ̀sɪfɪkéjʃən ɪz ə tájp əv məʃíjn lɜ́rnɪŋ tǽsk wɛ́ər ðə ɡówl ɪz tə əsájn mʌ́ltɪpəl pɒ́sɪbəl léjbəlz (kǽtəɡɔ̀rijz) tə ə sɪ́ŋɡəl ájtəm. ɪnstɛ́d əv dʒəst ajdɛ́ntɪfàjɪŋ wʌ́n sɪ́ŋɡəl kǽtəɡɔ̀rij (lájk 'kǽt' OR 'dɔ́ɡ'), ðə mɒ́dəl kən ajdɛ́ntɪfàj sɛ́vərəl kǽtəɡɔ̀rijz sàjməltéjnijəslij, sʌtʃ æz rɛ́kəɡnàjzɪŋ ðət ən ɪ́mɪdʒ kəntéjnz bówθ ə dɔ́ɡ AND ə bɔ́l. ɪt's əspɛ́ʃəlij júwsfəl ɪn ríjəl-wɜ́rld sənɛ́ərijowz, lájk tǽɡɪŋ píjpəl ənd ɒ́bdʒɛkts ɪn sówʃəl míjdijə ɪ́mɪdʒɪz, wɛ́ər ə sɪ́ŋɡəl pɪ́ktʃər ɔ́fən ɪnvɒ́lvz mɛ́nij ɛ́ləmənts."
    },
    {
        "Question": "Imagine building a machine learning model to automatically identify animal species. Rather than treating all species as completely unrelated, you design your model with multiple levels—for example: animal → mammal → carnivore → dog → labrador retriever. What kind of classification strategy are you using?",
        "RightAnswer": "Hierarchical Classification",
        "WrongAnswers": [
            "Binary Classification",
            "Linear Regression",
            "Unsupervised Clustering",
            "Random Forest Classification",
            "Reinforcement Learning"
        ],
        "Explanation": "Hierarchical classification means organizing categories into a structured hierarchy, much like a family tree. Instead of only assigning examples to flat categories, it considers relationships among classes—categories contain subcategories, allowing the machine learning model to classify items in multiple, nested steps. Think of it like sorting animals first by broad groups (like 'mammals'), then breaking down each group into narrower, more specific categories.",
        "trans_Question": "ɪmǽdʒɪn bɪ́ldɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə ɔ̀təmǽtɪklij ajdɛ́ntɪfàj ǽnɪməl spíjʃijz. rǽðər ðʌn tríjtɪŋ ɔl spíjʃijz æz kəmplíjtlij ʌ̀nrəléjtɪd, juw dəzájn jɔr mɒ́dəl wɪð mʌ́ltɪpəl lɛ́vəlz—fɔr əɡzǽmpəl: ǽnɪməl → mǽməl → kɑ́rnɪvɔ̀r → dɔ́ɡ → lǽbrədɔ̀r rətríjvər. wɒt kájnd əv klæ̀sɪfɪkéjʃən strǽtədʒij ɑr juw júwzɪŋ?",
        "trans_RightAnswer": "hàjərɑ́rkɪkəl klæ̀sɪfɪkéjʃən",
        "trans_WrongAnswers": [
            "bájnərij klæ̀sɪfɪkéjʃən",
            "lɪ́nijər rəɡrɛ́ʃən",
            "ʌ̀nsúwpərvàjzd klʌ́stərɪŋ",
            "rǽndəm fɔ́rəst klæ̀sɪfɪkéjʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "hàjərɑ́rkɪkəl klæ̀sɪfɪkéjʃən míjnz ɔ́rɡənàjzɪŋ kǽtəɡɔ̀rijz ɪntə ə strʌ́ktʃərd hájərɑ̀rkij, mʌtʃ lájk ə fǽmɪlij tríj. ɪnstɛ́d əv ównlij əsájnɪŋ əɡzǽmpəlz tə flǽt kǽtəɡɔ̀rijz, ɪt kənsɪ́dərz rəléjʃənʃɪ̀ps əmʌ́ŋ klǽsɪz—kǽtəɡɔ̀rijz kəntéjn sʌ́bkætəɡɔrijz, əláwɪŋ ðə məʃíjn lɜ́rnɪŋ mɒ́dəl tə klǽsɪfàj ájtəmz ɪn mʌ́ltɪpəl, nɛ́stɪd stɛ́ps. θɪ́ŋk əv ɪt lájk sɔ́rtɪŋ ǽnɪməlz fɜ́rst baj brɔ́d ɡrúwps (lájk 'mǽməlz'), ðɛn bréjkɪŋ dawn ijtʃ ɡrúwp ɪntə nǽrowər, mɔr spəsɪ́fɪk kǽtəɡɔ̀rijz."
    },
    {
        "Question": "When building a spam detection model for emails, you realize that marking a legitimate email as spam is far more costly than missing a spam message. To handle these differences in the consequences of mistakes, you decide to use an approach that explicitly incorporates the varying impacts or costs of errors into the learning process. What approach are you employing?",
        "RightAnswer": "Cost-Sensitive Learning",
        "WrongAnswers": [
            "Deep Reinforcement Learning",
            "Transfer Learning",
            "Supervised Clustering",
            "Dimensionality Reduction",
            "Unsupervised Feature Learning"
        ],
        "Explanation": "Cost-Sensitive Learning is an approach in machine learning where you clearly acknowledge that not all mistakes are created equal. Rather than treating every error equally, it specifically considers the real-world cost of each type of misclassification. For instance, missing a spam email might be slightly annoying, but mistakenly classifying an important work email as spam could be extremely costly by causing you to miss critical information. Cost-Sensitive Learning lets your model know the seriousness of each error type, helping it optimize its predictions to minimize the overall negative impact.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ ə spǽm dətɛ́kʃən mɒ́dəl fɔr íjmejlz, juw ríjəlàjz ðət mɑ́rkɪŋ ə lədʒɪ́tɪmət íjmejl æz spǽm ɪz fɑ́r mɔr kɒ́stlij ðʌn mɪ́sɪŋ ə spǽm mɛ́sɪdʒ. tə hǽndəl ðijz dɪ́fərənsɪz ɪn ðə kɒ́nsəkwɛ̀nsɪz əv mɪstéjks, juw dəsájd tə juwz ən əprówtʃ ðət əksplɪ́sɪtlij ɪnkɔ́rpərejts ðə vɛ́ərijɪŋ ɪ́mpækts ɔr kɒ́sts əv ɛ́ərərz ɪntə ðə lɜ́rnɪŋ prɒ́sɛs. wɒt əprówtʃ ɑr juw ɛmplɔ́jɪŋ?",
        "trans_RightAnswer": "kɒ́st-sɛ́nsɪtɪv lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "súwpərvàjzd klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "ʌ̀nsúwpərvàjzd fíjtʃər lɜ́rnɪŋ"
        ],
        "trans_Explanation": "kɒ́st-sɛ́nsɪtɪv lɜ́rnɪŋ ɪz ən əprówtʃ ɪn məʃíjn lɜ́rnɪŋ wɛ́ər juw klɪ́ərlij æknɒ́lɪdʒ ðət nɒt ɔl mɪstéjks ɑr krijéjtɪd íjkwəl. rǽðər ðʌn tríjtɪŋ ɛvərij ɛ́ərər íjkwəlij, ɪt spəsɪ́fɪklij kənsɪ́dərz ðə ríjəl-wɜ́rld kɒ́st əv ijtʃ tájp əv mɪ̀sklæsɪfɪkéjʃən. fɔr ɪ́nstəns, mɪ́sɪŋ ə spǽm íjmejl majt bij slájtlij ənɔ́jɪŋ, bʌt mɪstéjkənlij klǽsɪfàjɪŋ ən ɪmpɔ́rtənt wɜ́rk íjmejl æz spǽm kʊ́d bij əkstríjmlij kɒ́stlij baj kɒ́zɪŋ juw tə mɪ́s krɪ́tɪkəl ɪnfərméjʃən. kɒ́st-sɛ́nsɪtɪv lɜ́rnɪŋ lɛts jɔr mɒ́dəl nów ðə sɪ́ərijəsnəs əv ijtʃ ɛ́ərər tájp, hɛ́lpɪŋ ɪt ɒ́ptɪmàjz ɪts prədɪ́kʃənz tə mɪ́nɪmàjz ðə ówvərɔ̀l nɛ́ɡətɪv ɪ́mpækt."
    },
    {
        "Question": "Imagine you've trained an image recognition model on photos taken indoors, like kitchens and living rooms. Surprisingly, the model works impressively well when tested on entirely different settings, such as outdoor parks and streets, even though it never saw such images before. What machine learning concept describes this ability of a model to perform well across entirely new scenarios not encountered during training?",
        "RightAnswer": "Domain Generalization",
        "WrongAnswers": [
            "Feature Overfitting",
            "Gradient Descent Optimization",
            "Transfer Learning",
            "Ensemble Methods",
            "Data Augmentation"
        ],
        "Explanation": "'Domain Generalization' refers to a model's ability to perform effectively in new and different environments or settings it hasn't previously seen during training. Think of it like teaching someone to drive primarily in quiet neighborhoods, and then seeing them handle busy city streets confidently. Models with strong domain generalization don't just memorize patterns from limited scenarios—they truly learn what's fundamentally important, enabling them to adapt and succeed when encountering new domains.",
        "trans_Question": "ɪmǽdʒɪn júwv tréjnd ən ɪ́mɪdʒ rɛ̀kəɡnɪ́ʃən mɒ́dəl ɒn fówtòwz téjkən ɪ́ndɔ̀rz, lájk kɪ́tʃənz ənd lɪ́vɪŋ rúwmz. sərprájzɪŋlij, ðə mɒ́dəl wɜ́rks ɪ̀mprɛ́sɪvlij wɛ́l wɛ́n tɛ́stɪd ɒn əntájərlij dɪ́fərənt sɛ́tɪŋz, sʌtʃ æz áwtdɔ̀r pɑ́rks ənd stríjts, íjvən ðów ɪt nɛ́vər sɔ́ sʌtʃ ɪ́mɪdʒɪz bəfɔ́r. wɒt məʃíjn lɜ́rnɪŋ kɒ́nsɛpt dəskrájbz ðɪs əbɪ́lɪtij əv ə mɒ́dəl tə pərfɔ́rm wɛ́l əkrɔ́s əntájərlij núw sənɛ́ərijowz nɒt ənkáwntərd dʊ́rɪŋ tréjnɪŋ?",
        "trans_RightAnswer": "dowméjn dʒɛ̀nərəlɪzéjʃən",
        "trans_WrongAnswers": [
            "fíjtʃər òwvərfɪ́tɪŋ",
            "ɡréjdijənt dəsɛ́nt ɒptɪmɪzéjʃən",
            "trǽnsfər lɜ́rnɪŋ",
            "ɒnsɒ́mbəl mɛ́θədz",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "'dowméjn dʒɛ̀nərəlɪzéjʃən' rəfɜ́rz tə ə mɒ́dəl'z əbɪ́lɪtij tə pərfɔ́rm əfɛ́ktɪvlij ɪn núw ənd dɪ́fərənt ənvájərənmənts ɔr sɛ́tɪŋz ɪt hǽzənt príjvijəslij síjn dʊ́rɪŋ tréjnɪŋ. θɪ́ŋk əv ɪt lájk tíjtʃɪŋ sʌ́mwʌ̀n tə drájv prajmɛ́ərɪlij ɪn kwájət néjbərhʊ̀dz, ənd ðɛn síjɪŋ ðɛm hǽndəl bɪ́zij sɪ́tij stríjts kɒ́nfɪdəntlij. mɒ́dəlz wɪð strɔ́ŋ dowméjn dʒɛ̀nərəlɪzéjʃən dównt dʒəst mɛ́məràjz pǽtərnz frəm lɪ́mɪtɪd sənɛ́ərijowz—ðej trúwlij lɜ́rn wɒt's fʌ̀ndəmɛ́ntəlij ɪmpɔ́rtənt, ɛnéjbəlɪŋ ðɛm tə ədǽpt ənd səksíjd wɛ́n ɛnkáwntərɪŋ núw dowméjnz."
    },
    {
        "Question": "What is the term for a machine learning technique where multiple decentralized devices, like smartphones, collaborate to train a model without sending their individual data to a central server?",
        "RightAnswer": "Federated Learning",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Transfer Learning",
            "Supervised Learning",
            "Deep Learning",
            "Active Learning"
        ],
        "Explanation": "Federated Learning is a fresh approach in machine learning where multiple decentralized devices, such as smartphones and tablets, work together to train a shared model. Each device improves the model using locally available data without ever sending sensitive personal data directly to a central server. This helps protect people's privacy and reduces the need to transport large data amounts across the internet.",
        "trans_Question": "wɒt ɪz ðə tɜ́rm fɔr ə məʃíjn lɜ́rnɪŋ tɛkníjk wɛ́ər mʌ́ltɪpəl dəsɛ́ntrəlàjzd dəvájsɪz, lájk smɑ́rtfòwnz, kəlǽbərèjt tə tréjn ə mɒ́dəl wɪðáwt sɛ́ndɪŋ ðɛər ɪndɪvɪ́dʒəwəl déjtə tə ə sɛ́ntrəl sɜ́rvər?",
        "trans_RightAnswer": "fɛ́dərèjtɪd lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "díjp lɜ́rnɪŋ",
            "ǽktɪv lɜ́rnɪŋ"
        ],
        "trans_Explanation": "fɛ́dərèjtɪd lɜ́rnɪŋ ɪz ə frɛ́ʃ əprówtʃ ɪn məʃíjn lɜ́rnɪŋ wɛ́ər mʌ́ltɪpəl dəsɛ́ntrəlàjzd dəvájsɪz, sʌtʃ æz smɑ́rtfòwnz ənd tǽbləts, wɜ́rk təɡɛ́ðər tə tréjn ə ʃɛ́ərd mɒ́dəl. ijtʃ dəvájs ɪmprúwvz ðə mɒ́dəl júwzɪŋ lówkəlij əvéjləbəl déjtə wɪðáwt ɛ́vər sɛ́ndɪŋ sɛ́nsɪtɪv pɜ́rsənəl déjtə dɪərɛ́klij tə ə sɛ́ntrəl sɜ́rvər. ðɪs hɛ́lps prətɛ́kt píjpəl'z prájvəsij ənd rədjúwsɪz ðə níjd tə trǽnspɔrt lɑ́rdʒ déjtə əmáwnts əkrɔ́s ðə ɪ́ntərnɛ̀t."
    },
    {
        "Question": "What do we call the field in machine learning that focuses on training models on sensitive data without compromising people's confidentiality?",
        "RightAnswer": "Privacy-Preserving Machine Learning",
        "WrongAnswers": [
            "Confidential Neural Computing",
            "Encrypted Decision Analysis",
            "Anonymous Data Mining",
            "Secure Algorithm Processing",
            "Private Feature Extraction"
        ],
        "Explanation": "Privacy-Preserving Machine Learning refers to techniques that allow computers to learn from data without revealing sensitive personal information. Think of it as a way of helping your favorite apps or digital assistants get better at serving you, without them actually seeing or recording your private information. The goal is to provide the benefits of machine learning while ensuring people's privacy stays protected.",
        "trans_Question": "wɒt dúw wij kɔ́l ðə fíjld ɪn məʃíjn lɜ́rnɪŋ ðət fówkəsɪz ɒn tréjnɪŋ mɒ́dəlz ɒn sɛ́nsɪtɪv déjtə wɪðáwt kɒ́mprəmajzɪŋ píjpəl'z kɒ̀nfɪdɛ́nʃijǽlɪtij?",
        "trans_RightAnswer": "prájvəsij-prəzɜ́rvɪŋ məʃíjn lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "kɒ̀nfɪdɛ́nʃəl nʊ́rəl kəmpjúwtɪŋ",
            "ɛnkrɪ́ptɪd dəsɪ́ʒən ənǽlɪsɪs",
            "ənɒ́nəməs déjtə májnɪŋ",
            "səkjʊ́r ǽlɡərɪ̀ðəm prɒ́sɛsɪŋ",
            "prájvət fíjtʃər əkstrǽkʃən"
        ],
        "trans_Explanation": "prájvəsij-prəzɜ́rvɪŋ məʃíjn lɜ́rnɪŋ rəfɜ́rz tə tɛkníjks ðət əláw kəmpjúwtərz tə lɜ́rn frəm déjtə wɪðáwt rəvíjlɪŋ sɛ́nsɪtɪv pɜ́rsənəl ɪnfərméjʃən. θɪ́ŋk əv ɪt æz ə wej əv hɛ́lpɪŋ jɔr féjvərɪt ǽps ɔr dɪ́dʒɪtəl əsɪ́stənts ɡɛt bɛ́tər æt sɜ́rvɪŋ juw, wɪðáwt ðɛm ǽktʃùwəlij síjɪŋ ɔr rəkɔ́rdɪŋ jɔr prájvət ɪnfərméjʃən. ðə ɡówl ɪz tə prəvájd ðə bɛ́nəfɪts əv məʃíjn lɜ́rnɪŋ wájl ɛnʃʊ́rɪŋ píjpəl'z prájvəsij stéjz prətɛ́ktɪd."
    },
    {
        "Question": "What is the approach in machine learning that ensures the insights you gain from data don't accidentally reveal sensitive personal information about individuals in your dataset?",
        "RightAnswer": "Differential Privacy",
        "WrongAnswers": [
            "Feature Scaling",
            "Regularization",
            "Gradient Descent",
            "Transfer Learning",
            "Dimensionality Reduction"
        ],
        "Explanation": "Differential privacy is like ensuring anonymity in a crowded room—no matter how hard someone tries to analyze your data, they won't be able to pin down sensitive information about specific individuals. It achieves this by adding carefully calibrated randomness to the data or analysis process. This helps preserve privacy and keeps individual data secure while still providing accurate and useful insights from large datasets.",
        "trans_Question": "wɒt ɪz ðə əprówtʃ ɪn məʃíjn lɜ́rnɪŋ ðət ənʃʊ́rz ðə ɪ́nsàjts juw ɡéjn frəm déjtə dównt æ̀ksvdɛ́ntəlij rəvíjl sɛ́nsɪtɪv pɜ́rsənəl ɪnfərméjʃən əbawt ɪndɪvɪ́dʒəwəlz ɪn jɔr déjtəsɛ̀t?",
        "trans_RightAnswer": "dɪ̀fərɛ́nʃəl prájvəsij",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "trǽnsfər lɜ́rnɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "dɪ̀fərɛ́nʃəl prájvəsij ɪz lájk ɛnʃʊ́rɪŋ æ̀nənɪ́mɪtij ɪn ə kráwdɪd rúwm—now mǽtər háw hɑ́rd sʌ́mwʌ̀n trájz tə ǽnəlàjz jɔr déjtə, ðej wównt bij éjbəl tə pɪ́n dawn sɛ́nsɪtɪv ɪnfərméjʃən əbawt spəsɪ́fɪk ɪndɪvɪ́dʒəwəlz. ɪt ətʃíjvz ðɪs baj ǽdɪŋ kɛ́ərfəlij kǽləbrèjtɪd rǽndəmnəs tə ðə déjtə ɔr ənǽlɪsɪs prɒ́sɛs. ðɪs hɛ́lps prəzɜ́rv prájvəsij ənd kíjps ɪndɪvɪ́dʒəwəl déjtə səkjʊ́r wájl stɪ́l prəvájdɪŋ ǽkjərət ənd júwsfəl ɪ́nsàjts frəm lɑ́rdʒ déjtəsɛ̀ts."
    },
    {
        "Question": "When preparing datasets for machine learning models, it's crucial to protect sensitive personal information to ensure individuals' privacy. Which of the following terms describes the process of modifying or removing identifiable information from data, so individual people can't be recognized?",
        "RightAnswer": "Data Anonymization",
        "WrongAnswers": [
            "Data Normalization",
            "Data Augmentation",
            "Feature Selection",
            "Data Encoding",
            "Data Imputation"
        ],
        "Explanation": "Data anonymization is the process of altering personal data so that individuals can't be identified from it. This involves removing or modifying names, addresses, phone numbers, or any other information that could directly or indirectly identify a person. By anonymizing data, we ensure privacy protection while still being able to analyze overarching patterns and trends using machine learning.",
        "trans_Question": "wɛ́n prəpɛ́ərɪŋ déjtəsɛ̀ts fɔr məʃíjn lɜ́rnɪŋ mɒ́dəlz, ɪt's krúwʃəl tə prətɛ́kt sɛ́nsɪtɪv pɜ́rsənəl ɪnfərméjʃən tə ənʃʊ́r ɪndɪvɪ́dʒəwəlz' prájvəsij. wɪ́tʃ əv ðə fɒ́lowɪŋ tɜ́rmz dəskrájbz ðə prɒ́sɛs əv mɒ́dɪfàjɪŋ ɔr rijmúwvɪŋ ajdɛ́ntɪfàjəbəl ɪnfərméjʃən frəm déjtə, sow ɪndɪvɪ́dʒəwəl píjpəl kǽnt bij rɛ́kəɡnàjzd?",
        "trans_RightAnswer": "déjtə ənɒ̀nəməzéjʃən",
        "trans_WrongAnswers": [
            "déjtə nɔ̀rməlɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "fíjtʃər səlɛ́kʃən",
            "déjtə ɛnkówdɪŋ",
            "déjtə ɪ̀mpjətéjʃən"
        ],
        "trans_Explanation": "déjtə ənɒ̀nəməzéjʃən ɪz ðə prɒ́sɛs əv ɔ́ltərɪŋ pɜ́rsənəl déjtə sow ðət ɪndɪvɪ́dʒəwəlz kǽnt bij ajdɛ́ntɪfàjd frəm ɪt. ðɪs ɪnvɒ́lvz rijmúwvɪŋ ɔr mɒ́dɪfàjɪŋ néjmz, ǽdrɛ́sɪz, fówn nʌ́mbərz, ɔr ɛ́nij ʌ́ðər ɪnfərméjʃən ðət kʊ́d dɪərɛ́klij ɔr ɪ̀ndɪərɛ́ktlij ajdɛ́ntɪfàj ə pɜ́rsən. baj ənɒ́nəmàjzɪŋ déjtə, wij ənʃʊ́r prájvəsij prətɛ́kʃən wájl stɪ́l bíjɪŋ éjbəl tə ǽnəlàjz ówvərɑ̀rtʃɪŋ pǽtərnz ənd trɛ́ndz júwzɪŋ məʃíjn lɜ́rnɪŋ."
    },
    {
        "Question": "Imagine you're training a machine learning model but don't have enough real-world data. To effectively build your model, you decide to generate artificial datasets that mimic your real-world data closely. What term is used to describe this artificially created data?",
        "RightAnswer": "Synthetic Data",
        "WrongAnswers": [
            "Meta Data",
            "Virtual Metrics",
            "Simulation Models",
            "Pseudo Data",
            "Hypothetical Data"
        ],
        "Explanation": "Synthetic Data refers to artificially generated data created by algorithms or simulations, designed to mimic patterns and characteristics of real-world data. It's especially helpful when real-world data isn't sufficient, is costly to collect, or has privacy concerns. This enables machine learning models to train effectively without relying solely on original data sources.",
        "trans_Question": "ɪmǽdʒɪn júwr tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl bʌt dównt həv ənʌ́f ríjəl-wɜ́rld déjtə. tə əfɛ́ktɪvlij bɪ́ld jɔr mɒ́dəl, juw dəsájd tə dʒɛ́nərèjt ɑ̀rtɪfɪ́ʃəl déjtəsɛ̀ts ðət mɪ́mɪk jɔr ríjəl-wɜ́rld déjtə klówslij. wɒt tɜ́rm ɪz júwzd tə dəskrájb ðɪs ɑ̀rtɪfɪ́ʃəlij krijéjtɪd déjtə?",
        "trans_RightAnswer": "sɪnθɛ́tɪk déjtə",
        "trans_WrongAnswers": [
            "mɛ́tə déjtə",
            "vɜ́rtʃuwəl mɛ́trɪks",
            "sɪ̀mjəléjʃən mɒ́dəlz",
            "súwdow déjtə",
            "hàjpəθɛ́tɪkəl déjtə"
        ],
        "trans_Explanation": "sɪnθɛ́tɪk déjtə rəfɜ́rz tə ɑ̀rtɪfɪ́ʃəlij dʒɛ́nərèjtɪd déjtə krijéjtɪd baj ǽlɡərɪ̀ðəmz ɔr sɪ̀mjəléjʃənz, dəzájnd tə mɪ́mɪk pǽtərnz ənd kæ̀rəktərɪ́stɪks əv ríjəl-wɜ́rld déjtə. ɪt's əspɛ́ʃəlij hɛ́lpfəl wɛ́n ríjəl-wɜ́rld déjtə ɪzənt səfɪ́ʃənt, ɪz kɒ́stlij tə kəlɛ́kt, ɔr həz prájvəsij kənsɜ́rnz. ðɪs ɛnéjbəlz məʃíjn lɜ́rnɪŋ mɒ́dəlz tə tréjn əfɛ́ktɪvlij wɪðáwt rəlájɪŋ sówlij ɒn ərɪ́dʒɪnəl déjtə sɔ́rsɪz."
    },
    {
        "Question": "What do you call specially designed deceptive inputs, like slightly modified images, that can trick machine learning models into making incorrect but confident predictions?",
        "RightAnswer": "Adversarial Examples",
        "WrongAnswers": [
            "Gradient Descents",
            "Training Biases",
            "Activation Functions",
            "Feature Extractions",
            "Overfitting Examples"
        ],
        "Explanation": "Adversarial examples are cleverly crafted inputs—like subtly altered images—that mislead machine learning models into confidently making incorrect predictions. For example, adding tiny, barely noticeable changes to a photo of a cat could cause the model to confidently identify it as a dog. These tricky inputs highlight vulnerabilities and encourage us to build more robust AI systems.",
        "trans_Question": "wɒt dúw juw kɔ́l spɛ́ʃəlij dəzájnd dəsɛ́ptɪv ɪ́npʊ̀ts, lájk slájtlij mɒ́dɪfàjd ɪ́mɪdʒɪz, ðət kən trɪ́k məʃíjn lɜ́rnɪŋ mɒ́dəlz ɪntə méjkɪŋ ɪ̀nkərɛ́kt bʌt kɒ́nfɪdənt prədɪ́kʃənz?",
        "trans_RightAnswer": "æ̀dvərsɛ́ərijəl əɡzǽmpəlz",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nts",
            "tréjnɪŋ bájəsɪz",
            "æ̀ktɪvéjʃən fʌ́ŋkʃənz",
            "fíjtʃər əkstrǽkʃənz",
            "òwvərfɪ́tɪŋ əɡzǽmpəlz"
        ],
        "trans_Explanation": "æ̀dvərsɛ́ərijəl əɡzǽmpəlz ɑr klɛ́vərlij krǽftɪd ɪ́npʊ̀ts—lájk sʌ́təlij ɔ́ltərd ɪ́mɪdʒɪz—ðət mɪ̀slíjd məʃíjn lɜ́rnɪŋ mɒ́dəlz ɪntə kɒ́nfɪdəntlij méjkɪŋ ɪ̀nkərɛ́kt prədɪ́kʃənz. fɔr əɡzǽmpəl, ǽdɪŋ tájnij, bɛ́ərlij nówtɪsəbəl tʃéjndʒɪz tə ə fówtòw əv ə kǽt kʊ́d kɒ́z ðə mɒ́dəl tə kɒ́nfɪdəntlij ajdɛ́ntɪfàj ɪt æz ə dɔ́ɡ. ðijz trɪ́kij ɪ́npʊ̀ts hájlàjt vʌ̀lnərəbɪ́lɪtijz ənd ənkɜ́rɪdʒ ʌs tə bɪ́ld mɔr rowbʌ́st AI sɪ́stəmz."
    },
    {
        "Question": "In machine learning, what strategy involves intentionally training a model with challenging examples specifically designed to fool or confuse it, so it learns to be more robust against unexpected inputs?",
        "RightAnswer": "Adversarial Training",
        "WrongAnswers": [
            "Supervised Learning",
            "Regularization",
            "Data Augmentation",
            "Transfer Learning",
            "Cross-validation"
        ],
        "Explanation": "Adversarial training is somewhat like giving your AI model 'vaccine shots' of tricky or deceptive examples as it learns, helping it develop resistance to future attacks or unusual inputs. By intentionally exposing your model to subtly altered inputs designed to fool it, the model learns to handle sneaky scenarios better—making it tougher, smarter, and more reliable in real-world situations.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt strǽtədʒij ɪnvɒ́lvz ɪntɛ́nʃənəlij tréjnɪŋ ə mɒ́dəl wɪð tʃǽləndʒɪŋ əɡzǽmpəlz spəsɪ́fɪklij dəzájnd tə fúwl ɔr kənfjúwz ɪt, sow ɪt lɜ́rnz tə bij mɔr rowbʌ́st əɡéjnst ʌ̀nəkspɛ́ktɪd ɪ́npʊ̀ts?",
        "trans_RightAnswer": "æ̀dvərsɛ́ərijəl tréjnɪŋ",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "trǽnsfər lɜ́rnɪŋ",
            "krɔ́s-væ̀lɪdéjʃən"
        ],
        "trans_Explanation": "æ̀dvərsɛ́ərijəl tréjnɪŋ ɪz sʌ́mwʌ́t lájk ɡɪ́vɪŋ jɔr AI mɒ́dəl 'væ̀ksíjn ʃɒ́ts' əv trɪ́kij ɔr dəsɛ́ptɪv əɡzǽmpəlz æz ɪt lɜ́rnz, hɛ́lpɪŋ ɪt dəvɛ́ləp rəzɪ́stəns tə fjúwtʃər ətǽks ɔr ʌ̀njúwʒùwəl ɪ́npʊ̀ts. baj ɪntɛ́nʃənəlij əkspówzɪŋ jɔr mɒ́dəl tə sʌ́təlij ɔ́ltərd ɪ́npʊ̀ts dəzájnd tə fúwl ɪt, ðə mɒ́dəl lɜ́rnz tə hǽndəl sníjkij sənɛ́ərijowz bɛ́tər—méjkɪŋ ɪt tʌ́fər, smɑ́rtər, ənd mɔr rəlájəbəl ɪn ríjəl-wɜ́rld sɪ̀tʃuwéjʃənz."
    },
    {
        "Question": "When building machine learning models, unexpected or noisy data can throw your predictions off track. To make sure your model still performs well—even when facing uncertainties or abnormal data—you apply an optimization approach specifically designed for reliable performance under varying conditions. What is this approach known as?",
        "RightAnswer": "Robust Optimization",
        "WrongAnswers": [
            "Gradient Descent",
            "Hyperparameter Tuning",
            "Regularization",
            "Feature Extraction",
            "Data Augmentation"
        ],
        "Explanation": "Robust optimization is a modeling approach that helps machine learning models maintain strong, reliable performance even when they encounter unusual data or uncertainties. Instead of aiming only for the best possible results on ideal datasets, it prepares the model to handle real-world unpredictabilities. Think of robust optimization as preparing a car's suspension to smooth out unexpected bumps on the road, ensuring a safer, more comfortable ride.",
        "trans_Question": "wɛ́n bɪ́ldɪŋ məʃíjn lɜ́rnɪŋ mɒ́dəlz, ʌ̀nəkspɛ́ktɪd ɔr nɔ́jzij déjtə kən θrów jɔr prədɪ́kʃənz ɔ́f trǽk. tə méjk ʃʊ́r jɔr mɒ́dəl stɪ́l pərfɔ́rmz wɛ́l—íjvən wɛ́n féjsɪŋ ʌ̀nsɜ́rtəntijz ɔr æbnɔ́rməl déjtə—juw əpláj ən ɒptɪmɪzéjʃən əprówtʃ spəsɪ́fɪklij dəzájnd fɔr rəlájəbəl pərfɔ́rməns ʌ́ndər vɛ́ərijɪŋ kəndɪ́ʃənz. wɒt ɪz ðɪs əprówtʃ nówn æz?",
        "trans_RightAnswer": "rowbʌ́st ɒptɪmɪzéjʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "hàjpərpǽrəmətər túwnɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "fíjtʃər əkstrǽkʃən",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "rowbʌ́st ɒptɪmɪzéjʃən ɪz ə mɒ́dəlɪ̀ŋ əprówtʃ ðət hɛ́lps məʃíjn lɜ́rnɪŋ mɒ́dəlz mejntéjn strɔ́ŋ, rəlájəbəl pərfɔ́rməns íjvən wɛ́n ðej ənkáwntər ʌ̀njúwʒùwəl déjtə ɔr ʌ̀nsɜ́rtəntijz. ɪnstɛ́d əv éjmɪŋ ównlij fɔr ðə bɛ́st pɒ́sɪbəl rəzʌ́lts ɒn ajdíjəl déjtəsɛ̀ts, ɪt prəpɛ́ərz ðə mɒ́dəl tə hǽndəl ríjəl-wɜ́rld ʌ̀nprɪdɪ̀ktəbɪ́lətijz. θɪ́ŋk əv rowbʌ́st ɒptɪmɪzéjʃən æz prəpɛ́ərɪŋ ə kɑ́r'z səspɛ́nʃən tə smúwð awt ʌ̀nəkspɛ́ktɪd bʌ́mps ɒn ðə rówd, ɛnʃʊ́rɪŋ ə séjfər, mɔr kʌ́mftərbəl rájd."
    },
    {
        "Question": "In training a neural network, sometimes the updates on weights become excessively large, causing instability during training. To tackle this issue, a common approach is to limit how large these updates can get. What is this helpful technique called?",
        "RightAnswer": "Gradient Clipping",
        "WrongAnswers": [
            "Learning Rate Decay",
            "Dropout Regularization",
            "Early Stopping",
            "Batch Normalization",
            "Gradient Descent"
        ],
        "Explanation": "Gradient clipping is a practical and effective way to deal with exploding gradients during the training of neural networks. When your neural network's updates become too big, it can make training unstable and cause errors. Gradient clipping sets a threshold or cap to keep these updates within reasonable limits, ensuring stability and improving the training process.",
        "trans_Question": "ɪn tréjnɪŋ ə nʊ́rəl nɛ́twɜ̀rk, sʌ́mtàjmz ðə ʌ́pdèjts ɒn wéjts bəkʌ́m əksɛ́sɪvlij lɑ́rdʒ, kɒ́zɪŋ ɪnstəbɪ́lɪtij dʊ́rɪŋ tréjnɪŋ. tə tǽkəl ðɪs ɪ́ʃuw, ə kɒ́mən əprówtʃ ɪz tə lɪ́mɪt háw lɑ́rdʒ ðijz ʌ́pdèjts kən ɡɛt. wɒt ɪz ðɪs hɛ́lpfəl tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "ɡréjdijənt klɪ́pɪŋ",
        "trans_WrongAnswers": [
            "lɜ́rnɪŋ réjt dəkéj",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən",
            "ɜ́rlij stɒ́pɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "ɡréjdijənt klɪ́pɪŋ ɪz ə prǽktɪkəl ənd əféktɪv wej tə díjl wɪð əksplówdɪŋ ɡréjdijənts dʊ́rɪŋ ðə tréjnɪŋ əv nʊ́rəl nɛ́twɜ̀rks. wɛ́n jɔr nʊ́rəl nɛ́twɜ̀rk'z ʌ́pdèjts bəkʌ́m túw bɪ́ɡ, ɪt kən méjk tréjnɪŋ ʌ̀nstéjbəl ənd kɒ́z ɛ́ərərz. ɡréjdijənt klɪ́pɪŋ sɛ́ts ə θrɛ́ʃòwld ɔr kǽp tə kíjp ðijz ʌ́pdèjts wɪðɪ́n ríjzənəbəl lɪ́mɪts, ɛnʃʊ́rɪŋ stəbɪ́lɪtij ənd ɪmprúwvɪŋ ðə tréjnɪŋ prɒ́sɛs."
    },
    {
        "Question": "In deep learning, during the process of training neural networks, sometimes you notice your network's weights start changing by huge, unstable amounts. These massive fluctuations can make learning impossible, causing your training to fail completely. What's this crazy phenomenon called?",
        "RightAnswer": "Exploding Gradients",
        "WrongAnswers": [
            "Vanishing Gradients",
            "Overfitting",
            "Gradient Descent",
            "Underfitting",
            "Feature Explosion"
        ],
        "Explanation": "Exploding gradients happen when the calculated adjustments (gradients) to a neural network's weights become extremely large. Instead of making small, steady improvements, the network's parameters start swinging wildly, making it difficult or even impossible to learn effectively. It’s like turning the steering wheel far too dramatically while driving, causing loss of control. Techniques like gradient clipping or careful initialization can help prevent exploding gradients and stabilize training.",
        "trans_Question": "ɪn díjp lɜ́rnɪŋ, dʊ́rɪŋ ðə prɒ́sɛs əv tréjnɪŋ nʊ́rəl nɛ́twɜ̀rks, sʌ́mtàjmz juw nówtɪs jɔr nɛ́twɜ̀rk'z wéjts stɑ́rt tʃéjndʒɪŋ baj hjúwdʒ, ʌ̀nstéjbəl əmáwnts. ðijz mǽsɪv flʌ̀ktʃuwéjʃənz kən méjk lɜ́rnɪŋ ɪ̀mpɒ́sɪbəl, kɒ́zɪŋ jɔr tréjnɪŋ tə féjl kəmplíjtlij. wɒt's ðɪs kréjzij fənɒ́mənɒn kɔ́ld?",
        "trans_RightAnswer": "əksplówdɪŋ ɡréjdijənts",
        "trans_WrongAnswers": [
            "vǽnɪʃɪŋ ɡréjdijənts",
            "òwvərfɪ́tɪŋ",
            "ɡréjdijənt dəsɛ́nt",
            "ʌ̀ndərfɪ́tɪŋ",
            "fíjtʃər əksplówʒən"
        ],
        "trans_Explanation": "əksplówdɪŋ ɡréjdijənts hǽpən wɛ́n ðə kǽlkjəlèjtɪd ədʒʌ́stmənts (ɡréjdijənts) tə ə nʊ́rəl nɛ́twɜ̀rk'z wéjts bəkʌ́m əkstríjmlij lɑ́rdʒ. ɪnstɛ́d əv méjkɪŋ smɔ́l, stɛ́dij ɪmprúwvmənts, ðə nɛ́twɜ̀rk'z pərǽmətərz stɑ́rt swɪ́ŋɪŋ wájldlij, méjkɪŋ ɪt dɪ́fɪkəlt ɔr íjvən ɪ̀mpɒ́sɪbəl tə lɜ́rn əfɛ́ktɪvlij. ɪt's lájk tɜ́rnɪŋ ðə stɪ́ərɪŋ wíjl fɑ́r túw drəmǽtɪkəlij wájl drájvɪŋ, kɒ́zɪŋ lɔ́s əv kəntrówl. tɛkníjks lájk ɡréjdijənt klɪ́pɪŋ ɔr kɛ́ərfəl ɪnɪ́ʃəlɪzéjʃən kən hɛ́lp prəvɛ́nt əksplówdɪŋ ɡréjdijənts ənd stéjbɪlàjz tréjnɪŋ."
    },
    {
        "Question": "What do we call the issue in deep neural networks where earlier layers learn extremely slowly or stop learning completely because the gradient signals become very weak during backpropagation?",
        "RightAnswer": "Vanishing Gradients",
        "WrongAnswers": [
            "Exploding Gradients",
            "Overfitting",
            "Gradient Descent Plateau",
            "Activation Saturation",
            "Dead Neurons"
        ],
        "Explanation": "Vanishing gradients is a common problem in training deep neural networks, where early layers become difficult to train because the gradient signals (used to update and improve the network's weights) become extremely small. Think of it like a distant echo—by the time it reaches the beginning layers, it's barely noticeable, meaning those early layers barely change or learn at all. As a result, optimization becomes slow or ineffective, hindering your neural network's full potential.",
        "trans_Question": "wɒt dúw wij kɔ́l ðə ɪ́ʃuw ɪn díjp nʊ́rəl nɛ́twɜ̀rks wɛ́ər ɜ́rlijər léjərz lɜ́rn əkstríjmlij slówlij ɔr stɒ́p lɜ́rnɪŋ kəmplíjtlij bəkɒ́z ðə ɡréjdijənt sɪ́ɡnəlz bəkʌ́m vɛ́ərij wíjk dʊ́rɪŋ bǽkprəpəgéjʃən?",
        "trans_RightAnswer": "vǽnɪʃɪŋ ɡréjdijənts",
        "trans_WrongAnswers": [
            "əksplówdɪŋ ɡréjdijənts",
            "òwvərfɪ́tɪŋ",
            "ɡréjdijənt dəsɛ́nt plætów",
            "æ̀ktɪvéjʃən sæ̀tʃəréjʃən",
            "dɛ́d nʊ́rɒnz"
        ],
        "trans_Explanation": "vǽnɪʃɪŋ ɡréjdijənts ɪz ə kɒ́mən prɒ́bləm ɪn tréjnɪŋ díjp nʊ́rəl nɛ́twɜ̀rks, wɛ́ər ɜ́rlij léjərz bəkʌ́m dɪ́fɪkəlt tə tréjn bəkɒ́z ðə ɡréjdijənt sɪ́ɡnəlz (júwzd tə əpdéjt ənd ɪmprúwv ðə nɛ́twɜ̀rk'z wéjts) bəkʌ́m əkstríjmlij smɔ́l. θɪ́ŋk əv ɪt lájk ə dɪ́stənt ɛ́kow—baj ðə tájm ɪt ríjtʃɪz ðə bəɡɪ́nɪŋ léjərz, ɪt's bɛ́ərlij nówtɪsəbəl, míjnɪŋ ðowz ɜ́rlij léjərz bɛ́ərlij tʃéjndʒ ɔr lɜ́rn æt ɔl. æz ə rəzʌ́lt, ɒptɪmɪzéjʃən bəkʌ́mz slów ɔr ɪ̀nəfɛ́ktɪv, hɪ́ndərɪŋ jɔr nʊ́rəl nɛ́twɜ̀rk'z fʊ́l pətɛ́nʃəl."
    },
    {
        "Question": "In convolutional neural networks, what do we call the practice of using the very same parameters across different parts of the input, leading to more efficient learning and fewer parameters overall?",
        "RightAnswer": "Weight Sharing",
        "WrongAnswers": [
            "Gradient Boosting",
            "Activation Synchronization",
            "Parameter Tuning",
            "Data Augmentation",
            "Backpropagation Adjustment"
        ],
        "Explanation": "Weight sharing in machine learning, especially in convolutional neural networks (CNNs), refers to using the exact same set of weights (parameters) for multiple parts of the input data. Picture it like using the same paintbrush repeatedly to paint similar portions of an artwork—this allows CNNs to recognize patterns effectively, reduces the number of parameters they need to learn, and speeds up the training process.",
        "trans_Question": "ɪn kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks, wɒt dúw wij kɔ́l ðə prǽktɪs əv júwzɪŋ ðə vɛ́ərij séjm pərǽmətərz əkrɔ́s dɪ́fərənt pɑ́rts əv ðə ɪ́npʊ̀t, líjdɪŋ tə mɔr əfɪ́ʃənt lɜ́rnɪŋ ənd fjúwər pərǽmətərz ówvərɔ̀l?",
        "trans_RightAnswer": "wéjt ʃɛ́ərɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "æ̀ktɪvéjʃən sɪ̀ŋkrənɪzéjʃən",
            "pərǽmətər túwnɪŋ",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "bǽkprəpəgéjʃən ədʒʌ́stmənt"
        ],
        "trans_Explanation": "wéjt ʃɛ́ərɪŋ ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij ɪn kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks (CNNz), rəfɜ́rz tə júwzɪŋ ðə əɡzǽkt séjm sɛ́t əv wéjts (pərǽmətərz) fɔr mʌ́ltɪpəl pɑ́rts əv ðə ɪ́npʊ̀t déjtə. pɪ́ktʃər ɪt lájk júwzɪŋ ðə séjm péjntbrʌ̀ʃ rəpíjtɪdlij tə péjnt sɪ́mɪlər pɔ́rʃənz əv ən ɑ́rtwɜ̀rk—ðɪs əláwz CNNz tə rɛ́kəɡnàjz pǽtərnz əfɛ́ktɪvlij, rədjúwsɪz ðə nʌ́mbər əv pərǽmətərz ðej níjd tə lɜ́rn, ənd spíjdz ʌp ðə tréjnɪŋ prɒ́sɛs."
    },
    {
        "Question": "In machine learning, what term describes the technique used to automatically find the best possible arrangement of layers and connections within a neural network, without manually designing each detail?",
        "RightAnswer": "Neural Architecture Search",
        "WrongAnswers": [
            "Gradient Boosting",
            "Reinforcement Learning",
            "Hyperparameter Tuning",
            "Transfer Learning",
            "Dimensionality Reduction"
        ],
        "Explanation": "Neural Architecture Search (NAS) refers to an automated process of finding the best design or structure for artificial neural networks. Instead of designing networks manually—which can be tedious and challenging—NAS helps identify the optimal architecture, including how many layers, neurons, and connections a neural network should have, often leading to better performance with less trial-and-error effort.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tɜ́rm dəskrájbz ðə tɛkníjk júwzd tə ɔ̀təmǽtɪklij fájnd ðə bɛ́st pɒ́sɪbəl əréjndʒmənt əv léjərz ənd kənɛ́kʃənz wɪðɪ́n ə nʊ́rəl nɛ́twɜ̀rk, wɪðáwt mǽnjuwəlij dəzájnɪŋ ijtʃ díjtejl?",
        "trans_RightAnswer": "nʊ́rəl ɑ́rkɪtɛ̀ktʃər sɜ́rtʃ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "nʊ́rəl ɑ́rkɪtɛ̀ktʃər sɜ́rtʃ (NAS) rəfɜ́rz tə ən ɔ́təmèjtɪd prɒ́sɛs əv fájndɪŋ ðə bɛ́st dəzájn ɔr strʌ́ktʃər fɔr ɑ̀rtɪfɪ́ʃəl nʊ́rəl nɛ́twɜ̀rks. ɪnstɛ́d əv dəzájnɪŋ nɛ́twɜ̀rks mǽnjuwəlij—wɪ́tʃ kən bij tíjdijəs ənd tʃǽləndʒɪŋ—næs hɛ́lps ajdɛ́ntɪfàj ðə ɒ́ptɪməl ɑ́rkɪtɛ̀ktʃər, ɪnklúwdɪŋ háw mɛ́nij léjərz, nʊ́rɒnz, ənd kənɛ́kʃənz ə nʊ́rəl nɛ́twɜ̀rk ʃʊd həv, ɔ́fən líjdɪŋ tə bɛ́tər pərfɔ́rməns wɪð lɛ́s trájəl-ənd-ɛ́ərər ɛ́fərt."
    },
    {
        "Question": "In machine learning, what approach mimics the concepts of natural selection and mutation to optimize a model's parameters by iteratively generating and evolving different solutions?",
        "RightAnswer": "Evolutionary Strategies",
        "WrongAnswers": [
            "Gradient Descent",
            "Bayesian Optimization",
            "Support Vector Machines",
            "Reinforcement Learning",
            "Random Forests"
        ],
        "Explanation": "Evolutionary Strategies are a fascinating family of algorithms inspired by the concept of biological evolution. Imagine machines competing in a friendly 'survival of the fittest' contest: they create diverse 'offspring' solutions, test their performance, keep the best ones, and then make small 'mutations' to form new generations. Through repeated cycles, this approach gradually discovers optimal solutions without explicitly calculating gradients or derivatives—much like nature evolving successful adaptations over time.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt əprówtʃ mɪ́mɪks ðə kɒ́nsɛpts əv nǽtʃərəl səlɛ́kʃən ənd mjuwtéjʃən tə ɒ́ptɪmàjz ə mɒ́dəl'z pərǽmətərz baj ɪ́tərətɪvlij dʒɛ́nərèjtɪŋ ənd əvɒ́lvɪŋ dɪ́fərənt səlúwʃənz?",
        "trans_RightAnswer": "ɛ̀vəlúwʃənɛ̀ərij strǽtədʒijz",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "béjʒən ɒptɪmɪzéjʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "rǽndəm fɔ́rəsts"
        ],
        "trans_Explanation": "ɛ̀vəlúwʃənɛ̀ərij strǽtədʒijz ɑr ə fǽsɪnèjtɪŋ fǽmɪlij əv ǽlɡərɪ̀ðəmz ɪnspájərd baj ðə kɒ́nsɛpt əv bàjəlɒ́dʒɪkəl ɛ̀vəlúwʃən. ɪmǽdʒɪn məʃíjnz kəmpíjtɪŋ ɪn ə frɛ́ndlij 'sərvájvəl əv ðə fɪ́təst' kɒ́ntɛst: ðej krijéjt dajvɜ́rs 'ɔ́fsprɪ̀ŋ' səlúwʃənz, tɛ́st ðɛər pərfɔ́rməns, kíjp ðə bɛ́st wʌ́nz, ənd ðɛn méjk smɔ́l 'mjuwtéjʃənz' tə fɔ́rm núw dʒɛ̀nəréjʃənz. θrúw rəpíjtɪd sájkəlz, ðɪs əprówtʃ ɡrǽdʒuwəlij dɪskʌ́vərz ɒ́ptɪməl səlúwʃənz wɪðáwt əksplɪ́sɪtlij kǽlkjəlèjtɪŋ ɡréjdijənts ɔr dərɪ́vətɪvz—mʌtʃ lájk néjtʃər əvɒ́lvɪŋ səksɛ́sfəl æ̀dæptéjʃənz ówvər tájm."
    },
    {
        "Question": "Imagine you're trying to train machine learning models, but experimenting with every single possible model or hyperparameter takes way too long or requires too many resources. Which method cleverly balances exploring promising configurations and quickly eliminating poor ones to efficiently find an optimal setup?",
        "RightAnswer": "Hyperband",
        "WrongAnswers": [
            "Grid Search",
            "Cross Validation",
            "Gradient Boosting",
            "Early Stopping",
            "Bagging"
        ],
        "Explanation": "Hyperband is an efficient technique designed to quickly identify and discard low-performing model configurations during hyperparameter tuning. Instead of extensively running every model combination, Hyperband rapidly allocates limited resources to promising candidates. Roughly speaking, it 'races' models against each other, gradually increasing resource allocation (like computational time or iterations) only for the strongest performers. This clever approach significantly speeds up the model-tuning process while saving computational resources.",
        "trans_Question": "ɪmǽdʒɪn júwr trájɪŋ tə tréjn məʃíjn lɜ́rnɪŋ mɒ́dəlz, bʌt əkspɛ́ərɪmɛ̀ntɪŋ wɪð ɛvərij sɪ́ŋɡəl pɒ́sɪbəl mɒ́dəl ɔr hàjpərpǽrəmətər téjks wej túw lɔ́ŋ ɔr rəkwájərz túw mɛ́nij ríjsɔrsɪz. wɪ́tʃ mɛ́θəd klɛ́vərlij bǽlənsɪz əksplɔ́rɪŋ prɒ́mɪsɪŋ kənfɪ̀ɡjəréjʃənz ənd kwɪ́klij əlɪ́mɪnèjtɪŋ pɔ́r wʌ́nz tə əfɪ́ʃəntlij fájnd ən ɒ́ptɪməl sɛ́tʌ̀p?",
        "trans_RightAnswer": "hájpərbænd",
        "trans_WrongAnswers": [
            "ɡrɪ́d sɜ́rtʃ",
            "krɔ́s væ̀lɪdéjʃən",
            "ɡréjdijənt búwstɪŋ",
            "ɜ́rlij stɒ́pɪŋ",
            "bǽɡɪŋ"
        ],
        "trans_Explanation": "hájpərbænd ɪz ən əfɪ́ʃənt tɛkníjk dəzájnd tə kwɪ́klij ajdɛ́ntɪfàj ənd dɪskɑ́rd lów-pərfɔ́rmɪŋ mɒ́dəl kənfɪ̀ɡjəréjʃənz dʊ́rɪŋ hàjpərpǽrəmətər túwnɪŋ. ɪnstɛ́d əv əkstɛ́nsɪvlij rʌ́nɪŋ ɛvərij mɒ́dəl kɒ̀mbɪnéjʃən, hájpərbænd rǽpɪdlij ǽləkèjts lɪ́mɪtɪd ríjsɔrsɪz tə prɒ́mɪsɪŋ kǽndɪdejts. rʌ́flij spíjkɪŋ, ɪt 'réjsɪz' mɒ́dəlz əɡéjnst ijtʃ ʌ́ðər, ɡrǽdʒuwəlij ɪnkríjsɪŋ ríjsɔrs æ̀ləkéjʃən (lájk kɒ̀mpjuwtéjʃənəl tájm ɔr ɪ̀təréjʃənz) ównlij fɔr ðə strɔ́ŋɡəst pərfɔ́rmərz. ðɪs klɛ́vər əprówtʃ sɪɡnɪ́fɪkəntlij spíjdz ʌp ðə mɒ́dəl-túwnɪŋ prɒ́sɛs wájl séjvɪŋ kɒ̀mpjuwtéjʃənəl ríjsɔrsɪz."
    },
    {
        "Question": "Which machine learning technique involves training models specifically designed to sort items—like arranging search results or ranking recommendations—based on relevance or importance?",
        "RightAnswer": "Learning to Rank",
        "WrongAnswers": [
            "Clustering",
            "Dimensionality Reduction",
            "Anomaly Detection",
            "Reinforcement Learning",
            "Classification"
        ],
        "Explanation": "Learning to Rank is a specialized machine learning method used primarily in search and recommendation systems. Instead of categorizing or grouping data, it focuses on creating models that accurately order or rank items based on relevance, importance, or user preference—such as ranking webpages in Google or prioritizing shows on Netflix. Essentially, it's like teaching a machine to thoughtfully sort items, ensuring users find what matters most first.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk ɪnvɒ́lvz tréjnɪŋ mɒ́dəlz spəsɪ́fɪklij dəzájnd tə sɔ́rt ájtəmz—lájk əréjndʒɪŋ sɜ́rtʃ rəzʌ́lts ɔr rǽŋkɪŋ rɛ̀kəməndéjʃənz—béjst ɒn rɛ́ləvəns ɔr ɪmpɔ́rtəns?",
        "trans_RightAnswer": "lɜ́rnɪŋ tə rǽŋk",
        "trans_WrongAnswers": [
            "klʌ́stərɪŋ",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "ənɒ́məlij dətɛ́kʃən",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "klæ̀sɪfɪkéjʃən"
        ],
        "trans_Explanation": "lɜ́rnɪŋ tə rǽŋk ɪz ə spɛ́ʃəlàjzd məʃíjn lɜ́rnɪŋ mɛ́θəd júwzd prajmɛ́ərɪlij ɪn sɜ́rtʃ ənd rɛ̀kəməndéjʃən sɪ́stəmz. ɪnstɛ́d əv kǽtəɡəràjzɪŋ ɔr ɡrúwpɪŋ déjtə, ɪt fówkəsɪz ɒn krijéjtɪŋ mɒ́dəlz ðət ǽkjərətlij ɔ́rdər ɔr rǽŋk ájtəmz béjst ɒn rɛ́ləvəns, ɪmpɔ́rtəns, ɔr júwzər prɛ́fərəns—sʌtʃ æz rǽŋkɪŋ wɛbpèjdʒɪz ɪn ɡúwɡəl ɔr prajɔ́rɪtajzɪŋ ʃówz ɒn nɛ́tflɪks. əsɛ́nʃəlij, ɪt's lájk tíjtʃɪŋ ə məʃíjn tə θɔ́tfəlij sɔ́rt ájtəmz, ɛnʃʊ́rɪŋ júwzərz fájnd wɒt mǽtərz mówst fɜ́rst."
    },
    {
        "Question": "You're developing a machine learning model that predicts customer satisfaction ratings (like low, medium, or high) from survey responses. Which machine learning technique best fits this task?",
        "RightAnswer": "Ordinal Regression",
        "WrongAnswers": [
            "Linear Regression",
            "Binary Classification",
            "K-Means Clustering",
            "Support Vector Machines",
            "Principal Component Analysis"
        ],
        "Explanation": "Ordinal regression is a specialized regression technique designed specifically for situations when your target variable has an inherent order, like ratings from low to high. It's especially useful when you're working with survey data, rankings, or satisfaction scales, where the difference between categories like 'moderate' and 'high' isn't exactly numeric, but still has a natural ordering.",
        "trans_Question": "júwr dəvɛ́ləpɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl ðət prədɪ́kts kʌ́stəmər sæ̀tɪsfǽkʃən réjtɪŋz (lájk lów, míjdijəm, ɔr háj) frəm sɜ́rvej rəspɒ́nsɪz. wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk bɛ́st fɪ́ts ðɪs tǽsk?",
        "trans_RightAnswer": "ɔ́rdɪnəl rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "lɪ́nijər rəɡrɛ́ʃən",
            "bájnərij klæ̀sɪfɪkéjʃən",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "ɔ́rdɪnəl rəɡrɛ́ʃən ɪz ə spɛ́ʃəlàjzd rəɡrɛ́ʃən tɛkníjk dəzájnd spəsɪ́fɪklij fɔr sɪ̀tʃuwéjʃənz wɛ́n jɔr tɑ́rɡət vɛ́ərijəbəl həz ən ɪnhɛ́ərənt ɔ́rdər, lájk réjtɪŋz frəm lów tə háj. ɪt's əspɛ́ʃəlij júwsfəl wɛ́n júwr wɜ́rkɪŋ wɪð sɜ́rvej déjtə, rǽŋkɪŋz, ɔr sæ̀tɪsfǽkʃən skéjlz, wɛ́ər ðə dɪ́fərəns bijtwíjn kǽtəɡɔ̀rijz lájk 'mɒ́dərèjt' ənd 'háj' ɪzənt əɡzǽktlij njuwmɛ́ərɪk, bʌt stɪ́l həz ə nǽtʃərəl ɔ́rdərɪŋ."
    },
    {
        "Question": "In machine learning, when you want to predict not just the mean (average) but different percentiles of your target distribution (like median, quartiles or deciles) to better understand the full picture of possible outcomes, which method would you use?",
        "RightAnswer": "Quantile Regression",
        "WrongAnswers": [
            "Logistic Regression",
            "Principal Component Analysis",
            "Support Vector Machine",
            "Ridge Regression",
            "Random Forest"
        ],
        "Explanation": "Quantile regression is an advanced regression method that allows you to estimate multiple points (quantiles) in the prediction distribution, not just the average. For example, instead of only predicting the average house price in an area, quantile regression lets you predict different price ranges (like median or top 10%) to give you a richer, fuller understanding of the distribution of potential results.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n juw wɒ́nt tə prədɪ́kt nɒt dʒəst ðə míjn (ǽvərɪdʒ) bʌt dɪ́fərənt pərsɛ́ntàjlz əv jɔr tɑ́rɡət dɪ̀strəbjúwʃən (lájk míjdijən, kwɔ́rtajlz ɔr dɛ́sajlz) tə bɛ́tər ʌ̀ndərstǽnd ðə fʊ́l pɪ́ktʃər əv pɒ́sɪbəl áwtkʌ̀mz, wɪ́tʃ mɛ́θəd wʊd juw juwz?",
        "trans_RightAnswer": "kwɒ́ntajl rəɡrɛ́ʃən",
        "trans_WrongAnswers": [
            "lədʒɪ́stɪk rəɡrɛ́ʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "rɪ́dʒ rəɡrɛ́ʃən",
            "rǽndəm fɔ́rəst"
        ],
        "trans_Explanation": "kwɒ́ntajl rəɡrɛ́ʃən ɪz ən ədvǽnst rəɡrɛ́ʃən mɛ́θəd ðət əláwz juw tə ɛ́stɪmèjt mʌ́ltɪpəl pɔ́jnts (kwɒ́ntajlz) ɪn ðə prədɪ́kʃən dɪ̀strəbjúwʃən, nɒt dʒəst ðə ǽvərɪdʒ. fɔr əɡzǽmpəl, ɪnstɛ́d əv ównlij prədɪ́ktɪŋ ðə ǽvərɪdʒ haws prájs ɪn ən ɛ́ərijə, kwɒ́ntajl rəɡrɛ́ʃən lɛts juw prədɪ́kt dɪ́fərənt prájs réjndʒɪz (lájk míjdijən ɔr tɒ́p 10%) tə ɡɪ́v juw ə rɪ́tʃər, fʊ́lər ʌ̀ndərstǽndɪŋ əv ðə dɪ̀strəbjúwʃən əv pətɛ́nʃəl rəzʌ́lts."
    },
    {
        "Question": "When training a machine learning model, you're often trying to not just get accurate predictions, but also make sure the model runs quickly, uses less memory, and is easy to interpret. What's the name for the technique that involves balancing several outcomes like these at once during optimization?",
        "RightAnswer": "Multi-Objective Optimization",
        "WrongAnswers": [
            "Single-Dimensional Optimization",
            "Gradient Regularization",
            "Overfitting Prevention",
            "Feature Extraction Technique",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Multi-objective optimization is about finding solutions that balance multiple goals at the same time. In machine learning, this means you might not only aim for higher accuracy, but you'd also consider speed, simplicity, interpretability, or lower resource usage. Instead of a one-size-fits-all solution, you'll get a set of 'trade-off' solutions—called Pareto-optimal solutions—that allow you to choose depending on your specific needs and preferences.",
        "trans_Question": "wɛ́n tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, júwr ɔ́fən trájɪŋ tə nɒt dʒəst ɡɛt ǽkjərət prədɪ́kʃənz, bʌt ɔ́lsow méjk ʃʊ́r ðə mɒ́dəl rʌ́nz kwɪ́klij, júwsɪz lɛ́s mɛ́mərij, ənd ɪz íjzij tə ɪntɜ́rprət. wɒt's ðə néjm fɔr ðə tɛkníjk ðət ɪnvɒ́lvz bǽlənsɪŋ sɛ́vərəl áwtkʌ̀mz lájk ðijz æt wʌ́ns dʊ́rɪŋ ɒptɪmɪzéjʃən?",
        "trans_RightAnswer": "mʌ́ltij-əbdʒɛ́ktɪv ɒptɪmɪzéjʃən",
        "trans_WrongAnswers": [
            "sɪ́ŋɡəl-dajmɛ́nʃənəl ɒptɪmɪzéjʃən",
            "ɡréjdijənt rèɡjəlɛ̀ərɪzéjʃən",
            "òwvərfɪ́tɪŋ prəvɛ́nʃən",
            "fíjtʃər əkstrǽkʃən tɛkníjk",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "mʌ́ltij-əbdʒɛ́ktɪv ɒptɪmɪzéjʃən ɪz əbawt fájndɪŋ səlúwʃənz ðət bǽləns mʌ́ltɪpəl ɡówlz æt ðə séjm tájm. ɪn məʃíjn lɜ́rnɪŋ, ðɪs míjnz juw majt nɒt ównlij éjm fɔr hájər ǽkjərəsij, bʌt júwd ɔ́lsow kənsɪ́dər spíjd, sɪmplɪ́sɪtij, ɪntɜ̀rprɛtəbɪ́lɪtij, ɔr lówər ríjsɔrs júwsɪdʒ. ɪnstɛ́d əv ə wʌ́n-sájz-fɪ́ts-ɔl səlúwʃən, júwl ɡɛt ə sɛ́t əv 'tréjd-ɔ́f' səlúwʃənz—kɔ́ld pɑ̀rɛ́tow-ɒ́ptɪməl səlúwʃənz—ðət əláw juw tə tʃúwz dəpɛ́ndɪŋ ɒn jɔr spəsɪ́fɪk níjdz ənd prɛ́fərənsɪz."
    },
    {
        "Question": "Imagine you're teaching a robot how to navigate through a crowded warehouse. To do this effectively, you set specific goals like taking the shortest route, but also put limitations on how close it can get to obstacles and how fast it can move. What is this machine learning concept of finding the optimal solution within set limits called?",
        "RightAnswer": "Constraint Optimization",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Regularization",
            "Gradient Descent",
            "Dimensionality Reduction",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Constraint Optimization is the process of finding the best solution among many possibilities while respecting certain limits or restrictions. Think of it like setting rules or boundaries in a game, then strategizing to achieve the highest possible score without breaking any rules. In machine learning, this involves figuring out the most effective outcome (e.g., shortest path, lowest cost) given specific requirements (e.g., avoiding obstacles, adhering to safety standards).",
        "trans_Question": "ɪmǽdʒɪn júwr tíjtʃɪŋ ə rówbɒ̀t háw tə nǽvɪɡejt θrúw ə kráwdɪd wɛ́ərhàws. tə dúw ðɪs əfɛ́ktɪvlij, juw sɛ́t spəsɪ́fɪk ɡówlz lájk téjkɪŋ ðə ʃɔ́rtəst ráwt, bʌt ɔ́lsow pʊ́t lɪ̀mɪtéjʃənz ɒn háw klóws ɪt kən ɡɛt tə ɒ́bstəkəlz ənd háw fǽst ɪt kən múwv. wɒt ɪz ðɪs məʃíjn lɜ́rnɪŋ kɒ́nsɛpt əv fájndɪŋ ðə ɒ́ptɪməl səlúwʃən wɪðɪ́n sɛ́t lɪ́mɪts kɔ́ld?",
        "trans_RightAnswer": "kənstréjnt ɒptɪmɪzéjʃən",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən",
            "ɡréjdijənt dəsɛ́nt",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "kənstréjnt ɒptɪmɪzéjʃən ɪz ðə prɒ́sɛs əv fájndɪŋ ðə bɛ́st səlúwʃən əmʌ́ŋ mɛ́nij pɒ̀sɪbɪ́lɪtijz wájl rəspɛ́ktɪŋ sɜ́rtən lɪ́mɪts ɔr rəstrɪ́kʃənz. θɪ́ŋk əv ɪt lájk sɛ́tɪŋ rúwlz ɔr báwndərijz ɪn ə ɡéjm, ðɛn strǽtədʒajzɪŋ tə ətʃíjv ðə hájəst pɒ́sɪbəl skɔ́r wɪðáwt bréjkɪŋ ɛ́nij rúwlz. ɪn məʃíjn lɜ́rnɪŋ, ðɪs ɪnvɒ́lvz fɪ́ɡjərɪŋ awt ðə mówst əféktɪv áwtkʌ̀m (fər⋅ɪgzɒ́mpəl., ʃɔ́rtəst pǽθ, lówəst kɒ́st) ɡɪ́vən spəsɪ́fɪk rəkwájərmənts (fər⋅ɪgzɒ́mpəl., əvɔ́jdɪŋ ɒ́bstəkəlz, ədhɪ́ərɪŋ tə séjftij stǽndərdz)."
    },
    {
        "Question": "In machine learning, there's a technique where data is represented efficiently using only a small number of active components at a time, aiming for simplicity and clarity in capturing essential information. What's this technique called?",
        "RightAnswer": "Sparse Coding",
        "WrongAnswers": [
            "Gradient Boosting",
            "Deep Reinforcement Learning",
            "K-means Clustering",
            "Principal Component Analysis",
            "Convolutional Neural Networks"
        ],
        "Explanation": "Sparse coding is a machine learning method designed to represent complex data in the simplest way possible, using just a few active elements or building blocks. Imagine summarizing a complicated recipe with just the key ingredients—this is essentially how sparse coding works. It focuses on neatly capturing the essential features of data, helping models become clearer, simpler, and more efficient.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə tɛkníjk wɛ́ər déjtə ɪz rɛ̀prəzɛ́ntɪd əfɪ́ʃəntlij júwzɪŋ ównlij ə smɔ́l nʌ́mbər əv ǽktɪv kəmpównənts æt ə tájm, éjmɪŋ fɔr sɪmplɪ́sɪtij ənd klɛ́ərɪtij ɪn kǽptʃərɪŋ əsɛ́nʃəl ɪnfərméjʃən. wɒt's ðɪs tɛkníjk kɔ́ld?",
        "trans_RightAnswer": "spɑ́rs kówdɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "díjp rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "k-míjnz klʌ́stərɪŋ",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "spɑ́rs kówdɪŋ ɪz ə məʃíjn lɜ́rnɪŋ mɛ́θəd dəzájnd tə rɛ̀prəzɛ́nt kɒ́mplɛks déjtə ɪn ðə sɪ́mpləst wej pɒ́sɪbəl, júwzɪŋ dʒəst ə fjúw ǽktɪv ɛ́ləmənts ɔr bɪ́ldɪŋ blɒ́ks. ɪmǽdʒɪn sʌ́məràjzɪŋ ə kɒ́mplɪkèjtɪd rɛ́sɪpij wɪð dʒəst ðə kíj ɪnɡríjdijənts—ðɪs ɪz əsɛ́nʃəlij háw spɑ́rs kówdɪŋ wɜ́rks. ɪt fówkəsɪz ɒn níjtlij kǽptʃərɪŋ ðə əsɛ́nʃəl fíjtʃərz əv déjtə, hɛ́lpɪŋ mɒ́dəlz bəkʌ́m klɪ́ərər, sɪ́mplər, ənd mɔr əfɪ́ʃənt."
    },
    {
        "Question": "Imagine you're working with images and sounds, and you want your machine learning model to find a compact set of simple building blocks that best represent complex data—just like assembling Lego pieces to recreate complicated objects. What technique best describes this approach in machine learning?",
        "RightAnswer": "Dictionary Learning",
        "WrongAnswers": [
            "Gradient Boosting",
            "Random Forest",
            "Kernel Trick",
            "Backpropagation",
            "Clustering Analysis"
        ],
        "Explanation": "Dictionary Learning is a technique in machine learning where the goal is to find a compact, optimized set of simple components—called the 'dictionary'—that can represent complex data efficiently. It's similar to having a set of essential building blocks (like Lego pieces) that you mix and match in different ways to recreate a wide range of complicated structures. This approach is especially useful for tasks involving image and sound processing, compressing data, or extracting meaningful features from complex information.",
        "trans_Question": "ɪmǽdʒɪn júwr wɜ́rkɪŋ wɪð ɪ́mɪdʒɪz ənd sáwndz, ənd juw wɒ́nt jɔr məʃíjn lɜ́rnɪŋ mɒ́dəl tə fájnd ə kɒ́mpækt sɛ́t əv sɪ́mpəl bɪ́ldɪŋ blɒ́ks ðət bɛ́st rɛ̀prəzɛ́nt kɒ́mplɛks déjtə—dʒəst lájk əsɛ́mbəlɪŋ lɛ́ɡow píjsɪz tə rɛ́krijèjt kɒ́mplɪkèjtɪd ɒ́bdʒɛkts. wɒt tɛkníjk bɛ́st dəskrájbz ðɪs əprówtʃ ɪn məʃíjn lɜ́rnɪŋ?",
        "trans_RightAnswer": "dɪ́kʃənɛ̀ərij lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ",
            "rǽndəm fɔ́rəst",
            "kɜ́rnəl trɪ́k",
            "bǽkprəpəgéjʃən",
            "klʌ́stərɪŋ ənǽlɪsɪs"
        ],
        "trans_Explanation": "dɪ́kʃənɛ̀ərij lɜ́rnɪŋ ɪz ə tɛkníjk ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ðə ɡówl ɪz tə fájnd ə kɒ́mpækt, ɒ́ptɪmàjzd sɛ́t əv sɪ́mpəl kəmpównənts—kɔ́ld ðə 'dɪ́kʃənɛ̀ərij'—ðət kən rɛ̀prəzɛ́nt kɒ́mplɛks déjtə əfɪ́ʃəntlij. ɪt's sɪ́mɪlər tə hǽvɪŋ ə sɛ́t əv əsɛ́nʃəl bɪ́ldɪŋ blɒ́ks (lájk lɛ́ɡow píjsɪz) ðət juw mɪ́ks ənd mǽtʃ ɪn dɪ́fərənt wéjz tə rɛ́krijèjt ə wájd réjndʒ əv kɒ́mplɪkèjtɪd strʌ́ktʃərz. ðɪs əprówtʃ ɪz əspɛ́ʃəlij júwsfəl fɔr tǽsks ɪnvɒ́lvɪŋ ɪ́mɪdʒ ənd sáwnd prɒ́sɛsɪŋ, kəmprɛ́sɪŋ déjtə, ɔr əkstrǽktɪŋ míjnɪŋfəl fíjtʃərz frəm kɒ́mplɛks ɪnfərméjʃən."
    },
    {
        "Question": "In machine learning scenarios involving recommendation systems and prediction tasks with large-scale, sparse datasets, which algorithm helps by efficiently modeling feature interactions and uncovering patterns hidden within combinations of features?",
        "RightAnswer": "Factorization Machines",
        "WrongAnswers": [
            "Decision Trees",
            "Support Vector Machines",
            "Convolutional Neural Networks",
            "Gradient Boosted Trees",
            "K-Means Clustering"
        ],
        "Explanation": "Factorization Machines are machine learning algorithms designed to handle datasets that are large and sparse, like user ratings or product interactions in recommendation systems. They work by efficiently examining interactions between different features, uncovering hidden relationships, and achieving good prediction accuracy. They're popular because they manage to accurately capture the complex ways various features interact, without requiring extensive computational resources or overly complex models.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ sənɛ́ərijowz ɪnvɒ́lvɪŋ rɛ̀kəməndéjʃən sɪ́stəmz ənd prədɪ́kʃən tǽsks wɪð lɑ́rdʒ-skéjl, spɑ́rs déjtəsɛ̀ts, wɪ́tʃ ǽlɡərɪ̀ðəm hɛ́lps baj əfɪ́ʃəntlij mɒ́dəlɪ̀ŋ fíjtʃər ɪ̀ntərǽkʃənz ənd ʌ̀nkʌ́vərɪŋ pǽtərnz hɪ́dən wɪðɪ́n kɒ̀mbɪnéjʃənz əv fíjtʃərz?",
        "trans_RightAnswer": "fæ̀ktərajzéjʃən məʃíjnz",
        "trans_WrongAnswers": [
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "ɡréjdijənt búwstɪd tríjz",
            "k-míjnz klʌ́stərɪŋ"
        ],
        "trans_Explanation": "fæ̀ktərajzéjʃən məʃíjnz ɑr məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz dəzájnd tə hǽndəl déjtəsɛ̀ts ðət ɑr lɑ́rdʒ ənd spɑ́rs, lájk júwzər réjtɪŋz ɔr prɒ́dəkt ɪ̀ntərǽkʃənz ɪn rɛ̀kəməndéjʃən sɪ́stəmz. ðej wɜ́rk baj əfɪ́ʃəntlij əɡzǽmɪnɪŋ ɪ̀ntərǽkʃənz bijtwíjn dɪ́fərənt fíjtʃərz, ʌ̀nkʌ́vərɪŋ hɪ́dən rəléjʃənʃɪ̀ps, ənd ətʃíjvɪŋ ɡʊ́d prədɪ́kʃən ǽkjərəsij. ðɛ́ər pɒ́pjələr bəkɒ́z ðej mǽnɪdʒ tə ǽkjərətlij kǽptʃər ðə kɒ́mplɛks wéjz vɛ́ərijəs fíjtʃərz ɪ̀ntərǽkt, wɪðáwt rijkwájərɪŋ əkstɛ́nsɪv kɒ̀mpjuwtéjʃənəl ríjsɔrsɪz ɔr ówvərlij kɒ́mplɛks mɒ́dəlz."
    },
    {
        "Question": "Which machine learning approach combines the flexibility of deep neural networks with the uncertainty estimation capabilities of Gaussian processes, allowing models to learn complex patterns while accurately quantifying their predictions?",
        "RightAnswer": "Deep Kernel Learning",
        "WrongAnswers": [
            "Random Forest Regression",
            "Support Vector Machines",
            "Linear Regression",
            "Gradient Boosting Machines",
            "Hierarchical Clustering"
        ],
        "Explanation": "Deep Kernel Learning merges the strengths of deep learning and Gaussian processes. It leverages deep neural networks to discover complex, non-linear transformations of data, while Gaussian processes help the model understand how certain or uncertain its predictions are. This combination allows for more accurate and reliable models, especially useful in scenarios where uncertainty estimation is important—like healthcare decisions or finance forecasting.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ kəmbájnz ðə flɛ̀ksɪbɪ́lɪtij əv díjp nʊ́rəl nɛ́twɜ̀rks wɪð ðə ʌ̀nsɜ́rtəntij ɛ̀stɪméjʃən kèjpəbɪ́lɪtijz əv ɡáwsijən prɒ́sɛsɪz, əláwɪŋ mɒ́dəlz tə lɜ́rn kɒ́mplɛks pǽtərnz wájl ǽkjərətlij kwɑ́ntᵻfàjᵻŋ ðɛər prədɪ́kʃənz?",
        "trans_RightAnswer": "díjp kɜ́rnəl lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəst rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "lɪ́nijər rəɡrɛ́ʃən",
            "ɡréjdijənt búwstɪŋ məʃíjnz",
            "hàjərɑ́rkɪkəl klʌ́stərɪŋ"
        ],
        "trans_Explanation": "díjp kɜ́rnəl lɜ́rnɪŋ mɜ́rdʒɪz ðə strɛ́ŋθs əv díjp lɜ́rnɪŋ ənd ɡáwsijən prɒ́sɛsɪz. ɪt lɛ́vərɪdʒɪz díjp nʊ́rəl nɛ́twɜ̀rks tə dɪskʌ́vər kɒ́mplɛks, nɒn-lɪ́nijər træ̀nsfərméjʃənz əv déjtə, wájl ɡáwsijən prɒ́sɛsɪz hɛ́lp ðə mɒ́dəl ʌ̀ndərstǽnd háw sɜ́rtən ɔr ʌ̀nsɜ́rtən ɪts prədɪ́kʃənz ɑr. ðɪs kɒ̀mbɪnéjʃən əláwz fɔr mɔr ǽkjərət ənd rəlájəbəl mɒ́dəlz, əspɛ́ʃəlij júwsfəl ɪn sənɛ́ərijowz wɛ́ər ʌ̀nsɜ́rtəntij ɛ̀stɪméjʃən ɪz ɪmpɔ́rtənt—lájk hɛ́lθkɛ̀ər dəsɪ́ʒənz ɔr fájnæ̀ns fɔ́rkæ̀stɪŋ."
    },
    {
        "Question": "In machine learning, what specialized neural network approach do we use to analyze patterns, relationships, or connections within data structured as graphs, such as social networks or molecular bonds?",
        "RightAnswer": "Graph Convolutional Networks",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Generative Adversarial Networks",
            "Recurrent Neural Networks",
            "Autoencoder Networks",
            "Transformer Networks"
        ],
        "Explanation": "Graph Convolutional Networks, or GCNs for short, are specialized neural networks designed specifically to handle data that exists in the form of graphs—networks of connected nodes. They cleverly utilize both the data itself and how it's connected to find meaningful patterns. This makes GCNs invaluable for tasks like predicting friend recommendations on social media, analyzing citation networks, or even discovering molecules that might lead to new medicines.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt spɛ́ʃəlàjzd nʊ́rəl nɛ́twɜ̀rk əprówtʃ dúw wij juwz tə ǽnəlàjz pǽtərnz, rəléjʃənʃɪ̀ps, ɔr kənɛ́kʃənz wɪðɪ́n déjtə strʌ́ktʃərd æz ɡrǽfs, sʌtʃ æz sówʃəl nɛ́twɜ̀rks ɔr məlɛ́kjələr bɒ́ndz?",
        "trans_RightAnswer": "ɡrǽf kənvəlúwʃənəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "ɔ̀towənkówdər nɛ́twɜ̀rks",
            "trænsfɔ́rmər nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "ɡrǽf kənvəlúwʃənəl nɛ́twɜ̀rks, ɔr GCNS fɔr ʃɔ́rt, ɑr spɛ́ʃəlàjzd nʊ́rəl nɛ́twɜ̀rks dəzájnd spəsɪ́fɪklij tə hǽndəl déjtə ðət əɡzɪ́sts ɪn ðə fɔ́rm əv ɡrǽfs—nɛ́twɜ̀rks əv kənɛ́ktɪd nówdz. ðej klɛ́vərlij júwtɪlàjz bówθ ðə déjtə ɪtsɛ́lf ənd háw ɪt's kənɛ́ktɪd tə fájnd míjnɪŋfəl pǽtərnz. ðɪs méjks GCNS ɪ̀nvǽljəbəl fɔr tǽsks lájk prədɪ́ktɪŋ frɛ́nd rɛ̀kəməndéjʃənz ɒn sówʃəl míjdijə, ǽnəlàjzɪŋ sajtéjʃən nɛ́twɜ̀rks, ɔr íjvən dɪskʌ́vərɪŋ mɒ́ləkjùwlz ðət majt líjd tə núw mɛ́dɪsənz."
    },
    {
        "Question": "In machine learning, there's a type of AI that can create brand-new examples, such as realistic human faces, original artwork, or even creative writing, by learning from existing data. What is this kind of AI called?",
        "RightAnswer": "Generative Models",
        "WrongAnswers": [
            "Supervised Learning",
            "Reinforcement Learning",
            "Transfer Learning",
            "Data Augmentation",
            "Dimensionality Reduction"
        ],
        "Explanation": "Generative models are fascinating AI techniques capable of learning patterns from existing data and then using those patterns to generate entirely new examples—like lifelike images of people who don't actually exist, unique text or content, and even original music or art. Instead of just classifying or predicting, generative models are creators, opening doors for various creative and practical applications.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ðɛər'z ə tájp əv AI ðət kən krijéjt brǽnd-núw əɡzǽmpəlz, sʌtʃ æz rìjəlɪ́stɪk hjúwmən féjsɪz, ərɪ́dʒɪnəl ɑ́rtwɜ̀rk, ɔr íjvən krijéjtɪv rájtɪŋ, baj lɜ́rnɪŋ frəm əɡzɪ́stɪŋ déjtə. wɒt ɪz ðɪs kájnd əv AI kɔ́ld?",
        "trans_RightAnswer": "dʒɛ́nərətɪv mɒ́dəlz",
        "trans_WrongAnswers": [
            "súwpərvàjzd lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən"
        ],
        "trans_Explanation": "dʒɛ́nərətɪv mɒ́dəlz ɑr fǽsɪnèjtɪŋ AI tɛkníjks kéjpəbəl əv lɜ́rnɪŋ pǽtərnz frəm əɡzɪ́stɪŋ déjtə ənd ðɛn júwzɪŋ ðowz pǽtərnz tə dʒɛ́nərèjt əntájərlij núw əɡzǽmpəlz—lájk lájflàjk ɪ́mɪdʒɪz əv píjpəl huw dównt ǽktʃùwəlij əɡzɪ́st, juwnɪ́k tɛ́kst ɔr kɒ́ntənt, ənd íjvən ərɪ́dʒɪnəl mjúwzɪk ɔr ɑ́rt. ɪnstɛ́d əv dʒəst klǽsɪfàjɪŋ ɔr prədɪ́ktɪŋ, dʒɛ́nərətɪv mɒ́dəlz ɑr krijéjtərz, ówpənɪŋ dɔ́rz fɔr vɛ́ərijəs krijéjtɪv ənd prǽktɪkəl æ̀plɪkéjʃənz."
    },
    {
        "Question": "What is the term used in machine learning that describes training a model within a simulation environment and then deploying it effectively in the real physical world?",
        "RightAnswer": "Sim2Real",
        "WrongAnswers": [
            "SimNet",
            "RealWorldAI",
            "TransferFlow",
            "RealityBridge",
            "Virtu2Real"
        ],
        "Explanation": "Sim2Real refers to a machine learning method where algorithms are first trained in simulated environments—like a virtual robot in a computer model—and then successfully applied to real-life settings. It's especially useful because simulations are safer, cheaper, and quicker to run than experiments in the real world, allowing faster and more efficient process of developing AI solutions.",
        "trans_Question": "wɒt ɪz ðə tɜ́rm júwzd ɪn məʃíjn lɜ́rnɪŋ ðət dəskrájbz tréjnɪŋ ə mɒ́dəl wɪðɪ́n ə sɪ̀mjəléjʃən ənvájərənmənt ənd ðɛn dəplɔ́jɪŋ ɪt əfɛ́ktɪvlij ɪn ðə ríjəl fɪ́zɪkəl wɜ́rld?",
        "trans_RightAnswer": "sɪ̀mtuwríjl",
        "trans_WrongAnswers": [
            "sɪ́mnɛt",
            "ríjl",
            "trǽnsfərflow",
            "rijǽlətɪbrɪdʒ",
            "vɜ́rtʃuw"
        ],
        "trans_Explanation": "sɪ̀mtuwríjl rəfɜ́rz tə ə məʃíjn lɜ́rnɪŋ mɛ́θəd wɛ́ər ǽlɡərɪ̀ðəmz ɑr fɜ́rst tréjnd ɪn sɪ́mjəlèjtɪd ənvájərənmənts—lájk ə vɜ́rtʃuwəl rówbɒ̀t ɪn ə kəmpjúwtər mɒ́dəl—ənd ðɛn səksɛ́sfəlij əplájd tə ríjəl-lájf sɛ́tɪŋz. ɪt's əspɛ́ʃəlij júwsfəl bəkɒ́z sɪ̀mjəléjʃənz ɑr séjfər, tʃíjpər, ənd kwɪ́kər tə rʌ́n ðʌn əkspɛ́ərɪmənts ɪn ðə ríjəl wɜ́rld, əláwɪŋ fǽstər ənd mɔr əfɪ́ʃənt prɒ́sɛs əv dəvɛ́ləpɪŋ AI səlúwʃənz."
    },
    {
        "Question": "You're analyzing data about daily sales of a rare, luxury product, but your dataset has a surprising number of days where no sales occurred, leading to many zeros. Which type of statistical or machine learning method could you use to accurately model this kind of data?",
        "RightAnswer": "Zero-Inflated Models",
        "WrongAnswers": [
            "Random Forest Models",
            "Polynomial Regression",
            "Principal Component Analysis",
            "K-Nearest Neighbors Models",
            "Support Vector Machines"
        ],
        "Explanation": "Zero-Inflated Models are designed specifically to handle datasets that have many zero values. Imagine you're looking at something like ticket sales for an ultra-rare event—many days have zero sales, creating a tricky pattern. Regular statistical models might not capture this pattern well. Zero-Inflated Models separate the analysis into two parts: one focusing on predicting whether you'll have zero or non-zero outcomes (like sales), and another considering the number of sales on days when sales occur. This allows for more accurate predictions and better understanding of your data.",
        "trans_Question": "júwr ǽnəlàjzɪŋ déjtə əbawt déjlij séjlz əv ə rɛ́ər, lʌ́ɡʒərij prɒ́dəkt, bʌt jɔr déjtəsɛ̀t həz ə sərprájzɪŋ nʌ́mbər əv déjz wɛ́ər now séjlz əkɜ́rd, líjdɪŋ tə mɛ́nij zɪ́ərowz. wɪ́tʃ tájp əv stətɪ́stɪkəl ɔr məʃíjn lɜ́rnɪŋ mɛ́θəd kʊ́d juw juwz tə ǽkjərətlij mɒ́dəl ðɪs kájnd əv déjtə?",
        "trans_RightAnswer": "zíjərow-ɪnfléjtɪd mɒ́dəlz",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəst mɒ́dəlz",
            "pɒ̀lijnówmijəl rəɡrɛ́ʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "k-nɪ́ərəst néjbərz mɒ́dəlz",
            "səpɔ́rt vɛ́ktər məʃíjnz"
        ],
        "trans_Explanation": "zíjərow-ɪnfléjtɪd mɒ́dəlz ɑr dəzájnd spəsɪ́fɪklij tə hǽndəl déjtəsɛ̀ts ðət həv mɛ́nij zíjərow vǽljuwz. ɪmǽdʒɪn júwr lʊ́kɪŋ æt sʌ́mθɪŋ lájk tɪ́kət séjlz fɔr ən ʌ́ltrə-rɛ́ər əvɛ́nt—mɛ́nij déjz həv zíjərow séjlz, krijéjtɪŋ ə trɪ́kij pǽtərn. rɛ́ɡjələr stətɪ́stɪkəl mɒ́dəlz majt nɒt kǽptʃər ðɪs pǽtərn wɛ́l. zíjərow-ɪnfléjtɪd mɒ́dəlz sɛ́pərət ðə ənǽlɪsɪs ɪntə túw pɑ́rts: wʌ́n fówkəsɪŋ ɒn prədɪ́ktɪŋ wɛ́ðər júwl həv zíjərow ɔr nɒn-zíjərow áwtkʌ̀mz (lájk séjlz), ənd ənʌ́ðər kənsɪ́dərɪŋ ðə nʌ́mbər əv séjlz ɒn déjz wɛ́n séjlz əkɜ́r. ðɪs əláwz fɔr mɔr ǽkjərət prədɪ́kʃənz ənd bɛ́tər ʌ̀ndərstǽndɪŋ əv jɔr déjtə."
    },
    {
        "Question": "In machine learning, when you want to ensure your chosen model features aren't just random fluctuations, but genuinely important across different data subsamples, what method would you use?",
        "RightAnswer": "Stability Selection",
        "WrongAnswers": [
            "Feature Scaling",
            "Cross Validation",
            "Gradient Boosting",
            "Bagging",
            "Hyperparameter Tuning"
        ],
        "Explanation": "Stability Selection is a smart method in machine learning used to identify the most reliable and consistent features or variables. Instead of relying on just one dataset, it repeatedly selects features from multiple random subsets of your data. The features that keep showing up consistently across these subsets are considered stable and genuinely important. It's like checking many different groups' opinions before trusting something as a universal truth—you make sure your chosen features aren't just lucky guesses!",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n juw wɒ́nt tə ənʃʊ́r jɔr tʃówzən mɒ́dəl fíjtʃərz ɑrənt dʒəst rǽndəm flʌ̀ktʃuwéjʃənz, bʌt dʒénjuwɪnlij ɪmpɔ́rtənt əkrɔ́s dɪ́fərənt déjtə sʌ́bsæ̀mpəlz, wɒt mɛ́θəd wʊd juw juwz?",
        "trans_RightAnswer": "stəbɪ́lɪtij səlɛ́kʃən",
        "trans_WrongAnswers": [
            "fíjtʃər skéjlɪŋ",
            "krɔ́s væ̀lɪdéjʃən",
            "ɡréjdijənt búwstɪŋ",
            "bǽɡɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ"
        ],
        "trans_Explanation": "stəbɪ́lɪtij səlɛ́kʃən ɪz ə smɑ́rt mɛ́θəd ɪn məʃíjn lɜ́rnɪŋ júwzd tə ajdɛ́ntɪfàj ðə mówst rəlájəbəl ənd kənsɪ́stənt fíjtʃərz ɔr vɛ́ərijəbəlz. ɪnstɛ́d əv rəlájɪŋ ɒn dʒəst wʌ́n déjtəsɛ̀t, ɪt rəpíjtɪdlij səlɛ́kts fíjtʃərz frəm mʌ́ltɪpəl rǽndəm sʌ́bsɛ̀ts əv jɔr déjtə. ðə fíjtʃərz ðət kíjp ʃówɪŋ ʌp kənsɪ́stəntlij əkrɔ́s ðijz sʌ́bsɛ̀ts ɑr kənsɪ́dərd stéjbəl ənd dʒénjuwɪnlij ɪmpɔ́rtənt. ɪt's lájk tʃɛ́kɪŋ mɛ́nij dɪ́fərənt ɡrúwps' əpɪ́njənz bəfɔ́r trʌ́stɪŋ sʌ́mθɪŋ æz ə jùwnɪvɜ́rsəl trúwθ—juw méjk ʃʊ́r jɔr tʃówzən fíjtʃərz ɑrənt dʒəst lʌ́kij ɡɛ́sɪz!"
    },
    {
        "Question": "Imagine you're a data scientist at a healthcare startup, trying to predict how long patients might survive after receiving treatment. Which technique would you use to analyze and predict the expected time until an event (like death, relapse, or another significant occurrence) occurs?",
        "RightAnswer": "Survival Analysis",
        "WrongAnswers": [
            "Cluster Analysis",
            "Association Rule Mining",
            "Regression Trees",
            "Neural Network Classification",
            "Principal Component Analysis"
        ],
        "Explanation": "Survival Analysis is a type of statistical and machine learning technique used when you want to predict the time until a particular event happens—like the time until patients get sick, customers churn, or mechanical parts fail. It is very commonly used in healthcare to forecast patient survival and treatment effectiveness, but it's useful in many other fields too. It specifically helps handle scenarios where your data includes 'censored' observations—meaning the event hasn’t occurred yet during the period of study.",
        "trans_Question": "ɪmǽdʒɪn júwr ə déjtə sájəntɪst æt ə hɛ́lθkɛ̀ər stɑ́rtʌ̀p, trájɪŋ tə prədɪ́kt háw lɔ́ŋ péjʃənts majt sərvájv ǽftər rəsíjvɪŋ tríjtmənt. wɪ́tʃ tɛkníjk wʊd juw juwz tə ǽnəlàjz ənd prədɪ́kt ðə əkspɛ́ktɪd tájm əntɪ́l ən əvɛ́nt (lájk dɛ́θ, rijlǽps, ɔr ənʌ́ðər sɪɡnɪ́fɪkənt əkɜ́rəns) əkɜ́rz?",
        "trans_RightAnswer": "sərvájvəl ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "klʌ́stər ənǽlɪsɪs",
            "əsòwsijéjʃən rúwl májnɪŋ",
            "rəɡrɛ́ʃən tríjz",
            "nʊ́rəl nɛ́twɜ̀rk klæ̀sɪfɪkéjʃən",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs"
        ],
        "trans_Explanation": "sərvájvəl ənǽlɪsɪs ɪz ə tájp əv stətɪ́stɪkəl ənd məʃíjn lɜ́rnɪŋ tɛkníjk júwzd wɛ́n juw wɒ́nt tə prədɪ́kt ðə tájm əntɪ́l ə pərtɪ́kjələr əvɛ́nt hǽpənz—lájk ðə tájm əntɪ́l péjʃənts ɡɛt sɪ́k, kʌ́stəmərz tʃɜ́rn, ɔr məkǽnɪkəl pɑ́rts féjl. ɪt ɪz vɛ́ərij kɒ́mənlij júwzd ɪn hɛ́lθkɛ̀ər tə fɔ́rkæ̀st péjʃənt sərvájvəl ənd tríjtmənt əfɛ́ktɪvnəs, bʌt ɪt's júwsfəl ɪn mɛ́nij ʌ́ðər fíjldz túw. ɪt spəsɪ́fɪklij hɛ́lps hǽndəl sənɛ́ərijowz wɛ́ər jɔr déjtə ɪnklúwdz 'sɛ́nsərd' ɒ̀bzərvéjʃənz—míjnɪŋ ðə əvɛ́nt hǽzənt əkɜ́rd jɛt dʊ́rɪŋ ðə pɪ́ərijəd əv stʌ́dij."
    },
    {
        "Question": "Which machine learning technique helps you estimate complex probabilities and explore parameter spaces by repeatedly sampling from a distribution, relying on sequences where each choice depends only on the previous one?",
        "RightAnswer": "Markov Chain Monte Carlo",
        "WrongAnswers": [
            "Gradient Descent",
            "Decision Tree Learning",
            "Support Vector Machine",
            "Linear Regression",
            "K-Means Clustering"
        ],
        "Explanation": "Markov Chain Monte Carlo (MCMC) is an engaging method used in machine learning and statistics to approximate complex probabilities and study difficult probability distributions. Instead of calculating a probability directly, MCMC generates random samples from a distribution by using a chain of steps, where each step depends only on the previous step (this is called the 'Markov' property). Over time, as more samples are collected, these samples allow you to estimate quantities and probabilities that would otherwise be very challenging or impossible to calculate analytically.",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk hɛ́lps juw ɛ́stɪmèjt kɒ́mplɛks prɒ̀bəbɪ́lɪtìjz ənd əksplɔ́r pərǽmətər spéjsɪz baj rəpíjtɪdlij sǽmplɪŋ frəm ə dɪ̀strəbjúwʃən, rəlájɪŋ ɒn síjkwənsɪz wɛ́ər ijtʃ tʃɔ́js dəpɛ́ndz ównlij ɒn ðə príjvijəs wʌ́n?",
        "trans_RightAnswer": "mɑ́rkowv tʃéjn mɒ́ntij kɑ́rlow",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt",
            "dəsɪ́ʒən tríj lɜ́rnɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "lɪ́nijər rəɡrɛ́ʃən",
            "k-míjnz klʌ́stərɪŋ"
        ],
        "trans_Explanation": "mɑ́rkowv tʃéjn mɒ́ntij kɑ́rlow (MCMC) ɪz ən ənɡéjdʒɪŋ mɛ́θəd júwzd ɪn məʃíjn lɜ́rnɪŋ ənd stətɪ́stɪks tə əprɒ́ksəmèjt kɒ́mplɛks prɒ̀bəbɪ́lɪtìjz ənd stʌ́dij dɪ́fɪkəlt prɒ̀bəbɪ́lɪtij dɪ̀strəbjúwʃənz. ɪnstɛ́d əv kǽlkjəlèjtɪŋ ə prɒ̀bəbɪ́lɪtij dɪərɛ́klij, MCMC dʒɛ́nərèjts rǽndəm sǽmpəlz frəm ə dɪ̀strəbjúwʃən baj júwzɪŋ ə tʃéjn əv stɛ́ps, wɛ́ər ijtʃ stɛ́p dəpɛ́ndz ównlij ɒn ðə príjvijəs stɛ́p (ðɪs ɪz kɔ́ld ðə 'mɑ́rkowv' prɒ́pərtij). ówvər tájm, æz mɔr sǽmpəlz ɑr kəlɛ́ktɪd, ðijz sǽmpəlz əláw juw tə ɛ́stɪmèjt kwɑ́ntᵻtijz ənd prɒ̀bəbɪ́lɪtìjz ðət wʊd ʌ́ðərwàjz bij vɛ́ərij tʃǽləndʒɪŋ ɔr ɪ̀mpɒ́sɪbəl tə kǽlkjəlèjt æ̀nəlɪ́tɪklij."
    },
    {
        "Question": "In machine learning, algorithms often need to adapt quickly and efficiently based on real-time information streams, adjusting their decisions continuously as each data point arrives one at a time. What's the term given to the method where the algorithm minimizes a convex loss function incrementally and updates its decision-making process without needing the entire dataset upfront?",
        "RightAnswer": "Online Convex Optimization",
        "WrongAnswers": [
            "Batch Gradient Descent",
            "Polynomial Regression",
            "Support Vector Clustering",
            "Offline Stochastic Optimization",
            "Kernel Density Estimation"
        ],
        "Explanation": "Online convex optimization is a versatile approach in machine learning, especially popular in scenarios where data arrives sequentially, like user clicks, financial transactions, or sensor readings. Instead of waiting for the entire dataset to be available, the algorithm incrementally updates its parameters or decisions each time a new piece of data comes in. The objective function being minimized is convex—meaning it has a single, well-defined minimum, making optimization reliable and efficient. This approach allows machine learning systems to adapt rapidly in dynamic, real-time environments.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, ǽlɡərɪ̀ðəmz ɔ́fən níjd tə ədǽpt kwɪ́klij ənd əfɪ́ʃəntlij béjst ɒn ríjəl-tájm ɪnfərméjʃən stríjmz, ədʒʌ́stɪŋ ðɛər dəsɪ́ʒənz kəntɪ́njuwəslij æz ijtʃ déjtə pɔ́jnt ərájvz wʌ́n æt ə tájm. wɒt's ðə tɜ́rm ɡɪ́vən tə ðə mɛ́θəd wɛ́ər ðə ǽlɡərɪ̀ðəm mɪ́nɪmàjzɪz ə kɒ́nvɛ̀ks lɔ́s fʌ́ŋkʃən ɪnkrəmɛ́ntəlìj ənd ʌ́pdèjts ɪts dəsɪ́ʒən-méjkɪŋ prɒ́sɛs wɪðáwt níjdɪŋ ðə əntájər déjtəsɛ̀t ʌ́pfrʌ̀nt?",
        "trans_RightAnswer": "ɔ́nlàjn kɒ́nvɛ̀ks ɒptɪmɪzéjʃən",
        "trans_WrongAnswers": [
            "bǽtʃ ɡréjdijənt dəsɛ́nt",
            "pɒ̀lijnówmijəl rəɡrɛ́ʃən",
            "səpɔ́rt vɛ́ktər klʌ́stərɪŋ",
            "ɔ́flàjn stowkǽstɪk ɒptɪmɪzéjʃən",
            "kɜ́rnəl dɛ́nsɪtij ɛ̀stɪméjʃən"
        ],
        "trans_Explanation": "ɔ́nlàjn kɒ́nvɛ̀ks ɒptɪmɪzéjʃən ɪz ə vɜ́rsətajl əprówtʃ ɪn məʃíjn lɜ́rnɪŋ, əspɛ́ʃəlij pɒ́pjələr ɪn sənɛ́ərijowz wɛ́ər déjtə ərájvz səkwɛ́nʃəlij, lájk júwzər klɪ́ks, fàjnǽnʃəl trænzǽkʃənz, ɔr sɛ́nsər ríjdɪŋz. ɪnstɛ́d əv wéjtɪŋ fɔr ðə əntájər déjtəsɛ̀t tə bij əvéjləbəl, ðə ǽlɡərɪ̀ðəm ɪnkrəmɛ́ntəlìj ʌ́pdèjts ɪts pərǽmətərz ɔr dəsɪ́ʒənz ijtʃ tájm ə núw píjs əv déjtə kʌ́mz ɪn. ðə əbdʒɛ́ktɪv fʌ́ŋkʃən bíjɪŋ mɪ́nɪmàjzd ɪz kɒ́nvɛ̀ks—míjnɪŋ ɪt həz ə sɪ́ŋɡəl, wɛ́l-dəfájnd mɪ́nɪməm, méjkɪŋ ɒptɪmɪzéjʃən rəlájəbəl ənd əfɪ́ʃənt. ðɪs əprówtʃ əláwz məʃíjn lɜ́rnɪŋ sɪ́stəmz tə ədǽpt rǽpɪdlij ɪn dajnǽmɪk, ríjəl-tájm ənvájərənmənts."
    },
    {
        "Question": "When visualizing how a machine learning model learns, researchers often picture a 3D surface showing peaks, valleys, and slopes. This visualization helps identify where the model might get 'stuck' or how smoothly it might find the best possible predictions. What is this helpful graphical representation commonly known as?",
        "RightAnswer": "Loss Landscape",
        "WrongAnswers": [
            "Gradient Pathway",
            "Optimization Terrain",
            "Error Elevation Map",
            "Prediction Topography",
            "Learning Depth Chart"
        ],
        "Explanation": "Think of training a machine learning model as a hiker exploring mountains and valleys. A 'Loss Landscape' visually represents this terrain, showing you areas where the model might struggle (like steep hills) or find the best solutions easily (like gentle valleys). The lower the point, the better your model is performing. This landscape helps researchers see where a model might get stuck and understand how smoothly it learns.",
        "trans_Question": "wɛ́n vɪ́ʒwəlàjzɪŋ háw ə məʃíjn lɜ́rnɪŋ mɒ́dəl lɜ́rnz, ríjsərtʃərz ɔ́fən pɪ́ktʃər ə 3D sɜ́rfəs ʃówɪŋ píjks, vǽlijz, ənd slówps. ðɪs vɪ̀ʒwəlɪzéjʃən hɛ́lps ajdɛ́ntɪfàj wɛ́ər ðə mɒ́dəl majt ɡɛt 'stʌ́k' ɔr háw smúwðlij ɪt majt fájnd ðə bɛ́st pɒ́sɪbəl prədɪ́kʃənz. wɒt ɪz ðɪs hɛ́lpfəl ɡrǽfɪkəl rɛ̀prəzɛntéjʃən kɒ́mənlij nówn æz?",
        "trans_RightAnswer": "lɔ́s lǽnskèjp",
        "trans_WrongAnswers": [
            "ɡréjdijənt pǽθwèj",
            "ɒptɪmɪzéjʃən təréjn",
            "ɛ́ərər ɛ̀ləvéjʃən mǽp",
            "prədɪ́kʃən təpɒ́ɡrəfij",
            "lɜ́rnɪŋ dɛ́pθ tʃɑ́rt"
        ],
        "trans_Explanation": "θɪ́ŋk əv tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl æz ə hájkər əksplɔ́rɪŋ máwntənz ənd vǽlijz. ə 'lɔ́s lǽnskèjp' vɪ́ʒwəlij rɛ̀prəzɛ́nts ðɪs təréjn, ʃówɪŋ juw ɛ́ərijəz wɛ́ər ðə mɒ́dəl majt strʌ́ɡəl (lájk stíjp hɪ́lz) ɔr fájnd ðə bɛ́st səlúwʃənz íjzəlij (lájk dʒɛ́ntəl vǽlijz). ðə lówər ðə pɔ́jnt, ðə bɛ́tər jɔr mɒ́dəl ɪz pərfɔ́rmɪŋ. ðɪs lǽnskèjp hɛ́lps ríjsərtʃərz síj wɛ́ər ə mɒ́dəl majt ɡɛt stʌ́k ənd ʌ̀ndərstǽnd háw smúwðlij ɪt lɜ́rnz."
    },
    {
        "Question": "In machine learning, what approach involves training models by gradually presenting them with increasingly complex tasks, similar to how humans learn step-by-step?",
        "RightAnswer": "Curriculum Learning",
        "WrongAnswers": [
            "Transfer Learning",
            "Reinforcement Learning",
            "Supervised Learning",
            "Incremental Learning",
            "Meta Learning"
        ],
        "Explanation": "Curriculum Learning is an approach that mirrors how humans learn. Imagine teaching a child math: you start with basic concepts, then progress to harder topics as their understanding grows. Similarly, curriculum learning trains machine learning algorithms by initially presenting easier problems, gradually increasing the difficulty level, which can help models learn faster and achieve better performance.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt əprówtʃ ɪnvɒ́lvz tréjnɪŋ mɒ́dəlz baj ɡrǽdʒuwəlij prəzɛ́ntɪŋ ðɛm wɪð ɪnkríjsɪŋɡlij kɒ́mplɛks tǽsks, sɪ́mɪlər tə háw hjúwmənz lɜ́rn stɛ́p-baj-stɛ́p?",
        "trans_RightAnswer": "kərɪ́kjələm lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "trǽnsfər lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "ɪnkrəmɛ́ntəl lɜ́rnɪŋ",
            "mɛ́tə lɜ́rnɪŋ"
        ],
        "trans_Explanation": "kərɪ́kjələm lɜ́rnɪŋ ɪz ən əprówtʃ ðət mɪ́ərərz háw hjúwmənz lɜ́rn. ɪmǽdʒɪn tíjtʃɪŋ ə tʃájld mǽθ: juw stɑ́rt wɪð béjsɪk kɒ́nsɛpts, ðɛn prɒ́ɡrɛ̀s tə hɑ́rdər tɒ́pɪks æz ðɛər ʌ̀ndərstǽndɪŋ ɡrówz. sɪ́mɪlərlij, kərɪ́kjələm lɜ́rnɪŋ tréjnz məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəmz baj ɪnɪ́ʃəlij prəzɛ́ntɪŋ íjzijər prɒ́bləmz, ɡrǽdʒuwəlij ɪnkríjsɪŋ ðə dɪ́fɪkəltij lɛ́vəl, wɪ́tʃ kən hɛ́lp mɒ́dəlz lɜ́rn fǽstər ənd ətʃíjv bɛ́tər pərfɔ́rməns."
    },
    {
        "Question": "In machine learning, sometimes we have multiple types of data or representations available about the same thing, like images taken from different angles, different sensor data, or text descriptions alongside images. Which learning approach specifically aims to combine these different 'perspectives' or data views to improve learning accuracy and robustness?",
        "RightAnswer": "Multi-View Learning",
        "WrongAnswers": [
            "Transfer Learning",
            "Ensemble Learning",
            "Reinforcement Learning",
            "Semi-Supervised Learning",
            "Meta-Learning"
        ],
        "Explanation": "Multi-View Learning is a special approach in machine learning that uses different sources or perspectives of information—think of it like watching an event from multiple cameras—to better understand or predict results. By exploring these diverse viewpoints (data from different sensors, text and image data together, or different representations of the same information), Multi-View Learning creates a more accurate and reliable understanding than might be possible with just one perspective alone!",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, sʌ́mtàjmz wij həv mʌ́ltɪpəl tájps əv déjtə ɔr rɛ̀prəzəntéjʃənz əvéjləbəl əbawt ðə séjm θɪ́ŋ, lájk ɪ́mɪdʒɪz téjkən frəm dɪ́fərənt ǽŋɡəlz, dɪ́fərənt sɛ́nsər déjtə, ɔr tɛ́kst dəskrɪ́pʃənz əlɔ́ŋsájd ɪ́mɪdʒɪz. wɪ́tʃ lɜ́rnɪŋ əprówtʃ spəsɪ́fɪklij éjmz tə kɒ́mbajn ðijz dɪ́fərənt 'pərspɛ́ktɪvz' ɔr déjtə vjúwz tə ɪmprúwv lɜ́rnɪŋ ǽkjərəsij ənd rowbʌ́stnəs?",
        "trans_RightAnswer": "mʌ́ltij-vjúw lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "trǽnsfər lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
            "mɛ́tə-lɜ́rnɪŋ"
        ],
        "trans_Explanation": "mʌ́ltij-vjúw lɜ́rnɪŋ ɪz ə spɛ́ʃəl əprówtʃ ɪn məʃíjn lɜ́rnɪŋ ðət júwsɪz dɪ́fərənt sɔ́rsɪz ɔr pərspɛ́ktɪvz əv ɪnfərméjʃən—θɪ́ŋk əv ɪt lájk wɒ́tʃɪŋ ən əvɛ́nt frəm mʌ́ltɪpəl kǽmərəz—tə bɛ́tər ʌ̀ndərstǽnd ɔr prədɪ́kt rəzʌ́lts. baj əksplɔ́rɪŋ ðijz dajvɜ́rs vjúwpɔ̀jnts (déjtə frəm dɪ́fərənt sɛ́nsərz, tɛ́kst ənd ɪ́mɪdʒ déjtə təɡɛ́ðər, ɔr dɪ́fərənt rɛ̀prəzəntéjʃənz əv ðə séjm ɪnfərméjʃən), mʌ́ltij-vjúw lɜ́rnɪŋ krijéjts ə mɔr ǽkjərət ənd rəlájəbəl ʌ̀ndərstǽndɪŋ ðʌn majt bij pɒ́sɪbəl wɪð dʒəst wʌ́n pərspɛ́ktɪv əlówn!"
    },
    {
        "Question": "Imagine you have a limited amount of labeled data and a lot of unlabeled data. Which machine learning approach starts by training on the limited labeled data, then gradually labels more data itself based on its own confidence, effectively teaching itself to become smarter step by step?",
        "RightAnswer": "Self-Training",
        "WrongAnswers": [
            "Reinforcement Learning",
            "Ensemble Learning",
            "Supervised Learning",
            "Transfer Learning",
            "Active Learning"
        ],
        "Explanation": "Self-training is a semi-supervised learning approach in machine learning where the algorithm initially learns from a small amount of labeled data. It then gradually labels unlabeled examples it feels most confident about, retrains itself with this larger set, and repeats the process, thus effectively 'teaching itself'. It's an iterative process that leverages the model's own predictions to continually get better.",
        "trans_Question": "ɪmǽdʒɪn juw həv ə lɪ́mɪtɪd əmáwnt əv léjbəld déjtə ənd ə lɒ́t əv ʌ̀nléjbəld déjtə. wɪ́tʃ məʃíjn lɜ́rnɪŋ əprówtʃ stɑ́rts baj tréjnɪŋ ɒn ðə lɪ́mɪtɪd léjbəld déjtə, ðɛn ɡrǽdʒuwəlij léjbəlz mɔr déjtə ɪtsɛ́lf béjst ɒn ɪts ówn kɒ́nfɪdəns, əfɛ́ktɪvlij tíjtʃɪŋ ɪtsɛ́lf tə bəkʌ́m smɑ́rtər stɛ́p baj stɛ́p?",
        "trans_RightAnswer": "sɛ́lf-tréjnɪŋ",
        "trans_WrongAnswers": [
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ",
            "ɒnsɒ́mbəl lɜ́rnɪŋ",
            "súwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "ǽktɪv lɜ́rnɪŋ"
        ],
        "trans_Explanation": "sɛ́lf-tréjnɪŋ ɪz ə sɛ́maj-súwpərvàjzd lɜ́rnɪŋ əprówtʃ ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ðə ǽlɡərɪ̀ðəm ɪnɪ́ʃəlij lɜ́rnz frəm ə smɔ́l əmáwnt əv léjbəld déjtə. ɪt ðɛn ɡrǽdʒuwəlij léjbəlz ʌ̀nléjbəld əɡzǽmpəlz ɪt fíjlz mówst kɒ́nfɪdənt əbawt, rijtréjnz ɪtsɛ́lf wɪð ðɪs lɑ́rdʒər sɛ́t, ənd rəpíjts ðə prɒ́sɛs, ðʌs əfɛ́ktɪvlij 'tíjtʃɪŋ ɪtsɛ́lf'. ɪt's ən ɪ́tərətɪv prɒ́sɛs ðət lɛ́vərɪdʒɪz ðə mɒ́dəl'z ówn prədɪ́kʃənz tə kəntɪ́njuwəlij ɡɛt bɛ́tər."
    },
    {
        "Question": "Imagine you've built a machine learning model to predict weather conditions, and it often says it's 90% sure of sunny weather—but in reality, it's sunny only about 60% of those times. What concept refers to aligning the model's predicted certainty with the real outcomes?",
        "RightAnswer": "Confidence Calibration",
        "WrongAnswers": [
            "Hyperparameter Tuning",
            "Bias-Variance Tradeoff",
            "Loss Function Adjustment",
            "Feature Scaling",
            "Regularization Technique"
        ],
        "Explanation": "Confidence Calibration is like teaching your model to be more honest with itself. It ensures that when it tells you 'I'm 90% sure', events actually happen about 90% of the time. In other words, it's making sure the model's confidence levels accurately match the likelihood that predictions are correct, leading to better trust and decision-making.",
        "trans_Question": "ɪmǽdʒɪn júwv bɪ́lt ə məʃíjn lɜ́rnɪŋ mɒ́dəl tə prədɪ́kt wɛ́ðər kəndɪ́ʃənz, ənd ɪt ɔ́fən sɛ́z ɪt's 90% ʃʊ́r əv sʌ́nij wɛ́ðər—bʌt ɪn rìjǽlɪtij, ɪt's sʌ́nij ównlij əbawt 60% əv ðowz tájmz. wɒt kɒ́nsɛpt rəfɜ́rz tə əlájnɪŋ ðə mɒ́dəl'z prədɪ́ktɪd sɜ́rtəntij wɪð ðə ríjəl áwtkʌ̀mz?",
        "trans_RightAnswer": "kɒ́nfɪdəns kæ̀ləbréjʃən",
        "trans_WrongAnswers": [
            "hàjpərpǽrəmətər túwnɪŋ",
            "bájəs-vɛ́ərijəns tréjdɔ̀f",
            "lɔ́s fʌ́ŋkʃən ədʒʌ́stmənt",
            "fíjtʃər skéjlɪŋ",
            "rèɡjəlɛ̀ərɪzéjʃən tɛkníjk"
        ],
        "trans_Explanation": "kɒ́nfɪdəns kæ̀ləbréjʃən ɪz lájk tíjtʃɪŋ jɔr mɒ́dəl tə bij mɔr ɒ́nəst wɪð ɪtsɛ́lf. ɪt ənʃʊ́rz ðət wɛ́n ɪt tɛ́lz juw 'ájm 90% ʃʊ́r', əvɛ́nts ǽktʃùwəlij hǽpən əbawt 90% əv ðə tájm. ɪn ʌ́ðər wɜ́rdz, ɪt's méjkɪŋ ʃʊ́r ðə mɒ́dəl'z kɒ́nfɪdəns lɛ́vəlz ǽkjərətlij mǽtʃ ðə lájklijhʊ̀d ðət prədɪ́kʃənz ɑr kərɛ́kt, líjdɪŋ tə bɛ́tər trʌ́st ənd dəsɪ́ʒən-méjkɪŋ."
    },
    {
        "Question": "In machine learning, sometimes the labeled examples used during training can contain mistakes or inaccuracies. When a model is intentionally designed or adjusted to cope effectively with these incorrect or inaccurate labels, what do we call this approach?",
        "RightAnswer": "Learning with Noisy Labels",
        "WrongAnswers": [
            "Unsupervised Learning",
            "Transfer Learning",
            "Semi-supervised Learning",
            "Active Learning",
            "Reinforcement Learning"
        ],
        "Explanation": "Learning with Noisy Labels refers to techniques in machine learning designed to handle situations where training data isn't perfectly labeled—meaning there are errors or noise in the labels. Since real-world data is rarely perfect, these methods aim to help models learn effectively, even if some labels are incorrect or misleading.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, sʌ́mtàjmz ðə léjbəld əɡzǽmpəlz júwzd dʊ́rɪŋ tréjnɪŋ kən kəntéjn mɪstéjks ɔr ɪ̀nǽkjəræ̀sijz. wɛ́n ə mɒ́dəl ɪz ɪntɛ́nʃənəlij dəzájnd ɔr ədʒʌ́stɪd tə kówp əfɛ́ktɪvlij wɪð ðijz ɪ̀nkərɛ́kt ɔr ɪ̀nǽkjərət léjbəlz, wɒt dúw wij kɔ́l ðɪs əprówtʃ?",
        "trans_RightAnswer": "lɜ́rnɪŋ wɪð nɔ́jzij léjbəlz",
        "trans_WrongAnswers": [
            "ʌ̀nsúwpərvàjzd lɜ́rnɪŋ",
            "trǽnsfər lɜ́rnɪŋ",
            "sɛ́maj-súwpərvàjzd lɜ́rnɪŋ",
            "ǽktɪv lɜ́rnɪŋ",
            "rìjɪnfɔ́rsmənt lɜ́rnɪŋ"
        ],
        "trans_Explanation": "lɜ́rnɪŋ wɪð nɔ́jzij léjbəlz rəfɜ́rz tə tɛkníjks ɪn məʃíjn lɜ́rnɪŋ dəzájnd tə hǽndəl sɪ̀tʃuwéjʃənz wɛ́ər tréjnɪŋ déjtə ɪzənt pɜ́rfəktlij léjbəld—míjnɪŋ ðɛər ɑr ɛ́ərərz ɔr nɔ́jz ɪn ðə léjbəlz. sɪns ríjəl-wɜ́rld déjtə ɪz rɛ́ərlij pɜ́rfəkt, ðijz mɛ́θədz éjm tə hɛ́lp mɒ́dəlz lɜ́rn əfɛ́ktɪvlij, íjvən ɪf sʌm léjbəlz ɑr ɪ̀nkərɛ́kt ɔr mɪ̀slíjdɪŋ."
    },
    {
        "Question": "In machine learning, to help a neural network generalize better and avoid becoming overly confident, we sometimes slightly 'soften' the correct classifications. What's this approach called?",
        "RightAnswer": "Label Smoothing",
        "WrongAnswers": [
            "Early Stopping",
            "Batch Normalization",
            "Gradient Clipping",
            "Dropout",
            "Data Augmentation"
        ],
        "Explanation": "Label smoothing is a clever trick used in machine learning to gently discourage a neural network from becoming overly confident in its predictions. Rather than assigning 100% confidence in one right category, label smoothing gives a small amount of trust to the 'wrong' labels as well. This subtle adjustment encourages the network to be more cautious, helps prevent overfitting, and often leads to better generalization on unseen data.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, tə hɛ́lp ə nʊ́rəl nɛ́twɜ̀rk dʒɛ́nərəlàjz bɛ́tər ənd əvɔ́jd bəkʌ́mɪŋ ówvərlij kɒ́nfɪdənt, wij sʌ́mtàjmz slájtlij 'sɒ́fən' ðə kərɛ́kt klæ̀sɪfɪkéjʃənz. wɒt's ðɪs əprówtʃ kɔ́ld?",
        "trans_RightAnswer": "léjbəl smúwðɪŋ",
        "trans_WrongAnswers": [
            "ɜ́rlij stɒ́pɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "ɡréjdijənt klɪ́pɪŋ",
            "drɒ́pàwt",
            "déjtə ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "léjbəl smúwðɪŋ ɪz ə klɛ́vər trɪ́k júwzd ɪn məʃíjn lɜ́rnɪŋ tə dʒɛ́ntlij dɪskɜ́rɪdʒ ə nʊ́rəl nɛ́twɜ̀rk frəm bəkʌ́mɪŋ ówvərlij kɒ́nfɪdənt ɪn ɪts prədɪ́kʃənz. rǽðər ðʌn əsájnɪŋ 100% kɒ́nfɪdəns ɪn wʌ́n rájt kǽtəɡɔ̀rij, léjbəl smúwðɪŋ ɡɪ́vz ə smɔ́l əmáwnt əv trʌ́st tə ðə 'rɔ́ŋ' léjbəlz æz wɛ́l. ðɪs sʌ́təl ədʒʌ́stmənt ənkɜ́rɪdʒɪz ðə nɛ́twɜ̀rk tə bij mɔr kɔ́ʃəs, hɛ́lps prəvɛ́nt òwvərfɪ́tɪŋ, ənd ɔ́fən líjdz tə bɛ́tər dʒɛ̀nərəlɪzéjʃən ɒn ʌ̀nsíjn déjtə."
    },
    {
        "Question": "When you're training a lightweight, simple machine learning model to imitate the performance of a larger, more complicated one—allowing quick predictions without losing too much accuracy—which term describes this process?",
        "RightAnswer": "Distillation",
        "WrongAnswers": [
            "Regularization",
            "Fine-tuning",
            "Feature extraction",
            "Cross-validation",
            "Augmentation"
        ],
        "Explanation": "Distillation in machine learning is like teaching a capable apprentice the key skills of an experienced master. Here, a simpler, smaller model (the apprentice) learns the insights and knowledge from a larger, complex model (the master). This makes the smaller model faster and more efficient, without significantly sacrificing accuracy.",
        "trans_Question": "wɛ́n júwr tréjnɪŋ ə lájtwéjt, sɪ́mpəl məʃíjn lɜ́rnɪŋ mɒ́dəl tə ɪ́mɪtèjt ðə pərfɔ́rməns əv ə lɑ́rdʒər, mɔr kɒ́mplɪkèjtɪd wʌ́n—əláwɪŋ kwɪ́k prədɪ́kʃənz wɪðáwt lúwzɪŋ túw mʌtʃ ǽkjərəsij—wɪ́tʃ tɜ́rm dəskrájbz ðɪs prɒ́sɛs?",
        "trans_RightAnswer": "dɪ̀stɪléjʃən",
        "trans_WrongAnswers": [
            "rèɡjəlɛ̀ərɪzéjʃən",
            "fájn-túwnɪŋ",
            "fíjtʃər əkstrǽkʃən",
            "krɔ́s-væ̀lɪdéjʃən",
            "ɒ̀ɡmɛntéjʃən"
        ],
        "trans_Explanation": "dɪ̀stɪléjʃən ɪn məʃíjn lɜ́rnɪŋ ɪz lájk tíjtʃɪŋ ə kéjpəbəl əprɛ́ntɪs ðə kíj skɪ́lz əv ən əkspɪ́ərijənst mǽstər. hɪər, ə sɪ́mplər, smɔ́lər mɒ́dəl (ðə əprɛ́ntɪs) lɜ́rnz ðə ɪ́nsàjts ənd nɒ́lɪdʒ frəm ə lɑ́rdʒər, kɒ́mplɛks mɒ́dəl (ðə mǽstər). ðɪs méjks ðə smɔ́lər mɒ́dəl fǽstər ənd mɔr əfɪ́ʃənt, wɪðáwt sɪɡnɪ́fɪkəntlij sǽkrɪfàjsɪŋ ǽkjərəsij."
    },
    {
        "Question": "Machine learning models can sometimes be large and slow, making them tough to use on devices with limited storage or processing power, like smartphones. What's the name for the process of reducing the size of these models while maintaining most of their original performance?",
        "RightAnswer": "Model Compression",
        "WrongAnswers": [
            "Feature Extraction",
            "Model Augmentation",
            "Gradient Boosting",
            "Hyperparameter Tuning",
            "Data Normalization"
        ],
        "Explanation": "Model compression is like packing your suitcase more efficiently—you remove unnecessary items (simplify the model) or fold them cleverly (optimize it) so that the machine learning model becomes smaller and faster. This technique makes powerful AI models accessible on smaller or less powerful devices without greatly sacrificing their performance. Think of it as shrinking down something complicated, without losing its core abilities.",
        "trans_Question": "məʃíjn lɜ́rnɪŋ mɒ́dəlz kən sʌ́mtàjmz bij lɑ́rdʒ ənd slów, méjkɪŋ ðɛm tʌ́f tə juwz ɒn dəvájsɪz wɪð lɪ́mɪtɪd stɔ́rɪdʒ ɔr prɒ́sɛsɪŋ páwər, lájk smɑ́rtfòwnz. wɒt's ðə néjm fɔr ðə prɒ́sɛs əv rədjúwsɪŋ ðə sájz əv ðijz mɒ́dəlz wájl mejntéjnɪŋ mówst əv ðɛər ərɪ́dʒɪnəl pərfɔ́rməns?",
        "trans_RightAnswer": "mɒ́dəl kəmprɛ́ʃən",
        "trans_WrongAnswers": [
            "fíjtʃər əkstrǽkʃən",
            "mɒ́dəl ɒ̀ɡmɛntéjʃən",
            "ɡréjdijənt búwstɪŋ",
            "hàjpərpǽrəmətər túwnɪŋ",
            "déjtə nɔ̀rməlɪzéjʃən"
        ],
        "trans_Explanation": "mɒ́dəl kəmprɛ́ʃən ɪz lájk pǽkɪŋ jɔr súwtkèjs mɔr əfɪ́ʃəntlij—juw rijmúwv ʌ̀nnɛ́səsɛ̀ərij ájtəmz (sɪ́mpləfaj ðə mɒ́dəl) ɔr fówld ðɛm klɛ́vərlij (ɒ́ptɪmàjz ɪt) sow ðət ðə məʃíjn lɜ́rnɪŋ mɒ́dəl bəkʌ́mz smɔ́lər ənd fǽstər. ðɪs tɛkníjk méjks páwərfəl AI mɒ́dəlz æksɛ́sɪbəl ɒn smɔ́lər ɔr lɛ́s páwərfəl dəvájsɪz wɪðáwt ɡréjtlij sǽkrɪfàjsɪŋ ðɛər pərfɔ́rməns. θɪ́ŋk əv ɪt æz ʃrɪ́ŋkɪŋ dawn sʌ́mθɪŋ kɒ́mplɪkèjtɪd, wɪðáwt lúwzɪŋ ɪts kɔ́r əbɪ́lɪtìjz."
    },
    {
        "Question": "In machine learning, when analysts want to summarize and describe datasets to decide which models might perform best, they often use certain characteristics such as the number of features, data distributions, or statistical properties. What are these descriptive characteristics called?",
        "RightAnswer": "Meta-Features",
        "WrongAnswers": [
            "Hyperparameters",
            "Decision Boundaries",
            "Feature Embeddings",
            "Gradient Descent",
            "Feature Engineering"
        ],
        "Explanation": "Meta-features are high-level descriptions that summarize a dataset's characteristics, such as the number of samples, dimensionality, distributions, and statistical properties. They're kind of like quick 'snapshots' or summaries of the data that help machine learning practitioners understand how different models might interact with the dataset. Using meta-features can make it easier to choose the most effective model or approach for the particular data at hand.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɛ́n ǽnəlɪsts wɒ́nt tə sʌ́məràjz ənd dəskrájb déjtəsɛ̀ts tə dəsájd wɪ́tʃ mɒ́dəlz majt pərfɔ́rm bɛ́st, ðej ɔ́fən juwz sɜ́rtən kæ̀rəktərɪ́stɪks sʌtʃ æz ðə nʌ́mbər əv fíjtʃərz, déjtə dɪ̀strəbjúwʃənz, ɔr stətɪ́stɪkəl prɒ́pərtijz. wɒt ɑr ðijz dəskrɪ́ptɪv kæ̀rəktərɪ́stɪks kɔ́ld?",
        "trans_RightAnswer": "mɛ́tə-fíjtʃərz",
        "trans_WrongAnswers": [
            "hàjpərpǽrəmətərz",
            "dəsɪ́ʒən báwndərijz",
            "fíjtʃər əmbɛ́dɪŋz",
            "ɡréjdijənt dəsɛ́nt",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ"
        ],
        "trans_Explanation": "mɛ́tə-fíjtʃərz ɑr háj-lɛ́vəl dəskrɪ́pʃənz ðət sʌ́məràjz ə déjtəsɛ̀t's kæ̀rəktərɪ́stɪks, sʌtʃ æz ðə nʌ́mbər əv sǽmpəlz, dajmɛ̀nʃənǽlɪtij, dɪ̀strəbjúwʃənz, ənd stətɪ́stɪkəl prɒ́pərtijz. ðɛ́ər kájnd əv lájk kwɪ́k 'snǽpʃɒ̀ts' ɔr sʌ́mərijz əv ðə déjtə ðət hɛ́lp məʃíjn lɜ́rnɪŋ præktɪ́ʃənərz ʌ̀ndərstǽnd háw dɪ́fərənt mɒ́dəlz majt ɪ̀ntərǽkt wɪð ðə déjtəsɛ̀t. júwzɪŋ mɛ́tə-fíjtʃərz kən méjk ɪt íjzijər tə tʃúwz ðə mówst əféktɪv mɒ́dəl ɔr əprówtʃ fɔr ðə pərtɪ́kjələr déjtə æt hǽnd."
    },
    {
        "Question": "In machine learning, what term describes efforts to ensure models avoid biases and treat people fairly, without discriminating against specific groups or individuals?",
        "RightAnswer": "Algorithmic Fairness",
        "WrongAnswers": [
            "Predictive Optimization",
            "Data Normalization",
            "Model Parallelism",
            "Feature Engineering",
            "Gradient Descent"
        ],
        "Explanation": "Algorithmic fairness is all about making sure that machine learning models don't unfairly favor or discriminate against individuals or groups based on sensitive factors such as race, gender, or ethnicity. The goal is to build algorithms that give every person a fair opportunity and avoid biases caused by imbalanced or biased training data. Fundamentally, algorithmic fairness helps ensure ML systems make decisions that are equitable and ethical.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɒt tɜ́rm dəskrájbz ɛ́fərts tə ənʃʊ́r mɒ́dəlz əvɔ́jd bájəsɪz ənd tríjt píjpəl fɛ́ərlij, wɪðáwt dɪskrɪ́mɪnèjtɪŋ əɡéjnst spəsɪ́fɪk ɡrúwps ɔr ɪndɪvɪ́dʒəwəlz?",
        "trans_RightAnswer": "ǽlɡərɪ̀ðəmɪk fɛ́ərnəs",
        "trans_WrongAnswers": [
            "prədɪ́ktɪv ɒptɪmɪzéjʃən",
            "déjtə nɔ̀rməlɪzéjʃən",
            "mɒ́dəl pǽrəlɛ̀lɪ̀zəm",
            "fíjtʃər ɛ̀ndʒɪnɪ́ərɪŋ",
            "ɡréjdijənt dəsɛ́nt"
        ],
        "trans_Explanation": "ǽlɡərɪ̀ðəmɪk fɛ́ərnəs ɪz ɔl əbawt méjkɪŋ ʃʊ́r ðət məʃíjn lɜ́rnɪŋ mɒ́dəlz dównt ʌ̀nfɛ́ərlij féjvər ɔr dɪskrɪ́mɪnèjt əɡéjnst ɪndɪvɪ́dʒəwəlz ɔr ɡrúwps béjst ɒn sɛ́nsɪtɪv fǽktərz sʌtʃ æz réjs, dʒɛ́ndər, ɔr ɛθnɪ́sɪtij. ðə ɡówl ɪz tə bɪ́ld ǽlɡərɪ̀ðəmz ðət ɡɪ́v ɛvərij pɜ́rsən ə fɛ́ər ɒ̀pərtúwnɪtij ənd əvɔ́jd bájəsɪz kɒ́zd baj ɪmbǽlənst ɔr bájəst tréjnɪŋ déjtə. fʌ̀ndəmɛ́ntəlij, ǽlɡərɪ̀ðəmɪk fɛ́ərnəs hɛ́lps ənʃʊ́r ML sɪ́stəmz méjk dəsɪ́ʒənz ðət ɑr ɛ́kwɪtəbəl ənd ɛ́θɪkəl."
    },
    {
        "Question": "What do we call the process of actively identifying and reducing unfair or prejudiced outcomes in machine learning systems, to help models treat all individuals more fairly?",
        "RightAnswer": "Bias Mitigation",
        "WrongAnswers": [
            "Model Optimization",
            "Feature Selection",
            "Data Augmentation",
            "Algorithm Calibration",
            "Regularization"
        ],
        "Explanation": "Bias mitigation in machine learning means actively looking for and reducing unfairness or prejudice in AI models. It helps ensure that these models don't negatively affect or discriminate against certain groups of people, aiming for fairness and equal treatment for everyone involved.",
        "trans_Question": "wɒt dúw wij kɔ́l ðə prɒ́sɛs əv ǽktɪvlij ajdɛ́ntɪfàjɪŋ ənd rədjúwsɪŋ ʌ́nfɛ́ər ɔr prɛ́dʒədɪst áwtkʌ̀mz ɪn məʃíjn lɜ́rnɪŋ sɪ́stəmz, tə hɛ́lp mɒ́dəlz tríjt ɔl ɪndɪvɪ́dʒəwəlz mɔr fɛ́ərlij?",
        "trans_RightAnswer": "bájəs mɪ̀tɪɡéjʃən",
        "trans_WrongAnswers": [
            "mɒ́dəl ɒptɪmɪzéjʃən",
            "fíjtʃər səlɛ́kʃən",
            "déjtə ɒ̀ɡmɛntéjʃən",
            "ǽlɡərɪ̀ðəm kæ̀ləbréjʃən",
            "rèɡjəlɛ̀ərɪzéjʃən"
        ],
        "trans_Explanation": "bájəs mɪ̀tɪɡéjʃən ɪn məʃíjn lɜ́rnɪŋ míjnz ǽktɪvlij lʊ́kɪŋ fɔr ənd rədjúwsɪŋ ʌ̀nfɛ́ərnəs ɔr prɛ́dʒədɪs ɪn AI mɒ́dəlz. ɪt hɛ́lps ənʃʊ́r ðət ðijz mɒ́dəlz dównt nɛ́ɡətɪvlij əfɛ́kt ɔr dɪskrɪ́mɪnèjt əɡéjnst sɜ́rtən ɡrúwps əv píjpəl, éjmɪŋ fɔr fɛ́ərnəs ənd íjkwəl tríjtmənt fɔr ɛ́vrijwʌ̀n ɪnvɒ́lvd."
    },
    {
        "Question": "What term describes ensuring that a machine learning system makes unbiased decisions, treating individuals fairly regardless of sensitive attributes like ethnicity, gender, or age?",
        "RightAnswer": "Model Fairness",
        "WrongAnswers": [
            "Model Complexity",
            "Data Leakage",
            "Feature Importance",
            "Dimensionality Reduction",
            "Overfitting"
        ],
        "Explanation": "Model fairness means making sure that machine learning models aren't biased against any specific group of people. It's about guaranteeing that decisions made by algorithms, such as loan approvals or hiring processes, are fair and unbiased, regardless of factors like race, gender, or age. Essentially, it's about ensuring equal treatment and opportunity through technology.",
        "trans_Question": "wɒt tɜ́rm dəskrájbz ɛnʃʊ́rɪŋ ðət ə məʃíjn lɜ́rnɪŋ sɪ́stəm méjks ʌ̀nbájəst dəsɪ́ʒənz, tríjtɪŋ ɪndɪvɪ́dʒəwəlz fɛ́ərlij rəɡɑ́rdləs əv sɛ́nsɪtɪv ǽtrəbjùwts lájk ɛθnɪ́sɪtij, dʒɛ́ndər, ɔr éjdʒ?",
        "trans_RightAnswer": "mɒ́dəl fɛ́ərnəs",
        "trans_WrongAnswers": [
            "mɒ́dəl kəmplɛ́ksɪtij",
            "déjtə líjkɪdʒ",
            "fíjtʃər ɪmpɔ́rtəns",
            "dajmɛ̀nʃənǽlɪtij rədʌ́kʃən",
            "òwvərfɪ́tɪŋ"
        ],
        "trans_Explanation": "mɒ́dəl fɛ́ərnəs míjnz méjkɪŋ ʃʊ́r ðət məʃíjn lɜ́rnɪŋ mɒ́dəlz ɑrənt bájəst əɡéjnst ɛ́nij spəsɪ́fɪk ɡrúwp əv píjpəl. ɪt's əbawt ɡɛ̀ərəntíjɪŋ ðət dəsɪ́ʒənz méjd baj ǽlɡərɪ̀ðəmz, sʌtʃ æz lówn əprúwvəlz ɔr hájərɪŋ prɒ́sɛsɪz, ɑr fɛ́ər ənd ʌ̀nbájəst, rəɡɑ́rdləs əv fǽktərz lájk réjs, dʒɛ́ndər, ɔr éjdʒ. əsɛ́nʃəlij, ɪt's əbawt ɛnʃʊ́rɪŋ íjkwəl tríjtmənt ənd ɒ̀pərtúwnɪtij θrúw tɛknɒ́lədʒij."
    },
    {
        "Question": "What term describes the practice of designing and using artificial intelligence systems in ways that respect human values, fairness, and transparency, and aim to reduce bias and harm?",
        "RightAnswer": "Ethical AI",
        "WrongAnswers": [
            "Quantum AI",
            "Neural Networking",
            "AI Optimization",
            "Predictive Analytics",
            "Data Mining"
        ],
        "Explanation": "\"Ethical AI\" refers to the thoughtful and responsible development of artificial intelligence technologies, ensuring they align with human values and ethics. It involves actively working to minimize biases, maintain transparency, and protect people's rights, prioritizing fairness and accountability in AI systems.",
        "trans_Question": "wɒt tɜ́rm dəskrájbz ðə prǽktɪs əv dəzájnɪŋ ənd júwzɪŋ ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns sɪ́stəmz ɪn wéjz ðət rəspɛ́kt hjúwmən vǽljuwz, fɛ́ərnəs, ənd trænspɛ́ərənsij, ənd éjm tə rədjúws bájəs ənd hɑ́rm?",
        "trans_RightAnswer": "ɛ́θɪkəl AI",
        "trans_WrongAnswers": [
            "kwɑ́ntəm AI",
            "nʊ́rəl nɛ́twɜ̀rkɪŋ",
            "AI ɒptɪmɪzéjʃən",
            "prədɪ́ktɪv æ̀nəlɪ́tɪks",
            "déjtə májnɪŋ"
        ],
        "trans_Explanation": "\"ɛ́θɪkəl AI\" rəfɜ́rz tə ðə θɔ́tfəl ənd rəspɒ́nsɪbəl dəvɛ́ləpmənt əv ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns tɛknɒ́lədʒijz, ɛnʃʊ́rɪŋ ðej əlájn wɪð hjúwmən vǽljuwz ənd ɛ́θɪks. ɪt ɪnvɒ́lvz ǽktɪvlij wɜ́rkɪŋ tə mɪ́nɪmàjz bájəsɪz, mejntéjn trænspɛ́ərənsij, ənd prətɛ́kt píjpəl'z rájts, prajɔ́rɪtajzɪŋ fɛ́ərnəs ənd əkàwntəbɪ́lɪtij ɪn AI sɪ́stəmz."
    },
    {
        "Question": "What term best describes the strategies, rules, and practices organizations put in place to ensure their artificial intelligence systems are responsible, ethical, and aligned with societal values?",
        "RightAnswer": "AI Governance",
        "WrongAnswers": [
            "Machine Learning Optimization",
            "Predictive Analytics",
            "Data Engineering",
            "Algorithmic Efficiency",
            "Neural Network Training"
        ],
        "Explanation": "AI Governance refers to the set of policies, guidelines, and frameworks organizations implement to oversee their artificial intelligence systems. The goal is to ensure that AI technologies operate ethically, responsibly, transparently, and in ways that align with broader societal norms and regulations. Good AI Governance protects against unintended harm, promotes trust among users, and encourages ethical innovation.",
        "trans_Question": "wɒt tɜ́rm bɛ́st dəskrájbz ðə strǽtədʒijz, rúwlz, ənd prǽktɪsɪz ɔ̀rɡənɪzéjʃənz pʊ́t ɪn pléjs tə ənʃʊ́r ðɛər ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns sɪ́stəmz ɑr rəspɒ́nsɪbəl, ɛ́θɪkəl, ənd əlájnd wɪð səsájətəl vǽljuwz?",
        "trans_RightAnswer": "AI ɡʌ́vərnəns",
        "trans_WrongAnswers": [
            "məʃíjn lɜ́rnɪŋ ɒptɪmɪzéjʃən",
            "prədɪ́ktɪv æ̀nəlɪ́tɪks",
            "déjtə ɛ̀ndʒɪnɪ́ərɪŋ",
            "ǽlɡərɪ̀ðəmɪk əfɪ́ʃənsij",
            "nʊ́rəl nɛ́twɜ̀rk tréjnɪŋ"
        ],
        "trans_Explanation": "AI ɡʌ́vərnəns rəfɜ́rz tə ðə sɛ́t əv pɒ́lɪsijz, ɡájdlàjnz, ənd fréjmwɜ̀rks ɔ̀rɡənɪzéjʃənz ɪ́mpləmənt tə ówvərsìj ðɛər ɑ̀rtɪfɪ́ʃəl ɪntɛ́lɪdʒəns sɪ́stəmz. ðə ɡówl ɪz tə ənʃʊ́r ðət AI tɛknɒ́lədʒijz ɒ́pərèjt ɛ́θɪkəlij, rəspɒ́nsɪblij, trænspǽrəntlij, ənd ɪn wéjz ðət əlájn wɪð brɔ́dər səsájətəl nɔ́rmz ənd rɛ̀ɡjəléjʃənz. ɡʊ́d AI ɡʌ́vərnəns prətɛ́kts əɡéjnst ʌ̀nɪntɛ́ndɪd hɑ́rm, prəmówts trʌ́st əmʌ́ŋ júwzərz, ənd ənkɜ́rɪdʒɪz ɛ́θɪkəl ɪnəvéjʃən."
    },
    {
        "Question": "What refers to the practice in machine learning where researchers share their data, methods, and code clearly and openly, allowing others to easily replicate their results and verify findings?",
        "RightAnswer": "Reproducible Research",
        "WrongAnswers": [
            "Experimental Validation",
            "Cross-validation Tuning",
            "Algorithm Transparency",
            "Open-source Learning",
            "Collaborative Analysis"
        ],
        "Explanation": "Reproducible Research in machine learning means conducting studies in a way that others can easily reproduce the results. Researchers clearly share all necessary information—such as the original data, analysis methods, and code used—to allow anyone else to confirm or build upon their work. It's like providing a clear recipe with ingredients and instructions, so someone else can bake the same delicious cake! This transparency boosts confidence in the research outcomes and helps accelerate progress in the field.",
        "trans_Question": "wɒt rəfɜ́rz tə ðə prǽktɪs ɪn məʃíjn lɜ́rnɪŋ wɛ́ər ríjsərtʃərz ʃɛ́ər ðɛər déjtə, mɛ́θədz, ənd kówd klɪ́ərlij ənd ówpənlij, əláwɪŋ ʌ́ðərz tə íjzəlij rɛ́plɪkèjt ðɛər rəzʌ́lts ənd vɛ́ərɪfaj fájndɪŋz?",
        "trans_RightAnswer": "rìjprədúwsɪbəl ríjsərtʃ",
        "trans_WrongAnswers": [
            "əkspɛ̀ərɪmɛ́ntəl væ̀lɪdéjʃən",
            "krɔ́s-væ̀lɪdéjʃən túwnɪŋ",
            "ǽlɡərɪ̀ðəm trænspɛ́ərənsij",
            "ówpən-sɔ́rs lɜ́rnɪŋ",
            "kəlǽbərèjtɪv ənǽlɪsɪs"
        ],
        "trans_Explanation": "rìjprədúwsɪbəl ríjsərtʃ ɪn məʃíjn lɜ́rnɪŋ míjnz kəndʌ́ktɪŋ stʌ́dijz ɪn ə wej ðət ʌ́ðərz kən íjzəlij rìjprədúws ðə rəzʌ́lts. ríjsərtʃərz klɪ́ərlij ʃɛ́ər ɔl nɛ́səsɛ̀ərij ɪnfərméjʃən—sʌtʃ æz ðə ərɪ́dʒɪnəl déjtə, ənǽlɪsɪs mɛ́θədz, ənd kówd júwzd—tə əláw ɛ́nijwən ɛ́ls tə kənfɜ́rm ɔr bɪ́ld əpɒ́n ðɛər wɜ́rk. ɪt's lájk prəvájdɪŋ ə klɪ́ər rɛ́sɪpij wɪð ɪnɡríjdijənts ənd ɪnstrʌ́kʃənz, sow sʌ́mwʌ̀n ɛ́ls kən béjk ðə séjm dəlɪ́ʃəs kéjk! ðɪs trænspɛ́ərənsij búwsts kɒ́nfɪdəns ɪn ðə ríjsərtʃ áwtkʌ̀mz ənd hɛ́lps æksɛ́lərèjt prɒ́ɡrɛ̀s ɪn ðə fíjld."
    },
    {
        "Question": "You're exploring popular techniques to build powerful, accurate machine learning models that perform well even with large datasets. One versatile and efficient model, known for its speed, accuracy, and winning performance in data science competitions, uses boosted decision trees. Which model is this?",
        "RightAnswer": "XGBoost",
        "WrongAnswers": [
            "Random Forest",
            "K-Means Clustering",
            "Support Vector Machine",
            "Linear Regression",
            "Naive Bayes Classifier"
        ],
        "Explanation": "XGBoost, or Extreme Gradient Boosting, is a powerful machine learning algorithm famous for its speed, accuracy, and versatility. It creates a robust model by combining (or boosting) multiple simpler decision-tree models, each learning from the mistakes of the previous ones. This reliable approach often delivers excellent predictive performance, making XGBoost a favorite in many data science competitions and real-world applications.",
        "trans_Question": "júwr əksplɔ́rɪŋ pɒ́pjələr tɛkníjks tə bɪ́ld páwərfəl, ǽkjərət məʃíjn lɜ́rnɪŋ mɒ́dəlz ðət pərfɔ́rm wɛ́l íjvən wɪð lɑ́rdʒ déjtəsɛ̀ts. wʌ́n vɜ́rsətajl ənd əfɪ́ʃənt mɒ́dəl, nówn fɔr ɪts spíjd, ǽkjərəsij, ənd wɪ́nɪŋ pərfɔ́rməns ɪn déjtə sájəns kɒ̀mpətɪ́ʃənz, júwsɪz búwstɪd dəsɪ́ʒən tríjz. wɪ́tʃ mɒ́dəl ɪz ðɪs?",
        "trans_RightAnswer": "xgboost",
        "trans_WrongAnswers": [
            "rǽndəm fɔ́rəst",
            "k-míjnz klʌ́stərɪŋ",
            "səpɔ́rt vɛ́ktər məʃíjn",
            "lɪ́nijər rəɡrɛ́ʃən",
            "nàjíjv béjz klǽsɪfajər"
        ],
        "trans_Explanation": "xgboost, ɔr əkstríjm ɡréjdijənt búwstɪŋ, ɪz ə páwərfəl məʃíjn lɜ́rnɪŋ ǽlɡərɪ̀ðəm féjməs fɔr ɪts spíjd, ǽkjərəsij, ənd vɜ̀rsətɪ́lɪtij. ɪt krijéjts ə rowbʌ́st mɒ́dəl baj kəmbájnɪŋ (ɔr búwstɪŋ) mʌ́ltɪpəl sɪ́mplər dəsɪ́ʒən-tríj mɒ́dəlz, ijtʃ lɜ́rnɪŋ frəm ðə mɪstéjks əv ðə príjvijəs wʌ́nz. ðɪs rəlájəbəl əprówtʃ ɔ́fən dəlɪ́vərz ɛ́ksələnt prədɪ́ktɪv pərfɔ́rməns, méjkɪŋ xgboost ə féjvərɪt ɪn mɛ́nij déjtə sájəns kɒ̀mpətɪ́ʃənz ənd ríjəl-wɜ́rld æ̀plɪkéjʃənz."
    },
    {
        "Question": "Imagine you want a recommendation system that effectively handles both memorization (remembering specific patterns or popular items) and generalization (predicting user preferences based on broad features). What approach combines simple memorizing models with more complex predictive models to achieve both goals simultaneously?",
        "RightAnswer": "Wide and Deep Learning",
        "WrongAnswers": [
            "Gradient Boosted Trees",
            "Support Vector Machines",
            "Principal Component Analysis",
            "K-Nearest Neighbors Model",
            "Long Short-Term Memory Networks"
        ],
        "Explanation": "Wide and Deep Learning is a machine learning technique that combines the 'wide' part (a simpler model capable of memorizing frequent patterns in the data) with the 'deep' part (a more complex neural network that identifies underlying feature relationships). This combination allows the model to effectively memorize known interactions while also generalizing well to new, unseen examples—ideal for tasks like recommendation systems.",
        "trans_Question": "ɪmǽdʒɪn juw wɒ́nt ə rɛ̀kəməndéjʃən sɪ́stəm ðət əfɛ́ktɪvlij hǽndəlz bówθ mɛmɔ̀rɪzéjʃən (rəmɛ́mbərɪŋ spəsɪ́fɪk pǽtərnz ɔr pɒ́pjələr ájtəmz) ənd dʒɛ̀nərəlɪzéjʃən (prədɪ́ktɪŋ júwzər prɛ́fərənsɪz béjst ɒn brɔ́d fíjtʃərz). wɒt əprówtʃ kəmbájnz sɪ́mpəl mɛ́məràjzɪŋ mɒ́dəlz wɪð mɔr kɒ́mplɛks prədɪ́ktɪv mɒ́dəlz tə ətʃíjv bówθ ɡówlz sàjməltéjnijəslij?",
        "trans_RightAnswer": "wájd ənd díjp lɜ́rnɪŋ",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪd tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "prɪ́nsɪpəl kəmpównənt ənǽlɪsɪs",
            "k-nɪ́ərəst néjbərz mɒ́dəl",
            "lɔ́ŋ ʃɔ́rt-tɜ́rm mɛ́mərij nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "wájd ənd díjp lɜ́rnɪŋ ɪz ə məʃíjn lɜ́rnɪŋ tɛkníjk ðət kəmbájnz ðə 'wájd' pɑ́rt (ə sɪ́mplər mɒ́dəl kéjpəbəl əv mɛ́məràjzɪŋ fríjkwənt pǽtərnz ɪn ðə déjtə) wɪð ðə 'díjp' pɑ́rt (ə mɔr kɒ́mplɛks nʊ́rəl nɛ́twɜ̀rk ðət ajdɛ́ntɪfàjz ʌ̀ndərlájɪŋ fíjtʃər rəléjʃənʃɪ̀ps). ðɪs kɒ̀mbɪnéjʃən əláwz ðə mɒ́dəl tə əfɛ́ktɪvlij mɛ́məràjz nówn ɪ̀ntərǽkʃənz wájl ɔ́lsow dʒɛ́nərəlàjzɪŋ wɛ́l tə núw, ʌ̀nsíjn əɡzǽmpəlz—ajdíjəl fɔr tǽsks lájk rɛ̀kəməndéjʃən sɪ́stəmz."
    },
    {
        "Question": "Which machine learning technique allows you to transform your ordinary vacation photo to creatively mimic art styles like Van Gogh's \"Starry Night\" or Picasso's abstract paintings?",
        "RightAnswer": "Neural Style Transfer",
        "WrongAnswers": [
            "Convolutional Cloning",
            "Gradient Blending",
            "Deep Image Compression",
            "Autoencoder Reconstruction",
            "Generative Adversarial Filtering"
        ],
        "Explanation": "Neural Style Transfer is a fun and creative machine learning method that allows you to blend the content of one image with the artistic style of another. For example, you could take a simple photograph from vacation and apply the vivid brushstrokes of a Van Gogh painting, transforming it into a vibrant, artistic masterpiece using neural networks. Essentially, it's like giving your everyday snapshots famous artistic flair using AI!",
        "trans_Question": "wɪ́tʃ məʃíjn lɜ́rnɪŋ tɛkníjk əláwz juw tə trǽnsfɔrm jɔr ɔ́rdɪnɛ̀ərij vejkéjʃən fówtòw tə krijéjtɪvlij mɪ́mɪk ɑ́rt stájlz lájk vǽn ɡów'z \"stɑ́rìj nájt\" ɔr pɪkɒ́sow'z ǽbstræ̀kt péjntɪŋz?",
        "trans_RightAnswer": "nʊ́rəl stájl trǽnsfər",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl klównɪŋ",
            "ɡréjdijənt blɛ́ndɪŋ",
            "díjp ɪ́mɪdʒ kəmprɛ́ʃən",
            "ɔ̀towənkówdər rìjkənstrʌ́kʃən",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl fɪ́ltərɪŋ"
        ],
        "trans_Explanation": "nʊ́rəl stájl trǽnsfər ɪz ə fʌ́n ənd krijéjtɪv məʃíjn lɜ́rnɪŋ mɛ́θəd ðət əláwz juw tə blɛ́nd ðə kɒ́ntənt əv wʌ́n ɪ́mɪdʒ wɪð ðə ɑrtɪ́stɪk stájl əv ənʌ́ðər. fɔr əɡzǽmpəl, juw kʊ́d téjk ə sɪ́mpəl fówtəɡræ̀f frəm vejkéjʃən ənd əpláj ðə vɪ́vɪd brʌ́ʃstròwks əv ə vǽn ɡów péjntɪŋ, trænsfɔ́rmɪŋ ɪt ɪntə ə vájbrənt, ɑrtɪ́stɪk mǽstərpìjs júwzɪŋ nʊ́rəl nɛ́twɜ̀rks. əsɛ́nʃəlij, ɪt's lájk ɡɪ́vɪŋ jɔr ɛ́vrijdéj snǽpʃɒ̀ts féjməs ɑrtɪ́stɪk flɛ́ər júwzɪŋ AI!"
    },
    {
        "Question": "What technique in machine learning helps visualize high-dimensional data by grouping similar data points together on a two-dimensional grid, making it easy to spot patterns and clusters?",
        "RightAnswer": "Self-Organizing Maps",
        "WrongAnswers": [
            "Linear Regression",
            "Convolutional Networks",
            "Random Forests",
            "Recurrent Neural Networks",
            "Support Vector Machines"
        ],
        "Explanation": "Self-Organizing Maps (often called SOMs) are a neat way for computers to simplify a complicated set of data. Imagine having tons of information points scattered in high-dimensional space, making it tough to understand. SOMs bring these points down onto a flat grid, grouping similar items close together and showing clear patterns or clusters. It's like organizing a messy room by neatly placing related items close to one another so they’re easy to see and understand!",
        "trans_Question": "wɒt tɛkníjk ɪn məʃíjn lɜ́rnɪŋ hɛ́lps vɪ́ʒwəlàjz háj-dajmɛ́nʃənəl déjtə baj ɡrúwpɪŋ sɪ́mɪlər déjtə pɔ́jnts təɡɛ́ðər ɒn ə túw-dajmɛ́nʃənəl ɡrɪ́d, méjkɪŋ ɪt íjzij tə spɒ́t pǽtərnz ənd klʌ́stərz?",
        "trans_RightAnswer": "sɛ́lf-ɔ́rɡənàjzɪŋ mǽps",
        "trans_WrongAnswers": [
            "lɪ́nijər rəɡrɛ́ʃən",
            "kənvəlúwʃənəl nɛ́twɜ̀rks",
            "rǽndəm fɔ́rəsts",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "səpɔ́rt vɛ́ktər məʃíjnz"
        ],
        "trans_Explanation": "sɛ́lf-ɔ́rɡənàjzɪŋ mǽps (ɔ́fən kɔ́ld SOMs) ɑr ə níjt wej fɔr kəmpjúwtərz tə sɪ́mpləfaj ə kɒ́mplɪkèjtɪd sɛ́t əv déjtə. ɪmǽdʒɪn hǽvɪŋ tʌ́nz əv ɪnfərméjʃən pɔ́jnts skǽtərd ɪn háj-dajmɛ́nʃənəl spéjs, méjkɪŋ ɪt tʌ́f tə ʌ̀ndərstǽnd. SOMs brɪ́ŋ ðijz pɔ́jnts dawn ɒntə ə flǽt ɡrɪ́d, ɡrúwpɪŋ sɪ́mɪlər ájtəmz klóws təɡɛ́ðər ənd ʃówɪŋ klɪ́ər pǽtərnz ɔr klʌ́stərz. ɪt's lájk ɔ́rɡənàjzɪŋ ə mɛ́sij rúwm baj níjtlij pléjsɪŋ rəléjtɪd ájtəmz klóws tə wʌ́n ənʌ́ðər sow ðɛər íjzij tə síj ənd ʌ̀ndərstǽnd!"
    },
    {
        "Question": "In machine learning, which type of neural network takes inspiration directly from how biological neurons communicate by sending brief impulses or spikes, aiming to mimic better the efficiency and dynamics of the human brain?",
        "RightAnswer": "Spiking Neural Networks",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Recurrent Neural Networks",
            "Fully Connected Neural Networks",
            "Generative Adversarial Networks",
            "Transformer Networks"
        ],
        "Explanation": "Spiking Neural Networks, also known as SNNs, are a unique type of artificial neural network explicitly designed to imitate the way real neurons in our brains function. Instead of using continuous values, these networks use brief pulses known as 'spikes' to convey information. This approach makes them exciting because they operate more efficiently (warning: less energy use!) and more closely match how biological brains handle complex, dynamic activity. This can potentially lead to breakthroughs in how machines learn, making them more adaptive and better suited for tasks like real-time decision making or robotics.",
        "trans_Question": "ɪn məʃíjn lɜ́rnɪŋ, wɪ́tʃ tájp əv nʊ́rəl nɛ́twɜ̀rk téjks ɪnspəréjʃən dɪərɛ́klij frəm háw bàjəlɒ́dʒɪkəl nʊ́rɒnz kəmjúwnɪkèjt baj sɛ́ndɪŋ bríjf ɪ́mpəlsɪz ɔr spájks, éjmɪŋ tə mɪ́mɪk bɛ́tər ðə əfɪ́ʃənsij ənd dajnǽmɪks əv ðə hjúwmən bréjn?",
        "trans_RightAnswer": "spájkɪŋ nʊ́rəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "fʊ́lij kənɛ́ktɪd nʊ́rəl nɛ́twɜ̀rks",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
            "trænsfɔ́rmər nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "spájkɪŋ nʊ́rəl nɛ́twɜ̀rks, ɔ́lsow nówn æz ɛs, ɑr ə juwnɪ́k tájp əv ɑ̀rtɪfɪ́ʃəl nʊ́rəl nɛ́twɜ̀rk əksplɪ́sɪtlij dəzájnd tə ɪ́mɪtèjt ðə wej ríjəl nʊ́rɒnz ɪn awər bréjnz fʌ́ŋkʃən. ɪnstɛ́d əv júwzɪŋ kəntɪ́njuwəs vǽljuwz, ðijz nɛ́twɜ̀rks juwz bríjf pʌ́lsɪz nówn æz 'spájks' tə kənvéj ɪnfərméjʃən. ðɪs əprówtʃ méjks ðɛm əksájtɪŋ bəkɒ́z ðej ɒ́pərèjt mɔr əfɪ́ʃəntlij (wɔ́rnɪŋ: lɛ́s ɛ́nərdʒij juwz!) ənd mɔr klówslij mǽtʃ háw bàjəlɒ́dʒɪkəl bréjnz hǽndəl kɒ́mplɛks, dajnǽmɪk æktɪ́vɪtij. ðɪs kən pətɛ́nʃəlij líjd tə bréjkθrùwz ɪn háw məʃíjnz lɜ́rn, méjkɪŋ ðɛm mɔr ədǽptɪv ənd bɛ́tər súwtɪd fɔr tǽsks lájk ríjəl-tájm dəsɪ́ʒən méjkɪŋ ɔr ròwbɒ́tɪks."
    },
    {
        "Question": "Imagine a special type of neural network that simplifies complex calculations by representing its internal parameters using just two possible values (like -1 and +1) rather than many complicated numbers. This approach significantly reduces memory usage and can help AI models run faster on small devices. What's this type of neural network called?",
        "RightAnswer": "Binary Neural Networks",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Recurrent Neural Networks",
            "Deep Belief Networks",
            "Generative Adversarial Networks",
            "Autoencoder Networks"
        ],
        "Explanation": "Binary Neural Networks are a clever type of artificial neural network designed to be extremely lightweight by restricting their internal connections and weights to just two possible values, typically -1 and +1. Because they only use these two values rather than continuous numbers, calculations become faster, simpler, and require far less memory. This makes Binary Neural Networks especially useful for deploying AI on small devices like smartphones or tiny gadgets, where computing power and storage space are limited.",
        "trans_Question": "ɪmǽdʒɪn ə spɛ́ʃəl tájp əv nʊ́rəl nɛ́twɜ̀rk ðət sɪ́mpləfajz kɒ́mplɛks kæ̀lkjəléjʃənz baj rɛ̀prəzɛ́ntɪŋ ɪts ɪ̀ntɜ́rnəl pərǽmətərz júwzɪŋ dʒəst túw pɒ́sɪbəl vǽljuwz (lájk -1 ənd +1) rǽðər ðʌn mɛ́nij kɒ́mplɪkèjtɪd nʌ́mbərz. ðɪs əprówtʃ sɪɡnɪ́fɪkəntlij rədjúwsɪz mɛ́mərij júwsɪdʒ ənd kən hɛ́lp AI mɒ́dəlz rʌ́n fǽstər ɒn smɔ́l dəvájsɪz. wɒt's ðɪs tájp əv nʊ́rəl nɛ́twɜ̀rk kɔ́ld?",
        "trans_RightAnswer": "bájnərij nʊ́rəl nɛ́twɜ̀rks",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks",
            "díjp bəlíjf nɛ́twɜ̀rks",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
            "ɔ̀towənkówdər nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "bájnərij nʊ́rəl nɛ́twɜ̀rks ɑr ə klɛ́vər tájp əv ɑ̀rtɪfɪ́ʃəl nʊ́rəl nɛ́twɜ̀rk dəzájnd tə bij əkstríjmlij lájtwéjt baj rəstrɪ́ktɪŋ ðɛər ɪ̀ntɜ́rnəl kənɛ́kʃənz ənd wéjts tə dʒəst túw pɒ́sɪbəl vǽljuwz, tɪ́pɪkəlij -1 ənd +1. bəkɒ́z ðej ównlij juwz ðijz túw vǽljuwz rǽðər ðʌn kəntɪ́njuwəs nʌ́mbərz, kæ̀lkjəléjʃənz bəkʌ́m fǽstər, sɪ́mplər, ənd rəkwájər fɑ́r lɛ́s mɛ́mərij. ðɪs méjks bájnərij nʊ́rəl nɛ́twɜ̀rks əspɛ́ʃəlij júwsfəl fɔr dəplɔ́jɪŋ AI ɒn smɔ́l dəvájsɪz lájk smɑ́rtfòwnz ɔr tájnij ɡǽdʒəts, wɛ́ər kəmpjúwtɪŋ páwər ənd stɔ́rɪdʒ spéjs ɑr lɪ́mɪtɪd."
    },
    {
        "Question": "In the Transformer architecture used in many modern AI models, what mechanism allows the model to pay attention to various parts of the input simultaneously, helping it capture different relationships within data all at once?",
        "RightAnswer": "Multi-Head Attention",
        "WrongAnswers": [
            "Gradient Descent Optimization",
            "Batch Normalization",
            "Convolutional Layer",
            "Dropout Regularization",
            "Activation Function"
        ],
        "Explanation": "Multi-Head Attention is like having multiple brains working at once, each focused on different aspects of the information. Imagine you're watching a complex movie: one part of your mind focuses on character dialogue, another tracks plot twists, and yet another observes emotional cues. Similarly, multi-head attention lets a model simultaneously focus on different parts of the input data, helping it understand context and relationships better. This approach makes AI-powered language models more accurate, intuitive, and powerful.",
        "trans_Question": "ɪn ðə trænsfɔ́rmər ɑ́rkɪtɛ̀ktʃər júwzd ɪn mɛ́nij mɒ́dərn AI mɒ́dəlz, wɒt mɛ́kənɪzəm əláwz ðə mɒ́dəl tə péj ətɛ́nʃən tə vɛ́ərijəs pɑ́rts əv ðə ɪ́npʊ̀t sàjməltéjnijəslij, hɛ́lpɪŋ ɪt kǽptʃər dɪ́fərənt rəléjʃənʃɪ̀ps wɪðɪ́n déjtə ɔl æt wʌ́ns?",
        "trans_RightAnswer": "mʌ́ltij-hɛ́d ətɛ́nʃən",
        "trans_WrongAnswers": [
            "ɡréjdijənt dəsɛ́nt ɒptɪmɪzéjʃən",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "kənvəlúwʃənəl léjər",
            "drɒ́pàwt rèɡjəlɛ̀ərɪzéjʃən",
            "æ̀ktɪvéjʃən fʌ́ŋkʃən"
        ],
        "trans_Explanation": "mʌ́ltij-hɛ́d ətɛ́nʃən ɪz lájk hǽvɪŋ mʌ́ltɪpəl bréjnz wɜ́rkɪŋ æt wʌ́ns, ijtʃ fówkəst ɒn dɪ́fərənt ǽspɛkts əv ðə ɪnfərméjʃən. ɪmǽdʒɪn júwr wɒ́tʃɪŋ ə kɒ́mplɛks múwvij: wʌ́n pɑ́rt əv jɔr májnd fówkəsɪz ɒn kǽrəktər dájəlɔ̀ɡ, ənʌ́ðər trǽks plɒ́t twɪ́sts, ənd jɛt ənʌ́ðər əbzɜ́rvz əmòwʃənəl kjúwz. sɪ́mɪlərlij, mʌ́ltij-hɛ́d ətɛ́nʃən lɛts ə mɒ́dəl sàjməltéjnijəslij fówkəs ɒn dɪ́fərənt pɑ́rts əv ðə ɪ́npʊ̀t déjtə, hɛ́lpɪŋ ɪt ʌ̀ndərstǽnd kɒ́ntɛkst ənd rəléjʃənʃɪ̀ps bɛ́tər. ðɪs əprówtʃ méjks áj-páwərd lǽŋɡwədʒ mɒ́dəlz mɔr ǽkjərət, ɪntúwɪtɪv, ənd páwərfəl."
    },
    {
        "Question": "In natural language processing tasks, Transformer-based networks handle sequences of text but initially don't know the order of words. Which technique helps these models understand the order in which words or tokens appear?",
        "RightAnswer": "Positional Encoding",
        "WrongAnswers": [
            "Attention Masking",
            "Batch Normalization",
            "Feature Extraction",
            "Gradient Clipping",
            "Activation Function"
        ],
        "Explanation": "Think of positional encoding as tagging each word or token with a unique marker, signaling its exact position within a sequence. Transformers, powerful machine learning models, don't inherently grasp the order of words. Positional encoding helps them understand context by embedding positional information directly within the input data. This enables the model to differentiate similar words or tokens depending on where they're placed in a sentence, significantly enhancing its grasp of context and meaning.",
        "trans_Question": "ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ tǽsks, trænsfɔ́rmər-béjst nɛ́twɜ̀rks hǽndəl síjkwənsɪz əv tɛ́kst bʌt ɪnɪ́ʃəlij dównt nów ðə ɔ́rdər əv wɜ́rdz. wɪ́tʃ tɛkníjk hɛ́lps ðijz mɒ́dəlz ʌ̀ndərstǽnd ðə ɔ́rdər ɪn wɪ́tʃ wɜ́rdz ɔr tówkənz əpɪ́ər?",
        "trans_RightAnswer": "pəzɪʃʌ́nəl ɛnkówdɪŋ",
        "trans_WrongAnswers": [
            "ətɛ́nʃən mǽskɪŋ",
            "bǽtʃ nɔ̀rməlɪzéjʃən",
            "fíjtʃər əkstrǽkʃən",
            "ɡréjdijənt klɪ́pɪŋ",
            "æ̀ktɪvéjʃən fʌ́ŋkʃən"
        ],
        "trans_Explanation": "θɪ́ŋk əv pəzɪʃʌ́nəl ɛnkówdɪŋ æz tǽɡɪŋ ijtʃ wɜ́rd ɔr tówkən wɪð ə juwnɪ́k mɑ́rkər, sɪ́ɡnəlɪŋ ɪts əɡzǽkt pəzɪ́ʃən wɪðɪ́n ə síjkwəns. trænsfɔ́rmərz, páwərfəl məʃíjn lɜ́rnɪŋ mɒ́dəlz, dównt ɪnhɛ́ərəntlij ɡrǽsp ðə ɔ́rdər əv wɜ́rdz. pəzɪʃʌ́nəl ɛnkówdɪŋ hɛ́lps ðɛm ʌ̀ndərstǽnd kɒ́ntɛkst baj ɛmbɛ́dɪŋ pəzɪʃʌ́nəl ɪnfərméjʃən dɪərɛ́klij wɪðɪ́n ðə ɪ́npʊ̀t déjtə. ðɪs ɛnéjbəlz ðə mɒ́dəl tə dɪ̀fərɛ́nʃijèjt sɪ́mɪlər wɜ́rdz ɔr tówkənz dəpɛ́ndɪŋ ɒn wɛ́ər ðɛ́ər pléjst ɪn ə sɛ́ntəns, sɪɡnɪ́fɪkəntlij ɛnhǽnsɪŋ ɪts ɡrǽsp əv kɒ́ntɛkst ənd míjnɪŋ."
    },
    {
        "Question": "What machine learning model uses attention-based mechanisms, initially popular in natural language processing, to effectively analyze images by breaking them into smaller patches and treating each patch like a word in a sentence?",
        "RightAnswer": "Vision Transformers",
        "WrongAnswers": [
            "Convolutional Neural Networks",
            "Generative Adversarial Networks",
            "Decision Trees",
            "Support Vector Machines",
            "Recurrent Neural Networks"
        ],
        "Explanation": "Vision Transformers, or ViTs for short, cleverly adapt ideas originally used in language models to image analysis. Instead of looking at an image as a whole, ViTs divide it into smaller rectangular pieces or patches—similar to how sentences are divided into words. Then, they analyze the relationships and importance between these patches using attention mechanisms, enabling them to 'pay attention' to the most relevant image parts. This has allowed Vision Transformers to perform amazingly well on tasks involving image recognition and classification, matching or even surpassing traditional convolutional methods.",
        "trans_Question": "wɒt məʃíjn lɜ́rnɪŋ mɒ́dəl júwsɪz ətɛ́nʃən-béjst mɛ́kənɪzəmz, ɪnɪ́ʃəlij pɒ́pjələr ɪn nǽtʃərəl lǽŋɡwədʒ prɒ́sɛsɪŋ, tə əfɛ́ktɪvlij ǽnəlàjz ɪ́mɪdʒɪz baj bréjkɪŋ ðɛm ɪntə smɔ́lər pǽtʃɪz ənd tríjtɪŋ ijtʃ pǽtʃ lájk ə wɜ́rd ɪn ə sɛ́ntəns?",
        "trans_RightAnswer": "vɪ́ʒən trænsfɔ́rmərz",
        "trans_WrongAnswers": [
            "kənvəlúwʃənəl nʊ́rəl nɛ́twɜ̀rks",
            "dʒɛ́nərətɪv æ̀dvərsɛ́ərijəl nɛ́twɜ̀rks",
            "dəsɪ́ʒən tríjz",
            "səpɔ́rt vɛ́ktər məʃíjnz",
            "rəkɜ́rənt nʊ́rəl nɛ́twɜ̀rks"
        ],
        "trans_Explanation": "vɪ́ʒən trænsfɔ́rmərz, ɔr vɪts fɔr ʃɔ́rt, klɛ́vərlij ədǽpt ajdíjəz ərɪ́dʒɪnəlij júwzd ɪn lǽŋɡwədʒ mɒ́dəlz tə ɪ́mɪdʒ ənǽlɪsɪs. ɪnstɛ́d əv lʊ́kɪŋ æt ən ɪ́mɪdʒ æz ə hówl, vɪts dɪvájd ɪt ɪntə smɔ́lər rɛktǽŋɡjələr píjsɪz ɔr pǽtʃɪz—sɪ́mɪlər tə háw sɛ́ntənsɪz ɑr dɪvájdɪd ɪntə wɜ́rdz. ðɛn, ðej ǽnəlàjz ðə rəléjʃənʃɪ̀ps ənd ɪmpɔ́rtəns bijtwíjn ðijz pǽtʃɪz júwzɪŋ ətɛ́nʃən mɛ́kənɪzəmz, ɛnéjbəlɪŋ ðɛm tə 'péj ətɛ́nʃən' tə ðə mówst rɛ́ləvənt ɪ́mɪdʒ pɑ́rts. ðɪs həz əláwd vɪ́ʒən trænsfɔ́rmərz tə pərfɔ́rm əméjzɪŋlij wɛ́l ɒn tǽsks ɪnvɒ́lvɪŋ ɪ́mɪdʒ rɛ̀kəɡnɪ́ʃən ənd klæ̀sɪfɪkéjʃən, mǽtʃɪŋ ɔr íjvən sərpǽsɪŋ trədɪ́ʃənəl kənvəlúwʃənəl mɛ́θədz."
    },
    {
        "Question": "When training a machine learning model, this term describes one full pass where the model sees and learns from the entire training dataset. What is this term called?",
        "RightAnswer": "Epochs",
        "WrongAnswers": [
            "Iterations",
            "Batch size",
            "Learning rate",
            "Validation points",
            "Hyperparameters"
        ],
        "Explanation": "Think of an epoch as one complete 'tour' through your whole training data—like finishing the entire playlist once through. So if you're training your model and say it goes through 10 epochs, it means it has looked at the entire dataset 10 full times, each time fine-tuning its understanding a bit better.",
        "trans_Question": "wɛ́n tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, ðɪs tɜ́rm dəskrájbz wʌ́n fʊ́l pǽs wɛ́ər ðə mɒ́dəl síjz ənd lɜ́rnz frəm ðə əntájər tréjnɪŋ déjtəsɛ̀t. wɒt ɪz ðɪs tɜ́rm kɔ́ld?",
        "trans_RightAnswer": "ɛ́pəks",
        "trans_WrongAnswers": [
            "ɪ̀təréjʃənz",
            "bǽtʃ sájz",
            "lɜ́rnɪŋ réjt",
            "væ̀lɪdéjʃən pɔ́jnts",
            "hàjpərpǽrəmətərz"
        ],
        "trans_Explanation": "θɪ́ŋk əv ən ɛ́pək æz wʌ́n kəmplíjt 'tʊ́r' θrúw jɔr hówl tréjnɪŋ déjtə—lájk fɪ́nɪʃɪŋ ðə əntájər pléjlɪst wʌ́ns θrúw. sow ɪf júwr tréjnɪŋ jɔr mɒ́dəl ənd séj ɪt ɡówz θrúw 10 ɛ́pəks, ɪt míjnz ɪt həz lʊ́kt æt ðə əntájər déjtəsɛ̀t 10 fʊ́l tájmz, ijtʃ tájm fájn-túwnɪŋ ɪts ʌ̀ndərstǽndɪŋ ə bɪ́t bɛ́tər."
    },
    {
        "Question": "When training a machine learning model, it often goes through multiple cycles of refining its predictions and reducing errors step by step. These repeated cycles are known as what?",
        "RightAnswer": "Iterations",
        "WrongAnswers": [
            "Correlations",
            "Regularizations",
            "Activations",
            "Transformations",
            "Optimizations"
        ],
        "Explanation": "Iterations refer to each cycle or repeated step that the learning process goes through to gradually improve the accuracy and effectiveness of a machine learning model. Think of it as practicing a skill multiple times; each repetition lets you learn from mistakes and gradually become better. Similarly, in machine learning, each iteration is a chance for the model to learn from its previous attempts, refining itself to become smarter and more accurate.",
        "trans_Question": "wɛ́n tréjnɪŋ ə məʃíjn lɜ́rnɪŋ mɒ́dəl, ɪt ɔ́fən ɡówz θrúw mʌ́ltɪpəl sájkəlz əv rəfájnɪŋ ɪts prədɪ́kʃənz ənd rədjúwsɪŋ ɛ́ərərz stɛ́p baj stɛ́p. ðijz rəpíjtɪd sájkəlz ɑr nówn æz wɒt?",
        "trans_RightAnswer": "ɪ̀təréjʃənz",
        "trans_WrongAnswers": [
            "kɔ̀rəléjʃənz",
            "rɛ̀ɡjələrʌɪzéjʃənz",
            "æ̀ktɪvéjʃənz",
            "træ̀nsfərméjʃənz",
            "ɒ̀ptɪmɪzéjʃənz"
        ],
        "trans_Explanation": "ɪ̀təréjʃənz rəfɜ́r tə ijtʃ sájkəl ɔr rəpíjtɪd stɛ́p ðət ðə lɜ́rnɪŋ prɒ́sɛs ɡówz θrúw tə ɡrǽdʒuwəlij ɪmprúwv ðə ǽkjərəsij ənd əfɛ́ktɪvnəs əv ə məʃíjn lɜ́rnɪŋ mɒ́dəl. θɪ́ŋk əv ɪt æz prǽktɪsɪŋ ə skɪ́l mʌ́ltɪpəl tájmz; ijtʃ rɛ̀pətɪ́ʃən lɛts juw lɜ́rn frəm mɪstéjks ənd ɡrǽdʒuwəlij bəkʌ́m bɛ́tər. sɪ́mɪlərlij, ɪn məʃíjn lɜ́rnɪŋ, ijtʃ ɪ̀təréjʃən ɪz ə tʃǽns fɔr ðə mɒ́dəl tə lɜ́rn frəm ɪts príjvijəs ətɛ́mpts, rəfájnɪŋ ɪtsɛ́lf tə bəkʌ́m smɑ́rtər ənd mɔr ǽkjərət."
    },
    {
        "Question": "You've built two machine learning models and want to find out which one best explains your data. What statistical method helps you quantify how much more likely one model is compared to the other, based on their probabilities?",
        "RightAnswer": "Bayes Factor Analysis",
        "WrongAnswers": [
            "Gradient Boosting Analysis",
            "Confusion Matrix Evaluation",
            "ROC Curve Analysis",
            "Variance Inflation Factor",
            "Markov Chain Monte Carlo"
        ],
        "Explanation": "Bayes Factor Analysis is a powerful technique that compares two models based on their probabilities given the observed data. Imagine you're a detective weighing two theories; Bayes Factor helps you determine precisely how much more or less likely one theory (model) is compared to another, using the evidence (your data). This approach helps you make informed choices about which model is superior in a clear and intuitive way.",
        "trans_Question": "júwv bɪ́lt túw məʃíjn lɜ́rnɪŋ mɒ́dəlz ənd wɒ́nt tə fájnd awt wɪ́tʃ wʌ́n bɛ́st əkspléjnz jɔr déjtə. wɒt stətɪ́stɪkəl mɛ́θəd hɛ́lps juw kwɑ́ntᵻfàj háw mʌtʃ mɔr lájklij wʌ́n mɒ́dəl ɪz kəmpɛ́ərd tə ðə ʌ́ðər, béjst ɒn ðɛər prɒ̀bəbɪ́lɪtìjz?",
        "trans_RightAnswer": "béjz fǽktər ənǽlɪsɪs",
        "trans_WrongAnswers": [
            "ɡréjdijənt búwstɪŋ ənǽlɪsɪs",
            "kənfjúwʒən méjtrɪks əvæ̀ljuwéjʃən",
            "ROC kɜ́rv ənǽlɪsɪs",
            "vɛ́ərijəns ɪnfléjʃən fǽktər",
            "mɑ́rkowv tʃéjn mɒ́ntij kɑ́rlow"
        ],
        "trans_Explanation": "béjz fǽktər ənǽlɪsɪs ɪz ə páwərfəl tɛkníjk ðət kəmpɛ́ərz túw mɒ́dəlz béjst ɒn ðɛər prɒ̀bəbɪ́lɪtìjz ɡɪ́vən ðə əbzɜ́rvd déjtə. ɪmǽdʒɪn júwr ə dətɛ́ktɪv wéjɪŋ túw θíjərijz; béjz fǽktər hɛ́lps juw dətɜ́rmɪn prəsájslij háw mʌtʃ mɔr ɔr lɛ́s lájklij wʌ́n θíjərij (mɒ́dəl) ɪz kəmpɛ́ərd tə ənʌ́ðər, júwzɪŋ ðə ɛ́vɪdəns (jɔr déjtə). ðɪs əprówtʃ hɛ́lps juw méjk ɪnfɔ́rmd tʃɔ́jsɪz əbawt wɪ́tʃ mɒ́dəl ɪz suwpɪ́ərijər ɪn ə klɪ́ər ənd ɪntúwɪtɪv wej."
    }
]